{"Title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes for Traffic Flow", "Authors": "Danielle C Maddix, Nadim Saad, Yuyang Wang", "Abstract": "  The transport of traffic flow can be modeled by the advection equation. Finite difference and finite volumes methods have been used to numerically solve this hyperbolic equation on a mesh. Advection has also been modeled discretely on directed graphs using the graph advection operator [4, 18]. In this paper, we first show that we can reformulate this graph advection operator as a finite difference scheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model that incorporates the dynamics of this graph advection operator into the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic flow and its uncertainty as an advective process on a directed graph.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00001", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Advection on Directed Graphs using\nMat\u00e9rn Gaussian Processes for Traffic Flow\n\nDanielle C. Maddix\nAmazon Research\n\n2795 Augustine Dr.\nSanta Clara, CA 95054\ndmmaddix@amazon.com\n\nNadim Saad\nStanford University\n\n450 Serra Mall\nStanford, CA 94305\n\nnsaad31@stanford.edu\n\nYuyang Wang\nAmazon Research\n\n2795 Augustine Dr.\nSanta Clara, CA 95054\nyuyawang@amazon.com\n\nAbstract\n\nThe transport of traffic flow can be modeled by the advection equation. Finite\ndifference and finite volumes methods have been used to numerically solve this\nhyperbolic equation on a mesh. Advection has also been modeled discretely on\ndirected graphs using the graph advection operator [4, 18]. In this paper, we first\nshow that we can reformulate this graph advection operator as a finite difference\nscheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process\n(DGAMGP) model that incorporates the dynamics of this graph advection operator\ninto the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic\nflow and its uncertainty as an advective process on a directed graph.\n\n1 Introduction\n\nThe continuous linear advection equation models the flow of a scalar concentration along a vector\nfield. The solutions to this hyperbolic partial differential equation may develop discontinuities or\nshocks over time depending on the initial condition. These shocks can model the formation of traffic\njams, and their propagation along a road [20]. Figure 1 illustrates an example, where initially the\nfirst half of the road is 70% occupied with cars, and the second half of the road is empty. The traffic\npropagates to the right until the whole road is 70% occupied. Classical methods, such as finite\ndifferences and finite volumes, have been used to predict the flow of traffic along a road [14, 20].\nThese classical numerical methods do not incorporate any randomness into the model, and can be\nlimited in incorporating the uncertainty among different driver\u2019s behaviors [6].\n\nFigure 1: Propagation of cars on a road using an\nadvection process.\n\nGaussian processes (GPs) [19] can learn unknown\nfunctions that allow use of prior information\nabout their properties and for uncertainty model-\ning. K\u00fcper and Waldherr [9] propose the Gaussian\nProcess Kalman Filter (GPKF) method to simu-\nlate spatiotemporal models, and test on the ad-\nvection equation. Raissi et al. [17] train GPs on\ndata to learn the underlying physics of non-linear\nadvection-diffusion equations. Additional physics-\nbased machine learning models [2] use the Mat\u00e9rn\ncovariance function given below:\n\nu \u223c N\n(\n0,\n(2\u03bd\n\u03ba2\n\n+ \u2206\n)\u2212\u03bd)\n\n, (1)\n\nwhere u denotes an unknown function, \u03bd <\u221e, \u03ba <\u221e and \u2206 denotes the laplacian [1]. The Mat\u00e9rn\n\nFourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021).\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n1v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 1\n\n4 \nD\n\nec\n 2\n\n02\n1\n\n\n\nkernel captures physical processes due to its finite differentiability, and is also commonly used to\ndefine distances between two points that are d units distant from each other [2]. Perdikaris and\nKarniadakis [16] propose training joint Mat\u00e9rn GPs to model space-fractional differential equations,\nin which the advection-diffusion equation is a special case.\n\nRecent works including [22] have studied solving partial differential equation (PDEs) on graphs.\nChapman and Mesbahi [4], Rak [18] propose discrete advection and consensus operators to model\nadvection and diffusion flows, respectively on directed graphs. Ho\u0161ek and Volek [8] study the\nadvection-diffusion equation on graphs using this discrete advection operator, and show that finite vol-\nume numerical discretizations can be reformulated as equations on graphs resulting in a corresponding\nmaximum principle for this operator. Additional works have also looked at combining scientific\ncomputing and machine learning on graphs for spatiotemporal traffic modeling [11]. Chamberlain\net al. [3] propose the Graph Neural Diffusion (GRAND) method, which combines traditional ODE\nsolvers with graph neural networks (GNNs) to model diffusion on a undirected graph. Borovitskiy\net al. [2] propose to replace the continuous laplacian \u2206 in (1) with the discrete graph laplacian\noperator L to model diffusion on undirected graphs, which can be limited for traffic modeling.\n\nThe goal of this paper is two-fold: to develop a model that effectively models traffic flow as an\nadvective process on a directed graph and its uncertainty. We propose a novel method, Directed Graph\nAdvection Mat\u00e9rn Gaussian Process (DGAMGP) that uses a symmetric positive definite variant of\nthe graph advection operator Ladv as a covariance matrix in the Mat\u00e9rn Gaussian Process. We use the\nsquare of the singular values of Ladv to model the advection dynamics, and train a Mat\u00e9rn Gaussian\nProcess to model the uncertainty. We also show the connection between consistent finite difference\nstencils for solving the linear advection equation and the graph advection operator. Our novel linkage\nhelps improve the understanding and interpretability of this graph advection operator.\n\n2 Understanding the directed graph advection operator\n\nWe aim to model the continuous advection equation for unknown scalar u under vector field v:\n\n\u2202u\n\n\u2202t\n= \u2212\u2207 \u00b7 (vu),\n\nstochastically on a directed graph. We define a directed, weighted graph G = (V,E,W ) with |V | = n\nnodes and |E| = |W | = m edges, where V denotes the vertex, E the edge, and W the edge weight\nsets, respectively. We discretize the flow vu along edge (i, j) \u2208 E with weight wji \u2208W as wjiui(t),\nwhere ui(t) denotes the concentration u at node i and time t.\n\nThe graph advection operator Ladv is defined so that the flow into a node equals the flow out of it [4]:\n\ndui(t)\n\ndt\n=\n\n\u2211\nj:(j,i)\u2208E\n\nwijuj(t)\u2212\n\u2211\n\nj:(i,j)\u2208E\n\nwjiui(t) = \u2212[Ladvu(t)]i, (2)\n\nwhere Ladv = Dout \u2212 Ain for diagonal out-degree matrix Dout and in-degree adjacency matrix\nAin. For general directed graphs, Ladv belongs to the square, non-symmetric with non-negative real\npart eigenvalues [18] class of matrices in [13]. By design, Ladv is conservative, unlike the related\ndiffusion or consensus operator Lcons = Din \u2212 Ain, where Din denotes the diagonal in-degree\nmatrix [4, 18]. A main motivating reason for using Ladv to model traffic flow is that it results in a\nconservative scheme.\n\nReformulation of Ladv as finite difference on balanced graphs. We notice that Ladv at node i\nis a weighted linear combination of the other nodes adjacent to it, which resembles finite difference\nstencils of the unknown and its neighbors. We make this connection precise, and then construct\nexample graphs where Ladv corresponds to common finite difference schemes for linear advection.\n\nTheorem 2.1. Ladv corresponds to a semi-discrete finite difference advection scheme, where the sum\nof the coefficients is zero if and only if the graph G is balanced, i.e. Ladv = Lcons.\nProof. A finite difference approximation to the gradient can be written as the following weighted\nlinear combination of its neighbors uj for arbitrary coefficients cij \u2208 R:\n\n\u2212(ux)i \u2248\n\u2211\nj 6=i\n\ncijuj + ciiui. (3)\n\n2\n\n\n\nA consistent finite difference scheme is at least zero-th order accurate [10]. Since the derivative of a\nconstant is 0, the coefficients must sum to 0, i.e cii = \u2212\n\n\u2211\nj 6=i cij . Combining (2) with (3) gives:\n\n(Dout)ii =\n\u2211\n\nj:(i,j)\u2208E\n\nwji = \u2212cii =\n\u2211\nj 6=i\n\ncij =\n\u2211\n\nj:(j,i)\u2208E\n\nwij = (Din)ii.\n\nThe graph G is balanced by definition, and it follows that Ladv = Lcons. The other direction follows\nsimilarly.\n\nApplying Ladv on the directed line graph in Figure 2(a) results in the first order upwind scheme\nwith spatial step size \u2206x for v > 0 in (5) (See Appendix A and Figure 6 for the convergence study).\nSimilarly, Figure 2(b) illustrates the directed graph in which Ladv gives the second order central\ndifference scheme, where (ux)i \u2248 (ui+1 \u2212 ui\u22121)/(2\u2206x) (See Appendix B for additional examples).\n\nui\u22121 ui ui+1\nv/\u2206x v/\u2206x\n\n(a) first order upwind scheme\n\nui\u22121 ui ui+1\nv/2\u2206x \u2212v/2\u2206x\n\n\u2212v/2\u2206x v/2\u2206x\n\n(b) second order central scheme\n\nFigure 2: Balanced graphs on which Ladv corresponds to finite difference stencils of linear advection.\n\n3 Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\n\nWe propose the novel Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model, which\nuses the dynamics of Ladv to model advection stochastically on a directed graph through a discrete\napproximation to the continuous Laplacian \u2206 of the Mat\u00e9rn Gaussian Process in (1). The covariance\nmatrix or kernel K of a Gaussian process needs to be symmetric and positive semi-definite. This\nleads to some challenges with the Ladv operator as it is not guaranteed in general to be symmetric or\npositive semi-definite (See Section 2). Note that using the graph Laplacian L in the covariance matrix\nin the undirected graph case is more straightforward since L is symmetric positive semi-definite.\n\nIn our directed graph case, we propose using LTadvLadv as the covariance matrix since it is symmetric\npositive definite, and hence orthogonally diagonalizable. Analogous to [2], we define a function \u03c6 of\na diagonalizable matrix through Taylor series expansion. Then we can define its eigendecomposition\nas LTadvLadv = Xadv\u039badvX\n\nT\nadv, so that \u03c6(L\n\nT\nadvLadv) = Xadv\u03c6(\u039badv)X\n\nT\nadv, where \u03c6(\u039badv) is\n\ncomputed by applying \u03c6 to the diagonal elements of \u039badv .\n\nWe compute the eigendecomposition of LTadvLadv = Vadv\u03a3\n2\nadvV\n\nT\nadv , using the singular value decom-\n\nposition (SVD) of Ladv = Uadv\u03a3advV Tadv, where the eigenvalues and eigenvectors are the singular\nvalues squared and right singular vectors of Ladv, respectively. Hence, we model the advection\ndynamics using the square of the singular values of Ladv . Our approach can also be viewed as adding\nthe square of the singular values of Ladv to the diagonal for regularization. Computing the thin-SVD\nis more computationally efficient and numerically stable, since we avoid explicitly forming the\nmatrix-matrix product LTadvLadv , which has double the condition number of Ladv , and the numerical\nissues with then computing its eigendecomposition.\n\nWe chose \u03c6 to be the Mat\u00e9rn covariance function in (1), and our DGAMGP model is given by:\n\nu \u223c N\n(\n0,\n(\nVadv(\n\n2\u03bd\n\n\u03ba2\nI + \u03a32adv)\n\n\u2212\u03bdV Tadv\n))\n. (4)\n\nThis advective Gaussian Process is then trained on data by minimizing the negative log-likelihood of\nthe Gaussian Process to learn the kernel hyperparameters \u03bd and \u03ba, and predict u [7]. For inference,\nwe draw samples from the GP predictive posterior distribution with the learned hyperparameters [19].\nSee Algorithm 1 for details.\n\nChoice of LTadvLadv . There are alternate approaches to symmetrize Ladv . The first simple approach\nexplored is to utilize Lsym = (LTadv + Ladv)/2 . This operator is not positive semi definite except\n\n3\n\n\n\nin the balanced graph case. The second approach is to use the symmetrizer method in [21], which\ngenerates a symmetric matrix L\u2032sym with the same eigenvalues as Ladv but is not always positive\nsemi definite.\n\nAlgorithm 1 The Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\nGiven a directed graph G = (V,E,W ) and training data D = {(xi, yi)}ni=1.\n\n1. Compute Ladv(G) = Dout \u2212Ain.\n2. Compute the SVD of Ladv = Uadv\u03a3advV Tadv .\n3. Generate a DGAMGP model in (4).\n4. Minimize the GP negative log marginal likelihood using D to learn \u03bd, \u03ba and \u03c3 [7].\n5. Given test data {x\u2217i }, draw samples from the GP predictive posterior distribution [19].\n\n4 Numerical Results\nIn this section, we utilize our DGAMGP model for traffic modeling on synthetic and real-\nworld directed traffic graphs. The data D = {(xi, yi)}ni=1 denotes the traffic flow speed in\nmiles per hour yi at location xi. We test our model\u2019s predictive ability to predict the veloci-\nties of cars on a road at different positions. We use hold-out cross validation to split the data\npoints generated into training (70% of the data) and testing data (30% of the data). We extend\nthe code in [2] to compute the singular value decomposition of Ladv to train our DGAMGP\nmodel on a directed graph. The code is available at https://github.com/advectionmatern/\nModeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes, and\nthe experiments are run on Amazon Sagemaker [12].\n\nRegression results on synthetic graphs. We generate synthetic data that models traffic along a\nroad, which has a relatively high density of cars in the first half and a low density of cars in the second\nhalf. We train and test our model on the upwind scheme in Figure 2(a), central scheme in Figure\n2(b), an intersecting lane graph, where two lanes merge into one lane in Figure 3(a) and a loop graph\nrepresenting the upwind scheme with periodic boundary conditions in Figure 3(b). Table 1 compares\nthe results to the consensus baseline model of using the singular value decomposition of Lcons in\nEqn. (4).\n\nModel Graph type n = 280 n = 325 n = 400 \u03bd \u03ba \u03c3\nAdvection\n\nUpwind\n0.52 0.45 0.0005 0.65 8.09 7.75\n\nConsensus 0.51 0.44 0.0005 0.65 8.29 7.77\nAdvection\n\nCentral\n1.31 0.85 8.41e-05 0.67 9.00 8.03\n\nConsensus 0.97 0.8 8.02e-05 0.67 9.45 8.11\nAdvection\n\nIntersection\n0.96 0.45 0.0005 0.65 8.19 7.75\n\nConsensus 0.52 0.46 0.0005 0.64 8.28 7.77\nAdvection\n\nLoop\n0.47 0.41 0.00045 0.65 8.49 7.76\n\nConsensus 0.47 0.41 0.00045 0.65 8.49 7.76\n\nTable 1: Comparison of l2 test error on synthetic directed graphs with n nodes and the learned\nhyperparameters.\n\nui\u22122 ui\u22121 ui\n\nui\u22124 ui\u22123\n\nui+1\nv/\u2206x v/\u2206x\n\nv/\u2206x v/\u2206x\n\n2v/\u2206x\n\n(a) intersection graph\n\nu1 ui\u22121 ui un\nv/\u2206x v/\u2206x v/\u2206x\n\nv/\u2206x\n\n(b) loop graph\n\nFigure 3: Graphs representing two lanes merging into one (left) and a loop (right).\n\n4\n\nhttps://github.com/advectionmatern/Modeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes\nhttps://github.com/advectionmatern/Modeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes\n\n\nRegression results on a real-world traffic graph. We test on the real-world traffic data from the\nCalifornia Performance Measurement System [5] with the road network graph from the San Jose\nhighways from Open Street Map [15] at a fixed time. Since our method supports directed graphs,\nwe do not need to convert the raw directed traffic data to an undirected graph as in [2]. We use the\nsame experimental setup from [2] to generate the train and test data. Figure 4 shows the resulting\npredictive mean and standard deviation of the speed on the San Jose highways using the visualization\ntools from [2]. We notice that the predictive standard deviation along the nodes is relatively small,\nand is larger on the points that are farther from the sensors.\n\nFigure 4: Traffic speed interpolation over a graph of San Jose highways using our DGAMGP method\nwith \u03bd = 0.35, \u03ba = 1002.8, \u03c3 = 1.14 and plotting tools from [2].\n\n5 Conclusions\n\nIn this paper, we propose a novel method DGAMGP to model an advective process on a directed\ngraph and its uncertainties. We show connections between finite differences schemes used to solve\nthe linear advection equation and the graph advection operator Ladv employed in our model. We\nexplore a regression problem on various graphs, and show that our proposed DGAMGP model\nperforms similarly to other state-of-the-art models. Future work includes adding a time-varying\ncomponent to our model, comparing our method to classical numerical methods for solving PDEs,\nand incorporating the behavior of the non-linear advection equation for traffic modeling.\n\nReferences\n\n[1] Bakka, H., Krainski, E., Bolin, D., Rue, H., and Lindgren, F. (2020). The diffusion-based\nextension of the mat\u00e9rn field to space-time. arXiv:2006.04917.\n\n[2] Borovitskiy, V., Azangulov, I., Terenin, A., Mostowsky, P., Deisenroth, M., and Durrande,\nN. (2021). Mat\u00e9rn gaussian processes on graphs. In Banerjee, A. and Fukumizu, K., editors,\nProceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume\n130 of Proceedings of Machine Learning Research, pages 2593\u20132601. PMLR.\n\n5\n\n\n\n[3] Chamberlain, B., Rowbottom, J., Gorinova, M. I., Bronstein, M., Webb, S., and Rossi, E. (2021).\nGrand: Graph neural diffusion. In Meila, M. and Zhang, T., editors, Proceedings of the 38th\nInternational Conference on Machine Learning, volume 139 of Proceedings of Machine Learning\nResearch, pages 1407\u20131418. PMLR.\n\n[4] Chapman, A. and Mesbahi, M. (2011). Advection on graphs. IEEE Conference on Decision and\nControl and European Control Confereence (CDC-ECC), 50:1461\u20131466.\n\n[5] Chen, C., Petty, K., Skabardonis, A., Varaiya, P., and Jia, Z. (2001). Freeway performance\nmeasurement system: mining loop detector data. Transportation Research Record, 1748(1):96\u2013\n102.\n\n[6] Chen, Y., Sohani, N., and Peng, H. (2018). Modelling of uncertain reactive human driving\nbehavior: a classification approach. In 2018 IEEE Conference on Decision and Control (CDC),\npages 3615\u20133621.\n\n[7] Gardner, J., Pleiss, G., Bindel, D., Weinberger, K., and Wilson, A. (2018). GPytorch: Blackbox\nmatrix-matrix gaussian process inference with gpu acceleration. 32nd Conference on Neural\nInfromation Processing Systems (NIPS 2018) arXiv:1809.11165v2.\n\n[8] Ho\u0161ek, R. and Volek, J. (2019). Discrete advection\u2013diffusion equations on graphs: Maximum\nprinciple and finite volumes. Applied Mathematics and Computation, 361(C):630\u2013644.\n\n[9] K\u00fcper, A. and Waldherr, S. (2020). Numerical gaussian process kalman filtering. 21st IFAC\nWorld Congress.\n\n[10] LeVeque, R. J. (2007). Finite Difference Methods for Ordinary and Partial Differential Equa-\ntions: Steady-State and Time-Dependent Problems. SIAM.\n\n[11] Li, Y., Yu, R., Shahabi, C., and Liu, Y. (2018). Diffusion convolutional recurrent neural network:\nData-driven traffic forecasting. International Conference on LEarning Representations (ICLR).\n\n[12] Liberty, E., Karnin, Z., Xiang, B., Rouesnel, L., Coskun, B., Nallapati, R., Delgado, J.,\nSadoughi, A., Astashonok, Y., Das, P., Balioglu, C., Chakravarty, S., Jha, M., Gautier, P., Arpin,\nD., Januschowski, T., Flunkert, V., Wang, Y., Gasthaus, J., Stella, L., Rangapuram, S., Salinas, D.,\nSchelter, S., and Smola, A. (2020). Elastic machine learning algorithms in amazon sagemaker. In\n2020 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201920, New York,\nNY, USA. Association for Computing Machinery., pages 731\u2013737.\n\n[13] Liesen, J. and Parlett, B. N. (2008). On nonsymmetric saddle point matrices that allow conjugate\ngradient iterations. Numer. Math., 108:605\u2013624.\n\n[14] Lighthill, M. and Whitham, G. (1955). On kinematic waves ii. a theory of traffic flow on long\ncrowded roads. Proceedings of the Royal Society of London. Series A. Mathematical and Physical\nSciences, 229:317 \u2013 345.\n\n[15] OpenStreetMap (2017). https://www.openstreetmap.org.\n\n[16] Perdikaris, P. and Karniadakis, G. (2019). Machine learning of space-fractional differential\nequations, SIAM Journal on Scientific Computing, Vol. 41, No. 4, Society for Industrial and\nApplied Mathematics.\n\n[17] Raissi, M., Perdikaris, P., and Karniadakis, G. (2019). Physics-informed neural networks: A\ndeep learning framework for solving forward and inverse problems involving nonlinear partial\ndifferential equations. Journal of Computational Physics, 378:686\u2013707.\n\n[18] Rak, A. (2017). Advection on graphs. http://nrs.harvard.edu/urn-3:HUL.InstRepos:\n38779537.\n\n[19] Rasmussen, C. and Williams, C. (2006). Gaussian Processes for Machine Learning. MIT Press.\n\n[20] Richards, P. (1956). Shock waves on the highway. Operation Res., pages 42 \u2013 51.\n\n[21] Sen, S. and Venkaiah, V. C. (1988). On symmetrizing a matrix. Indian J. pure appl. Math.,\n19(6):554\u2013561.\n\n[22] Solomon, J. (2015). PDE approaches to graph analysis. ArXiv, abs/1505.00185.\n\n6\n\nhttps://www.openstreetmap.org\nhttp://nrs.harvard.edu/urn-3:HUL.InstRepos:38779537\nhttp://nrs.harvard.edu/urn-3:HUL.InstRepos:38779537\n\n\nA Upwinding discretizations of linear advection\n\nWe discretize the 1D linear advection equation with velocity v:\nut + vux = 0,\n\nusing the standard first order upwinding scheme on a simple uniform Cartesian mesh with spatial step\nsize \u2206x. Then the classical finite difference first-order upwind scheme depends on the sign of v. For\nflow moving from left to right, v > 0, and we have the following semi-discrete discretization [10]:\n\ndui\ndt\n\n+ v\nui \u2212 ui\u22121\n\n\u2206x\n= 0, if v > 0,\n\ndui\ndt\n\n+ v\nui+1 \u2212 ui\n\n\u2206x\n= 0, if v < 0.\n\n(5)\n\nUpwinding schemes are useful in the advection case since information is moving from left to right.\nThe Courant-Friedrichs-Lewy (CFL) condition for stability of the first order upwinding scheme with\nForward Euler time-stepping discretization with time step \u2206t is given by:\u2223\u2223\u2223v\u2206t\n\n\u2206x\n\n\u2223\u2223\u2223 \u2264 1 \u21d0\u21d2 \u2206t \u2264 \u2223\u2223\u2223 v\n\u2206x\n\n\u2223\u2223\u2223.\nA less diffusive second order upwind scheme is also known as linear upwind differencing (LUD),\nand is given by:\n\ndui\ndt\n\n= v\n\u2212ui\u22122 + 4ui\u22121 \u2212 3ui\n\n2\u2206x\n. (6)\n\nWe can show that the scheme is second-order accurate using Taylor expansions. It is designed to be\nless diffusive because the uxx term from the first-order upwinding scheme cancels. We have\n\nui\u22122 \u2212 4ui\u22121 + 3ui\n2\u2206x\n\n=\n1\n\n2\u2206x\n\n[(\nu\u2212 2\u2206xux +\n\n4\u2206x2\n\n2\nuxx \u2212\n\n8\u2206x3\n\n6\nuxxx +O(\u2206x4)\n\n)\n+\n(\n\u2212 4(u\u2212\u2206xux +\n\n\u2206x2\n\n2\nuxx \u2212\n\n\u2206x3\n\n6\nuxxx +O(\u2206x4))\n\n)\n+ 3u\n\n]\n\n= ux \u2212\n\u2206x2\n\n3\nuxxx +O(\u2206x4).\n\nHence, the scheme is second order accurate with a dispersive uxxx leading error term.\n\nB Examples of Ladv on balanced graphs resulting in finite difference\ndiscretizations of linear advection\n\nIn addition to the finite difference schemes provided in Section 2, we also provide an example of a\nnon-uniform mesh discretization:\n\ndui\ndx\n\u2248\n\n4\n3\nui+1/2 \u2212 ui \u2212 13ui\u22121\n\n\u2206x\n,\n\nwhich results in the following graph, where the in-going and out-going edges from ui:\n\nui\u22121 ui\u22121/2 ui ui+1/2 ui+1\n\nv/3\u2206x\n\n\u22124v/3\u2206x\u22124v/3\u2206x\n\nv/3\u2206x\n\nWe can obtain the less diffusive second order upwind scheme (LUD) in (6) using the following graph:\n\nui\u22122 ui\u22121 ui ui+1 ui+2\n\n\u2212v/2\u2206x\n\n2v/\u2206x 2v/\u2206x\n\n\u2212v/2\u2206x\n\n2v/\u2206x\n\n\u2212v/2\u2206x\n\n2v/\u2206x\n\n7\n\n\n\nC Additional Experiments\n\nC.1 Gaussian Process prior results with DGAMGP\n\nA main property of the Mat\u00e9rn Gaussian Process kernel is that it varies along Riemannian manifolds.\nThe variance of the kernel is a function of degree, and depends on a complex manner on the graph.\nWe show the results generated with a star graph directed towards the center node and a directed\ncomplete graph. Figure 5(a) shows that as expected for the complete graph, the nodes have the\nsame variability, since for a random walk starting from any node, there is equal probability to get to\nanother node. For the star graph in Figure 5(b), we observe that the center node has a variability of\napproximately 0 as starting from any node on the graph, the random walk always ends at the center.\n\n(a) complete graph prior. (b) star graph prior.\n\nFigure 5: Prior results using DGAMGP obtained using various graphs, and plotting tools from [2].\n\nC.2 Convergence Studies\n\nWe conduct a convergence study of applying Ladv on the upwind graph in Figure 2(a), and show that\nit has first order convergence matching the performance of the equivalent first order upwind scheme.\nWe use the same initial condition as in Figure 1. We then solve the resulting system of ODEs using\nthe RK5 ODE solver. Figure 6(a) shows the solution at different time steps, and we see how the\nsolution is propagating to the right. Figure 6(b) shows a loglog plot, where the error is decreasing\nlinearly with a slope of 1 as the number of nodes n is increasing, as expected.\n\n(a) Solution of the linear advection equation using (2) (b) Convergence study in a log-log plot\n\nFigure 6: Upwinding solution with RK5 to the linear advection equation over time and corresponding\nconvergence study.\n\n8\n\n\n\t1 Introduction\n\t2 Understanding the directed graph advection operator\n\t3 Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\n\t4 Numerical Results\n\t5 Conclusions\n\tReferences\n\tA Upwinding discretizations of linear advection\n\tB Examples of Ladv on balanced graphs resulting in finite difference discretizations of linear advection\n\tC Additional Experiments\n\tC.1 Gaussian Process prior results with DGAMGP\n\tC.2 Convergence Studies\n\n\n"}
{"Title": "Time-Dependent Duhamel Renormalization method with Multiple Conservation and Dissipation Laws", "Authors": "Sathyanarayanan Chandramouli, Aseel Farhat, Ziad Musslimani", "Abstract": "  The time dependent spectral renormalization (TDSR) method was introduced by Cole and Musslimani as a novel way to numerically solve initial boundary value problems. An important and novel aspect of the TDSR scheme is its ability to incorporate physics in the form of conservation laws or dissipation rate equations. However, the method was limited to include a single conserved or dissipative quantity. The present work significantly extends the computational features of the method with the (i) incorporation of multiple conservation laws and/or dissipation rate equations, (ii) ability to enforce versatile boundary conditions, and (iii) higher order time integration strategy. The TDSR method is applied on several prototypical evolution equations of physical significance. Examples include the Korteweg-de Vries (KdV), multi-dimensional nonlinear Schr\u00f6dinger (NLS) and the Allen-Cahn equations.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00002", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE\nCONSERVATION AND DISSIPATION LAWS\n\nSATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nABSTRACT. The time dependent spectral renormalization (TDSR) method was introduced by Cole and Musslimani as\na novel way to numerically solve initial boundary value problems. An important and novel aspect of the TDSR scheme\nis its ability to incorporate physics in the form of conservation laws or dissipation rate equations. However, the method\nwas limited to include a single conserved or dissipative quantity.\n\nThe present work significantly extends the computational features of the method with the (i) incorporation of multiple\nconservation laws and/or dissipation rate equations, (ii) ability to enforce versatile boundary conditions, and (iii) higher\norder time integration strategy. The TDSR method is applied on several prototypical evolution equations of physical\nsignificance. Examples include the Korteweg-de Vries (KdV), multi-dimensional nonlinear Schro\u0308dinger (NLS) and the\nAllen-Cahn equations.\n\nKeywords: Renormalization method, initial boundary value problems, partial differential equations, Duhamel\u2019s\nprinciple, nonlinear waves, soliton equations, Hamiltonian and dissipative systems.\n\n1. INTRODUCTION\n\nNumerical simulation of initial boundary value problems is of utmost importance in several engineering and\nscientific disciplines. Over the last few decades, several time-stepping methods have been developed and proposed\nto achieve this goal. Among them are the class of implicit/explicit Runge-Kutta methods [35], exponential time-\ndifferencing [12, 25, 37, 43] and the split-step operator splitting [40] to name a few. For evolution equations that\narise in physical applications, it is highly desirable to devise time-stepping schemes that reflect the underlying\nphysics at hand. Such structure preserving numerical schemes are of paramount importance for long-time integra-\ntion, where either it is necessary to ensure numerical stability (e.g., if the numerics could conserve the L2 norm of\nthe solution for the KdV/NLS), or preserve other features (such as capturing the correct shock speed in the con-\ntext of systems of hyperbolic partial differential equations).To date, there are various ways to input some physics\ninto the numerical time-integration. For example, the geometric/symplectic integrators that preserve the Hamil-\ntonian and symplectic structure [18], the operator splitting method that was used for the NLS equation to preserve\nthe power and the non-linear dispersion relation [40], the multi-symplectic schemes designed for the generalized\nSchro\u0308dinger equations [21\u201323], the Taha-Ablowitz [38], the Ablowitz-Ladik [6], and the Ablowitz-Musslimani\n[2, 4] schemes that preserve the integrable structure of the KdV, NLS and class of nonlocal NLS equations, re-\nspectively. Other relevant works correspond to the conservative finite volume Godunov schemes [16, 19, 28],\nfinite difference schemes that preserve the energy or dissipation property of the underlying model equation (see,\ne.g.,[15, 36]), as well as a finite volume scheme that conserve mass and momentum of the KdV equation (see, e.g.,\n[13]). Recently, Cole and Musslimani [11] proposed an alternative method to simulate dynamical systems that\nenables the inclusion of physics \u201con-demand\u201d. The core idea is to make use of the Duhamel\u2019s principle to recast\nthe underlying evolution equation as a space-time integral equation. The resulting system is then solved iteratively\nusing a novel time-dependent renormalization process that controls both the numerical convergence properties of\nthe scheme while at the same time preserving a single physical law.\n\nIn this paper, we extend the time-dependent spectral renormalization method to allow for multiple conserva-\ntion laws or dissipation rates to be simultaneously incorporated in the simulation. This is achieved by introducing\nas many time-dependent renormalization factors as the number of conservation/dissipation laws being enforced.\nThe solution sought is then written as a linear superposition of finite number of space-time dependent auxiliary\nwave functions with the time-dependent renormalization factors envisioned to play the role of \u201cexpansion coeffi-\ncients\u201d. When inserted into the corresponding Duhamel\u2019s formula, a finite set of \u201csub-Duhamel\u201d integral equations\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n2v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 1\n\n9 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nare obtained governing the space-time dynamics of each individual auxiliary function. These integral equations\nare then numerically solved using a novel space-time fixed point iteration. The importance of such a dynamic\nrenormalization process are twofold: (i) it provides convergence when needed and (ii) enables the inclusion of\nconservation/dissipation laws. The Duhamel integrals are numerically computed using a Cauchy-Filon-Simpson\nquadrature formula. The TDSR method is implemented on several prototypical evolution equations of physical\nsignificance. This includes the KdV, Allen-Cahn, multi-dimensional and the PT symmetric integrable nonlocal\nNLS equations.\n\nThe paper is organized as follows. In Sec. 2 we put forward a general framework for the TDSR scheme in\narbitrary space dimensions and show how to incorporate multiple conservation laws or dissipation rate equations\ninto the algorithm. The Cauchy-Filon Simpson time integration is derived in Sec. 3.1 for evolution equations\nsubject to either periodic or rapidly decaying boundary conditions. The TDSR scheme is applied on the KdV\nand NLS equations, with single and multiple conservation laws. In Sec. 3.2 the Cauchy-Filon trapezoidal time\nintegration is developed for evolution equations subject to non-periodic and non decaying boundary conditions. In\nthis regard, the Allen-Cahn equation is used as a test bed to assess the performance of the algorithm. We conclude\nin Sec. 7 with comments on future directions.\n\n2. TDSR AND DUHAMEL PRINCIPLE\n\nIn this section, we formulate the TDSR method using Duhamel\u2019s principle in conjunction with multiple conser-\nvation laws. Consider the evolution equation for the real (or complex) valued function u(x, t):\n\nut = L (u)+N (u), u(x,0) = u0(x), (2.1)\nwhere L is a linear, constant coefficient differential operator and N (u) is a nonlinear operator. The initial-\nboundary value problem (2.1) is posed on a spatial domain \u2126 that is either bounded or unbounded. Furthermore,\nEq. (2.1) is supplemented with either periodic, rapidly decaying, or other types of boundary conditions. As men-\ntioned above, we are interested in evolution equations that are either (i) conservative, in which case, there exists N\nconserved quantities given by\n\nQm(u)\u2261\n\u222b\n\n\u2126\n\nQm[u(x, t)]dx =\n\u222b\n\n\u2126\n\nQm[u0(x)]dx\u2261Cm , m = 1,2,3, \u00b7 \u00b7 \u00b7N, (2.2)\n\nor (ii) dissipative, so that there are N densities \u03c1m and fluxes Fm that obey the rate equations\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m[u(x, t)]dx =\u2212\n\u222b\n\n\u2126\n\nFm[u(x, t)]dx , m = 1,2,3, \u00b7 \u00b7 \u00b7 ,N. (2.3)\n\nEquation (2.1) is rewritten in an integral form using the Duhamel\u2019s principle:\n\nu(x, t) = etL [u0(x)]+\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [u(x,\u03c4)]d\u03c4. (2.4)\n\nRecall that for any periodic or L2 function w(x), the semi-group etL admits the spectral representation:\n\netL [w(x)] = F\u22121[exp(tL\u0302 )F [w(x)]], (2.5)\n\nwhere L\u0302 is the Fourier symbol associated with L and F , F\u22121 denote the d-dimensional forward and inverse\nFourier transforms, defined by\n\nw\u0302(k)\u2261F [w(x)] = (2\u03c0)\u2212d/2\n\u222b\nRd\n\nw(x)e\u2212ik\u00b7xdx, (2.6)\n\nF\u22121[w\u0302(k)] = (2\u03c0)\u2212d/2\n\u222b\nRd\n\nw\u0302(k)eik\u00b7xdk. (2.7)\n\nFor periodic functions defined on a bounded spatial domain the forward Fourier integral (2.6) represents the coef-\nficients of its Fourier series.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 3\n\nWe now outline in details how to incorporate multiple conservation laws or dissipation rate equations in the\nTDSR scheme. To this end, we seek a solution to Eq. (2.4) in the form\n\nu(x, t) =\nN\n\n\u2211\nj=1\n\nR j(t)v j(x, t), (2.8)\n\nwhere R j(t) are time-dependent renormalization factors to be determined from knowledge of the conservation or\ndissipation laws and v j(x, t) are space-time dependent auxiliary functions that satisfy the same boundary conditions\nas the solution u(x, t). Our extensive numerical experiments seem to indicate that in order for the TDSR iteration\nto converge, the initial condition u0(x) needs to be re-written as a sum of N (identically non-zero) functions f j(x)\n(here referred to as pseudo initial conditions). Namely, we write\n\nu0(x) =\nN\n\n\u2211\nj=1\n\nf j(x), (2.9)\n\nwhere each f j is chosen to be compatible with the underlying boundary conditions. The specific choice of the\nfunctions { f j(x)}, j = 1,2, \u00b7 \u00b7 \u00b7 ,N, is discussed in Sec. (5) when solving the KdV equation. Substituting Eqns. (2.8)\nand (2.9) into (2.4), we obtain an equation for the auxiliary functions v j(x, t), j = 1,2, \u00b7 \u00b7 \u00b7N:\n\nN\n\n\u2211\nj=1\n\nR j(t)v j(x, t) =\nN\n\n\u2211\nj=1\n\netL [ f j(x)]+\n\u222b t\n\n0\ne(t\u2212\u03c4)L N\n\n[\nN\n\n\u2211\nj=1\n\nR j(\u03c4)v j(x,\u03c4)\n\n]\nd\u03c4. (2.10)\n\nScrutinizing Eq. (2.10) reveals the existence of N\u22121 degrees of freedom for the variables v1,v2, \u00b7 \u00b7 \u00b7 ,vN\u22121. Next,\nwe outline how to eliminate each degree of freedom and derive a self-consistent set of equations that forms the\nbasis for the TDSR scheme. To begin with, we choose v1(x, t) such that\n\nv1(x, t) = M1[R1,v1]\u2261\n1\n\nR1(t)\n\n{\netL [ f1(x)]+\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)]d\u03c4\n}\n. (2.11)\n\nThe rationale behind this choice is rooted in the fact that Eq. (2.11) must reduce back to the case when only\none conservation or dissipation law is under consideration with f1(x) \u2261 u0(x). With this at hand, we next require\nv2(x, t) to satisfy\n\nv2(x, t) = M2[R1,R2,v1,v2]\n\n\u2261\n1\n\nR2(t)\n\n(\netL [ f2(x)]+\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)+R2(\u03c4)v2(x,\u03c4)]d\u03c4\n)\n\n\u2212\n1\n\nR2(t)\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)]d\u03c4, (2.12)\n\nand for general j = 3,4, \u00b7 \u00b7 \u00b7 ,N,\nv j(x, t) = M j[R1,R2, \u00b7 \u00b7 \u00b7 ,R j;v1,v2, \u00b7 \u00b7 \u00b7 ,v j] (2.13)\n\n\u2261\n1\n\nR j(t)\netL [ f j(x)]+\n\n1\nR j(t)\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N\n\n[\nj\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]\nd\u03c4\n\n\u2212\n1\n\nR j(t)\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N\n\n[\nj\u22121\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]\nd\u03c4,\n\n\n\n4 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nNote that Eqns. (2.11)-(2.13) are self-consistent with the Duhamel\u2019s formula (2.10). Indeed, multiplying (2.12)\nby R2 and (2.13) by R j and summing over all j = 2,3, \u00b7 \u00b7 \u00b7 ,N, we obtain\n\nN\n\n\u2211\nj=2\n\nR j(t)v j(x, t) = etL\n[\n\nN\n\n\u2211\nj=2\n\nf j(x)\n\n]\n\n+\n\u222b t\n\n0\ne(t\u2212\u03c4)L\n\nN\n\n\u2211\nj=2\n\n{\nN\n\n[\nj\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]}\nd\u03c4\n\n\u2212\n\u222b t\n\n0\ne(t\u2212\u03c4)L\n\nN\n\n\u2211\nj=2\n\n{\nN\n\n[\nj\u22121\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]}\nd\u03c4. (2.14)\n\nThe last two terms on the right hand side of Eq. (2.14) satisfy\u222b t\n0 d\u03c4e\n\n(t\u2212\u03c4)L\n\u2211\n\nN\nj=2\n\n{\nN\n[\n\u2211\n\nj\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]\n\u2212N\n\n[\n\u2211\n\nj\u22121\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]}\n=\n\u222b t\n\n0 d\u03c4e\n(t\u2212\u03c4)L N\n\n[\n\u2211\n\nN\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]\n\u2212N [R1(\u03c4)v1(x,\u03c4)]. (2.15)\n\nThe conclusion is complete once we multiply Eq. (2.11) by R1(t); add the result to Eq. (2.15) and use the condition\n(2.9). In summary, Eqns. (2.11)-(2.13) give an implicit integral representation for the auxiliary functions v j. To\nclose the system, all we need is to compute the renormalization factors R j(t). Substituting Eq. (2.8) into Eqns. (2.2)\nand (2.3) gives:\n\nConservative case:\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n)\n\u2261\n\u222b\n\n\u2126\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n)\ndx =Cm, (2.16)\n\nDissipative case:\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m\n\n[\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\ndx =\u2212\n\n\u222b\n\u2126\n\nFm\n\n[\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\ndx, (2.17)\n\nwhere m = 1,2, \u00b7 \u00b7 \u00b7 ,N. System (2.16) defines N algebraic equations for the time-dependent renormalization factors\nwhereas (2.17) a set of coupled nonlinear ordinary differential equations governing the evolution of R j(t). With\nthis at hand, the TDSR iterative process is summarized below:\n\nv(n+1)1 = M1[R\n(n)\n1 (t),v\n\n(n)\n1 ], (2.18)\n\nv(n+1)2 = M2[R\n(n)\n1 ,R\n\n(n)\n2 ,v\n\n(n)\n1 ,v\n\n(n)\n2 ], (2.19)\n\nv(n+1)j = M j[R\n(n)\n1 ,R\n\n(n)\n2 , \u00b7 \u00b7 \u00b7 ,R\n\n(n)\nj ,v\n\n(n)\n1 ,v\n\n(n)\n2 , \u00b7 \u00b7 \u00b7 ,v\n\n(n)\nj ] , j = 3, \u00b7 \u00b7 \u00b7 ,N, (2.20)\n\nwith R(n)j , j = 1,2, \u00b7 \u00b7 \u00b7 ,N given by (for conservative cases)\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR(n)` (t)v\n(n)\n` (x, t)\n\n)\n\u2261Cm , (2.21)\n\nand\n\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m\n\n[\nN\n\n\u2211\n`=1\n\nR(n)` (t)v\n(n)\n` (x, t)\n\n]\ndx =\u2212\n\n\u222b\n\u2126\n\nFm\n\n[\nN\n\n\u2211\n`=1\n\nR(n)` (t)v\n(n)\n` (x, t)\n\n]\ndx, (2.22)\n\nfor the dissipative cases where m = 1,2, \u00b7 \u00b7 \u00b7 ,N. As a reminder, the functionals M1 and M j, j = 2,3, \u00b7 \u00b7 \u00b7 ,N are\nrespectively defined by Eqns. (2.11) - (2.13). A workflow for the TDSR algorithm is given below, clarifying the\nstructure of the iterative process:\n\n(1) Choose the pseudo initial conditions: The set of pseudo initial conditions f j(x), j = 1,2, \u00b7 \u00b7 \u00b7 N, are\nchosen in such a way that Eq. (2.9) is satisfied (see Sec.5 for further details). Note that they are used in\nthe Picard iterations defined by Eqs. (2.11)-(2.13).\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 5\n\n(2) Select initial guesses v(1)j (x, t) for j = 1,2, \u00b7 \u00b7 \u00b7 ,N: We seed Eqs. (2.11)-(2.13) with these initial guesses\nfor the space-time dependent auxiliary functions.\n\n(3) Compute the initial iterate of the set of renormalization factors: The set of auxiliary functions are used\nto evaluate the time-dependent renormalization factors R(1)j (t) , j = 1,2, \u00b7 \u00b7 \u00b7 ,N via the system of equations\n(2.21) or (2.22) depending on whether the underlying evolution equation is conservative or dissipative.\n\n(4) Compute the Duhamel integrals defined in Eqs. (2.18)-(2.20): The Duhamel integrals are computed\nusing v(1)j (x, t) and R\n\n(1)\nj (t), for j = 1,2, \u00b7 \u00b7 \u00b7 ,N.\n\n(5) Update the Duhamel iteration: The Duhamel integrals computed in the previous step are now used to\ncompute the second iterate of v(2)j (x, t) using Eqs. (2.18)-(2.20).\n\n(6) Update the renormalization factors: The updated {v(2)j (x, t)}\u2019s are now used to correct the the set of\nrenormalization factors {R(2)j (t)} , j = 1,2, \u00b7 \u00b7 \u00b7 ,N; from the system of equations given by (2.21) (for the\nconservative case), or (2.22) (for the dissipative case).\n\n(7) Iterative update: Repeat steps (5) and (6) till convergence is achieved.\n\n3. TIME INTEGRATION WITH VARIOUS BOUNDARY CONDITIONS\n\n3.1. Periodic and decaying boundary conditions. In this section, we detail the numerical approach used to\napproximate the Duhamel integral\n\nI(x, t)\u2261\n\u222b t\n\n0\ne(t\u2212\u03c4)L G(x,\u03c4)d\u03c4, (3.1)\n\nwith G(x,\u03c4) \u2261N [u(x,\u03c4)]. When subject to periodic or rapidly decaying boundary conditions, the action of the\nsemi-group exp(tL ) on G follows from its spectral representation F [exp(tL )G] = exp[tL\u0302 ]F [G] where L\u0302 is\nthe Fourier symbol associated with the constant coefficients linear operator L . Our approach in approximating the\nintegral Eq. (3.1) is based on the Filon-Simpson quadrature method [9, 20, 34]. To this end, we consider an NT\nequally spaced mesh points residing inside the time interval [0,T ] with ti = i\u2206t, i = 0,1,2, \u00b7 \u00b7 \u00b7 ,NT , labeling all grid\npoints. It can be shown that I\u0302(k, ti) satisfies the exact recurrence relation\n\nI\u0302(k, ti+1) = e2\u2206tL\u0302 (k)\n[\n\nI\u0302(k, ti\u22121)+\n\u222b ti+1\n\nti\u22121\ne(ti\u22121\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\n\n]\n. (3.2)\n\nAs a reminder, a hat over a quantity represents its Fourier transform (see definition (2.6)) or its Fourier series\ncoefficients. Next, we approximate the function G\u0302(k,\u03c4) by a quadratic polynomial defined in the interval [ti\u22121, ti+1]\n\nG\u0302(k,\u03c4) \u2248 G\u0302(k, ti\u22121)\n(\u03c4\u2212 ti)(\u03c4\u2212 ti+1)\n\n2(\u2206t)2\n\u2212 G\u0302(k, ti)\n\n(\u03c4\u2212 ti\u22121)(\u03c4\u2212 ti+1)\n(\u2206t)2\n\n+ G\u0302(k, ti+1)\n(\u03c4\u2212 ti\u22121)(\u03c4\u2212 ti)\n\n2(\u2206t)2\n. (3.3)\n\nSubstituting Eq. (3.3) back into (3.2) and integrating by parts gives a recursive formula for the Duhamel integral\n(3.1):\n\nI\u0302(k, ti+1) = e2\u2206tL\u0302 (k)[I\u0302(k, ti\u22121)+q1G\u0302(k, ti\u22121)+q2G\u0302(k, ti)+q3G\u0302(k, ti+1)]. (3.4)\nThe quadrature coefficients q j \u2261 q j(k,\u2206t), j = 1,2,3, depend on the Fourier wavenumber and the time step \u2206t but\nnot on the iteration index i. Thus, they are computed only once. The exact expressions for the q j\u2019s, j = 1,2,3, are\ngiven by (z\u2261 \u2206tL\u0302 (k))\n\nq1 = \u2206t(\u2212ze\u22122z\u22122e\u22122z +2z2\u22123z+2)/(2z3), (3.5a)\nq2 = \u2206t(2ze\n\n\u22122z +2e\u22122z +2z\u22122)/z3, (3.5b)\nq3 = \u2206t(\u22122z2e\u22122z\u22123ze\u22122z\u22122e\u22122z\u2212 z+2)/(2z3). (3.5c)\n\nFor linear operators satisfying L\u0302 (0) = 0 we find (in the limiting case k\u2192 0), q1(0,\u2206t) = q2(0,\u2206t)/4= q3(0,\u2206t)\u2261\n\u2206t/3. Equation (3.4) needs to be initialized with I\u0302(k, t = 0)= 0 and the quantity I\u0302(k,\u2206t)=\n\n\u222b\n\u2206t\n0 e\n\n(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\n\n\n\n6 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nwhich we next explain how to find. Note that in the interval [0,\u2206t], the values (in time) of the function G\u0302(k,\u03c4)\nare available only at two grid points: 0 and \u2206t. To maintain the same order of accuracy as was done at the other\ntemporal grid points, we apply a combination of two different quadrature rules to approximate I\u0302(k,\u2206t). First,\nconsider the following identity:\u222b 3\u2206t\n\n0\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4 =\n\n\u222b\n\u2206t\n\n0\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\ufe38 \ufe37\ufe37 \ufe38\n\nI\u0302(k,\u2206t)\n\n+\n\u222b 3\u2206t\n\n\u2206t\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4. (3.6)\n\nThe second integral on the right-hand side of Eq. (3.6) is computed using a quadratic interpolation (in time) for\nG\u0302(k,\u03c4). Indeed, after some algebra, we find\u222b 3\u2206t\n\n\u2206t\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4 \u2248 q1G\u0302(k,\u2206t)+q2G\u0302(k,2\u2206t)+q3G\u0302(k,3\u2206t). (3.7)\n\nTo obtain a similar order of accuracy for the integral on the left hand side of Eq. (3.6), we first represent G\u0302(k,\u03c4) as\na cubic polynomial (in time)\n\nG\u0302(k,\u03c4) \u2248 \u2212G\u0302(k,0)\n(\u03c4\u2212\u2206t)(\u03c4\u22122\u2206t)(\u03c4\u22123\u2206t)\n\n6(\u2206t)3\n+ G\u0302(k,\u2206t)\n\n\u03c4(\u03c4\u22122\u2206t)(\u03c4\u22123\u2206t)\n2(\u2206t)3\n\n\u2212 G\u0302(k,2\u2206t)\n\u03c4(\u03c4\u2212\u2206t)(\u03c4\u22123\u2206t)\n\n2(\u2206t)3\n+ G\u0302(k,3\u2206t)\n\n\u03c4(\u03c4\u2212\u2206t)(\u03c4\u22122\u2206t)\n6(\u2206t)3\n\n. (3.8)\n\nSubstituting expressions (3.8) and (3.7) into Eq. (3.6) gives (after integration by parts)\n\nI\u0302(k,\u2206t) = q4e\u2206tL\u0302 (k)G\u0302(k,0)+\n(\n\nq5e\n\u2206tL\u0302 (k)\u2212q1\n\n)\nG\u0302(k,\u2206t) (3.9)\n\n+\n(\n\nq6e\n\u2206tL\u0302 (k)\u2212q2\n\n)\nG\u0302(k,2\u2206t)+\n\n(\nq7e\n\n\u2206tL\u0302 (k)\u2212q3\n)\n\nG\u0302(k,3\u2206t).\n\nHere, q j \u2261 q j(k,\u2206t), j = 4,5,6,7, denote the quadrature coefficients whose expressions are given by\n\nq4 = \u2206t(2z\n2e\u22123z +6ze\u22123z +6e\u22123z +6z3 +12z\u221211z2\u22126)/(6z4), (3.10a)\n\nq5 = \u2206t(\u22123z2e\u22123z\u22128ze\u22123z\u22126e\u22123z +6z2\u221210z+6)/(2z4), (3.10b)\nq6 = \u2206t(6z\n\n2e\u22123z +10ze\u22123z +6e\u22123z\u22123z2 +8z\u22126)/(2z4), (3.10c)\nq7 = \u2206t(\u22126z3e\u22123z\u221211z2e\u22123z\u221212ze\u22123z\u22126e\u22123z +2z2\u22126z+6)/(6z4). (3.10d)\n\nFor linear operators satisfying L\u0302 (0)= 0, and for wavenumber k\u2192 0, q4(0,\u2206t)= q7(0,\u2206t)\u2261 3\u2206t/8, and q5(0,\u2206t)=\nq6(0,\u2206t)\u2261 9\u2206t/8. To summarize, the Duhamel integral I(x, t) is determined from iterating Eq. (3.4) subject to the\ninitial conditions: I(x,0) = 0 and I(x,\u2206t) given in Fourier space by Eq. (3.9). Note that in some cases, the Filon\ncoefficients q j may exhibit a removable singularity in the variable z \u2261 \u2206tL\u0302 (k) at zero wave number that could\ntrigger numerical instability. To remedy this, we represent each quadrature term as a Cauchy integral that allows a\nstable and uniform approximation valid for all wavenumbers. This idea has been first implemented in the context\nof exponential time differencing fourth order Runge-Kutta (ETDRK4) [25]. For the sake of completeness, we\nshow how to implement this approach on the coefficient q1. The computation of the other quadrature coefficients\nfollow similar derivation. Since the function q1(\u03b6 ;\u2206t) is analytic in the \u03b6 complex plane, by the Cauchy integral\nformula we have\n\nq1(z;\u2206t) =\n1\n\n2\u03c0i\n\n\u222b\nC\n\nq1(\u03b6 ;\u2206t)\n\u03b6 \u2212 z\n\nd\u03b6 , (3.11)\n\nwhere C is a circle of constant radius centered at z. The above integral can be evaluated to spectral accuracy with\nthe use of the trapezoidal quadrature [14, 25].\n\n3.2. Time integration: non-periodic boundary conditions. So far, we have discussed the development and\napplication of the TDSR method to evolution equations subject to periodic or localized boundary conditions. Here,\nwe intend to extend the TDSR scheme to allow for non-periodic and non-decaying boundary conditions where the\nuse of Fourier analysis is not applicable. In such circumstances the matrix approximating the linear operator could\nbe banded (as is the case with finite differences) or dense, for example, in case of Chebyshev spectral method.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 7\n\nThe derivation of the Duhamel formula follows similar steps as outlined in Sec.2 with the exception of the use\nof trapezoidal scheme instead of Simpson. Using a Chebyshev basis function or other discretization methods we\nrepresent the differential operator L in Eq. (3.1) by a finite dimensional matrix L. The boundary conditions are\nincorporated within the matrix L. By creating a mesh in time domain, Eq.(3.1) can be put in the recursive form\n\nI(ti+1) = e\u2206tLI(ti)+ e\u2206tL\n\u222b ti+1\n\nti\ne(ti\u2212\u03c4)LG(\u03c4)d\u03c4, (3.12)\n\nwhere now I(ti) is the matrix representing the Duhamel integral at space meshgrid x and time level ti. Additionally,\nG(ti) is the matrix representing the nonlinear terms at ti = i\u2206t with i = 0,1, \u00b7 \u00b7 \u00b7NT . Using a linear interpolant to\napproximation G(\u03c4) in the interval [ti, ti+1] we find\n\nG(\u03c4)\u2248G(ti)+\nG(ti+1)\u2212G(ti)\n\n\u2206t\n(\u03c4\u2212 ti). (3.13)\n\nSubstituting Eq.(3.13) into (3.12) we obtain after some algebra\n\nI(ti+1) = e\u2206tL[I(ti)+AG(ti)+BG(ti+1)], (3.14)\nwhere the matrix valued quadrature coefficients A\u2261 A(L,\u2206t) and B\u2261 B(L,\u2206t) are defined by\n\nA\u2261 \u2206tA\u0303, A\u0303 = L\u0303\u22122\n(\n\ne\u2212L\u0303 + L\u0303\u2212I\n)\n, (3.15)\n\nB\u2261 \u2206tB\u0303, B\u0303 = L\u0303\u22122\n(\nI \u2212 L\u0303e\u2212L\u0303\u2212 e\u2212L\u0303\n\n)\n, (3.16)\n\nwith I being the identity matrix and L\u0303\u2261 \u2206tL. As was done in Sec. 3.1 for the periodic case [25], we again adopt\nthe Cauchy integral formula to represent each quadrature coefficient as a contour integral in the complex plane.\nThus we write :\n\nA\u0303(L\u0303) =\n1\n\n2\u03c0i\n\n\u222b\n\u0393\n\nA\u0303(\u03b6 )(\u03b6I \u2212 L\u0303)\u22121d\u03b6 , B\u0303(L\u0303) =\n1\n\n2\u03c0i\n\n\u222b\n\u0393\n\nB\u0303(\u03b6 )(\u03b6I \u2212 L\u0303)\u22121d\u03b6 (3.17)\n\nwith \u0393 being a circular contour that encloses all the eigenvalues of L\u0303. The integral in Eq.(3.17) is computed to a\nspectral accuracy with the use of the trapezoidal rule.\n\n4. NUMERICAL IMPLEMENTATION OF TDSR: ONE CONSERVATION OR DISSIPATION LAW WITH VARIOUS\nBOUNDARY CONDITIONS\n\n4.1. The KdV equation. In this section, we use the KdV equation as a testbed PDE model to examine various\nnumerical aspects related to the TDSR method such as convergence, accuracy and dependence on initial guesses.\nThe KdV equation is given by:\n\nut +\u03b1uux + \u03b5\n2uxxx = 0, (4.1)\n\nwhere \u03b1,\u03b5 are real and positive numbers. When considered on the whole real line with rapidly decaying boundary\nconditions, Eq.(4.1) admits a one parameter family of soliton solution given by (e.g. \u03b1 = 6,\u03b5 = 1)\n\nuex(x, t) = 2\u03b2\n2sech2(\u03b2 (x\u22124\u03b2 2t)), \u03b2 > 0. (4.2)\n\nIt is noteworthy that the KdV equation is an integrable dynamical system admitting infinitely many conservation\nlaws. Among them are the physically relevant mass, momentum and Hamiltonian given for \u03b1 = 6,\u03b5 = 1 by\nEq. (2.2) with Q1 = u, Q2 = u2 and Q3 = \u2212u3 + 12 u\n\n2\nx , respectively. All numerical simulations reported in this\n\nsection were performed on a spatial domain of size L = 100 or L = 800 (depending on the case at hand) with\ncorresponding number of spatial grid points (Fourier modes) NS = 2048, NS = 16384 respectively and time interval\n[0,T ] with T = 5,10,20,30 or 60. In this section, the renormalization factors were computed by enforcing a single\nconservation law. Numerical convergence and accuracy were quantified by monitoring the error between two\nsuccessive iterations\n\nmax\nx,t\n|u(n+1)(x, t)\u2212u(n)(x, t)|,\n\n\n\n8 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nand the quantities\n\n\u03b4u(t)\u2261max\nx\n|u(x, t)\u2212uex(x, t)|, (4.3)\n\n\u03b4Q j(t)\u2261Q j[u(x, t)]\u2212Q j[u0(x)] , j = 1,2,3, (4.4)\n\nwhere u0(x) = 2\u03b2 2sech\n2(\u03b2x) is the initial condition associated with Eq. (4.1), for the parameters \u03b1 = 6,\u03b5 = 1,\n\nwhere uex(x, t) is the one-parameter soliton solution for the KdV given in Eq. (4.2). For all simulations reported\nhere, convergence tolerance was set near 1\u00d7 10\u221216. All functionals Q j, j = 1,2,3, are defined in Eq. (2.2). We\nperform numerical experiments on the KdV equation while conserving one of the following quantities: mass,\nmomentum, or Hamiltonian. The renormalization factor R(t) in each case, is given by:\n\nmass: R(t) =\nQ1[u0(x)]\nQ1[v(x, t)]\n\n, (4.5)\n\nmomentum: R(t) =\n(\n\nQ2[u0(x)]\nQ2[v(x, t)]\n\n)1/2\n, (4.6)\n\nHamiltonian: A(t)R3(t)\u2212B(t)R2(t)\u2212C3 = 0, (4.7)\nwhere A(t) =\u2212\n\n\u222b\nR v\n\n3(x, t)dx, B(t) =\u2212 12\n\u222b\nR v\n\n2\nx dx and C3 is the initial value of the Hamiltonian. All spatial integrals\n\nare computed to spectral accuracy with the use of fast Fourier transform. We initialize the TDSR algorithm with\na space-time random function v(1)(x, t) constructed by superimposing several Gaussians each being centered at a\nrandom location and having a random time-dependent amplitude. The centers and amplitudes are sampled from\na uniform distribution on the interval [\u2212L/2,L/2] and [\u22121,1] respectively. To ensure the initial guess v(1)(x, t)\nsatisfies the underlying boundary conditions, we mollify it with \u03c7(x). Thus, we have\n\nv(1)(x, t) =\n\u2211\n\nNG\nn=1 an(t)exp\n\n[\n\u2212\n( x\u2212cn\n\nd\n\n)2]\nmaxx,t |\u2211\n\nNG\nn=1 an(t)exp\n\n[\n\u2212\n( x\u2212cn\n\nd\n\n)2]|\u03c7(x), (4.8)\nwhere NG denotes the number of Gaussians with cn and an(t) representing their centres and time-varying ampli-\ntudes and d is the width. Here, \u03c7(x) is the mollifier with unit peak amplitude defined by:\n\n\u03c7(x) =\n\n\uf8f1\uf8f2\n\uf8f3exp\n\n(\nb\na2\n\u2212 b\n\na2\u2212x2\n\n)\n, if x \u2208 (\u2212a,a)\n\n0, if |x|> a,\n(4.9)\n\nwith arbitrary mollifier parameters a and b. As expected, the numerical result agrees well with the exact solution.\nIn generating Fig. 1, conservation of momentum is imposed in which case the renormalization parameter R(t) is\ncomputed from Eq. (4.6). One could instead reach the same conclusion by using a different dynamic renormal-\nization process emanating from either conservation of mass or Hamiltonian. This numerical experiment reveals\nthe simplistic (albeit powerful) nature of our proposed method as measured by its easy formulation, actual im-\nplementation, robustness to initial guesses and its ability to impose conservation laws \u201con-demand\u201d. To further\ncharacterize the numerical performance of the TDSR scheme, we have investigated its temporal convergence prop-\nerties by measuring the space-time maximum error between the numerically obtained solution to the KdV equation\n(relative to its exact solution) and all conservation laws, as quantified by Eqs. (4.3) and (4.4), as a decreasing func-\ntion of time step \u2206t. It is evident from Fig. 2(a) that the maximum (over time) error in the solution decreases at\na fourth order rate. This trend seems to persist independently of the choice of specific conservation law. When\nconservation of mass is imposed, the error in the Hamiltonian and momentum reduces with decreasing \u2206t. Similar\nscenarios occur when imposing conservation of momentum or Hamiltonian \u2013 see Fig. 2 (b)-(d). We remark that\nto conserve the Hamiltonian structure, we need to solve a cubic equation defined by Eq. (4.7). As such, there are\nthree possible expressions for the renormalization factor, of which only one is feasible. It turns out that the right\nexpression yields R(0)v(x,0) = u0(x) at any Duhamel iteration, while the other two roots violate this criterion.\nFinally, for cases where the renormalization factor satisfies an associated equation that lacks exact solution, one\nneeds to resort to a root finding algorithms such as the Newton\u2019s method. It is interesting to note that when it\ncomes to long time simulations, the TDSR performs optimally when imposing conservation of momentum rather\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 9\n\n0 5 10 15 20\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\nj/\nu\n(t\n\n)j\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n#10 -10 (c)\n\nFIGURE 1. (a) A random space-time initial guess constructed from a linear superposition of randomly\ncentered Gaussians with random amplitudes \u2013 see Eq.(4.8). (b) Numerical solution for the KdV equation\nobtained from the TDSR algorithm after 30 Duhamel iterations. Parameters are: T = 20,\u2206t = 0.025,L =\n100,NS = 2048 (Fourier modes). Here, the wave speed is 4\u03b2 2 = 2/5. This figure was generated by impos-\ning conservation of momentum for which the renormalization parameter R(t) is computed from Eq. (4.6).\nThe soliton initial condition is u0(x) = 2\u03b2 2sech\n\n2(\u03b2x) with \u03b1 = 6 and \u03b5 = 1. (c) Time evolution of the\nrelative error between the TDSR and the exact solution. Mollifier parameters are a = 0.95\u00d7 L2 , b = 1.\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -10\n\n10 -5\n\n10 0\n\nm\na\nx\n\ntj/\nu\n(t\n\n)j\n=\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n(a)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -30\n\n10 -15\n\n10 0\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j\n=\njQ\n\n1\n[u\n\n0\n]j\n\n(b)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -15\n\n10 -10\n\n10 -5\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j\n=\njQ\n\n2\n[u\n\n0\n]j\n\n(c)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -15\n\n10 -10\n\n10 -5\n\n10 0\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j\n=\njQ\n\n3\n[u\n\n0\n]j\n\n(d)\n\nFIGURE 2. The relative error in (a) TDSR solution, (b) mass, (c) momentum, and (d) Hamiltonian. Pa-\nrameters are T = 10, L = 100, NS = 2048. The renormalization factor R(t) is computed by enforcing either\nconservation of mass (red), momentum (green), or Hamiltonian (blue).\n\nthan mass or Hamiltonian. Indeed, we have tested the TDSR method on the long-time evolution of the 1-soliton so-\nlution for the KdV equation while conserving momentum (the L2 norm of the solution). The numerical experiment\nwas performed with parameters T = 240,\u2206t = 0.1875,NS = 4096,L = 300 using the idea of multi-blocking with\nMb = 8 time blocks (see remark below). The relative error in the solution, mass and Hamiltonian at end time were\nin the order of 10\u22126, 10\u22127 and 10\u221210 respectively, while the relative error in momentum remained near machine\nprecision.\nRemark: Below, we describe the idea of multi-blocking used when the time interval is too large for the renor-\nmalized Picard iterations to converge (this is not due to a CFL-type restriction prevalent in generic time-stepping\nschemes). The idea is to divide the full time interval [0,T ] into Mb sub-intervals such that [0,T ] = \u222a\n\nMb\ni=1[Ti\u22121,Ti]\n\nwith T0 = 0. For a fixed i, the quantity Ti\u2212Ti\u22121 is chosen sufficiently large so that the spectral renormalization\nalgorithm is efficient and convergent. On the first segment [0,T1], the solution of the TDSR scheme with the initial\ncondition u0(x) is obtained from the iteration:\n\nv(n+1)(x, t) =\n1\n\nR(n)(t)\n\n(\netL [u0(x)]+\n\n\u222b t\n0\n\ne(t\u2212\u03c4)L N [R(n)(\u03c4)v(n)(x,\u03c4)]d\u03c4\n)\n,\n\n\n\n10 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nwhile on the second segment [T1,T2], from:\n\nv(n+1)(x, t) =\n1\n\nR(n)(t)\n\n(\ne(t\u2212T1)L [u(x,T1)]+\n\n\u222b t\nT1\n\ne(t\u2212T1\u2212\u03c4)L N [R(n)(\u03c4)v(n)(x,\u03c4)]d\u03c4\n)\n.\n\nThe renormalization factor R(n)(t) (corresponding to a single conservation law) is obtained from\n\nQm\n(\n\nR(n)(t)v(n)(x, t)\n)\n=Cm.\n\nThis process is repeated Mb times until final time T is reached. It should be pointed out that the number of\nsegment Mb is chosen such that the Duhamel fixed point iteration, without renormalization, would diverge on any\ngiven sub interval [Ti\u22121,Ti].\n\n4.2. Zabusky-Kruskal experiment. Our goal in this section is to reproduce the well-known numerical results\nof Zabusky and Kruskal on the KdV equation [44] using our algorithm. Their simulation displays rich nonlinear\ndynamics which, as such, represents a challenge for numerical methods as far as the choice of time-steps, long-\ntime accuracy and stability are concerned [10, 13, 15, 36]. To this end, we apply the TDSR method on the KdV\nEq. (4.1) with \u03b1 = 1 and \u03b5 = 0.022 subject to periodic boundary conditions u(x+2, t) = u(x, t) and initial condition\nu0(x) = cos(\u03c0x). Figure 3 (a) shows the Zabusky-Kruskal results while rigorously conserving the momentum\u222b 2\n\n0 u\n2dx. We compare our findings with those obtained using the ETDRK4 method [25]. Note that, in order to keep\n\nthe level of solution accuracy of the ETDRK4 method comparable with that of the TDSR scheme while conserving\nmomentum, the time step \u2206tET D (of the ETDRK4) has to be about one order of magnitude lesser than its TDSR\ncounterpart (\u2206tT DSR). This can be seen by gradually reducing the relative time step (\u2206tr = \u2206tET D/\u2206tT DSR) while\nmonitoring the relative difference between the two numerical solutions. At \u2206tr = 0.125, this difference was seen to\ndrop to O(10\u22126). Using the same spatio-temporal discretization as before, we checked the TDSR results\u2019 fidelity\nup to 20 recurrence times. This was done, by monitoring the time evolution of the first six conserved quantities of\nthe KdV equation with \u03b1 = 1 and \u03b5 = 0.022 given by:\n\nQ1 = u, Q2 = u\n2\n\nQ3 =\u2212\nu3\n\n6\n+\n\n\u03b5\n2u2x\n2\n\n, Q4 =\nu4\n\n4\n\u22123\u03b52uu2x +\n\n9\u03b54u2xx\n5\n\n,\n\nQ5 =\nu5\n\n5\n\u22126\u03b52u2u2x +\n\n36\u03b54uu2xx\n5\n\n\u2212\n108\u03b56u2xxx\n\n35\n,\n\nQ6 =\nu6\n\n6\n\u221210\u03b52u3u2x +18\u03b5\n\n4u2u2xx\u22125\u03b5\n4u4x\u2212\n\n108\u03b56uu2xxx\n7\n\n+\n120\u03b56u3xx\n\n7\n+\n\n36\u03b58u2xxxx\n7\n\n.\n\nClearly, the relative error in the momentum remains close to machine precision, while at the same time resulting\nin the conservation of the mass as well. This can be explained by considering the Fourier series representations of\nthe KdV solution u(x, t) = \u2211\u221em=\u2212\u221e u\u0302m(t)e\n\ni\u03c0mx, and its corresponding auxiliary function v(x, t) = \u2211\u221em=\u2212\u221e v\u0302m(t)e\ni\u03c0mx.\n\nWith this at hand, the (n+1)th renormalized Duhamel iterate takes the form:\n\nv\u0302(n+1)m (t) =\n1\n\nR(n)(t)\n\n(\nei\u03b5\n\n2m3\u03c03t u\u0302m(0)\u2212\n\u222b t\n\n0\nei\u03b5\n\n2m3\u03c03(t\u2212\u03c4) im\u03c0\n2\n\n\u221e\n\n\u2211\nl=\u2212\u221e\n\nu\u0302(n)l u\u0302\n(n)\nm\u2212ld\u03c4\n\n)\n(4.10)\n\nwhere (R(n)(t))2 =C2/\n(\u222b 2\n\n0\n\n(\nv(n)(x, t)\n\n)2\ndx\n)\n\n. Substituting m = 0 in Eq. (4.10), we obtain:\n\nv\u0302(n+1)0 (t) =\nu\u03020(0)\n\nR(n)(t)\n. (4.11)\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 11\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\nu\n\n(b)\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\nu\n\n(c)\n\nTDSR\nETDRK4\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nu\n\n(e)\n\nFIGURE 3. (a) Space-time contour plot for the KdV solution with \u03b1 = 1,\u03b5 = 0.022 and initial condition\nu(x,0) = cos(\u03c0x). Other parameters are \u2206t \u2248 0.0008, L = 2, NS = 256 and the time block size T1 \u2248 0.016\n(multi-blocking with Mb sub-intervals of equal size). (b) The solution at T = 3.6/\u03c0 depicting the fission\nof the initial condition into an eight soliton train. (c) The solution at one recurrence time T = tR = 30.4/\u03c0\nobtained via TDSR Simpson showing good agreement with the fourth-order accurate (in time) ETDRK4\nsolution. A time step of \u2206t = 0.0001 (for the ETDRK4 scheme) was used to obtain a solution of comparable\naccuracy to ours. (d) A space-time contour plot for the solution obtained from the TDSR algorithm using\nthe same spatio-temporal discretization as in (a), over the time span [19tR,20tR]. The stable numerical\nsimulation produced accurate results, as evidenced by the minor relative errors in the first six conserved\nquantities (see Fig. 4). (e) The solution at T = 20tR obtained using TDSR Simpson.\n\nUsing the identity u\u0302(n+1)0 (t) = R\n(n+1)(t)v\u0302(n+1)0 (t) we find\n\nu\u0302(n+1)0 (t) =\n\n\u221a\u221a\u221a\u221a\u221a\u221a\n\u222b 2\n\n0\n\n(\nv(n)(x, t)\n\n)2\ndx\n\n\u222b 2\n0\n\n(\nv(n+1)(x, t)\n\n)2\ndx\n\nu\u03020(0). (4.12)\n\nFor the initial condition considered here u0(x) = cos(\u03c0x), one finds u\u03020(0) = 0, resulting in u\u0302\n(n+1)\n0 (t) \u2261 0, i.e.,\n\nthe mass is also preserved at every Duhamel iterate. Additionally, the relative errors of the other four conserved\nquantities are within O(10\u22125). In particular, some aspects of our scheme (such as solution accuracy) outperforms\nother well known conservative numerical methods to simulate the KdV equation, such as the one developed in [13].\nIn [13], the authors develop an operator splitting scheme in conjunction with a finite volume spatial discretization\nto locally conserve the mass and momentum. While their scheme demonstrates impressive long time stability\nproperties (Zabusky-Kruskal dynamics), there were some phase errors at T = 20tR, that arise from the global\n(absolute) errors in the conservation of the Hamiltonian (\u223c 10\u22123).\n\nPresently, it is unclear if there are other finite volume based schemes capable of incorporating more than two\nconserved quantities for the KdV equation. Also, it is worth to mention that the ETDRK4 scheme (which does not\nconserve momentum at the local or global level for the KdV), suffers from numerical instabilities (for \u2206t \u2248 0.0008)\nand for time integration up to T = 20tR.\n\nFinally, we examine the performance of the TDSR method by measuring the local errors in the mass and\nmomentum. Specifically, we compute the errors for mass and momentum at end time T = 20tR respectively\ndefined by\n\nE1(x,T ) = ut +\u03b1uux + \u03b5\n2uxxx, (4.13)\n\n\n\n12 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n50 100 150 200\n0\n\n0.5\n\n1\n\n1.5\n\nj/\nQ\n\n1\n(t\n\n)j\n\n#10 -15 (a)\n\n50 100 150 200\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\nj/\nQ\n\n2\n(t\n\n)j\n=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -16 (b)\n\n50 100 150 200\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\nj/\nQ\n\n3\n(t\n\n)j\n=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -5 (c)\n\n50 100 150 200\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\nj/\nQ\n\n4\n(t\n\n)j\n=\njQ\n\n4\n[u\n\n0\n]j\n\n#10 -7 (d)\n\n50 100 150 200\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nQ\n\n5\n(t\n\n)j\n=\njQ\n\n5\n[u\n\n0\n]j\n\n#10 -5 (e)\n\n50 100 150 200\nt\n\n0\n\n2\n\n4\n\n6\n\n8\n\nj/\nQ\n\n6\n(t\n\n)j\n=\njQ\n\n6\n[u\n\n0\n]j\n\n#10 -7 (f)\n\nFIGURE 4. Errors in conserved quantities for the Zabusky-Kruskal test case monitored over the time-span\n[0, 20tR]; computational parameters for the simulation can be found in caption of Fig. 3: (a) absolute error\nin the mass (the initial mass Q1[u0] = 0), relative errors in (b) momentum (L2-norm), (c) Hamiltonian,\n(d) fourth conserved quantity (Q4[u0]), (e) fifth conserved quantity (Q5[u0]) and (f) sixth conserved quan-\ntity (Q6[u0]). By construction, the relative error in the conservation of momentum is kept near machine\nprecision, while the absolute error in mass remains at \u223c 10\u221215.\n\n0 1 2\nx\n\n-5\n\n0\n\n5\n\nE 1\n(x\n\n;t\n=\n\n2\n0\nt R\n\n)\n\n#10 -5 (a)\n\n0 1 2\nx\n\n-5\n\n0\n\n5\n\nE 2\n(x\n\n;t\n=\n\n2\n0\nt R\n\n)\n\n#10 -5 (b)\n\nFIGURE 5. A snapshot of the local errors in (a) conservation of mass (E1(x, t)) and (b) conser-\nvation of momentum (E2(x, t)) as a function of x at time T = 20tR.\n\nE2(x,T ) = (u\n2/2)t +\n\n(\n\u03b1\n\n3\nu3 + \u03b52\n\n(\nuuxx\u2212u2x/2\n\n))\nx\n. (4.14)\n\nThe time derivatives are computed using the fourth-order backward differentiation formula [35]:\n\nut(xm,T )\u2248\n\n(\n25u(xm,T )\u221248u(xm,T \u2212\u2206t)+36u(xm,T \u22122\u2206t)\u221216u(xm,T \u22123\u2206t)+3u(xm,T \u22124\u2206t)\n\n)\n12\u2206t\n\n, (4.15)\n\nwhereas, all the spatial derivatives were computed to spectral accuracy with the use of fast Fourier transforms.\nFig. 5 shows the variations of E1 and E2 as a function of x at time T = 20tR. Remarkably, the local errors remain\nrelatively small even over such long time intervals.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 13\n\n0.01 0.015 0.02\nt\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nj/\nu\n(t\n\n)j\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n#10 -4 (b)\n\nFIGURE 6. (a) Travelling wave solution for the Allen-Cahn equation with simulation parameters: L = 4,\n\u03b5 = 0.05, NS = 1024, \u2206t = 0.000125, and end time T = 0.02. Solution advanced to the final time with the\nidea of multi-blocking with sub-interval size T1 = 0.01. The error in solution was restricted to 6.3\u00d710\u22124\nwith this parameter choice. (b) The absolute error, in time, between the TDSR numerical and the exact\nsolutions in the time interval [0.01,0.02].\n\n4.3. Travelling waves for the Allen-Cahn equation. In this section, we apply the TDSR method on the Allen-\nCahn equation, a prototypical reaction-diffusion type equation that arises in material science [8]. It is given by\n\nut = Duxx + \u03b3(u\u2212u3), (4.16)\nwhere D > 0 is the diffusion coefficient and \u03b3 measures the strength of reaction. The Allen-Cahn equation is\ndissipative in nature. In fact when subject to homogeneous Dirichlet/Neumann boundary conditions (considered\nin this paper), multiplying Eq. (4.16) by 2u and integrating over the whole domain leads to the dissipation rate\nEq. (2.3) with density and flux:\n\n\u03c1 = u2, F = 2Du2x\u22122\u03b3(u\n2\u2212u4). (4.17)\n\nIn this case, as we shall see later, the renormalization factor R(t) obeys a nonlinear ordinary differential equation.\nWe present numerical results on two canonical problems associated with the Allen-Cahn equation: (i) dynamics\nof traveling waves and (ii) observation of meta-stable dynamics. Both examples represent a departure from the\nperiodic case for which the linear operator L is diagonalizable. Indeed, for the Allen-Cahn equation, the discrete\nrepresentation of L is now dense as is the case when using spectral differentiation matrices. Thus, the semi-\ngroup exp(tL ) forms a rank-3 tensor. We implement the TDSR method on the Allen-Cahn Eq. (4.16) to compute\ntraveling waves with diffusion coefficient D = 1 and large reaction parameter \u03b3 that scales like \u03b5\u22122, with \u03b5 \ufffd 1.\nEquation (4.16) is subject to the initial condition u(x,0) = 0.5\u2212 0.5tanh\n\n(\nx/(2\n\u221a\n\n2\u03b5)\n)\n\nand Neumann boundary\nconditions: ux(x, t)\u2192 0 as |x| \u2192 \u221e. Interestingly enough, the Allen-Cahn Eq. (4.16) admits an exact travelling\nwave solution given by u(x, t) = 0.5\u2212 0.5tanh\u03be/(2\n\n\u221a\n2\u03b5), \u03be = x\u2212 3t/(\n\n\u221a\n2\u03b5) [24]. It is the aim of this section\n\nto reproduce this exact solution using the TDSR while enforcing the dissipation rate equation given in (2.3) and\n(4.17). We proceed by substituting the ansatz u(x, t) = R(t)v(x, t) into Eq. (4.16); multiply by 2u and integrate the\nresulting system over the whole computational domain to obtain a first order dynamical system for the variable\np(t)\u2261 r(t)R2(t):\n\nd p\ndt\n\n= (\u2212a(t)+2\u03b3)p\u2212b(t)p2, (4.18)\n\nwhere the expressions for the time-dependent coefficients r(t), a(t) and b(t)> 0 are given by (here \u2126 denotes the\nspatial domain of the Allen-Cahn equation)\n\nr(t) =\n\u222b\n\n\u2126\n\nv2(x, t)dx, a(t) =\n2D\n\u222b\n\n\u2126\nv2x(x, t)dx\nr(t)\n\n, b(t) =\n2\u03b3\n\u222b\n\n\u2126\nv4(x, t)dx\nr2(t)\n\n. (4.19)\n\nThe presence of the large coefficient \u03b3 \u223c \u03b5\u22122 in Eq.(4.18) causes the differential equation to become stiff,\nthus severely limiting the choice of time-steps. With this in mind, we use an implicit scheme (such as Crank-\nNicolson) to time-step (4.18) [35]. The coefficients r(t), a(t) and b(t) are computed to spectral accuracy using\n\n\n\n14 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nFIGURE 7. (a) Spatio-temporal field distribution illustrating the meta-stable dynamics. Simulations were\nperformed using the idea of multi-blocking with block size T1 = 8 and final time T = 80. Computational\nparameters: NS = 256, \u2206t \u2248 0.016. (b) Comparison with the ETDRK4 scheme (at end time), showing a\ngood agreement with the TDSR trapezoidal result.\n\nClenshaw-Curtis quadrature method [39]. The spatial domain \u2126 is truncated, in which case, x \u2208 [\u2212L/2,L/2]\nand taking advantage of the spatial decay of ux to enforce homogeneous Neumann boundary conditions. Several\nremarks are in order: (i) The Chebyshev (Chebyshev-Lobatto) series representation is originally developed for\nfunctions defined on the interval [\u22121,1]. It can, nonetheless be applied on the interval [\u2212L/2,L/2] using a linear\ntransformation. (ii) We incorporate the homogeneous Neumann boundary conditions following similar procedure\nas outlined in [29]. For example, the second derivative is represented by the matrix product DD0 with D being\nthe standard first order spectral differentiation matrix while D0 is the first order differentiation matrix whose first\nand last rows have been replaced by the zero-vector respectively. This implicitly enforces the underlying boundary\nconditions. The numerical results obtained in this section are summarized in Fig. 6 where a surface plot describing\nthe time evolution of the traveling wave as well as its numerical accuracy are shown.\n\n4.4. Meta-stable dynamics of the Allen-Cahn equation. Our last example is concerned with the dynamics of\na meta-stable state associated with the Allen-Cahn Eq. (4.16) with parameters D = 0.01,\u03b3 = 1 and subject to the\nboundary conditions u(\u22121, t) =\u22121, u(1, t) = 1 and initial condition u(x,0) = 0.53x+0.47sin(\u22121.5\u03c0x). This test\nbed case is particularly interesting since the dynamics of an initial hump is observed to be meta-stable, i.e., it\nremains unchanged over long time, before abruptly vanishing. This type of rapid change in the wave profile over\nshort time scales inevitably creates numerical challenges. Such dynamic metastability was numerically observed\nby Kassam and Trefethen [25] using the modified ETDRK4 scheme. In this section, we demonstrate the robust-\nness of our TDSR method by reproducing this type of abrupt transition from a meta-stable state to another stable\nwavefunction profile. Here, the renormalization factor R(t) is governed by the same nonlinear ordinary differential\nequation Eq. (4.18) with the exception that now the parameters are D = 0.01,\u03b3 = 1 with a spatial domain [\u22121,1].\nFew remarks are in order: (i) To simplify the computation, we first homogenize the boundary conditions by de-\nriving a new evolution equation on which the TDSR method is implemented. (ii) To impose Dirichlet boundary\nconditions, the operator d2/dx2 is approximated by D2 where D is the first order spectral differentiation matrix\n[39]. The time evolution of the Allen-Cahn front is shown in Fig. 7 (a). As expected, our method is indeed ca-\npable of reproducing those well known results. We have also compared our results with those obtained using the\nETDRK4 scheme and found good agreement (see Fig. 7 (b) for a comparison at end time).\n\n5. NUMERICAL IMPLEMENTATION OF TDSR WITH MULTI-CONSERVATION LAWS\n\nSo far we have addressed several cases where a single conservation law is \u201cinjected\u201d into the numerical sim-\nulations. In this section, we shall present results when multiple conservation laws are enforced. There are three\nchoices that we considered: conservation of (i) mass and momentum; (ii) mass and Hamiltonian ; (iii) mass, mo-\nmentum and Hamiltonian. All numerical results reported in this section are for the KdV equation (4.1), subject to\nrapidly decaying boundary conditions with \u03b1 = 6 and \u03b5 = 1.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 15\n\nWe remark that the pseudo initial conditions f j(x), j = 1,2, \u00b7 \u00b7 \u00b7 ,N, introduced in the TDSR formulation (see\nEqs. 2.11-2.13) are crucial for the success of the method. They greatly control the scheme\u2019s convergence and allow\nthe renormalization factors to act as \u201cexpansion\u201d coefficients. Our numerical tests strongly indicate that taking none\nof the pseudo-initial conditions be identically equal to zero, (albeit satisfying the underlying boundary conditions),\nin order for the scheme to converge. With this in mind, a natural and important issue that immediately arises is\nhow to choose them? Our extensive numerical experiments seem to suggest that the natural choice f j(x)\u2261\u03b1 ju0(x)\nwith non-zero constant \u03b1 j\u2019s does not lead to convergence. However, several other possible choices for f j are given\nby f j(x) = \u03b1 j(x)u0(x) where \u03b1 j(x) are spatially localized functions. For evolution equations in (1+1)D subject\nto rapidly decaying boundary conditions (such as the KdV, NLS, mKdV), the algorithm seems to converge (at least\nover some time interval) when the first (N\u22121) f j(x) are chosen to belong to the class of bell-shaped, sign-definite\nfunctions. For example, f j \u2208 {sech(x),e\u2212x\n\n2\n,sech2(x)} for j = 1,2, \u00b7 \u00b7 \u00b7(N\u22121), while the entire set of pseudo-initial\n\nconditions is required to satisfy the normalization condition in Eq. (2.9). A full characterization on the choice of\nthe pseudo-initial conditions f j(x) is the subject for future work.\n\n5.1. Conservation of mass and momentum. Here the KdV solution is decomposed in the form: u(x, t) =\nR1(t)v1(x, t)+R2(t)v2(x, t), where R1(t) and R2(t) are computed from the coupled system\n\nQ j [R1(t)v1(x, t)+R2(t)v2(x, t)] = Q j\n[\n2\u03b2 2sech2(\u03b2x)\n\n]\n, j = 1,2. (5.1)\n\nWe choose f1(x) = (1/300)sech\n(\n\nx/\n\u221a\n\n600\n)\n\n, and f2(x) = u0(x)\u2212 f1(x). The explicit expressions for R1(t) and\nR2(t) can be obtained from the coupled system\n\nR1(t) =\nC1\u2212A2(t)R2(t)\n\nA1(t)\n, and \u00b51(t)R\n\n2\n2 +\u00b52(t)R2 +\u00b53(t) = 0,\n\nwhere\n\u00b51(t) = A3A\n\n2\n2 +A4A\n\n2\n1\u22122A1A2A5, \u00b52(t) = 2A1A5C1\u22122A2A3C1, \u00b53(t) = A3C\n\n2\n1 \u2212C2A\n\n2\n1,\n\nand\n\nA1(t) =\n\u222b\nR\n\nv1(x, t)dx, A2(t) =\n\u222b\nR\n\nv2(x, t)dx, A3(t) =\n\u222b\n\n\u221e\n\n\u2212\u221e\nv21(x, t)dx,\n\nA4(t) =\n\u222b\nR\n\nv22(x, t)dx, A5(t) =\n\u222b\nR\n\nv1(x, t)v2(x, t)dx.\n\nNumerical tests indicate that the algorithm converges to the correct solution when using the root R2(t) = [\u2212\u00b52(t)+\u221a\n\u00b5\n\n2\n2 (t)\u22124\u00b51(t)\u00b53(t)]/[2\u00b51(t)], while the other one causes the TDSR algorithm to diverge. The correct root was\n\nfound to always satisfy R2(0)v2(x,0) = f2(x) at any Duhamel iteration while the other consistently violated it.\nFigure 8 shows results of TDSR simulations where mass and momentum are both conserved. Another interesting\nnumerical experiment (discussed below), is related to interaction (or collision) between two 1-soliton solutions to\nthe KdV equation. The corresponding initial condition is\n\nu0(x) = 2\u03b2\n2\n1 sech\n\n2 (\u03b21x)+2\u03b2\n2\n2 sech\n\n2 (\u03b22(x\u2212 x0)) , (5.2)\nwith \u03b21 =\n\n1\u221a\n10\n, \u03b22 =\n\n1\n2\n\u221a\n\n10\nand an initial separation of x0 = 40. We simulated this to end time T = 200 using the idea\n\nof multi-blocking (see Fig. 9). The solitons interact elastically, mainly emerging unscathed from the interaction,\nsuffering only from a phase shift as expected. As before, we prescribed f1(x) = (1/300)sech\n\n(\nx/\n\u221a\n\n600\n)\n\n, while\nf2(x) = u0(x)\u2212 f1(x).\n\n\n\n16 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\nj/\nu\n(t\n\n)j\n=\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n#10 -4\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j\n=\njQ\n\n1\n[u\n\n0\n]j #10 -16\n\n0 50\nt\n\n0\n\n2\n\n4\n\n6\n\n8\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j\n=\njQ\n\n2\n[u\n\n0\n]j #10 -16\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j\n=\njQ\n\n3\n[u\n\n0\n]j #10 -6\n\nFIGURE 8. (a) Time evolution of the relative error between the numerically obtained solution for the KdV\nequation compared to its exact solution given in Eq. (4.3). Time evolution of the conserved quantities given\nin Eq. (4.4): mass (b), momentum (c) and Hamiltonian (d). Note that the relative errors in conservation\nof mass and momentum stay close to machine precision. Parameters are: L = 800, \u2206t = 0.5, T = 60,\nNs = 16384 with the renormalization factors obtained from system (5.1) for j=1, 2. Note the renormalized\nDuhamel iterations converge over such a large time-span, a significant improvement over when a single\nquantity is conserved.\n\nFIGURE 9. Interaction between two 1-soliton solution for the KdV equation with \u03b1 = 6,\u03b5 = 1 and initial\ncondition u(x,0) = (1/5)sech2\n\n(\nx/\n\u221a\n\n10\n)\n+(1/20)sech2\n\n(\n(x\u221240)/2\n\n\u221a\n10\n)\n. Other parameters are \u2206t = 0.5,\n\nL= 800, NS = 16384 and the time block size T1 = 20. The renormalization factors are obtained by enforcing\nthe conservation of mass and momentum simultaneously. The relative error in Hamiltonian \u2248 7.86\u00d710\u22126\nat T = 200, while relative error in mass\u2248 1.9\u00d710\u221216 and momentum\u2248 5.9\u00d710\u221216 are kept near machine\nprecision.\n\n0 10 20 30\nt\n\n0\n\n0.5\n\n1\n\nj/\nu\n(t\n\n)j\n=\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n#10 -4\n\n0 10 20 30\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j\n=\njQ\n\n1\n[u\n\n0\n]j\n\n#10 -16\n\n0 10 20 30\nt\n\n0\n\n1\n\n2\n\n3\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j\n=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -7\n\n0 10 20 30\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j\n=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -16\n\nFIGURE 10. (a) Time evolution of the relative error between the numerically obtained (TDSR) solution\nto the KdV equation with conservation of mass and Hamiltomian compared to its exact solution given in\nEq. (4.3). Time evolution of the conserved quantities given in Eq. (4.4): mass (b), momentum (c) and\nHamiltonian (d). Note that the relative errors in conservation of mass and Hamiltonian now stay close to\nmachine precision. Parameters are: L = 800, \u2206t = 0.5, T = 30, Ns = 16384 with the renormalization factors\nobtained from system (5.1) for j=1, 3.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 17\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nu\n(t\n\n)j\n=\njju\n\ne\nx\n(x\n\n;t\n)j\nj 1\n\n#10 -4\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j\n=\njQ\n\n1\n[u\n\n0\n]j\n\n#10 -16\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j\n=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -16\n\n0 2 4\nt\n\n0\n\n2\n\n4\n\n6\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j\n=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -16\n\nFIGURE 11. (a) Time evolution of the relative error between the numerically obtained solution, from\nTDSR with conservation of mass, momentum and Hamiltonian, for the KdV equation compared to its\nexact solution given in Eq. (4.3). Time evolution of the conserved quantities given in Eq. (4.4): mass\n(b), momentum (c) and Hamiltonian (d). Parameters are: \u2206t = 0.5, T = 5, Ns = 2048, L = 100 with the\nrenormalization factors obtained from Eqs.(5.3).\n\n5.2. Conservation of mass and Hamiltonian. In this case, the renormalization factors R1(t) and R2(t) are now\ncomputed from the coupled system of equations given in (5.1) with j taking the values 1 and 3. Like before,\nwe pick the pseudo-initial conditions to be f1(x) = (1/300)sech\n\n(\nx/\n\u221a\n\n600\n)\n\nand f2(x) = u0(x)\u2212 f1(x). We solved\nsystem (5.1) for j = 1,3 using the Newton\u2019s method. Our findings are similar to those reported for the simultaneous\nconservation of mass and momentum, i.e., conservation of mass and Hamiltonian are achieved (see Fig. 10).\n\n5.3. Conservation of mass, momentum and Hamiltonian. Lastly, we seek three renormalization factors R1(t),\nR2(t) and R3(t) that satisfy u(x, t) = \u2211\n\n3\nj=1 R j(t)v j(x, t) and obey the conservation laws\n\nQ j\n\n[\n3\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\n= Q j\n\n[\n2\u03b2 2sech2(\u03b2x)\n\n]\n, j = 1,2,3. (5.3)\n\nUnlike the previous cases, of mass-momentum and mass-Hamiltonian conservation, two of the current conserved\nquantities now are nonlinear functionals further limiting the choices for the pseudo-initial conditions as far as\nthe convergence over large time intervals is concerned. It turns out that convergence over moderately long time\nintervals (T = 5) is achieved with pseudo-initial conditions in the Duhamel integral formulas Eqs. (2.11) and (2.13)\nas f3(x) = 0.15exp(\u2212x2), f2(x) = 0.05exp(\u2212x2) and f1(x) = u0(x)\u2212 f2(x)\u2212 f3(x). The renormalization factors\nare found from the coupled system of equations derived from enforcing the conservation of mass, momentum and\nconservation of Hamiltonian simultaneously Eq. (5.1) for j = 1,2,3, using the Newton\u2019s root finding method. The\nresults are depicted in Fig. 11 where the error in the momentum, Hamiltonian and mass are kept at the level of\nmachine precision.\n\n6. TDSR METHOD: MULTI-DIMENSIONAL TEST CASE\n\nThe nonlinear Schro\u0308dinger equation\n\niut +V (x)u+\u22072u+ |u|2u = 0, (6.1)\nplays an important role in modeling fundamental physics ranging from photonics, Bose-Einstein condensation to\nfluid mechanics [1]. Depending on the physics at hand, \u22072 = \u2202 2/\u2202x2 +\u2202 2/\u2202y2 denotes wave diffraction, V is the\nrefractive index, photonic lattice or an external potential and |u|2 measuring the intensity or density of a complex\nvalued wavefunction u. As such, using the TDSR method to simulate the NLS equation would seem natural. In\nthe absence of any external potential (V (x) = 0), Eq. (6.1) admits a special class of solutions known as the Townes\n\n\n\n18 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n0 1 2\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nu\n(t\n\n)j\n=\njju\n\n0\n(x\n\n;y\n)j\nj 1\n\n#10 -5 (a)\n\n0 1 2\nt\n\n0\n\n1\n\n2\n\n3\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j\n=\njQ\n\n1\n[u\n\n0\n(x\n\n;y\n)]\nj #10\n\n-16 (b)\n\nFIGURE 12. (a) The error in the TDSR solution, as defined relative to the initial profile of the Townes\nsoliton, (b) the relative error in the power as a function of time t. As one can see, it is kept close to machine\nprecision over the entire time span [0,2]. Parameters are: \u2206t = 0.05, a square spatial domain with L = 40 ,\nand a spatial discretization of 512\u00d7512 for the computations.\n\nsolitons. They are of the form u(x, t) = U\u03bb (x)ei\u03bb\n2t ,\u03bb \u2208 R with real valued function U\u03bb satisfying the boundary\n\nvalue problem\n\n\u2207\n2U\u03bb +U\n\n3\n\u03bb\n= \u03bb 2U\u03bb . (6.2)\n\nThe numerical computation of the Townes soliton is well documented in the literature and can be achieved with\nthe use of various boundary value problem solvers (Quasi-Newton methods, spectral renormalization, etc. [3, 26,\n27, 41]). While the implementation of the TDSR method on the NLS equation was first reported in [11] it was\nexemplified in one spatial dimension for which the semi-group exp(it\u2202 2/\u2202x2) lives in (1+ 1) dimensions. Here,\nthe (1+2)D NLS equation, subject to sufficiently rapidly decaying boundary conditions is chosen as a prototypical\nexample to demonstrate the applicability of the TDSR scheme in multiple spatial dimensions. The NLS Eq. (6.1)\nadmits three conservation laws: power Q1 = |u|2, Hamiltonian Q3 =\u2212 14 |u|\n\n4 + 12 |\u2207u|\n2 and momentum Q2 = u\u2207u\u2217.\n\nWe were able to reproduce the time evolution of the Townes soliton, to within a relative error of \u223c 1.8\u00d7 10\u22125,\nwhen the algorithm was implemented on time interval [0,2] using time step of size \u2206t = 0.05 and number of spatial\n(square) grid points NS = 512. We rigorously conserve the power Q1, and as can be seen in Fig. 12 (b), the relative\nerror in power stays close to machine precision.\n\n7. CONCLUSIONS AND FUTURE DIRECTIONS\n\nIn 2005 Ablowitz and Musslimani proposed the spectral renormalization method as a tool to numerically ap-\nproximate solutions to nonlinear boundary value problems. Since then, it has been successfully used in many\nphysical settings that include photonics [42], Bose-Einstein condensation [7], Kohn-Sham density functional the-\nory [17], and water waves [5]. In 2016, Cole and Musslimani proposed the time dependent spectral renormalization\nmethod to simulate evolution equations with periodic boundary conditions. This important idea brings two novel\naspects: (i) it extends the original steady state spectral renormalization method to the time domain, thus offering\na unifying approach by which time-independent as well as evolution equations are solved by the same numerical\nscheme, (ii) it allowed the inclusion of certain physics such as conservation and dissipation laws. In this paper we\nhave significantly empowered the computational capabilities of the TDSR method that allows the (i) enforcement\nof several conservation laws or dissipation rate equations, (ii) flexibility to apply other non-periodic boundary\nconditions. We have successfully demonstrated these ideas on prototypical dynamical systems of physical signif-\nicance. Examples include the Korteweg-de Vries equation and dynamics of fronts modeled by the Allen-Cahn\nequation. We conclude this section by making a remark regarding possible application of the TDSR to weak wave\nturbulence. Wave turbulence describes the chaotic interactions of dispersive wavetrains (analogs to eddies) when\nan external forcing term added to the underlying nonlinear evolution equations are mediated by dissipative forces\n(see [31\u201333] and references contained). Numerical investigations of these phenomena is a challenging task, requir-\ning very long time runs for statistical equilibrium to be reached. Carefully designed numerical integrators are used\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 19\n\n(see [30]) to integrate the potentially stiff, underlying nonlinear field equations over long time. In such scenarios,\na close control over the conserved quantities of the dynamical system can prove vital to ensure long time accuracy\nof the solution. The application of the TDSR to this field thus seems natural and is kept for future work.\n\nREFERENCES\n\n[1] Mark J Ablowitz. Nonlinear dispersive waves: asymptotic analysis and solitons, volume 47. Cambridge\nUniversity Press, 2011.\n\n[2] Mark J Ablowitz, Xu-Dan Luo, and Ziad H Musslimani. Discrete nonlocal nonlinear schro\u0308dinger systems:\nIntegrability, inverse scattering and solitons. Nonlinearity, 33(7):3653, 2020.\n\n[3] Mark J. Ablowitz and Ziad H. Musslimani. Spectral renormalization method for computing self-localized\nsolutions to nonlinear systems. Opt. Lett., 30(16):2140\u20132142, Aug 2005.\n\n[4] Mark J Ablowitz and Ziad H Musslimani. Integrable discrete p t symmetric model. Physical Review E,\n90(3):032912, 2014.\n\n[5] MJ Ablowitz, AS Fokas, and ZH Musslimani. On a new non-local formulation of water waves. Journal of\nFluid Mechanics, 562:313, 2006.\n\n[6] MJ Ablowitz and JF Ladik. A nonlinear difference scheme and inverse scattering. Studies in Applied Mathe-\nmatics, 55(3):213\u2013229, 1976.\n\n[7] Eric Akkermans, Sankalpa Ghosh, and Ziad H Musslimani. Numerical study of one-dimensional and in-\nteracting Bose\u2013Einstein condensates in a random potential. Journal of Physics B: Atomic, Molecular and\nOptical Physics, 41(4):045302, 2008.\n\n[8] Samuel M. Allen and John W. Cahn. A microscopic theory for antiphase boundary motion and its application\nto antiphase domain coarsening. Acta Metallurgica, 27(6):1085 \u2013 1095, 1979.\n\n[9] Uri M Ascher and Chen Greif. A first course on numerical methods. SIAM, 2011.\n[10] Uri M Ascher and Robert I McLachlan. On symplectic and multisymplectic schemes for the kdv equation.\n\nJournal of Scientific Computing, 25(1):83\u2013104, 2005.\n[11] Justin T Cole and Ziad H Musslimani. Time-dependent spectral renormalization method. Physica D: Non-\n\nlinear Phenomena, 358:15\u201324, 2017.\n[12] Steven M Cox and Paul C Matthews. Exponential time differencing for stiff systems. Journal of Computa-\n\ntional Physics, 176(2):430\u2013455, 2002.\n[13] Yanfen Cui and De-kang Mao. Numerical method satisfying the first two conservation laws for the korteweg\u2013\n\nde vries equation. Journal of Computational Physics, 227(1):376\u2013399, 2007.\n[14] Philip J Davis. On the numerical integration of periodic analytic functions. On numerical approximation,\n\npages 21\u201323, 1959.\n[15] Daisuke Furihata. Finite difference schemes for \u2202u\n\n\u2202 t = (\n\u2202\n\n\u2202x )\n\u03b1 \u03b4g\n\n\u03b4u that inherit energy conservation or dissipation\nproperty. Journal of Computational Physics, 156(1):181\u2013205, 1999.\n\n[16] Sergei Konstantinovich Godunov. A difference scheme for numerical solution of discontinuous solution of\nhydrodynamic equations. Math. Sbornik, 47:271\u2013306, 1959.\n\n[17] Juri Grossi, Ziad H. Musslimani, Michael Seidl, and Paola Gori-Giorgi. Kohn-Sham equations with func-\ntionals from the strictly-correlated regime: Investigation with a spectral renormalization method. Journal of\nPhysics. Condensed matter, 32(47), 2020.\n\n[18] Ernst Hairer, Christian Lubich, and Gerhard Wanner. Geometric numerical integration: structure-preserving\nalgorithms for ordinary differential equations, volume 31. Springer Science & Business Media, 2006.\n\n[19] Charles Hirsch. Numerical computation of internal and external flows. vol. 2-computational methods for\ninviscid and viscous flows(book). Chichester, England and New York, John Wiley & Sons, 1990, 708, 1990.\n\n[20] Arieh Iserles. On the numerical quadrature of highly-oscillating integrals i: Fourier transforms. IMA Journal\nof Numerical Analysis, 24(3):365\u2013391, 2004.\n\n[21] AL Islas, DA Karpeev, and CM Schober. Geometric integrators for the nonlinear schro\u0308dinger equation.\nJournal of computational physics, 173(1):116\u2013148, 2001.\n\n\n\n20 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n[22] A.L. Islas and C.M. Schober. Multi-symplectic methods for generalized schro\u0308dinger equations. Future\nGeneration Computer Systems, 19(3):403\u2013413, 2003. Special Issue on Geometric Numerical Algorithms.\n\n[23] A.L. Islas and C.M. Schober. Backward error analysis for multisymplectic discretizations of hamiltonian\npdes. Mathematics and Computers in Simulation, 69(3):290\u2013303, 2005. Nonlinear Waves: Computation and\nTheory III.\n\n[24] Darae Jeong, Seunggyu Lee, Dongsun Lee, Jaemin Shin, and Junseok Kim. Comparison study of numerical\nmethods for solving the Allen\u2013Cahn equation. Computational Materials Science, 111:131\u2013136, 2016.\n\n[25] Aly-Khan Kassam and Lloyd N Trefethen. Fourth-order time-stepping for stiff PDEs. SIAM Journal on\nScientific Computing, 26(4):1214\u20131233, 2005.\n\n[26] Panayotis G Kevrekidis, Dimitri J Frantzeskakis, and Ricardo Carretero-Gonza\u0301lez. Emergent nonlinear phe-\nnomena in Bose-Einstein condensates: theory and experiment, volume 45. Springer Science & Business\nMedia, 2007.\n\n[27] Yuri S Kivshar and Govind P Agrawal. Optical solitons: from fibers to photonic crystals. Academic press,\n2003.\n\n[28] Randall J LeVeque et al. Finite volume methods for hyperbolic problems, volume 31. Cambridge university\npress, 2002.\n\n[29] Yi-Xin Liu and Hong-Dong Zhang. Exponential time differencing methods with Chebyshev collocation for\npolymers confined by interacting surfaces. The Journal of chemical physics, 140(22):224101, 2014.\n\n[30] AJ Majda, DW McLaughlin, and EG Tabak. A one-dimensional model for dispersive wave turbulence.\nJournal of Nonlinear Science, 7(1):9\u201344, 1997.\n\n[31] Sergey Nazarenko. Wave turbulence, volume 825. Springer Science & Business Media, 2011.\n[32] Alan C Newell, Sergey Nazarenko, and Laura Biven. Wave turbulence and intermittency. Physica D: Non-\n\nlinear Phenomena, 152:520\u2013550, 2001.\n[33] Alan C Newell and Benno Rumpf. Wave turbulence. Annual review of fluid mechanics, 43:59\u201378, 2011.\n[34] Sheehan Olver. Numerical approximation of highly oscillatory integrals. PhD thesis, University of Cam-\n\nbridge, 2008.\n[35] Alfio Quarteroni, Riccardo Sacco, and Fausto Saleri. Numerical mathematics, volume 37. Springer Science\n\n& Business Media, 2010.\n[36] JM Sanz-Serna. An explicit finite-difference scheme with exact conservation properties. Journal of Compu-\n\ntational Physics, 47(2):199\u2013210, 1982.\n[37] A. Taflove. Advances in Computational Electrodynamics: The Finite-difference Time-domain Method. Artech\n\nHouse antenna library. Artech House, 1998.\n[38] Thiab R Taha and Mark I Ablowitz. Analytical and numerical aspects of certain nonlinear evolution equations.\n\niii. numerical, Korteweg-de Vries equation. Journal of Computational Physics, 55(2):231\u2013253, 1984.\n[39] Lloyd N Trefethen. Spectral methods in MATLAB, volume 10. Siam, 2000.\n[40] J. A. C. Weideman and B. M. Herbst. Split-step methods for the solution of the nonlinear Schro\u0308dinger\n\nequation. SIAM Journal on Numerical Analysis, 23(3):485\u2013507, 1986.\n[41] Jianke Yang. Newton-conjugate-gradient methods for solitary wave computations. Journal of Computational\n\nPhysics, 228(18):7007\u20137024, 2009.\n[42] Jianke Yang and Ziad H Musslimani. Fundamental and vortex solitons in a two-dimensional optical lattice.\n\nOptics letters, 28(21):2094\u20132096, 2003.\n[43] L Minah Yang, Ian Grooms, and Keith A Julien. The fidelity of exponential and IMEX integrators for\n\nwave turbulence: Introduction of a new near-minimax integrating factor scheme. Journal of Computational\nPhysics, page 109992, 2020.\n\n[44] Norman J Zabusky and Martin D Kruskal. Interaction of \u201csolitons\u201d in a collisionless plasma and the recur-\nrence of initial states. Physical review letters, 15(6):240, 1965.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 21\n\n(S. Chandramouli) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: schandra@math.fsu.edu\n\n(A. Farhat) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: afarhat@fsu.edu\n\n(Z. Musslimani) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: musliman@math.fsu.edu\n\n\n\t1. Introduction\n\t2. TDSR and Duhamel principle\n\t3. Time integration with various boundary conditions\n\t3.1. Periodic and decaying boundary conditions\n\t3.2. Time integration: non-periodic boundary conditions\n\n\t4. Numerical Implementation of TDSR: One conservation or dissipation law with various boundary conditions\n\t4.1. The KdV equation.\n\t4.2. Zabusky-Kruskal experiment \n\t4.3. Travelling waves for the Allen-Cahn equation.\n\t4.4. Meta-stable dynamics of the Allen-Cahn equation.\n\n\t5. Numerical Implementation of TDSR with multi-conservation laws\n\t5.1. Conservation of mass and momentum\n\t5.2. Conservation of mass and Hamiltonian\n\t5.3. Conservation of mass, momentum and Hamiltonian\n\n\t6. TDSR method: Multi-dimensional test case\n\t7. Conclusions and future directions\n\tReferences\n\n"}
{"Title": "Simulating local fields in carbon nanotube reinforced composites for infinite strip with voids", "Authors": "Mohamed Nasser, El Mostafa Kalmoun, Vladimir Mityushev, Natalia Rylko", "Abstract": "  We consider the steady heat conduction problem within a thermal isotropic and homogeneous infinite strip composite reinforced by uniformly and randomly distributed non-overlapping carbon nanotubes (CNTs) and containing voids. We treat the CNTs as thin perfectly conducting elliptic inclusions and assume the voids to be of circular shape and act as barriers to heat flow. We also impose isothermal conditions on the external boundaries by assuming the lower infinite wall to be a heater under a given temperature, and the upper wall to be a cooler that can be held at a lower fixed temperature. The equations for the temperature distribution are governed by the two-dimensional Laplace equation with mixed Dirichlet-Neumann boundary conditions. The resulting boundary value problem is solved using the boundary integral equation with the generalized Neumann kernel. We illustrate the performance of the proposed method through several numerical examples including the case of the presence a large number of CNTs and voids.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00003", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating local fields in carbon nanotube\nreinforced composites for infinite strip with voids\n\nMohamed Nassera, El Mostafa Kalmounb, Vladimir Mityushevc,\nand Natalia Rylkoc\n\naMathematics Program, Department of Mathematics, Statistics and Physics,\nCollege of Arts and Sciences, Qatar University, Doha, Qatar\n\nbSchool of Science and Engineering, Al Akhawayn University in Ifrane,\nPO Box 104, Ifrane 53000, Morocco\n\ncFaculty of Computer Science and Telecommunications,\nCracow University of Technology, Krako\u0301w, Poland\n\nAbstract\n\nWe consider the steady heat conduction problem within a thermal isotropic\nand homogeneous infinite strip composite reinforced by uniformly and ran-\ndomly distributed non-overlapping carbon nanotubes (CNTs) and containing\nvoids. We treat the CNTs as thin perfectly conducting elliptic inclusions and\nassume the voids to be of circular shape and act as barriers to heat flow. We\nalso impose isothermal conditions on the external boundaries by assuming the\nlower infinite wall to be a heater under a given temperature, and the upper\nwall to be a cooler that can be held at a lower fixed temperature. The equa-\ntions for the temperature distribution are governed by the two-dimensional\nLaplace equation with mixed Dirichlet-Neumann boundary conditions. The\nresulting boundary value problem is solved using the boundary integral equa-\ntion with the generalized Neumann kernel. We illustrate the performance of\nthe proposed method through several numerical examples including the case\nof the presence a large number of CNTs and voids.\n\nKeywords. Local fields in 2D composites, Boundary integral equation,\nCarbon nanotube composites\n\n1 Introduction\n\nNanofibers embedded in polymer matrices have attracted attention as one of the\nreinforcements for composite materials. Carbon nanotubes (CNTs) reinforced poly-\nmer nanocomposites are considered as conventional micro- and macro-composites\n[1]. Their thermal, mechanical, and electric properties are determined by experi-\nmental and theoretical investigations [2, 3, 4]. CNTs are considered as perfectly\nconducting inclusions, which suggests imposing Dirichlet boundary conditions on\nthe boundary of CNTs. On the other hand, the classical problems for materials\nwith holes in porous media and materials with voids and insulting inclusions are\nmodeled by the Neumann boundary condition [5, 6].\n\nThe present paper is devoted to the heat conduction within a 2D (two-dimensional)\nthermal isotropic and homogeneous nanocomposite, which takes the form of an infi-\nnite strip, when it is reinforced by non-overlapping and randomly distributed CNTs\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n3v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 2\n\n8 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2\n\nand contains defects and voids. In particular, we are interested in studying the\neffect of CNTs as well as of the presence of voids on the macroscopic conductive and\nmechanical properties of this composite. Owing to the superconductivity of CNTs\nand the extremely low conductivity of voids, we can assume that the conductiv-\nity of CNTs, of the polymer host and of voids to be governed by the inequalities\n\u03bbc \ufffd \u03bb \ufffd \u03bb0. Such an assumption leads to a mixed boundary value problem\nwhere the latter inequality becomes +\u221e \ufffd \u03bb \ufffd 0. The host conductivity can be\nnormalized to unity, i.e., \u03bb = 1.\n\nTheoretical investigation of mixed boundary value problems by integral equa-\ntions can be found in [7, 8]. In the same time, implementation of numerical methods\nfor large number of inclusions and holes is still a challenging problem of applied and\ncomputational mathematics. We propose in this work a fast and effective algorithm\nfor the numerical solution of the formulated mixed boundary value problem. The\nmethod is based on the boundary integral equation with the generalized Neumann\nkernel. The integral equation has been used in [8] to solve a similar mixed bound-\nary value problem related to the capacity of generalized condensers. The proposed\nmethod can be even employed when the number of perfectly conducting inclusions\nand holes is very large.\n\nAs a result of simulations, we first study the 2D local fields for three types of me-\ndia. In the first type, we consider the case of pure m void cracks with m = 5, 30, 50.\nThe second type consists of pure ` CNT inclusions with ` = 5 and 200. Finally, we\ntreat the case of a large number of combined inclusions and holes by considering\neither 2000 of one of the two or 1000 of each. Afterward, we take up the systematic\ninvestigation of the effective conductivity of the considered composites. It is im-\nportant in applications to predict the macroscopic properties of composites which\ndepend on the concentration of perfectly conducting CNTs as well as on the concen-\ntration of holes and voids. It is worth noting that the notation of concentration are\ndifferent for slit shapes of CNTs and circular shapes of holes. The performed sim-\nulations of local fields and computation of their averaged conductivities for various\nconcentrations allows to establish the dependence of the macroscopic conductivity\non the main geometrical parameters.\n\n2 Problem formulation\n\nLet us consider a channel medium embedding m inhomogeneities in the form of `\nnanofillers and p = m \u2212 ` holes (voids). As many nanofillers (e.g, carbon nanon-\ntubes [9]) have cross sections of elliptical shapes, we model them as ellipses C1, . . . , C`.\nFurthermore, we represent the non-conducting holes by inner circles C`+1, . . . , Cm.\nThe top and bottom infinite walls of the channel are denoted respectively by C \u20320\nand C \u2032\u20320 , which yields a multiply connected domain \u2126 of connectivity m + 1 with a\nboundary set C =\n\n\u22c3m\nk=0Ck where C0 = C\n\n\u2032\n0 \u222aC \u2032\u20320 . An example of this domain for the\n\ncase of ` = 4 and m = 7 is illustrated in Figure 1.\nThe medium matrix without inhomogeneities is supposed to be homogeneous\n\nand isotropic with a constant thermal conductivity \u03bb = 1. We also assume that\nconduction is the only dominating mechanism of heat transfer in the medium. Ex-\ncept being non-overlapping, no other restriction is imposed on the inhomogeneities\nas they can be placed at random orientation and position.\n\nThe nanofillers are treated as heat superconductors with an almost uniform tem-\nperature distribution within each one. Therefore the temperature T is assumed to\n\n\n\n3\n\nbe fixed to an indeterminate constant value \u03b4k along each ellipse Ck for k = 1 . . . , `.\nThis assumption is consistent with the numerical results reported in [10] for CNT\nreinforced polymer composites. Furthermore, by the law of energy conservation in\nsteady-state heat conduction, there should be no net thermal flow through each\nnanofiller. This constraint is written by means of the net heat flux boundary con-\ndition (1e).\n\nOn the other hand, the curves C`+1, . . . , Cm are assumed to be perfect insulators\nand therefore they act as barriers to heat flow. Henceforth, the Neumann boundary\ncondition (1f) is imposed along the holes contours. Finally, isothermal conditions\nare imposed on the external boundaries by assuming that the lower infinite wall is\na heater of temperature T1, and the upper wall acts as a heat sink, which can be\nheld at a fixed temperature T0 < T1. Thee two values T0 and T1 of the temperature\non the external boundaries are normalized to 0 and 1, respectively.\n\nUnder steady-state conditions, Fourier\u2019s law of heat conduction and the above\nspecified heat boundaries conditions yield the temperature distribution T governed\nby the following mixed Dirichlet-Neumann boundary value problem:\n\n\u2206T = 0 in \u2126, (1a)\n\nT = 0 on C \u20320, (1b)\n\nT = 1 on C \u2032\u20320 , (1c)\n\nT = \u03b4k on Ck, k = 1, 2, . . . , `, (1d)\u222b\nCk\n\n\u2202T\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (1e)\n\n\u2202T\n\n\u2202n\n= 0 on Ck, k = `+ 1, `+ 2, . . . ,m, (1f)\n\nwhere \u2202T/\u2202n denotes the normal derivative of T , and \u03b41, . . . , \u03b4m are undetermined\nreal constants that need to be found alongside the distribution temperature T .\n\nFigure 1: Geometry of the problem (for ` = 4 and m = 7).\n\n3 The integral equation method\n\nThe boundary integral equation with the generalized Neumann kernel is not di-\nrectly applicable to the above boundary value problem (1) because of the external\nboundary component. However, the boundary value problem (1) is invariant under\n\n\n\n4\n\nconformal mapping. The mapping function\n\nz = \u03a6(\u03b6) =\n1\n\n\u03c0\nlog\n\n1 + \u03b6\n\n1\u2212 \u03b6\n+\n\ni\n\n2\n\nconformally maps the unit disk |\u03b6| < 1 onto the infinite strip 0 < Im z < 1. Thus,\nthe inverse mapping\n\n\u03b6 = \u03a6\u22121(z) = tanh\n\n(\n\u03c0z\n\n2\n\u2212\n\u03c0i\n\n4\n\n)\nconformally maps the infinite strip 0 < Im z < 1 onto the unit disk |\u03b6| < 1, the real\naxis onto the lower half of the unit circle, the line Im z = 1 onto the upper half of\nthe unit circle, and satisfies \u03a6\u22121(\u00b1\u221e + 0i) = \u00b11. Consequently, the function \u03a6\u22121\nmaps the multiply connected domain \u2126 in the z-plane (the physical domain) onto a\nmultiply connected domain G in the \u03b6-plane interior of the unit circle and exterior\nof m smooth Jordan curves (the computational domain). In Figure 2, we display\nthe result of the conformal mapping of the example shown in Figure 1.\n\nFigure 2: The computational domain G corresponding to the physical domain in\nFigure 1.\n\nIt follows that the harmonic function T can be written as\n\nT (z) = U(\u03a6\u22121(z))\n\nin which the function U is the solution of the following boundary value problem in\nthe \u03b6-plane:\n\n\u2206U = 0 in G, (2a)\n\nU = 0 on \u0393\u20320, (2b)\n\nU = 1 on \u0393\u2032\u20320, (2c)\n\nU = \u03b4k on \u0393k, k = 1, 2, . . . , `, (2d)\u222b\n\u0393k\n\n\u2202U\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (2e)\n\n\u2202U\n\n\u2202n\n= 0 on \u0393k, k = `+ 1, `+ 2, . . . ,m, (2f)\n\n\n\n5\n\nwhere \u0393\u20320 = \u03a6\n\u22121(C \u20320), \u0393\n\n\u2032\u2032\n0 = \u03a6\n\n\u22121(C \u2032\u20320 ), and \u0393k = \u03a6\n\u22121(Ck) for k = 1, 2, . . . ,m. Note\n\nthat the restriction of the function U(\u03b6) on the external boundary is discontinuous\nat \u03b6 = \u00b11. However, the function U can be cast into the form\n\nU(\u03b6) = u0(\u03b6) + u(\u03b6)\n\nwhere u(\u03b6) is a harmonic function in G, and\n\nu0(\u03b6) =\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b6\n1 + \u03b6\n\n+\n1\n\n2\n.\n\nThe function u0(\u03b6) is harmonic in G with u0(\u03b6) = 0 on the upper half of the unit\ncircle and u0(\u03b6) = 1 on the lower part. The function u(\u03b6) is the solution of the\nboundary value problem\n\n\u2206u(\u03b6) = 0 if \u03b6 \u2208 G, (3a)\nu(\u03b6) = 0 if \u03b6 \u2208 \u03930, (3b)\n\nu(\u03b6) = \u03b4k \u2212\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b6\n1 + \u03b6\n\n\u2212\n1\n\n2\nif \u03b6 \u2208 \u0393k, k = 1, 2, . . . , `, (3c)\u222b\n\n\u0393k\n\n\u2202u\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (3d)\n\n\u2202u\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6\n\n= \u2212\n\u2202u0\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6\n\nif \u03b6 \u2208 \u0393k, k = `+ 1, `+ 2, . . . ,m, (3e)\n\nwhere \u03930 is the unit circle.\nFor the orientation of the boundary components of G, we assume that \u03930 is\n\noriented counterclockwise and the other curves \u03931, . . . ,\u0393m are oriented clockwise.\nWe assume that each boundary component \u0393k, k = 0, 1, . . . ,m, is parametrized by a\n2\u03c0-periodic function \u03b7k(t), t \u2208 Jk := [0, 2\u03c0] such that \u03b7\u2032k(t) 6= 0. Let J be the disjoint\nunion of the m + 1 intervals J0, . . . , Jm, the whole boundary \u0393 is parametrized by\nthe complex function \u03b7 defined on J by [11, 12]\n\n\u03b7(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f3\n\n\u03b70(t), t \u2208 J0,\n\u03b71(t), t \u2208 J1,\n\n...\n\u03b7m(t), t \u2208 Jm.\n\nNote that the unit circle \u03930 is parametrized by \u03b70(t) = e\nit, t \u2208 J0 = [0, 2\u03c0].\n\nLet n(\u03b6) be the unit outward normal vector at \u03b6 \u2208 \u0393 and let \u03bd(\u03b6) be the angle\nbetween the normal vector n(\u03b6) and the positive real axis. Then, for \u03b6 = \u03b7(t) \u2208 \u0393,\n\nn(\u03b6) = ei\u03bd(\u03b6) = \u2212i\n\u03b7\u2032(t)\n\n|\u03b7\u2032(t)|\n. (4)\n\nThus\n\n\u2202u0\n\u2202n\n\n= \u2207u0 \u00b7 n = cos \u03bd\n\u2202u0\n\u2202x\n\n+ sin \u03bd\n\u2202u0\n\u2202y\n\n= Re\n\n[\nei\u03bd\n(\n\u2202u0\n\u2202x\n\u2212 i\n\n\u2202u0\n\u2202y\n\n)]\n. (5)\n\nThe harmonic function u0(\u03b6) is the real part of a single-valued analytic function\nf0(\u03b6), i.e., u0(\u03b6) = Re[f0(\u03b6)], where\n\nf0(\u03b6) =\n1\n\n\u03c0i\nlog\n\n1\u2212 \u03b6\n1 + \u03b6\n\n+\n1\n\n2\n, (6)\n\n\n\n6\n\nand the branch of the logarithm function is chosen such that log 1 = 0. Then by the\nCauchy-Riemann equations, we have\n\nf \u20320(\u03b6) =\n\u2202u0(\u03b6)\n\n\u2202x\n\u2212 i\n\n\u2202u0(\u03b6)\n\n\u2202y\n,\n\nwhich, in view of (4) and (5), implies that\n\n|\u03b7\u2032(t)|\n\u2202u0\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b7(t)\n\n= Re [\u2212i\u03b7\u2032(t) f \u20320(\u03b7(t))] , \u03b7(t) \u2208 \u0393k, k = `+ 1, . . . ,m. (7)\n\nSince\n\nf \u20320(\u03b6) =\ni\n\n\u03c0\n\n(\n1\n\n1\u2212 \u03b6\n+\n\n1\n\n1 + \u03b6\n\n)\n,\n\nit follows that for \u03b7(t) \u2208 \u0393k and k = `+ 1, . . . ,m,\n\n|\u03b7\u2032(t)|\n\u2202u0\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6=\u03b7(t)\n\n=\n1\n\n\u03c0\nRe\n\n[\n\u03b7\u2032(t)\n\n1\u2212 \u03b7(t)\n+\n\n\u03b7\u2032(t)\n\n1 + \u03b7(t)\n\n]\n. (8)\n\nThe harmonic function u can be assumed to be a real part of an analytic function\nf(\u03b6), \u03b6 \u2208 G. The boundary conditions (3b) and (3c) give the real parts of the\nfunction f(\u03b6) on \u0393k for k = 0, 1, . . . , `. Specifically, we have\n\nRe[f(\u03b7(t))] = 0, \u03b7(t) \u2208 \u03930 (9)\n\nand\n\nRe[f(\u03b7(t))] = \u03b4k \u2212\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b7(t)\n1 + \u03b7(t)\n\n\u2212\n1\n\n2\nif \u03b7(t) \u2208 \u0393k, k = 1, . . . , `. (10)\n\nFor the remaining boundary components \u0393k for k = ` + 1, . . . ,m, we use the con-\ndition (3e) to determine the boundary condition on f(\u03b7). By the Cauchy-Riemann\nequations, we can show using the same arguments as in (7) that\n\n|\u03b7\u2032(t)|\n\u2202u\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b7(t)\n\n= Re [\u2212i\u03b7\u2032(t) f \u2032(\u03b7(t))] (11)\n\nThus, for \u03b7(t) \u2208 \u0393k for k = `+ 1, . . . ,m, it follows from (3e), (8), and (11) that\n\nRe [\u2212i\u03b7\u2032(t) f \u2032(\u03b7(t))] = \u2212\n1\n\n\u03c0\nRe\n\n[\n\u03b7\u2032(t)\n\n1\u2212 \u03b7(t)\n+\n\n\u03b7\u2032(t)\n\n1 + \u03b7(t)\n\n]\n.\n\nIntegrating with respect to the parameter t for t \u2208 Jk, k = `+ 1, . . . ,m, we obtain\n\nRe [\u2212if(\u03b7(t))] =\n1\n\n\u03c0\nlog\n\n\u2223\u2223\u2223\u22231\u2212 \u03b7(t)1 + \u03b7(t)\n\u2223\u2223\u2223\u2223+ \u03b4k, (12)\n\nwhere the integration constants \u03b4k are undetermined. The constants \u03b4k, k = 1, . . . ,m\nin (10) and (12) are determined so that f(z) is a single-valued analytic function.\n\nSince we are interested in the function u, the real part of f , we may assume that\nc = f(\u03b1) is real for some given point \u03b1 in G. Define an analytic function g(\u03b6) in\nthe domain G through\n\nf(\u03b6) = (\u03b6 \u2212 \u03b1)g(\u03b6) + c. (13)\n\n\n\n7\n\nDefine also\nA(t) = e\u2212i\u03b8(t)(\u03b7(t)\u2212 \u03b1), (14)\n\nwhere \u03b8(t) is the piecewise constant function given by\n\n\u03b8(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n0, t \u2208 J0,\n...\n\n0, t \u2208 J`,\n\u03c0/2, t \u2208 J`+1,\n\n...\n\u03c0/2, t \u2208 Jm.\n\n(15)\n\nThus\ne\u2212i\u03b8(t)f(\u03b7(t)) = A(t)g(\u03b7(t)) + e\u2212i\u03b8(t)c,\n\nwhich implies that\n\nRe[A(t)g(\u03b7(t))] = Re[e\u2212i\u03b8(t)f(\u03b7(t))]\u2212 c cos \u03b8(t).\n\nOn the basis of the conditions (9), (10), and (12), the function g(z) satisfies the\nRiemann-Hilbert problem\n\nRe[A(t)g(\u03b7(t))] = \u03b3(t) + h(t), (16)\n\nwhere\n\nh(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n\u2212c, t \u2208 J0,\n\u03b41 \u2212 12 \u2212 c, t \u2208 J1,\n\n...\n\u03b4` \u2212 12 \u2212 c, t \u2208 J`,\n\u03b4`+1, t \u2208 J`+1,\n\n...\n\u03b4m, t \u2208 Jl+p.\n\n, \u03b3(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n0, t \u2208 J0,\n\u2212 1\n\u03c0\n\nIm log\n1\u2212\u03b7(t)\n1+\u03b7(t)\n\n, t \u2208 J1,\n...\n\n\u2212 1\n\u03c0\n\nIm log\n1\u2212\u03b7(t)\n1+\u03b7(t)\n\n, t \u2208 Jl,\n1\n\u03c0\n\nlog\n\u2223\u2223\u22231\u2212\u03b7(t)1+\u03b7(t) \u2223\u2223\u2223 , t \u2208 J`+1,\n\n...\n1\n\u03c0\n\nlog\n\u2223\u2223\u22231\u2212\u03b7(t)1+\u03b7(t) \u2223\u2223\u2223 , t \u2208 Jm.\n\n(17)\n\nIt is clear that the function \u03b3 is known and the piecewise constant function h is\nunknown and should be determined. Let \u00b5(t) = Im[A(t)g(\u03b7(t))], i.e., the boundary\nvalues of an analytic function g are given by\n\ng(\u03b7(t)) =\n\u03b3(t) + h(t) + i\u00b5(t)\n\nA(t)\n, t \u2208 J. (18)\n\nThus, in order to find the boundary values of the analytic function g, we need to\ndetermine the two unknown functions \u00b5 and h. These two functions can be computed\nusing the boundary integral equation with the generalized Neumann kernel [11, 12,\n13].\n\nLet H be the space of all real Ho\u0308lder continuous functions on \u0393, let I be the\nidentity operator, and let the integral operators N and M are defined on H by\n\nN\u00b5(s) =\n\n\u222b\nJ\n\n1\n\n\u03c0\nIm\n\n(\nA(s)\n\nA(t)\n\n\u03b7\u2032(t)\n\n\u03b7(t)\u2212 \u03b7(s)\n\n)\n\u00b5(t)dt, s \u2208 J,\n\nM\u00b5(s) =\n\n\u222b\nJ\n\n1\n\n\u03c0\nRe\n\n(\nA(s)\n\nA(t)\n\n\u03b7\u2032(t)\n\n\u03b7(t)\u2212 \u03b7(s)\n\n)\n\u00b5(t)dt, s \u2208 J.\n\n\n\n8\n\nThe kernel of the operator N is known as the generalized Neumann kernel. For\nmore details, see [11, 12, 13]. On account of [13], we have \u00b5 is the unique solution\nof the integral equation\n\n(I\u2212N)\u00b5 = \u2212M\u03b3. (19)\n\nAdditionally, the piecewise constant function h is given by\n\nh = [M\u00b5\u2212 (I\u2212N)\u03b3]/2. (20)\n\nWe compute approximations to the functions \u00b5 in (19) and h in (20) by the\nMATLAB function fbie from [12]. This function employs a discretization of the\nintegral equation (19) by the Nystro\u0308m method using the trapezoidal rule [14] to\nobtain an algebraic linear system of size (m+1)n\u00d7(m+1)n where n is the number of\ndiscretization points in each boundary component. The resulting system is solved by\napplying the generalized minimal residual method through the MATLAB function\ngmres. The matrix-vector multiplication in gmres is computed using the MATLAB\nfunction zfmm2dpart from the FMMLIB2D MATLAB toolbox [15]. The values of the\nother parameters in the function fbie are chosen as in [16]. For more details, we\nrefer the reader to [12].\n\n4 Computing the temperature distribution and\n\nthe heat flux\n\nBy computing \u00b5 and h, we obtain the boundary values of the function g through (18).\nThe values of the function g(\u03b6) for \u03b6 \u2208 G can be computed by the Cauchy integral\nformula. For the numerical computation of g(\u03b6) for \u03b6 \u2208 G, we use the MATLAB\nfunction fcau from [12]. Then, the values of f(\u03b6) can be computed by (13) and\nhence the values of the solution of the boundary value problem (2) is given for\n\u03b6 \u2208 G by\n\nU(\u03b6) = Re [f(\u03b6) + f0(\u03b6)] .\n\nWe deduce the values of the temperature distribution T (z) for any z \u2208 \u2126 by\n\nT (z) = Re\n[\nf(\u03a6\u22121(z)) + f0(\u03a6\n\n\u22121(z))\n]\n.\n\nMoreover, by computing the piecewise constant function h, we can compute as well\nthe values of the undetermined real constants c, \u03b41, . . . , \u03b4m from (16).\n\nThe function T (z) is the real part of the function\n\nF (z) = f(\u03a6\u22121(z)) + f0(\u03a6\n\u22121(z)), z \u2208 \u2126.\n\nAccording to the Cauchy-Riemann equations, it follows that the derivative of the\ncomplex potential F (z) on \u2126 is given by\n\nF \u2032(z) =\n\u2202T\n\n\u2202x\n\u2212 i\n\n\u2202T\n\n\u2202y\n.\n\nOne the other hand,\n\nF \u2032(z) =\nf \u2032(\u03a6\u22121(z))\n\n\u03a6\u2032(\u03a6\u22121(z))\n+\nf \u20320(\u03a6\n\n\u22121(z))\n\n\u03a6\u2032(\u03a6\u22121(z))\n, z \u2208 \u2126, (21)\n\n\n\n9\n\nwhere the denominator does not vanish in the domain \u2126 since \u03a6 is a conformal\nmapping. Therefore the heat flux can be expressed for z \u2208 D in terms of F \u2032(z) by\nthe formula\n\nq(z) = \u2212\n(\n\u2202T\n\n\u2202x\n,\n\u2202T\n\n\u2202y\n\n)\u2223\u2223\u2223\u2223\nz\n\n\u2261 \u2212F \u2032(z). (22)\n\nHence\n\u2202T\n\n\u2202y\n= \u2212 ImF \u2032(z). (23)\n\nThe derivatives f \u20320(\u03a6\n\u22121(z) and \u03a6\u2032(\u03a6\u22121(z)) in (21) can be computed analytically.\n\nSo, the values of the heat flux q can be estimated on the domain \u2126 by first approx-\nimating the derivatives of the boundary values of the analytic function f on each\nboundary components. This can be done by approximating the function f(\u03b7(t))\nusing trigonometric interpolating polynomials then differentiating. The values of\nf \u2032(\u03a6\u22121(z)), in the right-hand side of (21), can be then computed for z \u2208 \u2126 using\nthe Cauchy integral formula.\n\n5 Computing the effective thermal conductivity\n\nThe medium matrix without inhomogeneities is assumed to be homogeneous and\nisotropic. We will assume that the CNTs and the circular voids are in the part of\nthe domain between x = \u22121 and x = 1. Thus, the effective conductivity of a layer\nin the y-direction \u03bby is calculated by the formula (3.2.33) from the book [6, p. 53],\nwhich in our case on account of (23) becomes\n\n\u03bby = \u2212\n1\n\n2\n\n\u222b 1\n\u22121\n\n\u2202T\n\n\u2202y\n(x, 0) dx =\n\n1\n\n2\nIm\n\n[\u222b 1\n\u22121\nF \u2032(x) dx\n\n]\n. (24)\n\nSince\n\n\u03be0(t) = \u03a6(\u03b70(t)) = \u03a6(e\nit) =\n\n1\n\n\u03c0\nlog\n\n1 + eit\n\n1\u2212 eit\n+\n\ni\n\n2\n, 0 \u2264 t \u2264 2\u03c0,\n\nwhere for 0 < t < \u03c0, \u03be0(t) is on the line y = 1 and for \u03c0 < t < 2\u03c0, \u03be0(t) is on the\nreal line. Thus, for \u03c0 < t < 2\u03c0, we have\n\n\u03be0(t) =\n1\n\n\u03c0\nlog\n\n\u2223\u2223\u2223\u2223cot t2\n\u2223\u2223\u2223\u2223 .\n\nSince \u22121 = \u03be0(t1) and 1 = \u03be0(t2) where\n\n\u03c0 < t1 = 2\u03c0 \u2212 2 tan\u22121 (e\u03c0) < t2 = 2\u03c0 \u2212 2 tan\u22121\n(\ne\u2212\u03c0\n)\n< 2\u03c0. (25)\n\nConsequently, (24) can be written as\n\n\u03bby =\n1\n\n2\nIm\n\n[\u222b t2\nt1\n\nF \u2032(\u03be0(t))\u03be\n\u2032\n0(t) dt\n\n]\n. (26)\n\nIn combining (21) with the fact that \u03be\u20320(t) = ie\nit\u03a6\u2032(eit), we can see that\n\nF \u2032(\u03be0(t)) =\nf \u2032(\u03a6\u22121(\u03be0(t)))\n\n\u03a6\u2032(\u03a6\u22121(\u03be0(t)))\n+\nf \u20320(\u03a6\n\n\u22121(\u03be0(t)))\n\n\u03a6\u2032(\u03a6\u22121(\u03be0(t)))\n=\nf \u2032(eit)\n\n\u03a6\u2032(eit)\n+\nf \u20320(e\n\nit)\n\n\u03a6\u2032(eit)\n.\n\n\n\n10\n\nHence,\n\n\u03bby =\n1\n\n2\nIm\n\n[\u222b t2\nt1\n\n[\nieit\n(\nf \u2032(eit) + f \u20320(e\n\nit)\n)]\n\ndt\n\n]\n, (27)\n\nwhich implies that\n\n\u03bby =\n1\n\n2\nIm\n[\nf(eit2)\u2212 f(eit1)\n\n]\n+\n\n1\n\n2\nIm\n[\nf0(e\n\nit2)\u2212 f0(eit1)\n]\n. (28)\n\nThe second term in the right-hand side of (27) does not depend on the CNTs or the\nvoids. In view of (6) and (25), we have\n\n1\n\n2\nIm\n[\nf0(e\n\nit2)\u2212 f0(eit1)\n]\n\n= 1,\n\nand hence\n\n\u03bby = 1 +\n1\n\n2\nIm\n[\nf(eit2)\u2212 f(eit1)\n\n]\n. (29)\n\nSince eit1 and eit2 are on the unit circle \u03930, the external boundary of G, and taking\ninto account (13), (14), (15), and (18), Equation (29) can be written as\n\n\u03bby = 1 +\n1\n\n2\n[\u00b5(t2)\u2212 \u00b5(t1)] . (30)\n\nBy solving the integral equation (19), we obtain approximate values of \u00b5 at the\ndiscretization points. These values are employed to interpolate the approximate\nsolution \u00b5 on J0 by a trigonometric interpolation polynomial, which is then used to\napproximate the values of \u00b5(t1) and \u00b5(t2).\n\n6 Numerical results\n\nThe above proposed method with n = 211 is applied to compute the temperature\nfield T and the heat flux q for several examples. We will choose the CNTs and the\ncircular voids within the part of the domain between x = \u22121 and x = 1. To compute\nthe values of the temperature distribution T and the heat flux q, we discretize part\nof the domain \u2126, namely for \u22121.5 \u2264 x \u2264 1.5 and 0.0001 \u2264 y \u2264 0.9999. Afterwards,\nwe compute the values of the temperature distribution T and the heat flux q at\nthese points as described in Section 4.\n\n6.1 The domain \u2126 with only circular voids\n\nIn this subsection, we consider the domain \u2126 with m non-overlapping circular holes\nand without any CNT (i.e., ` = 0). We also assume that all circular holes have the\nsame radius r with the parametrization\n\n\u03b7j(t) = zj + re\n\u2212it, 0 \u2264 t \u2264 2\u03c0, j = 1, 2, . . . ,m,\n\nwhere z1, z2, . . . , zm are the centers of the circular holes. As these circular holes\nare chosen in the part of the domain \u2126 between x = \u22121 and x = 1, we define the\nconcentration c(m, r) of these voids to be the area of these circular holes over the\narea of the rectangle {(x, y) : \u22121 \u2264 x \u2264 1, 0 \u2264 y \u2264 1}, i.e.,\n\nc(m, r) =\nmr2\u03c0\n\n2\n. (31)\n\n\n\n11\n\nThe Clausius-Mossotti approximation (CMA) also known as Maxwel\u2019s formula\ncan be applied for dilute composites when the concentration (31) is sufficiently small.\nBelow, we write this formula for a macroscopically isotropic media with insulators\nof identical circular holes within the precisely established precision in [17]\n\n\u03bbe =\n1\u2212 c\n1 + c\n\n+O(c3). (32)\n\nExample 1 We consider m = 5 circular holes with the radius r for 0 < r < 0.2.\nFor Case I, we assume the centers of the holes to be set to \u22120.8 + 0.5i, \u22120.4 + 0.5i,\n0.5i, 0.4 + 0.5i, and 0.8 + 0.5i. The contour plot of T and |q| for r = 0.1 are shown\nin Figure 3 (first row). The approximate value of the effective thermal conductivity\nfor r = 0.1 is\n\n\u03bby = 0.8533491.\n\nWhen r is close to 0.2, the circular holes become adjacent to each other. To show\nthe effects of the radius r on the effective thermal conductivity \u03bby, we compute the\nvalues of \u03bby for several values of r, 0.00001 \u2264 r \u2264 0.19999. The obtained results\nare presented in Figure 4 where, by (31), the concentration of these 5 holes is\nc = c(5, r) = 5r2\u03c0/2 \u2248 7.854r2 for 0 < c < \u03c0/10 and 0 < r < 0.2. The values of\nthe estimated effective conductivity \u03bbe is given also in Figure 4. As one can expect,\nthere is a good agreement between \u03bby and \u03bbe for small values of c. In the same time,\nthe divergence of \u03bby and \u03bbe is observed for the concentrations greater than 0.1.\n\nFor Case II, the centers of the holes become \u22120.8+0.5i, \u22120.4+0.3i, 0.5i, 0.4+0.7i,\nand 0.8 + 0.5i, which means the centers are not anymore horizontally aligned as the\nsecond and fourth centers are now shifted by 0.2 up and down, respectively. This is\ndisplayed in Figure 3 (second row). The curve showing the obtained values of \u03bby as\na function of the concentration is depicted in Figure 4.\n\nFigure 4 illustrates that the values of \u03bby depend on the position of the circular\nholes centers while the values of \u03bbe are the same for both cases since it depends only\non the concentration of the circular holes and not on their positions. We notice a\nbetter agreement between \u03bby and \u03bbe in Cases II when comparing to Case I.\n\nExample 2 We consider m = 30 circular holes with centers xk + 0.25i, xk + 0.5i,\nand xk + 0.75i, where xk = \u22120.9 + 0.2(k \u2212 1) for k = 1, 2, . . . , 10, and with radius r\nfor 0 < r < 0.1. The contour plot of T and |q| for r = 0.099 are shown in Figure 5.\nThe approximate value of the effective thermal conductivity for r = 0.099 is\n\n\u03bby = 0.1519156.\n\nWhen r is close to 0.1, the circular holes become adjacent to each other. We\ncompute the values of \u03bby for several values of r, 0.00001 \u2264 r \u2264 0.09999. The\nobtained results are depicted in Figure 6 (left) where, by (31), the concentration of\nthese 30 holes is c = c(30, r) = 30r2\u03c0/2 \u2248 47.124r2. Note that 0 < c < 3\u03c0/20 for\n0 < r < 0.1.\n\nExample 3 We take up here the case of m = 50 circular holes with centers xk+0.1i,\nxk + 0.3i, xk + 0.5i, xk + 0.7i, and xk + 0.9i, where xk = \u22120.9 + 0.2(k \u2212 1) for\nk = 1, 2, . . . , 10, and with radius r for 0 < r < 0.1. On the basis of (31), the\nconcentration of these 50 holes is c = c(50, r) = 50r2\u03c0/2 \u2248 78.54r2. For 0 < r < 0.1,\n\n\n\n12\n\nFigure 3: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with m = 5 circular holes (Example 1 for r = 0.1). First row for Case\nI and second row for Case II.\n\nFigure 4: The effective thermal conductivity \u03bby and the estimated effective con-\nductivity \u03bbe in (32) vs. the concentration c(m, r) = 5r\n\n2\u03c0/2 for the domain \u2126 with\nm = 5 circular holes for 0.00001 \u2264 r \u2264 0.19999. The vertical dotted line is c = \u03c0/10.\n\nwe have 0 < c < \u03c0/4. When r is close to 0.1, the circular holes become adjacent\nto each other, and the concentration is almost equal to \u03c0/4. The obtained results\nshowing the behavior of \u03bby as a function of the radius r, for 0.001 \u2264 r \u2264 0.099, are\npresented in Figure 6 (right).\n\n6.2 The domain \u2126 with only CNTs\n\nIn this subsection, we consider the domain \u2126 with m non-overlapping elliptic CNTs\nwithout any circular holes (i.e., m = `). We assume that all CNTs have equal sizes\nand are of elliptic shape where the ellipses have the parametrization\n\n\u03b7j(t) = zj + a cos t\u2212 ib sin t, 0 \u2264 t \u2264 2\u03c0, j = 1, 2, . . . ,m, (33)\n\nwhere zj is the center of the ellipse, 2a and 2b are the length of the ellipses axes\nin the x and y-directions, respectively. If a/b > 1, the major axis of the ellipses is\n\n\n\n13\n\nFigure 5: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with 30 circular holes (r = 0.099).\n\nFigure 6: The effective thermal conductivity \u03bby vs. the concentration c(m, r) =\nmr2\u03c0/2. On the left, the domain \u2126 with m = 30 circular holes (Example 2) and\n0.00001 \u2264 r \u2264 0.09999. The vertical dotted line is c = 3\u03c0/20. On the right, the\ndomain \u2126 with m = 50 circular holes (Example 3) and 0.001 \u2264 r \u2264 0.099. The\nvertical dotted line is c = \u03c0/4.\n\nhorizontal, if a/b < 1, the major axis of the ellipses is vertical, and if a/b = 1, the\nellipses reduced to circles. Here, we choose a and b such that their ratio satisfies\n0.1 \u2264 a/b \u2264 10. These elliptic shape CNTs are chosen in the part of the domain\n\u2126 between x = \u22121 and x = 1. So, we define the concentration c(m, a, b) of these\nCNTs to be\n\nc(m, a, b) =\nmab\u03c0\n\n2\n. (34)\n\nIf a\nb\n\ufffd 1, instead of (34) the plane slits density is considered in the theory of\n\ncomposites and porous media\n\n\u03c6 =\nmb2\n\n|\u2126|\n=\nmb2\n\n2\n, (35)\n\nFor a macroscopically isotropic media with only perfectly conducting identical\ncircular inclusions (CNTs), an approximation of the effective conductivity \u03bbe is given\nby the inverse to (32) value (see [17])\n\n\u03bbe =\n1 + c\n\n1\u2212 c\n+O(c3). (36)\n\nExample 4 We consider m = 5 elliptic CNTs with centers \u22120.8 + 0.5i, \u22120.4 + 0.5i,\n0.5i, 0.4 + 0.5i, and 0.8 + 0.5i, and where 0 < a < 0.2 and 0 < b < 0.5. Figure 7\n\n\n\n14\n\n(first row) presents the contour plot of T and |q| for a = 0.19 and b = 0.019 (the\nellipses are horizontal). For these values of a and b, the approximate value of the\neffective thermal conductivity is\n\n\u03bby = 1.0272480.\n\nFor a = 0.019 and b = 0.19, the contour plot of T and |q| are shown in Figure 7\n(second row). The approximate value of the effective thermal conductivity for these\nvalues of a and b is\n\n\u03bby = 1.2804116.\n\nThe CNTs in Figure 7 have the same concentration. However, the value of \u03bby is\nlarger for the vertical ellipses case.\n\nWhen a approaches 0.2, the ellipses get adjacent to each other. On the other\nhand, they come close to the upper and lower walls when b approaches 0.5. We\ncompute the values of \u03bby for several values of a, 0.0001 \u2264 a \u2264 0.1999, with b =\n0.1a. The obtained results are presented in Figure 8 (left) where, by (34), the\nconcentration of these 5 ellipses is c = c(5, a, b) = 5ab\u03c0/2 = a2\u03c0/4 \u2248 0.7854a2.\nNote that, for 0 < a < 0.2 and b = 0.1a, we have 0 < c < \u03c0/100.\n\nThe values of \u03bby are also computed for several values of b for 0.001 \u2264 b \u2264 0.499\nwith a = 0.1b. Since a/b = 0.1 is small, the obtained values of \u03bby are plotted versus\nthe values of \u03c6 = 2.5b2, given by (35), where 0 < \u03c6 < 5/8 for 0 < b < 0.5. The\nobtained results are presented in Figure 8 (right).\n\nFigure 7: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with m = 5 elliptic CNTs (Example 4), where a = 0.19 and b = 0.019\nfor the first row and a = 0.019 and b = 0.19 for the second row.\n\nExample 5 We consider m = 200 elliptic CNTs with centers xk + iyj for k =\n1, 2, . . . , 20 and j = 1, 2, . . . , 10 where xk = \u22120.95 + (k\u2212 1)/10 and yj = 0.05 + (j\u2212\n1)/10, and with 0 < a < 0.05 and 0 < b < 0.05.\n\nWe compute the values of \u03bby for several values of a, 0.0002 \u2264 a \u2264 0.0498,\nand a/b = 10 (i.e., the ellipses are horizontal) where the ellipses become close to\neach other when a approaches 0.05. The obtained results are presented in Figure 9\n\n\n\n15\n\nFigure 8: The effective thermal conductivity \u03bby for the domain \u2126 with m = 5\nelliptic CNTs (Example 4). On the left, the effective thermal conductivity \u03bby vs.\nthe concentration c = a2\u03c0/4 for 0.0001 \u2264 a \u2264 0.1999 and a/b = 10. The vertical\ndotted line is c = \u03c0/100. On the right, the effective thermal conductivity \u03bby vs.\nthe plane slits density \u03c6 = 2.5b2 for 0.001 \u2264 b \u2264 0.499 and a/b = 0.1. The vertical\ndotted line is \u03c6 = 0.625.\n\n(left) where the concentration of these 200 ellipses is c = 10a2\u03c0 \u2248 31.416a2. For\n0 < a < 0.05 and a/b = 10, we have 0 < c < \u03c0/40. Then, we compute the values\nof \u03bby for several values of b, 0.0002 \u2264 b \u2264 0.0498, and a/b = 0.1. The obtained\nresults for \u03bby versus the the plane slits density \u03c6 = mb\n\n2/2 = 100b2 are presented in\nFigure 9 (right) where 0 < \u03c6 < 1/4 for 0 < b < 0.05 and a/b = 0.1.\n\nWhen a/b = 1, the ellipses reduce to circles. We compute the values of \u03bby for\nseveral values of a, 0.0002 \u2264 a \u2264 0.0498. The obtained results are presented in\nFigure 10 where the concentration of these 200 ellipses is c = 100a2\u03c0 \u2248 314.16a2.\nFor 0 < a < 0.05 and a/b = 1, we have 0 < c < \u03c0/4. Figure 10 presents also the\nvalues of the estimated effective conductivity \u03bbe given by (36).\n\nFigure 9: The effective thermal conductivity \u03bby for the domain \u2126 with m = 200\nelliptic CNTs (Example 5). On the left, the effective thermal conductivity \u03bby vs.\nthe concentration c = 10a2\u03c0 for 0.0002 \u2264 a \u2264 0.0498 with a/b = 10. The vertical\ndotted line is c = \u03c0/40. On the right, the effective thermal conductivity \u03bby vs. the\nplane slits density \u03c6 = 100b2 for 0.0002 \u2264 b \u2264 0.0498, with a/b = 0.1. The vertical\ndotted line is \u03c6 = 1/4. The vertical dotted line is c = 1/4.\n\n\n\n16\n\nFigure 10: The effective thermal conductivity \u03bby (for the domain \u2126 with m = 200\ncircular CNTs obtained by setting b = a in Example 5) and the estimated effective\nconductivity \u03bbe in (36) vs. the concentration c = 100a\n\n2\u03c0 for 0.0002 \u2264 a \u2264 0.0498.\nThe vertical dotted line is c = \u03c0/4.\n\n6.3 The domain \u2126 with 2000 CNTs and/or circular voids\n\nWe are concerned in this section with the study of a large number of perfect con-\nductors and/or insulators. We consider two example where in the first both perfect\nconductors and insulators have the same circular shape, while in the second, con-\nductors have an elliptic shape and insulators have a circular shape. The present\ninvestigation is useful when studying the impact of geometric shapes on the macro-\nscopic properties of three-phases high contrast media.\n\nExample 6 We take m = 2000 circular holes of equal size with radius r = 0.0075.\nIn this example, the concentration c = c(m, r) = 1000r2\u03c0 \u2248 0.1767 is constant\nand the locations of these holes are chosen randomly. In this case, the following\nextension of CMA may be used\n\n\u03bbe =\n1 + c1 \u2212 c2\n1\u2212 c1 + c2\n\n+O(c3), (37)\n\nwhere c1 denotes the conductor concentration, c2 the insulator concentration, and\nc = c1 + c2. Three cases are considered:\n\nCase I: We assume that half of the holes are CNTs and the other half are voids (see\nFigure 11). For this case, c1 and c2 are given by c1 = c2 = 500r\n\n2\u03c0 \u2248 0.0884.\n\nCase II: All holes are voids, and hence c1 = 0 while c2 = 1000r\n2\u03c0 \u2248 0.1767.\n\nCase III: All holes are CNTs, and hence c1 = 1000r\n2\u03c0 \u2248 0.1767 while c2 = 0.\n\nFor each case, we run the code for 20 times, so that to get 20 different locations\nfor these circular holes. In each of these 20 experiments, we compute the value of\nthe effective thermal conductivity \u03bby by the presented method and the values of the\nestimated effective conductivity \u03bbe by (32). As we can see from Figure 12, \u03bbe is a\nconstant and the values of \u03bby depend on the locations of the holes.\n\n\n\n17\n\nFigure 11: The domain \u2126 with m = 2000 circular holes. Case I: We have p = 1000\nvoids (blue circles) and ` = 1000 CNTs (red circles).\n\nExample 7 We consider m = 2000 elliptic and circular holes with ` = 1000 elliptic\nperfect conductors and p = 1000 circular insulators of equal area \u03c0r2 (see Figure 13).\nThe radius r is chosen to be the same as in the previous example, i.e., r = 0.0075.\nThe locations of both elliptic and circular holes are chosen randomly. For the ellipses,\nwe assume that the ratio between the length of the major axis and the minor axis\nis 4, and the angles between the major axis and the x-axis are chosen randomly.\nAs in the previous example, we run the code for 20 times. In each of these 20\nexperiments, we compute the value of the effective thermal conductivity \u03bby by the\npresented method. The computed values are shown in Figure 13 (left).\n\nSince we have the same number of elliptic perfect conductors and circular insu-\nlators of equal area \u03c0r2, the conductor concentration c1 and the insulator concen-\ntration c2 are equal and given by c1 = c2 = 500r\n\n2\u03c0 \u2248 0.0884. Although c1 and c2\nhere are the same as in Case I of the previous example, it is clear from Figures 12\n(first row) and 13 (right) that the values \u03bby in this example (elliptic conductors) are\nlarger than those in the previous example (circular conductors).\n\n\n\n18\n\nFigure 12: The values of the effective thermal conductivity \u03bby and the estimated\neffective conductivity \u03bbe in (37) (for the domain \u2126 with m = 2000 circular holes in\nExample 6) vs. the number of the experiment for Case I (first row), Case II (second\nrow, left), and Case III (second row, right).\n\nFigure 13: On the left, the domain \u2126 in Example 7 with m = p + ` = 2000 holes,\np = 1000 circular voids (blue) and ` = 1000 elliptic CNTs (red). On the right, the\nvalues of the effective thermal conductivity \u03bby vs. the number of the experiment.\n\n\n\n19\n\n6.4 The dependence of \u03bby on \u03c6 and c\n\nWe consider now a domain domain \u2126 with m = ` = 276 non-overlapping elliptic\nCNTs without any void. We assume that all CNTs are of equal size and elliptic\nshape. The ellipses are parametrized by (33) with a < b, which means they are\ntaken to be vertical.\n\nFirst we assume that the concentration c = c(m, a, b) is constant and we choose\nthe values of the parameters a and b such that the plane slits density \u03c6 = \u03c6(m, a, b) \u2208\n[0.4, 1.3]. The domain \u2126 for c = 0.5 and \u03c6 = 1.3 is shown in Figure 14. We consider\nas well five values of the concentration, c = 0.1, 0.2, 0.3, 0.4, 0.5. Then, for each of\nthese values, we compute and show in Figure 15 (left) the values of \u03bby = \u03bby(\u03c6).\n\nAfterwards, we take up the plane slits density \u03c6 = \u03c6(m, a, b) to be constant\nand we choose the values of the parameters a and b such that the concentration\nc = c(m, a, b) \u2208 [0.1, 0.5]. We consider four values of \u03c6, \u03c6 = 0.4, 0.7, 1, 1.3, and\ncompute again \u03bby = \u03bby(c) for each case. The obtained results are presented in\nFigure 15 (right).\n\nFigure 14: The domain \u2126 with m = 276 elliptic CNTs for c = 0.5 and \u03c6 = 1.3.\n\nFigure 15: The effective thermal conductivity \u03bby for the domain \u2126 with m = 276\nelliptic CNTs. On the left, the values of \u03bby = \u03bby(\u03c6) for \u03c6 \u2208 [0.4, 1.3] and for several\nvalues of c. On the right, the values of \u03bby = \u03bby(c) for c \u2208 [0.1, 0.5] and for several\nvalues of \u03c6.\n\n\n\n20\n\n7 Conclusion\n\nA systematic estimation of the local fields and the effective conductivity properties\nof 2D composites reinforced by uniformly and randomly distributed CNTs is car-\nried out. It is assumed that the medium may contains voids as well. The CNTs\nare considered as perfectly conducting elliptic inclusions and the voids as circular\ninsulators. For definiteness, a composite strip is considered with the given constant\nexternal field passing through the strip. The local field is governed by the Laplace\nequation in the multiply connected domain formed by the strip without two types\nof holes, CNTs and voids. The Dirichlet boundary condition is imposed on the\nCNTs boundary and the Neumann boundary condition governs the void boundary.\nA numerical method is developed to solve the mixed problem for a large number\nof CNTs and voids. The method is based on using the boundary integral equation\nwith the generalized Neumann kernel [11, 12]. One key feature of this method is\nthat it can be employed for domains with complex geometry as it provides accurate\nresults even when the boundaries are close together. To solve the integral equation,\nthe Fast Multipole Method has been employed, which enables to treat the case of\nthousands of CNTs and voids. With the help of conformal mappings, the presented\nmethod can be extended to include the case when CNTs and voids are rectilinear\nslits as done in [16] for example.\n\nThe computational study has shown a dependence of the local fields and the\neffective conductivity \u03bby on the concentration of voids c given by (34) as well as\non the density \u03c6 of CNTs given by (35). Besides the opposite conductive proper-\nties, voids and CNTs have also different types of the geometric parameters c and\n\u03c6 that are not reduced to each other. Hence, the present study is concerned ad-\nditionally with the case of three-phase composites of high contrast conductivity.\nIt is demonstrated that our simulations are covered with the classical lower order\napproximations (Clausius-Mossotti, Maxwell) for dilute composites. The high or-\nder concentrations and densities led to different results from the classical ones. It\nis worth noting that the huge number of numerical experiments for uniformly dis-\ntributed inclusions yield the graphical dependencies of \u03bby on c and \u03c6, which can be\nused in practical applications.\n\nAcknowledgments\n\nReferences\n\n[1] Mostafizur Rahaman, Dipak Khastgir, and Ali Kanakhir Aldalbahi. Carbon-\ncontaining polymer composites. Springer, 2019.\n\n[2] Lichao Feng, Ning Xie, and Jing Zhong. Carbon nanofibers and their compos-\nites: a review of synthesizing, properties and applications. Materials, 7(5):3919\u2013\n3945, 2014.\n\n[3] Marcio Loos. Carbon nanotube reinforced composites: CNT Polymer Science\nand Technology. Elsevier, 2014.\n\n[4] Ronald L Poveda and Nikhil Gupta. Carbon nanofiber reinforced polymer com-\nposites. Springer, 2016.\n\n\n\n21\n\n[5] Pierre M Adler, Jean-Franc\u0327ois Thovert, and Valeri V Mourzenko. Fractured\nporous media. Oxford University Press, 2013.\n\n[6] S. Gluzman, V. Mityushev, and W. Nawalaniec. Computational analysis of\nstructured Media. Academic Press, London, 2017.\n\n[7] Mohamed Nasser, Ali HM Murid, and Samer AA Al-Hatemi. A boundary\nintegral equation with the generalized neumann kernel for a certain class of\nmixed boundary value problem. J. Appl. Math., 2012, 2012.\n\n[8] Mohamed MS Nasser and Matti Vuorinen. Numerical computation of the ca-\npacity of generalized condensers. J. Comput. Appl. Math., 377:112865, 2020.\n\n[9] S Malekie and F Ziaie. Study on a novel dosimeter based on polyethylene\u2013\ncarbon nanotube composite. Nuclear Instruments and Methods in Physics Re-\nsearch Section A: Accelerators, Spectrometers, Detectors and Associated Equip-\nment, 791:1\u20135, 2015.\n\n[10] Jianming Zhang, Masataka Tanaka, and Toshiro Matsumoto. A simplified ap-\nproach for heat conduction analysis of cnt-based nano-composites. Computer\nmethods in applied mechanics and engineering, 193(52):5597\u20135609, 2004.\n\n[11] R. Wegmann and M.M.S. Nasser. The Riemann-Hilbert problem and the gener-\nalized Neumann kernel on multiply connected regions. J. Comput. Appl. Math.,\n214:36\u201357, 2008.\n\n[12] M.M.S. Nasser. Fast solution of boundary integral equations with the general-\nized Neumann kernel. Electron. Trans. Numer. Anal., 44:189\u2013229, 2015.\n\n[13] M.M.S. Nasser. Numerical conformal mapping of multiply connected regions\nonto the second, third and fourth categories of Koebe canonical slit domains.\nJ. Math. Anal. Appl., 382:47\u201356, 2011.\n\n[14] K.E. Atkinson. The Numerical Solution of Integral Equations of the Second\nKind. Cambridge University Press, Cambridge, 1997.\n\n[15] L. Greengard and Z. Gimbutas. FMMLIB2D: A MATLAB toolbox for fast\nmultipole method in two dimensions, version 1.2. edition, 2012. http://www.\ncims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html. Accessed 1 Jan 2018.\n\n[16] M.M.S. Nasser and E. Kalmoun. Application of integral equations to simulat-\ning local fields in carbon nanotube reinforced composites. In R. Mcphedran,\nS. Gluzman, V. Mityushev, and N. Rylko, editors, 2D and Quasi-2D Compos-\nite and Nanocomposite Materials: Properties and Photonic Applications, pages\n233\u2013248. Elsevier, Amsterdam, 2020.\n\n[17] V Mityushev and N Rylko. Maxwell\u2019s approach to effective conductivity and\nits limitations. Quarterly Journal of Mechanics and Applied Mathematics,\n66(2):241\u2013251, 2013.\n\nhttp://www.cims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html\nhttp://www.cims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html\n\n\t1 Introduction\n\t2 Problem formulation\n\t3 The integral equation method\n\t4 Computing the temperature distribution and the heat flux\n\t5 Computing the effective thermal conductivity\n\t6 Numerical results\n\t6.1 The domain  with only circular voids\n\t6.2 The domain  with only CNTs\n\t6.3 The domain  with 2000 CNTs and/or circular voids\n\t6.4 The dependence of y on  and c\n\n\t7 Conclusion\n\n"}
{"Title": "Robust reliability-based topology optimization under random-field material model", "Authors": "Trung Pham, Christopher Hoyle", "Abstract": "  This paper proposes an algorithm to find robust reliability-based topology optimized designs under a random-field material model. The initial design domain is made of linear elastic material whose property, i.e., Young's modulus, is modeled by a random field. To facilitate computation, the Karhunen-Lo\u00e8ve expansion discretizes the modeling random field into a small number of random variables. Robustness is achieved by optimizing a weighted sum of mean and standard deviation of a quantity of interest, while reliability is employed through a probabilistic constraint. The Smolyak-type sparse grid and the stochastic response surface method are applied to reduce computational cost. Furthermore, an efficient inverse-reliability algorithm is utilized to decouple the double-loop structure of reliability analysis. The proposed algorithm is tested on two common benchmark problems in literature. Finally, Monte Carlo simulation is used to validate the claimed robustness and reliability of optimized designs.      ", "Subject": "Optimization and Control (math.OC)", "ID": "arXiv:2201.00004", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust reliability-based topology optimization\nunder random-field material model\n\nTrung Pham\u2217\nDepartment of Aerospace Engineering\n\nUniversity of Michigan\nAnn Arbor, Michigan 48109, USA\n\nEmail: trungp@umich.edu\n\nChristopher Hoyle\nSchool of Mechanical, Industrial & Manufacturing Engineering\n\nOregon State University\nCorvallis, Oregon 97331\u20136001, USA\nEmail: chris.hoyle@oregonstate.edu\n\nThis paper proposes an algorithm to find robust reliability-\nbased topology optimized designs under a random-field ma-\nterial model. The initial design domain is made of linear\nelastic material whose property, i.e., Young\u2019s modulus, is\nmodeled by a random field. To facilitate computation, the\nKarhunen\u2212\u2013Loe\u0300ve expansion discretizes the modeling ran-\ndom field into a small number of random variables. Robust-\nness is achieved by optimizing a weighted sum of mean and\nstandard deviation of a quantity of interest, while reliability\nis employed through a probabilistic constraint. The Smolyak-\ntype sparse grid and the stochastic response surface method\nare applied to reduce computational cost. Furthermore, an\nefficient inverse-reliability algorithm is utilized to decouple\nthe double-loop structure of reliability analysis. The pro-\nposed algorithm is tested on two common benchmark prob-\nlems in literature. Finally, Monte Carlo simulation is used to\nvalidate the claimed robustness and reliability of optimized\ndesigns.\n\n1 Introduction\nA mechanical structure is characterized by its boundary\n\nand loading conditions, its material properties, and its topol-\nogy. Finding an appropriate topology is often a major task\nin structural design, which has fueled the rise of topology\noptimization (TO) in the last two decades. Without consid-\nering a designer\u2019s experience, TO is a mathematical tool to\nidentify the optimal size, shape, and connectivity of a de-\nsign [1], resulting in improved performance while using the\nleast amount of material. However, research in TO often\nonly concerns with deterministic inputs, while uncertainty\nis inherent in nature, which manifests itself in the stochastic-\nity of random parameters of engineered systems. The anal-\n\n\u2217Address all correspondence related to this paper to this author.\n\nysis and design of engineered systems are affected heavily\nby uncertainty; for example, modern design codes, such as\nACI 318 [2] and AISC 360 [3], have comprehensive recom-\nmendations of safety factors for loading, material property,\nconstruction conditions, etc., which obviously are intended\nto take into account uncertainty. Among different sources\nof uncertainty, material property is intrinsically random in\nspace, which has been modeled by random field in the de-\nsign of composite structures [4, 5, 6]. Such a modeling tech-\nnique has been especially popular in the vast literature of the\nStochastic Finite Element Method [7, 8, 9], which certainly\nproves its validity and the need to be considered in TO. So\nfar, uncertainty in TO has been treated separately by robust\noptimization or reliability-based optimization, while both ro-\nbustness and reliability are desired properties of design under\nuncertainty. Therefore, this paper presents an algorithm to\nfind robust reliability-based topology optimized design un-\nder a random-field material model.\n\nThere are a number of steps in our proposed algo-\nrithm, which are addressed in depth in the subsequent\nsections. Here we provide a brief overview of them.\nFirst, from a known covariance function, the modeling ran-\ndom field is estimated by a random polynomial using the\nKarhunen\u2212\u2013Loe\u0300ve expansion. To make the design robust,\na weighted sum of mean and standard deviation of a quantity\nof interest, which are computed by a Smolyak-type sparse\ngrid, is considered as the objective function. Reliability of\nthe design is reflected in the probabilistic constraint, which\nis handled by the Sequential Optimization and Reliability\nAssessment (SORA) method [10]\u2212a single-loop inverse-\nreliability algorithm\u2212coupled with the performance measure\napproach [11] to reduce the computational cost of reliability\nanalysis. The stochastic response surface method approxi-\nmates the random output, which is required to solve the in-\n\n1 Copyright \u00a9 by ASME\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n4v\n1 \n\n [\nm\n\nat\nh.\n\nO\nC\n\n] \n 2\n\n9 \nD\n\nec\n 2\n\n02\n1\n\n\n\nverse reliability analysis problem.\nThe layout of this paper is as follows. Section 2 is\n\na literature review of uncertainty propagation, robust and\nreliability-based optimization, and reliability analysis, with\nfocus on TO under uncertainty. Section 3 derives the math-\nematical formulation of the deterministic TO problem and\nthe robust reliability-based topology optimization (RRBTO)\nproblem. This section also exposes the details of our pro-\nposed solution for the RRBTO problem. Two numerical ex-\namples show how our proposed algorithm works, and are\nverified by Monte Carlo simulation in section 4 followed by\ndiscussions of the results. Finally, the paper is summarized\nwith major findings, and then suggests future work.\n\n2 Background\nThe earliest idea of topology optimization (TO) can be\n\ntraced back to Michell\u2019s paper [12] in 1904. Since then TO\nhas been mature enough to have its own treatise [1]. As a\nmathematical optimization problem, TO requires specifica-\ntion of objective function(s) and constraint(s), which do not\ninvolve any probabilistic quantities when using deterministic\ninputs. Thus, changes are needed to deal with uncertainty\nin the forms of robust optimization (RO) and reliability-\nbased optimization (RBO). A number of papers, which are\nreviewed below, have tried to integrate uncertainty into a TO\nproblem using RO and RBO separately.\n\nRO primarily aims to minimize the variability of an\noutput of interest [13], due to uncertainty, around its mean\nvalue. Therefore, this goal can be formulated by minimizing\na weighted sum of mean and standard deviation of the output\nof interest. This approach was chosen in several papers cov-\nering various sources of uncertainty and solution methods:\nspatial variation of manufacturing error with Monte Carlo\nsimulations [14]; random-field truss material with a multi-\nobjective approach [15]; random loading field and random\nmaterial field with the level set method [16]; material and\ngeometric uncertainties with stochastic collocation methods\nand perturbation techniques [17, 18]; misplacement of ma-\nterial and imperfect geometry [19, 20]; Young\u2019s modulus of\ntruss members with a perturbation method [21]; random-field\nmaterial properties with a polynomial chaos expansion [22];\ngeometric and material property uncertainties with a stochas-\ntic perturbation method for frame structures [23]; material\nuncertainty with known second-order statistics [24]; random\nspatial distribution of Young\u2019s modulus and loading uncer-\ntainty in a stress-based problem [25,26]; and random loading\nfield with stochastic collocation methods [27]. The robust\ntopology optimization (RTO) problem is solved by a unified\nframework based on polynomial chaos expansion in [28],\nwhile [29] tackled the problem exploiting the linear elas-\nticity of structure. The seemingly arbitrary factors in the\nweighted sum are often cited as one major weakness of this\nRO methodology [30, 15]; however, they are well-defined in\ndecision-based design reflecting risk-taking attitude of de-\nsigners [31, 32, 33].\n\nInstead of modifying the objective function, RBO makes\nsome of the constraints probabilistic\u2212probability of failure\n\nevent is used in place of the event itself. This change requires\nspecialized methods to handle, because the probabilistic con-\nstraints are expressed by multiple integrals of the joint prob-\nability density function (PDF) of random variables, both of\nwhich are either practically impossible to obtain or very dif-\nficult to evaluate [34]. Many methods have been devised to\novercome such difficulties, which were surveyed thoroughly\nin [35]. Within the scope of this paper, we only briefly review\nthe first-order reliability methods (FORM), the second-order\nreliability methods (SORM), and the Sequential Optimiza-\ntion and Reliability Assessment (SORA) method. FORM\nappeared early [36] together with the concept of reliability\nindex [37] to solve RBO problems. SORM [38] followed\nto improve accuracy of the FORM in case of highly nonlin-\near limit state functions and/or slow decay of the joint PDF.\nThe main idea of FORM and SORM is to approximate the\nlimit state functions using first-order and second-order Tay-\nlor series, respectively, at appropriate values (i.e., means) of\nrandom variables. This results in a double-loop optimiza-\ntion problem to find the most probable point (MPP). In the\ncontext of reliability-based topology optimization (RBTO),\ndirectly solving the double-loop optimization problem has\nbeen shown in [39] for MEMS mechanisms with stochastic\nloading, boundary conditions as well as material properties;\nin [40] for shape uncertainty; in [41] for geometric imperfec-\ntions; in [42] for frame structures using system reliability un-\nder random-variable inputs; in [43] for electromagnetic sys-\ntems; in [44] for geometrically nonlinear structures; in [45]\nfor local failure constraints; and in [46] for continuum struc-\ntures subject to local stress constraints. In [47], FORM was\nreplaced by a mean-value, second-order saddlepoint approx-\nimation method, which was asserted to be more accurate.\nThe double-loop approach is prohibitively expensive and\nlacks robustness when a large number of random variables\npresents [48]. For this reason, single-loop approaches have\nbeen developed, in which, i.e., the Karush\u2212Kuhn\u2212Tucker\n(KKT) optimality conditions are utilized to avoid the inner\nloop. Both [49] and [50] used variants of the single-loop\nmethod in [51] for component and system reliability-based\nTO. In [52], it is somewhat unique when the authors used\ntheir own single-loop method [53]. Kogiso et al. [54] applied\nthe single-loop-single-vector method [55] for frame struc-\ntures under random-variable loads and nonstructural mass.\nAnother way to bypass the double-loop problem is the de-\ncoupling approaches [35], in which reliability analysis re-\nsults are used to facilitate the optimization loops. Among\nthem, the SORA method is known for its simple implemen-\ntation compared to the above single-loop methods, and its ef-\nficiency with FORM [10,56]. This method was employed for\nRBTO under random-variable inputs in [57] and [58]. Meta\nmodeling or surrogate modeling used together with simula-\ntion techniques to solve RBO problems has received consid-\nerable attention [59], but still remained relatively unexplored\nin TO literature. In [60], reliability was assessed using a\nprobabilistic neural network classifier for truss structures un-\nder random Young\u2019s modulus.\n\nBoth robustness and reliability are desired properties of\ndesign under uncertainty; however, to the best of our knowl-\n\n2 Copyright \u00a9 by ASME\n\n\n\nedge, this paper is the first one considering both criteria in\nTO. Therefore, a literature review of robust reliability-based\noptimization (RRBO) has to be drawn from other fields. The\nRRBO problem was investigated in [61] using an inverse re-\nliability strategy; in [62] using a performance moment inte-\ngration method to estimate the product quality loss; in [63]\nusing a preference aggregation method to produce a single-\nobjective RBO problem; and in [64] under epistemic un-\ncertainty. Both [65] and [66] used a genetic algorithm to\nsolve the problem. The dimension reduction method and its\nderivatives were introduced in [67, 68, 69] as an alternative\napproach to the RRBO problem.\n\nWith respect to RBTO, the approaches in [57], [30],\nand [70] are closest to ours. Still, random-field modeling was\nnot used for material property in [57] and [70]. Furthermore,\nseveral concerns can be identified from [70]. One of the most\nimportant stages in their method is the approximation of both\nfailure probability and its sensitivity, which were calculated\nby Monte Carlo sampling. Direct Monte Carlo sampling is\nwell-known to have variability [71], meaning two indepen-\ndent runs are very likely to get different values of failure\nprobability and its sensitivity which would obviously affect\nthe optimization results. Another concern is that the value\nof the parameter \u03b5 needed to replace the Heaviside func-\ntion with a smooth approximation [72] and was chosen by a\n\u201crecommendation\u201d backed by observation only. In [30], the\nmodeling random field was assumed with a known marginal\ndistribution, and in order to apply a perturbation technique,\nrandom variability of Young\u2019s modulus had to be small. Both\nof these assumptions clearly restrict the general applicability\nof their method. Lastly, robustness against uncertainty was\nnot studied in the three papers. As described in the following\nsections, our proposed method considers random field un-\ncertainty with the Karhunen\u2212\u2013Loe\u0300ve (KL) expansion used\nto reduce the dimension of the random field. The KL ex-\npansion covers a large class of random field without any re-\nstrictions on random variability. In this way, we are able to\nuse the FORM-based inverse reliability method within the\nSORA framework coupled with the stochastic response sur-\nface method to avoid the aforementioned weaknesses of di-\nrect Monte Carlo sampling.\n\n3 Topology Optimization under Uncertainty\n3.1 Deterministic Topology Optimization\n\nA standard notation is adopted throughout this\npaper\u2212bold upper and lower case letters denote matrices\nand vectors, respectively. The below formulation shows a\ndensity-based deterministic topology optimization (DTO):\n\nmin\n\u03c1\u03c1\u03c1\n\nC(\u03c1\u03c1\u03c1) = uT Ku\n\nsubject to K(\u03c1\u03c1\u03c1)u(\u03c1\u03c1\u03c1) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(1)\n\nwhere \u03c1\u03c1\u03c1 is the vector of design variables of the TO prob-\nlem, which also are the deterministic finite-element densi-\nties; V (\u03c1\u03c1\u03c1) and V0 are the total and the initial volume of the\nfinite-element mesh, respectively; \u03b3 is the predetermined vol-\nume fraction; K(\u03c1\u03c1\u03c1), u(\u03c1\u03c1\u03c1), and f are the stiffness matrix, the\ndisplacement vector, and the external load vector, respec-\ntively; and C(\u03c1\u03c1\u03c1) is the structural compliance. In the opti-\nmization problem (1), there are three constraints: the first ex-\npresses the equilibrium of the structure; the second requires\nthe optimized design to have a prescribed volume; and the\nthird is a component-wise inequality, in which each density\n(design variable) must be between 1 and a lower limit (i.e.,\n\u03c1min = 0.001).\n\nTo ensure manufacturability, the optimized design must\nhave a well-defined boundary, which is not guaranteed if\nsolving (1) directly because there is nothing to prevent\nintermediate values of densities from dominating the de-\nsign. Hence, the Solid Isotropic Material with Penalization\n(SIMP) method [1] is used to make intermediate densities\nunfavorable compared to \u03c1min or 1. According to SIMP,\neach finite element has a Young\u2019s modulus Ei specified by\nEi = \u03c1\n\np\ni E\n\n0\ni , where p is the penalization factor and E\n\n0\ni is the\n\ninitial value of the Young\u2019s modulus corresponding to unit\ndensity. The interpretation and possible values of p were\nelaborated in [73]. Any established gradient-based algo-\nrithms can solve the problem (1) after it is converted into\na nonlinear optimization problem using the SIMP method.\nThis paper follows common practice in the literature, select-\ning the Method of Moving Asymptotes (MMA) [74, 75] as\nthe optimizer of the DTO problem. The MMA has proved its\nreliability and competitive performance in various settings\nof TO. However, SIMP alone is plagued with checkerboard-\ning, mesh dependence, and local minima [76]. Many mesh-\nindependent filtering methods [77] have been designed to\npreclude checkerboarding and mesh dependence, while lo-\ncal minima remain an open question. This paper uses the\ndensity filtering [78, 79] as implemented in [80]. The next\nsections describe how uncertainty shapes our problem for-\nmulation and the solution algorithm.\n\n3.2 Robust Reliability-based Topology Optimization\n3.2.1 Problem Formulation\n\nConsidering input uncertainty modeled by a random\nfield y(\u03c9,x), a robust reliability-based topology optimization\n(RRBTO) problem is formulated as follows:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\nPi [gi(\u03c1\u03c1\u03c1,y)< 0]\u2264 P0i , i = 1,2 . . . ,m,\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(2)\n\nwhere x \u2208 D \u2282 Rd is coordinates of a point in a d-\ndimensional physical domain D; \u03c9 \u2208 \u2126 is an element of the\n\n3 Copyright \u00a9 by ASME\n\n\n\nsample space \u2126; \u00b5 [C(\u03c1\u03c1\u03c1,y)] and \u03c3 [C(\u03c1\u03c1\u03c1,y)] are the mean and\nstandard deviation of the compliance C(\u03c1\u03c1\u03c1,y), respectively;\n\u03ba1 and \u03ba2 are the real non-negative weighting factors. The\nlimit state function gi(\u03c1\u03c1\u03c1,y) is defined so that gi(\u03c1\u03c1\u03c1,y) < 0\nmeans failure of the design, and Pi[gi(\u03c1\u03c1\u03c1,y) < 0] shows the\nprobability of the ith failure event. The target probability P0i\nis the upper bound of the failure probability Pi and often de-\nfined as P0i = \u03a6(\u2212\u03b2i), where \u03b2i is the reliability index and\n\u03a6(\u00b7) is the standard normal cumulative distribution function.\nIn this paper the random field y(\u03c9,x) is taken to be the mate-\nrial Young\u2019s modulus, which must be physically meaningful\n(i.e., taking only positive values) and is modeled as in [17]:\n\nE(x) = F\u22121 \u25e6\u03a6 [y(\u03c9,x)] , (3)\n\nwhere \u03a6[\u00b7] is the standard normal cumulative distribution\nfunction (CDF), and F\u22121 is the inverse of a prescribed CDF.\nThe uniform distribution is chosen for the two numerical ex-\namples resulting in\n\nE(x) = a+(b\u2212a)\u03a6 [y(\u03c9,x)] , (4)\n\nwhere a and b are the two bounds of the distribution. The\nlog-normal and the beta distribution are also capable of mod-\neling non-negative, bounded physical quantities, which can\nsupersede the uniform distribution in (3) with minimal effort.\n\nA number of challenges need to be cleared before we\nare able to solve (2). The modeling random field, which tries\nto capture spatial variability of material property, needs to\nbe cast into an explicit, computable form because a defined\nvalue of material property is required to perform finite el-\nement analysis. The Karhunen\u2212\u2013Loe\u0300ve (KL) expansion in\nSection 3.2.3 is able to turn a random field into a series of\nrandom variables. The mean and standard deviation of the\ncompliance, and the probabilistic constraints are often very\nhard or expensive to evaluate because of complex geome-\ntry of their domains. A Smolyak-type sparse grid in Sec-\ntion 3.2.2 is an efficient method to calculate the mean and\nstandard deviation, while Inverse Reliability Analysis (IRA)\nand SORA in Section 3.2.4, coupled with the Stochastic Re-\nsponse Surface Method (SRSM) in Section 3.2.5, handle the\nprobabilistic constraints effectively by avoiding the demand-\ning double-loop problem. Combining the above methods, a\ndetailed description of our proposed algorithm is laid out in\nSection 3.2.6.\n\n3.2.2 Smolyak-type Sparse Grid\nIn practice, it is very difficult or even impossible to\n\ncalculate the mean and standard deviation of the compli-\nance in (2) analytically through multidimensional integrals.\nSuch difficulties have motivated the development of various\nnumerical methods such as simulation-based methods (i.e.,\nMonte Carlo (MC), important sampling, adaptive sampling,\netc.), and the stochastic collocation methods (SCM) [81].\nSimulation-based methods are usually more straightforward\nto implement and embarrassingly parallel, and their cost does\n\nnot depend on the number of dimensions; however, even\nwith better sampling techniques, they still require a lot more\nsampling points than the SCM. Depending on the smooth-\nness of the target function, the convergence rate of the SCM\ncan be orders of magnitude faster than MC-based methods\n[82, 83]. The SCM approximates the quantity of interest by\na weighted sum, whose weighing factors and terms are com-\nputed at specific collocation points. Locating such points is\none of the central topics in SCM. The popular approach is\nto pick a known one-dimensional quadrature rule and then\nbuild up the multidimensional grid from the one-dimension\nrule. Interested readers can find in [84] a list of popular\nquadrature rules. The Gauss-Hermite quadrature, which is\nparticularly suitable for approximating the mean of a normal\ndistribution, is selected in this paper. The multidimensional\ngrid can be constructed using a tensor product; nevertheless,\ndue to the well-known curse of dimensionality, the cost of\nSCM on a full tensor-product grid is still excessively high\nfor a large number of dimensions. The Smolyak-type sparse\ngrid (SSG), which may be traced back to the Smolyak algo-\nrithm [85], can significantly reduce the cost by using only a\nsubset of the full tensor grid. In [86] numerical experiments\nwith random input, whose dimension was up to 50, showed\nthat the SCM on sparse grids was more efficient than MC.\n\nFor the sake of completeness the SSG is reviewed here.\nThe construction presented below follows [87]. Consider a\nd-dimensional function f (x), the difference \u2206(1)l f is defined\nas\n\n\u2206\n(1)\nl f =\n\n(\nQ(1)l \u2212Q\n\n(1)\nl\u22121\n\n)\nf , (5)\n\nwhere\n\nQ(1)l f =\nn\n(1)\nl\n\n\u2211\ni=1\n\nf\n(\n\nx(i)l\n)\n\nw(i)l ,\n\nQ(1)0 f = 0,\n\n(6)\n\nand n(1)l is the number of nodes for the l-level quadrature\n\nformula. The collocation points x(i)l and the corresponding\nweights w(i)l are calculated using the Gauss-Hermite quadra-\nture rule, which is a natural choice for the class of integrals\ninvolving an exponential function over an infinite interval\nsuch as mean and standard deviation [88]. The sparse in-\ntegration formula at level l is expressed as\n\nQ(d)l f = \u2211\n|`|\u2264l+d\u22121\n\n(\n\u2206\n(1)\nl1\n\u2297\u2206(1)l2 \u2297\u00b7\u00b7 \u00b7\u2297\u2206\n\n(1)\nld\n\n)\nf , (7)\n\nwhere |`| = l1 + l2 + . . .+ ld . The mean and standard devia-\ntion of f (x) can be approximated using (7).\n\n3.2.3 Karhunen\u2212\u2013Loe\u0300ve Expansion\nIn a physical system, the quantity of interest can be mea-\n\nsured at spatial points over the system domain. If a random\n\n4 Copyright \u00a9 by ASME\n\n\n\nfield is considered an appropriate model for such a quan-\ntity, it is then required to construct the random field from\nmeasurements. Several methods, including the Expansion\nOptimal Linear Estimator [89] and polynomial chaos expan-\nsion [82, 8], have been adopted. Compared to others, the\nKarhunen\u2212\u2013Loe\u0300ve (KL) expansion [90] is \u201cthe most effi-\ncient in terms of the number of random variables required\nfor a given accuracy\u201d [7]. The KL expansion of a random\nfield y(\u03c9,x) is given as\n\ny(\u03c9,x) = E[x]+\n\u221e\n\n\u2211\ni=1\n\n\u221a\n\u03bbi\u03bei(\u03c9)ei(x) (8)\n\nwhere E[x] is the mean of the random field. The orthogo-\nnal eigenfunctions ei(x) and the corresponding eigenvalues\n\u03bbi are solutions of the following eigenvalue problem:\n\n\u222b\nD\n\nK(x1,x2)ei(x)dx = \u03bbiei(x) x,x1,x2 \u2208 D (9)\n\nwhere K(x1,x2) is the covariance function of the random\nfield\n\nK(x1,x2) = E [y(x1)y(x2)] x1,x2 \u2208 D (10)\n\nThe random variables \u03bei(\u03c9) are uncorrelated and satisfy:\n\nE[\u03bei] = 0,E[\u03bei\u03be j] = \u03b4i j,\n\n\u03bei(\u03c9) =\n1\n\u221a\n\n\u03bbi\n\n\u222b\nD\n(y(\u03c9,x)\u2212E[x])ei(x)dx,\n\n(11)\n\nwhere \u03b4i j is the Kronecker delta. The infinite series in (8) has\nto be truncated to use in practice. Because the influence of\nhigher order terms decays rapidly, satisfactory precision can\nbe achieved using only the first few terms of the expansion.\n\nThe KL expansion requires the solution of the eigen-\nvalue problem (9), which is pretty straightforward in the case\nof a random process (1-dimensional random field) [91]. For\nthe purpose of demonstration and without loss of generality,\nthis paper in Section 4 assumes the separability of the covari-\nance function of a 2-dimensional random field:\n\nK(s, t) = exp\n(\n\u2212|s1\u2212 t1|\n\nl1\n\u00d7\n\u2212|s2\u2212 t2|\n\nl2\n\n)\n= exp\n\n(\n\u2212\n|s1\u2212 t1|\n\nl1\n\n)\nexp\n(\n\u2212\n|s2\u2212 t2|\n\nl2\n\n)\n,\n\ns, t \u2208 D\u2282R2,\n\n(12)\n\nwhere l1 and l2 are the correlation lengths in the two coordi-\nnate directions. The separability of the covariance function\nleads to separable eigenvalues and eigenfunctions, which are\nthe product of their univariate counterparts [92].\n\n3.2.4 Inverse Reliability Analysis and SORA\nThe probabilistic constraints formulated as in (2) are\n\ncalled the reliability index approach (RIA); however, as [11]\nreported, the performance measure approach (PMA) pro-\nvides better numerical stability and higher rate of conver-\ngence. Using the PMA, (2) is transformed as follows:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\ngi(\u03c1\u03c1\u03c1,y)\u2265 0, i = 1,2 . . . ,m,\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1.\n\n(13)\n\nThe most notable change is that the probabilistic constraints\nare replaced by inequalities of the limit state functions. Solv-\ning the new problem requires a truncated KL expansion\ny(\u03c9,x)\u2248 y(\u03be\u03be\u03be(\u03c9),x), FORM, and inverse reliability analysis\n(IRA). In order to apply FORM, the random vector \u039e\u039e\u039e = {\u03bei}\nis first transformed into a vector of standard normal random\nvariables \u03a8\u03a8\u03a8 = {\u03c8i} using the Rosenblatt or the Nataf trans-\nformation \u03a8\u03a8\u03a8 = T (\u039e\u039e\u039e) or \u039e\u039e\u039e = T\u22121(\u03a8\u03a8\u03a8). Then, the most prob-\nable point (MPP) \u03be\u03be\u03be\u2217i in physical space or \u03c8\u03c8\u03c8\n\n\u2217\ni in transformed\n\nspace is obtained by solving the following IRA problem:\n\nmin\n\u03c8\u03c8\u03c8\n\ngi(\u03c8\u03c8\u03c8)\n\ns.t. \u2016 \u03c8\u03c8\u03c8 \u2016= \u03b2i,\n(14)\n\nwhere gi(\u03c8\u03c8\u03c8) is the ith limit state function in transformed\nspace. In this paper, the Matlab CODES toolbox [93] is\nchosen to solve (14). Furthermore, the SORA framework\nis adopted to decouple the double-loop structure of (13).\nIn SORA, instead of nesting the optimization problem (14)\nwithin (13), it serializes (13) into a chain of loops of DTO\nand IRA (Fig. 1). Each kth loop starts with DTO followed by\nIRA:\n\nmin\n\u03c1\u03c1\u03c1k\n\n\u03ba1\u00b5\n[\nC(\u03c1\u03c1\u03c1k,y)\n\n]\n+\u03ba2\u03c3\n\n[\nC(\u03c1\u03c1\u03c1k,y)\n\n]\n\ns.t. K(\u03c1\u03c1\u03c1k,y)u(\u03c1\u03c1\u03c1k,y) = f,\n\nV (\u03c1\u03c1\u03c1k)\nV0\n\n= \u03b3,\n\ngi\n(\n\n\u03c1\u03c1\u03c1\nk,y(\u03be\u03be\u03be\u2217(k\u22121)i ,x)\n\n)\n\u2265 0, i = 1,2 . . . ,m,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1k \u2264 1.\n\n(15)\n\nwhere \u03be\u03be\u03be\u2217(k\u22121)i denotes the MPP in physical space of i\nth limit\n\nstate function in the (k\u22121)th loop. Solving (15) gives \u03c1\u03c1\u03c1\u2217(k),\nwhich is substituted into (14) to find the next MPP \u03be\u03be\u03be\u2217(k)i in\n\n5 Copyright \u00a9 by ASME\n\n\n\nthe form of \u03c8\u03c8\u03c8\u2217(k)i :\n\nmin\n\u03c8\u03c8\u03c8\n\ngi(\u03c1\u03c1\u03c1\n\u2217(k),\u03c8\u03c8\u03c8)\n\ns.t. \u2016 \u03c8\u03c8\u03c8 \u2016= \u03b2i.\n(16)\n\nStart\n\nInitialization:\n- Initial values\n- KL expansion\n- Collocation and sample points\n\nFinite Element Analysis\n\nSensitivity and filtering\n\nUpdate densities\n\nConverge\nNo\n\nSIMP\nDTO\n\nFinite Element Analysis\n\nConstruct limit state \nfunction\n\nFind MPP\n\nConverge\n\nInverse \nReliability \nAnalysis\n\nSRSM\n\nYes\n\nNo\n\nEnd\n\nYes\n\nUpdate Young\u2019s \nmodulus using \n\nMPP\n\nCalculate robust objective and \nits derivarives using the SCM\n\nFig. 1. SORA-based RRBTO flowchart [57].\n\nThe SORA framework coupled with the PMA can save\ncomputational cost significantly by reducing the number of\nreliability analyses performed to reach convergence of both\nDTO and IRA. However, as a heuristic method, the optimiza-\ntion solution \u03c1\u03c1\u03c1\u2217 acquired by SORA may not be the one found\nin the double-loop problem, which is corrected in each loop\nby shifting the random design variables using information\nfrom the previous loop [94]. Such modification is not neces-\nsary in this paper because there are only deterministic design\nvariables (only the material property is random).\n\n3.2.5 Stochastic Response Surface Method\nAs uncertainty is propagated from random input to out-\n\nput through complex computations such as finite element\nanalysis, it is almost unlikely to derive the output directly\nas an explicit expression of input. However, such an expres-\nsion is needed to run the gradient-based algorithm in IRA.\nThe SRSM deals with this difficulty by approximating the\noutput by a polynomial chaos expansion [82]. The below\nformulations follows [95]. The multidimensional Hermite\npolynomials of degree p are used in the SRSM and defined\nas:\n\nHp(\u03b1i1 ,\u03b1i2 , . . . ,\u03b1ip)\n\n= (\u22121)pe\n1\n2 \u03b1\u03b1\u03b1\n\nT\n\u03b1\u03b1\u03b1\n\n\u2202\np\n\n\u2202\u03b1i1 ,\u2202\u03b1i2 , . . . ,\u2202\u03b1ip\ne\u2212\n\n1\n2 \u03b1\u03b1\u03b1\n\nT\n\u03b1\u03b1\u03b1\n\n(17)\n\nwhere \u03b1\u03b1\u03b1 = {\u03b1ik}\np\nk=1 is a vector of standard normal random\n\nvariables. The output of interest z is estimated as follows:\n\nz = a0 +\nn\n\n\u2211\ni1=1\n\nai1H1(\u03b1i1)+\nn\n\n\u2211\ni1=1\n\ni1\n\n\u2211\ni2=1\n\nai1i2H2(\u03b1i1 ,\u03b1i2)\n\n+\nn\n\n\u2211\ni1=1\n\ni1\n\n\u2211\ni2=1\n\ni2\n\n\u2211\ni3=1\n\nai1i2i3H3(\u03b1i1 ,\u03b1i2 ,\u03b1i3)+ . . .\n\n(18)\n\nwhere n is the number of standard normal random vari-\nables used in the expansion, and a0,ai1 ,ai1i2 ,ai1i2i3 , . . . are\nunknown coefficients. If n = 2 and p = 3, then the expan-\nsion (18) will become:\n\nz(\u03b1i1 ,\u03b1i2) = a0 +a1\u03b1i1 +a2\u03b1i2 +a3(\u03b1\n2\ni1 \u22121)+a4(\u03b1\n\n2\ni2 \u22121)\n\n+a5\u03b1i1\u03b1i2 +a6(\u03b1\n3\ni1 \u22123\u03b1i1)+a7(\u03b1\n\n3\ni2 \u22123\u03b1i2)\n\n+a8(\u03b1i1\u03b1\n2\ni2 \u2212\u03b1i1)+a9(\u03b1\n\n2\ni1\u03b1i2 \u2212\u03b1i2)\n\n= a0 +\n9\n\n\u2211\nk=1\n\nakhik\n\n(19)\nwhere 1,hi1 ,hi2 , . . . ,hi9 are Hermite polynomials. The ten\nunknown coefficients a0,a1, . . . ,a9 are found by solving a\nsystem of linear equations using at least ten different realiza-\ntions of (\u03b1i1 ,\u03b1i2). Such realizations can be chosen at colloca-\ntion points according to the SSG in Section 3.2.2, or a much\nsimpler heuristic rule in [96], which is selected in this paper.\nFor the approximation in (19) the rule generates 17 colloca-\ntion points to form a stochastic response surface, which was\nvery close to the target output [95].\n\n3.2.6 Solution Algorithm\nThe optimization algorithm (Fig. 1) to solve the RRBTO\n\nproblem (2) is expounded below:\n\n1. Initialize the problem: size of the finite element mesh;\ninitial values of design variables, SIMP and optimization\nparameters; KL expansion of random field; collocation\npoints and weights for the SSG, and the SRSM; etc.\n\n6 Copyright \u00a9 by ASME\n\n\n\n2. Until convergence do:\n\n\u2022 Solve Kiui = fi and compute\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\nfor i =\n\n1,2, . . . ,n(d)l .\n\u2022 Calculate mean, variance and their derivatives:\n\nE [C] =\nn\n(d)\nl\n\n\u2211\ni=1\n\nwiCi,\n\n\u03c3\n2 [C] =\n\nn\n(d)\nl\n\n\u2211\ni=1\n\nwiC\n2\ni \u2212E\n\n2 [C] ,\n\n\u2202E [C]\n\u2202\u03c1\u03c1\u03c1\n\n=\n\nn\n(d)\nl\n\n\u2211\ni=1\n\nwi\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\n,\n\n\u2202\u03c3\n2 [C]\n\u2202\u03c1\u03c1\u03c1\n\n=\n\nn\n(d)\nl\n\n\u2211\ni=1\n\n2Ci(\u03c1\u03c1\u03c1)wi\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\n\u22122E [C]\n\n\u2202E [C]\n\u2202\u03c1\u03c1\u03c1\n\n.\n\n(20)\n\n\u2022 Compute derivative of the robust objective:\n\n\u03ba1\n\u2202E [C]\n\n\u2202\u03c1\u03c1\u03c1\n+\u03ba2\n\n1\n\n2\n\u221a\n\n\u03c32[C]\n\n\u2202\u03c3\n2 [C]\n\u2202\u03c1\u03c1\u03c1\n\n. (21)\n\n\u2022 Deterministic topology optimization (DTO): the most\nprobable point (MPP) \u03be\u03be\u03be\u2217(k\u22121)i found in the previous loop\n(or some initial values for the first loop) is used in place\nof random parameters \u03be\u03be\u03be(\u03c9), making (15) a regular TO\nproblem. The SIMP and the MMA method are em-\nployed to solve it.\n\n\u2022 Inverse reliability analysis (IRA): the optimum values\nof design variables from the DTO step and the colloca-\ntion points given in Section 3.2.5 are used to construct\nstochastic response surfaces, which in turn are utilized\nin (16) to find the next MPP. Based on convergence con-\nditions, the algorithm may stop, or a new loop is re-\nquested with updated Young\u2019s modulus using the new\nMPP.\n\n4 Results\nIn this section our proposed algorithm is run on two\n\ncommon benchmark problems (the cantilever and the L-\nshaped beam) with three target reliability levels, six weight-\ning factors, and one parameter tuple of the uniform distribu-\ntion in (4). The correctness and accuracy of our algorithm\nis then verified on the optimization results by Monte Carlo\nsimulations. All quantities given below are dimensionless\nfor simplicity.\n\nTo ensure the generality of our approach, we intention-\nally do not specify the limit state functions gi(\u03c1\u03c1\u03c1,y) in the\nprevious sections, which is essential for the two numerical\n\nexamples. The RRBTO problem now becomes:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\nP [u(\u03c1\u03c1\u03c1,y)\u2212u0 < 0]\u2264 P0,\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(22)\n\nwhere u(\u03c1\u03c1\u03c1,y) and u0 are the actual displacement and the\nminimum allowable displacement at a selected point, respec-\ntively. The above formulation is inspired by design of com-\npliant mechanisms [97], in which both flexibility and stiff-\nness are required. Flexibility allows the mechanisms to reach\ndesigned deformation, implied by the limit state function\ng(\u03c1\u03c1\u03c1,y) = u(\u03c1\u03c1\u03c1,y)\u2212 u0, while maximizing stiffness, or min-\nimizing compliance, helps them withstand loads. Further-\nmore, the weighting factors \u03ba1 and \u03ba2 need substantial at-\ntention. Our preliminary numerical results showed that the\nmean and standard deviation of the compliance are differ-\nent by about two orders of magnitude, which may have crit-\nical impact on the solution. This was examined carefully\nin [98] and normalization transforming them into the same\nscale has been recommended. \u03ba1 and \u03ba2 are identified ac-\ncording to [21]:\n\n\u03ba1 =\n\u03b5\n\n\u00b5\u2217\n,\u03ba2 =\n\n1\u2212 \u03b5\n\u03c3\u2217\n\n, (23)\n\nwhere \u03b5 \u2208 [0,1], \u00b5\u2217 is the mean of the compliance when\n(\u03b5,1\u2212 \u03b5) = (0,1), and \u03c3\u2217 is the standard deviation of the\ncompliance when (\u03b5,1\u2212\u03b5)= (1,0). \u00b5\u2217 and \u03c3\u2217 have to be cal-\nculated on the same set of input parameters except \u03b5, under\nwhich they are the maximum values of the mean and stan-\ndard deviation of the compliance resulting in 0 <\n\n\u00b5\n\u00b5\u2217\n\n,\n\u03c3\n\n\u03c3\u2217\n\u2264 1\n\nin (22).\nCoding the algorithm demands concrete values of ev-\n\nery parameter, many of which are shared between the two\nexamples. The finite element mesh in both examples is as-\nsembled from square, linear, plane stress elements, whose\nside length and thickness are unit dimension. Those ele-\nments are made of an isotropic, linear elastic material with\nPoisson\u2019s ratio \u03bd = 0.3. The material Young\u2019s modulus\nis assumed to be a centered, mean-square Gaussian ran-\ndom field with known covariance function as in (12), ex-\npanded into a series of independent, standard normal ran-\ndom variables [99]. The correlation lengths are chosen as\nl1 = l2 = 0.6, and only the first two eigenvalues and eigen-\nfunctions are picked for the truncated KL expansion. A wide\nrange of optimization algorithms for reliability analysis is\navailable in the CODES toolbox [93], including the Hybrid\nMean Value method selected for the examples due to its ef-\nficiency [100]. Other parameters of the optimization prob-\nlem (22) are the target reliability levels \u03b2 = {1.0,2.0,3.0},\n\n7 Copyright \u00a9 by ASME\n\n\n\nweighting factors \u03b5 = {1,0.9,0.8,0.5,0.2,0}, and the ma-\nterial property limits (a,b) = (1,1.5). Due to iterative na-\nture of MMA and SORA, several convergence criteria are\nenforced. The MMA optimizer stops when the maximum\ndifference of design variables of two consecutive iterations\nis smaller than a prescribed value (dMMAmax \u2264 0.001), or the\nnumber of iterations is more than nMMA = 200. The sim-\nilar conditions are applied in the SORA loops, but for the\nMPPs (dMPPmax \u2264 0.001) and a different maximum allowable\nnumber of iterations (nSORA = 20). The level of sparse grid\napproximation is 4 using Gauss-Hermite quadrature as the\nbase one-dimensional rule. In SIMP, the minimum length\nscale rmin = 1.5 and penalization factor p = 3 are used. Each\nexample is then validated by 50000 Monte Carlo simulations\n(MCS), which compute failure probabilities of the limit state\nfunction, and the mean and standard deviation of the compli-\nance. The examples are implemented in Matlab using Latin\nhypercube sampling for MCS with seed 0. Those probabil-\nities are compared with values calculated from the three re-\nliability levels, while statistical moments of the compliance\nprove robustness of the optimization results against uncer-\ntainty.\n\n4.1 The Cantilever Beam\n\n/ \n\nA B A B\n\nFig. 2. The cantilever beam\n\nFig. 2 displays the cantilever beam, a two-dimensional\ndomain used in this example. The beam is fixed on its left\nside, meshed into 60 \u00d7 20 elements, and subject to two unit\nvertical loads, which are placed on its bottom edge at equal\ndistances (points A and B). The optimization problem is set\nup as in (22), in which the minimum allowable displacement\nat the load application point B is given as u0 = 220. Then our\nproposed algorithm is tested on the example with different\nvalues of target reliability, material parameters and weight-\ning factors. The 18 optimized designs are presented in Tables\n1 and 2. The MCS and SRSM utilize those designs to calcu-\nlate the mean and standard deviation of vertical displacement\nof point B (\u00b5B and \u03c3B in Table 3), as well as the probabili-\nties of failure event Pf = P [g(\u03c1\u03c1\u03c1,y)< 0] to show the reliabil-\nity levels achieved by the designs. Moreover, the mean and\nstandard deviation of the compliance are also obtained from\nthe MCS (\u00b5[C] and \u03c3[C] in Table 3) to examine how they\nvary with respect to the weighting factors \u03b5. All of theses\nvalues are gathered in Table 3, whose second column shows\n\nexpected failure probabilities Pf = \u03a6(\u2212\u03b2). Some conclu-\nsions from this example results can be found in Section 5.\n\n4.2 The L-shaped Beam\n\n/ \n\nA B A B\n\nFig. 3. The L-shaped beam\n\nThe second numerical example to illustrate our proposed\nalgorithm is the L-shaped beam as shown in Fig. 3. The\nbeam is fixed on its topmost edge and subject to two unit\nvertical loads on its bottom edge\u2212one at the right endpoint\nB and the other at point A located one quarter of the bot-\ntom edge length from point B. As in the previous example,\nthe weighted sum of the two statistical moments of the com-\npliance is minimized, while a probabilistic constraint is im-\nposed on the vertical displacement of one load application\npoint (point B in Fig. 3) to design for flexibility. The mini-\nmum allowable vertical displacement of point B is chosen as\nu0 = 130. The design domain is discretized using a 60\u00d760\nmesh of finite elements, and then one quarter of the mesh is\nremoved to make the domain L-shaped by forcing the ele-\nment densities in this region to be 0.001 before proceeding\nto the next operation. The larger mesh used in this exam-\nples results in much longer running time based on our ex-\nperiments on the same computer. The results also exhibit the\nsame trends as in the previous example. Therefore, instead of\nrunning the complete set of 18 combinations, only 12 cases,\nwhich are the combinations of \u03b2 = {1,3}, six weighting fac-\ntors, and (a,b) = (1,1.5), are considered. Table 6 shows the\nprobabilities of displacement constraint violation Pf at point\nB, the statistical moments of that point\u2019s vertical displace-\nment (\u00b5B and \u03c3B) calculated from both the MCS and SRSM,\nand the mean and standard deviation of the compliance (\u00b5[C]\nand \u03c3[C]). The L-shaped optimized designs are analyzed for\ninsights in the next section.\n\n5 Discussions\nIn this section we closely scrutinize the two numerical\n\nexamples for comparison, verification, and insights.\nVisual inspection and analysis of topology optimized de-\n\nsigns (i.e., identifying and comparing their differences) is\n\n8 Copyright \u00a9 by ASME\n\n\n\nTa\nbl\n\ne\n1.\n\nT\nhe\n\nca\nnt\n\nile\nve\n\nr\nbe\n\nam\n:\n\nR\nR\n\nB\nT\n\nO\nre\n\nsu\nlts\n\n(\u03b5\n,1\n\u2212\n\n\u03b5\n)\n\n(1\n,0\n)\n\n(0\n.9\n,0\n.1\n)\n\n(0\n.8\n,0\n.2\n)\n\n\u03b2\n=\n\n1\n\n\u03b2\n=\n\n2\n\n\u03b2\n=\n\n3\n\nTa\nbl\n\ne\n2.\n\nT\nhe\n\nca\nnt\n\nile\nve\n\nr\nbe\n\nam\n:\n\nR\nR\n\nB\nT\n\nO\nre\n\nsu\nlts\n\n(\u03b5\n,1\n\u2212\n\n\u03b5\n)\n\n(0\n.5\n,0\n.5\n)\n\n(0\n.2\n,0\n.8\n)\n\n(0\n,1\n)\n\n\u03b2\n=\n\n1\n\n\u03b2\n=\n\n2\n\n\u03b2\n=\n\n3\n\n9 Copyright \u00a9 by ASME\n\n\n\nTable 3. The cantilever beam: Numerical results\n\nMCS SRSM\n\n\u03b2 Expected Pf (\u03b5,1\u2212 \u03b5) \u00b5[C] \u03c3[C] \u00b5B \u03c3B Pf \u00b5B \u03c3B\n\n1 0.15865\n\n(1,0) 162.9505 0.9263 -220.6120 0.6071 0.15674 -220.6120 0.6071\n\n(0.9,0.1) 162.9992 0.9188 -220.6070 0.6017 0.15642 -220.6070 0.6017\n\n(0.8,0.2) 163.2204 0.8953 -220.5980 0.5853 0.15326 -220.5980 0.5853\n\n(0.5,0.5) 166.5160 0.9032 -225.0110 0.5906 0.00000 -225.0110 0.5906\n\n(0.2,0.8) 177.7632 0.8588 -240.6990 0.5572 0.00000 -240.6990 0.5572\n\n(0,1) 206.2317 0.8559 -278.9100 0.5527 0.00000 -278.9100 0.5527\n\n2 0.02275\n\n(1,0) 163.4230 0.9150 -221.1960 0.5995 0.02252 -221.1960 0.5995\n\n(0.9,0.1) 163.6040 0.9106 -221.1880 0.5961 0.02250 -221.1880 0.5961\n\n(0.8,0.2) 163.7847 0.9118 -221.1890 0.5967 0.02266 -221.1890 0.5967\n\n(0.5,0.5) 164.7008 0.8953 -222.9560 0.5866 0.00000 -222.9560 0.5866\n\n(0.2,0.8) 178.0176 0.8586 -241.0670 0.5570 0.00000 -241.0670 0.5570\n\n(0,1) 206.2320 0.8559 -278.9110 0.5527 0.00000 -278.9110 0.5527\n\n3 0.001349\n\n(1,0) 163.7490 0.9094 -221.7690 0.5962 0.001340 -221.7690 0.5962\n\n(0.9,0.1) 164.0019 0.9078 -221.7630 0.5944 0.001340 -221.7630 0.5944\n\n(0.8,0.2) 164.0458 0.9015 -221.7520 0.5907 0.001320 -221.7520 0.5907\n\n(0.5,0.5) 165.0556 0.8938 -223.2560 0.5855 0.000000 -223.2560 0.5855\n\n(0.2,0.8) 177.8977 0.8585 -240.8960 0.5570 0.000000 -240.8960 0.5570\n\n(0,1) 206.2320 0.8559 -278.9110 0.5527 0.000000 -278.9110 0.5527\n\nlargely an untouched topic in TO research, which, in our\nopinion, is curious because topology is all about geometry\nand \u201cappearance\u201d of structures. Without such tools, the best\neffort is to compare those results qualitatively. To make their\ndifferences more pronounced, readers may render them into\nshort animations, which would reveal much more than hu-\nman eyes can perceive using only static images. There would\nbe subtle material re-distributions (i.e., among results under\nthe same tuple (\u03b5,1\u2212\u03b5)), as well as thickening or thinning of\ncertain features, which could be almost undetectable by com-\nparing static images. The removal or addition of features is\neasier to spot among results. The most distinct results corre-\nspond to \u03b5 = 1 and \u03b5 = 0, which is understandable because\nthey are the extreme cases. The results between them are sort\nof transitions from one bounding value to the other.\n\nA number of trends can be observed from both the opti-\nmized designs and their corresponding numerical results:\n\n1. The MCS-based Pf is always smaller than the expected\nPf , which confirms that the designs have achieved the\ndesired reliability level.\n\n2. Decreasing \u03b5, or increasing the weight on standard de-\nviation in the robust objective, makes the MCS-based\nPf smaller until reaching 0. We hypothesize that there\nare two classes of solutions depending on the weight:\none on the constraint boundary and the other inside the\nfeasible region of the optimization problem. In the first\nclass, the MCS-based Pf is close to the expected Pf :\ndecreasing rate of the MCS-based Pf is very slow for\ncertain range of \u03b5 (i.e., \u03b5 = {1,0.9,0.8} in Table 3, and\n\u03b5 = {1,0.9} in Table 6). In the second class, the so-\n\n10 Copyright \u00a9 by ASME\n\n\n\nTable 4. The L-shaped beam: RRBTO results\n\n(\u03b5,1\u2212 \u03b5) (1,0) (0.9,0.1) (0.8,0.2)\n\n\u03b2 = 1\n\n\u03b2 = 3\n\nTable 5. The L-shaped beam: RRBTO results\n\n(\u03b5,1\u2212 \u03b5) (0.5,0.5) (0.2,0.8) (0,1)\n\n\u03b2 = 1\n\n\u03b2 = 3\n\n11 Copyright \u00a9 by ASME\n\n\n\nTable 6. The L-shaped beam: Numerical results\n\nMCS SRSM\n\n\u03b2 Expected Pf (\u03b5,1\u2212 \u03b5) \u00b5[C] \u03c3[C] \u00b5B \u03c3B Pf \u00b5B \u03c3B\n\n1 0.15865\n\n(1,0) 96.4893 0.5352 -130.3580 0.3577 0.15808 -130.3580 0.3577\n\n(0.9,0.1) 96.3536 0.5321 -130.3560 0.3553 0.15790 -130.3560 0.3553\n\n(0.8,0.2) 96.8678 0.5241 -131.0290 0.3498 0.00144 -131.0290 0.3498\n\n(0.5,0.5) 99.5821 0.5045 -135.7740 0.3396 0.00000 -135.7740 0.3396\n\n(0.2,0.8) 108.7352 0.4917 -149.3090 0.3332 0.00000 -149.3090 0.3332\n\n(0,1) 133.3052 0.4762 -183.8160 0.3238 0.00000 -183.8160 0.3238\n\n3 0.001349\n\n(1,0) 96.8866 0.5300 -131.0510 0.3544 0.00130 -131.0510 0.3544\n\n(0.9,0.1) 96.7519 0.5298 -131.0510 0.3545 0.00126 -131.0510 0.3545\n\n(0.8,0.2) 96.8852 0.5240 -131.0560 0.3497 0.00106 -131.0560 0.3497\n\n(0.5,0.5) 99.6087 0.5049 -135.9450 0.3399 0.00000 -135.9450 0.3399\n\n(0.2,0.8) 108.7883 0.4916 -149.3880 0.3331 0.00000 -149.3880 0.3331\n\n(0,1) 133.9731 0.4755 -184.5450 0.3229 0.00000 -184.5450 0.3229\n\nlutions are away from the constraint boundary but still\ninside the feasible region: the decreasing rate acceler-\nates and the MCS-based Pf eventually becomes 0 (i.e.,\n\u03b5\u2265 0.5 in Table 3, and \u03b5\u2265 0.8 in Table 6).\n\n3. From our understanding of robust optimization, increas-\ning the weight on standard deviation in a minimization\nproblem will decrease its value and have the opposite ef-\nfect on the mean, which is actually the case as observed\nin Tables 3 and 6. However, there are a couple of out-\nliers to this trend (i.e., (\u03b5,\u03b2) = (0.8,2) in Table 3, and\n\u03b5 = 0.9 in Table 6). An explanation can be made by in-\nvestigating where the solution converges in the design\nspace. When the solutions are away from the constraint\nboundary, the robust objective is more dominant in the\nsolution: a marked increase and decrease of the mean\nand standard deviation, respectively, is observed. In so-\nlutions at the constraint limit, the robust objective has\nless in the solution.\nThis trend explains the decreasing tendency of the MCS-\nbased Pf . Increasing the weight on standard deviation\nleads to decreased influence of the mean compliance,\nwhose major proportion is contributed by the displace-\nment of point B (Fig. 2 and 3) which is constrained prob-\nabilistically in (22) to be larger than the minimum al-\nlowable value u0. This results in increasing the mean of\npoint B displacement, whose changing rate is slow for\nsolutions close to constraint boundary and much more\n\nrapid in the remaining cases (i.e., the sixth column of\nTables 3 and 6). The bigger the displacement of point B\nbecomes, the smaller the MCS-based Pf is. It is ob-\nvious that under a specific set of inputs (i.e., loading\nand boundary conditions, material property) mechani-\ncal capabilities of a structure (i.e., stress, strain, dis-\nplacement), even if heavily optimized, are always finite.\nThus, the MCS-based Pf approaches 0 when the dis-\nplacement of point B continues to increase.\n\n4. The Smolyak-type sparse grid and the SRSM are both\nvery good methods for their respective approximating\ntargets. As shown in Tables 3 and 6, approximately\nsix significant digits are required to see the differences\nbetween the MCS-based and the SRSM results. The\ncumulative distribution functions of point B displace-\nment from the two methods are also almost identi-\ncal, so they are not included in the paper. This also\nmakes us confident in choosing only two terms in the\nKL expansion\u2212adding more terms would only increase\ncomputational cost without clear benefits. The same ob-\nservation is applied to the Smolyak-type sparse grid and\nMCS-based results of the mean and standard deviation\nof the compliance. Because of such agreement, we de-\ncide to use only one level of the sparse grid. Multiple\nlevels were tested in [17, 27].\n\n12 Copyright \u00a9 by ASME\n\n\n\n6 Conclusions\nIn this paper, we have presented an efficient robust\n\nreliability-based design approach for topology optimized de-\nsigns, considering random field uncertainty in material prop-\nerty. Our approach avoids a double-loop approach to reliabil-\nity evaluation, and utilizes a number of techniques to reduce\ncomputational cost without sacrificing solution accuracy.\nThe two case studies have demonstrated the methodology,\nand have shown the impact of using the robust reliability-\nbased design approach. As shown in the case studies, the\ntopology can converge to a (local) solution where either the\nreliability-based constraint or the robust objective has more\ninfluence upon the resulting topology. This difference in\nconverged solution is determined by the relative weight of\nthe mean versus the variance in the robust objective. This\nfinding is significant to designers because it shows that us-\ning either exclusively a robust design approach or reliability-\nbased design approach will not identify the optimal topology\nconsidering material property uncertainty. Only the robust\nreliability-based design approach is capable of identifying\nthe optimal topology considering the influence of material\nproperty uncertainty in both the objective and the constraint.\n\nExplicitly considering material property uncertainty will\nbe significant in design for additive manufacturing, where\nthe additive process can lead to significant material property\nuncertainty due to temperature gradients or other sources of\nvariation. In terms of future work, the following are rec-\nommended. Further case studies should be considered to\nbetter understand the interplay between the reliability con-\nstraint and the robust objective. Different objectives and con-\nstraints can be considered as well. Considering topology op-\ntimization as a tool for design for additive manufacturing,\nanother significant characteristic of the material property is\nnon-linearity. Polymeric materials used in additive manu-\nfacturing will be better modeled as hyper-elastic or visco-\nelastic, as opposed to linear elastic. Another need is visu-\nalization of the results. As noted in the text, it can be dif-\nficult to understand the differences in topology based upon\nvisual inspection. A more systematic comparison of differ-\nent converged results will help researchers better understand\nthe differences in designs resulting from different problem\nformulations, and will lead to a better understanding of the\ndesign principles leading to robust, reliable designs.\n\nAcknowledgements\nThe first author would like to thank the Vietnam Edu-\n\ncation Foundation (VEF) for their financial support through\nthe VEF fellowship, and Prof. Krister Svanberg for his assis-\ntance on the MMA code.\n\nReferences\n[1] Bends\u00f8e, M. P., and Sigmund, O., 2003. Topol-\n\nogy optimization: theory, methods, and applications.\nSpringer, Berlin ; New York.\n\n[2] American Concrete Institute. Building Code Require-\nments for Structural Concrete (ACI 318-14).\n\n[3] American Institute of Steel Construction. Specifica-\ntion for Structural Steel Buildings (ANSI/AISC 360-\n16).\n\n[4] Sriramula, S., and Chryssanthopoulos, M. K., 2013.\n\u201cAn experimental characterisation of spatial variabil-\nity in GFRP composite panels\u201d. Structural Safety, 42,\npp. 1\u201311.\n\n[5] Nader, J. W., Dagher, H. J., Lopez-Anido, R., El Chiti,\nF., Fayad, G. N., and Thomson, L., 2008. \u201cProba-\nbilistic Finite Element Analysis of Modified ASTM\nD3039 Tension Test for Marine Grade Polymer Ma-\ntrix Composites\u201d. Journal of Reinforced Plastics and\nComposites, 27(6), pp. 583\u2013597.\n\n[6] Sriramula, S., and Chryssanthopoulos, M. K., 2009.\n\u201cQuantification of uncertainty modelling in stochastic\nanalysis of FRP composites\u201d. Composites Part A: Ap-\nplied Science and Manufacturing, 40(11), pp. 1673\u2013\n1684.\n\n[7] Sudret, B., and Kiureghian, A. D., 2000. Stochastic\nFinite Element Methods and Reliability: A State-of-\nthe-Art Report (Report No. UCB/SEMM-2000/08).\nDepartment of Civil and Environmental Engineering,\nUniversity of California, Berkeley.\n\n[8] Ghanem, R., and Spanos, P., 2003. Stochastic Finite\nElements: A Spectral Approach. Civil, Mechanical\nand Other Engineering Series. Dover Publications.\n\n[9] Charmpis, D., Schue\u0308ller, G., and Pellissetti, M., 2007.\n\u201cThe need for linking micromechanics of materials\nwith stochastic finite elements: A challenge for ma-\nterials science\u201d. Computational Materials Science,\n41(1), pp. 27\u201337.\n\n[10] Du, X., and Chen, W., 2004. \u201cSequential Optimiza-\ntion and Reliability Assessment Method for Efficient\nProbabilistic Design\u201d. Journal of Mechanical Design,\n126(2), p. 225.\n\n[11] Tu, J., Choi, K. K., and Park, Y. H., 1999. \u201cA\nNew Study on Reliability-Based Design Optimiza-\ntion\u201d. Journal of Mechanical Design, 121(4), p. 557.\n\n[12] Michell, A., 1904. \u201cThe limits of economy of ma-\nterial in frame-structures\u201d. The London, Edinburgh,\nand Dublin Philosophical Magazine and Journal of\nScience, 8(47), pp. 589\u2013597.\n\n[13] Taguchi, G., 1986. Introduction to quality engineer-\ning: designing quality into products and processes.\nDistributed by the American Supplier Institute, Inc.,\nDearborn, MI.\n\n[14] Schevenels, M., Lazarov, B., and Sigmund, O., 2011.\n\u201cRobust topology optimization accounting for spa-\ntially varying manufacturing errors\u201d. Computer Meth-\nods in Applied Mechanics and Engineering, 200(49-\n52), Dec., pp. 3613\u20133627.\n\n[15] Richardson, J. N., Filomeno Coelho, R., and Adri-\naenssens, S., 2015. \u201cRobust topology optimization\nof truss structures with random loading and material\nproperties: A multiobjective perspective\u201d. Computers\n& Structures, 154, July, pp. 41\u201347.\n\n[16] Chen, S., Chen, W., and Lee, S., 2010. \u201cLevel set\nbased robust shape and topology optimization under\n\n13 Copyright \u00a9 by ASME\n\n\n\nrandom field uncertainties\u201d. Structural and Multidis-\nciplinary Optimization, 41(4), Apr., pp. 507\u2013524.\n\n[17] Lazarov, B. S., Schevenels, M., and Sigmund, O.,\n2012. \u201cTopology optimization considering material\nand geometric uncertainties using stochastic colloca-\ntion methods\u201d. Structural and Multidisciplinary Opti-\nmization, 46(4), Oct., pp. 597\u2013612.\n\n[18] Lazarov, B. S., Schevenels, M., and Sigmund, O.,\n2012. \u201cTopology optimization with geometric un-\ncertainties by perturbation techniques\u201d. Interna-\ntional Journal for Numerical Methods in Engineering,\n90(11), June, pp. 1321\u20131336.\n\n[19] Jansen, M., Lombaert, G., Diehl, M., Lazarov, B. S.,\nSigmund, O., and Schevenels, M., 2013. \u201cRobust\ntopology optimization accounting for misplacement\nof material\u201d. Structural and Multidisciplinary Opti-\nmization, 47(3), Mar., pp. 317\u2013333.\n\n[20] Jansen, M., Lombaert, G., and Schevenels, M., 2015.\n\u201cRobust topology optimization of structures with im-\nperfect geometry based on geometric nonlinear anal-\nysis\u201d. Computer Methods in Applied Mechanics and\nEngineering, 285, Mar., pp. 452\u2013467.\n\n[21] Asadpoure, A., Tootkaboni, M., and Guest, J. K.,\n2011. \u201cRobust topology optimization of structures\nwith uncertainties in stiffness \u2212 Application to truss\nstructures\u201d. Computers & Structures, 89(11-12),\nJune, pp. 1131\u20131141.\n\n[22] Tootkaboni, M., Asadpoure, A., and Guest, J. K.,\n2012. \u201cTopology optimization of continuum struc-\ntures under uncertainty \u2212 A Polynomial Chaos ap-\nproach\u201d. Computer Methods in Applied Mechanics\nand Engineering, 201-204, Jan., pp. 263\u2013275.\n\n[23] Changizi, N., and Jalalpour, M., 2017. \u201cRobust topol-\nogy optimization of frame structures under geometric\nor material properties uncertainties\u201d. Structural and\nMultidisciplinary Optimization, 56(4), Oct., pp. 791\u2013\n807.\n\n[24] da Silva, G. A., and Cardoso, E. L., 2016. \u201cTopology\noptimization of continuum structures subjected to un-\ncertainties in material properties\u201d. International Jour-\nnal for Numerical Methods in Engineering, 106(3),\nApr., pp. 192\u2013212.\n\n[25] da Silva, G., and Cardoso, E., 2017. \u201cStress-based\ntopology optimization of continuum structures under\nuncertainties\u201d. Computer Methods in Applied Me-\nchanics and Engineering, 313, Jan., pp. 647\u2013672.\n\n[26] da Silva, G. A., Beck, A. T., and Cardoso, E. L., 2018.\n\u201cTopology optimization of continuum structures with\nstress constraints and uncertainties in loading\u201d. Inter-\nnational Journal for Numerical Methods in Engineer-\ning, 113(1), Jan., pp. 153\u2013178.\n\n[27] Zhao, Q., Chen, X., Ma, Z.-D., and Lin, Y., 2015.\n\u201cRobust Topology Optimization Based on Stochastic\nCollocation Methods under Loading Uncertainties\u201d.\nMathematical Problems in Engineering, 2015, pp. 1\u2013\n14.\n\n[28] Richardson, J., Coelho, R. F., and Adriaenssens, S.,\n2016. \u201cA unified stochastic framework for robust\n\ntopology optimization of continuum and truss-like\nstructures\u201d. Engineering Optimization, 48(2), Feb.,\npp. 334\u2013350.\n\n[29] Zhao, J., and Wang, C., 2014. \u201cRobust topology op-\ntimization under loading uncertainty based on linear\nelastic theory and orthogonal diagonalization of sym-\nmetric matrices\u201d. Computer Methods in Applied Me-\nchanics and Engineering, 273, May, pp. 204\u2013218.\n\n[30] Jalalpour, M., and Tootkaboni, M., 2016. \u201cAn effi-\ncient approach to reliability-based topology optimiza-\ntion for continua under material uncertainty\u201d. Struc-\ntural and Multidisciplinary Optimization, 53(4), Apr.,\npp. 759\u2013772.\n\n[31] McIntire, M. G., Vasylkivska, V., Hoyle, C., and Gib-\nson, N., 2014. \u201cApplying robust design optimiza-\ntion to large systems\u201d. In ASME 2014 International\nDesign Engineering Technical Conferences and Com-\nputers and Information in Engineering Conference,\npp. V02BT03A054\u2013V02BT03A054.\n\n[32] Lewis, K., Chen, W., and Schmidt, L., 2006. Decision\nMaking in Engineering Design. ASME Press, New\nYork.\n\n[33] Beck, A. T., Gomes, W. J. S., Lopez, R. H., and\nMiguel, L. F. F., 2015. \u201cA comparison between ro-\nbust and risk-based optimization under uncertainty\u201d.\nStructural and Multidisciplinary Optimization, 52(3),\nSept., pp. 479\u2013492.\n\n[34] Haldar, A., and Mahadevan, S., 2000. Probability,\nreliability, and statistical methods in engineering de-\nsign. John Wiley.\n\n[35] Valdebenito, M. A., and Schue\u0308ller, G. I., 2010. \u201cA sur-\nvey on approaches for reliability-based optimization\u201d.\nStructural and Multidisciplinary Optimization, 42(5),\nNov., pp. 645\u2013663.\n\n[36] Cornell, C., 1969. \u201cA probability-based structural\ncode\u201d. ACI Journal Proceedings, 66(12).\n\n[37] Hasofer, A. M., and Lind, N. C., 1974. \u201cExact\nand invariant second moment code format\u201d. Journal\nof Engineering Mechanics Division, 100(EM1), 01,\npp. 111\u2013121.\n\n[38] Fiessler, B., Neumann, H., and Rackwitz, R., 1979.\n\u201cQuadratic limit states in structural reliability\u201d. Jour-\nnal of Engineering Mechanics Division, 105(4), 08,\npp. 661\u2013676.\n\n[39] Maute, K., and Frangopol, D. M., 2003. \u201cReliability-\nbased design of MEMS mechanisms by topology op-\ntimization\u201d. Computers & Structures, 81(8-11), May,\npp. 813\u2013824.\n\n[40] Sato, Y., Izui, K., Yamada, T., Nishiwaki, S., Ito, M.,\nand Kogiso, N., 2018. \u201cReliability-based topology\noptimization under shape uncertainty modeled in Eu-\nlerian description\u201d. Structural and Multidisciplinary\nOptimization, Sept.\n\n[41] Kang, Z., and Liu, P., 2018. \u201cReliability-based topol-\nogy optimization against geometric imperfections\nwith random threshold model\u201d. International Journal\nfor Numerical Methods in Engineering, 115(1), July,\npp. 99\u2013116.\n\n14 Copyright \u00a9 by ASME\n\n\n\n[42] Mogami, K., Nishiwaki, S., Izui, K., Yoshimura,\nM., and Kogiso, N., 2006. \u201cReliability-based struc-\ntural optimization of frame structures for multiple fail-\nure criteria using topology optimization techniques\u201d.\nStructural and Multidisciplinary Optimization, 32(4),\nOct., pp. 299\u2013311.\n\n[43] Kang, J., Kim, C., and Wang, S., 2004. \u201cReliability-\nbased topology optimization for electromagnetic sys-\ntems\u201d. COMPEL - The international journal for com-\nputation and mathematics in electrical and electronic\nengineering, 23(3), Sept., pp. 715\u2013723.\n\n[44] Jung, H.-S., and Cho, S., 2004. \u201cReliability-\nbased topology optimization of geometrically nonlin-\near structures with loading and material uncertain-\nties\u201d. Finite Elements in Analysis and Design, 41(3),\nDec., pp. 311\u2013331.\n\n[45] Luo, Y., Zhou, M., Wang, M. Y., and Deng, Z., 2014.\n\u201cReliability based topology optimization for contin-\nuum structures with local failure constraints\u201d. Com-\nputers & Structures, 143, Sept., pp. 73\u201384.\n\n[46] da Silva, G. A., and Beck, A. T., 2018. \u201cReliability-\nbased topology optimization of continuum structures\nsubject to local stress constraints\u201d. Structural and\nMultidisciplinary Optimization, 57(6), Jun, pp. 2339\u2013\n2355.\n\n[47] Papadimitriou, D. I., and Mourelatos, Z. P., 2018.\n\u201cReliability-Based Topology Optimization Using\nMean-Value Second-Order Saddlepoint Approxima-\ntion\u201d. Journal of Mechanical Design, 140(3), Jan.,\np. 031403.\n\n[48] Schue\u0308ller, G., Pradlwarter, H., and Koutsourelakis, P.,\n2004. \u201cA critical appraisal of reliability estimation\nprocedures for high dimensions\u201d. Probabilistic En-\ngineering Mechanics, 19(4), Oct., pp. 463\u2013474.\n\n[49] Nguyen, T. H., Song, J., and Paulino, G. H., 2011.\n\u201cSingle-loop system reliability-based topology opti-\nmization considering statistical dependence between\nlimit-states\u201d. Structural and Multidisciplinary Opti-\nmization, 44(5), Nov., pp. 593\u2013611.\n\n[50] Silva, M., Tortorelli, D. A., Norato, J. A., Ha, C.,\nand Bae, H.-R., 2010. \u201cComponent and system\nreliability-based topology optimization using a single-\nloop method\u201d. Structural and Multidisciplinary Opti-\nmization, 41(1), Feb., pp. 87\u2013106.\n\n[51] Liang, J., Mourelatos, Z. P., and Tu, J., 2004. \u201cA\nSingle-Loop Method for Reliability-Based Design\nOptimization\u201d. In Volume 1: 30th Design Automa-\ntion Conference, Vol. 2004, ASME, pp. 419\u2013430.\n\n[52] Kharmanda, G., Olhoff, N., Mohamed, A., and\nLemaire, M., 2004. \u201cReliability-based topology op-\ntimization\u201d. Structural and Multidisciplinary Opti-\nmization, 26(5), Mar., pp. 295\u2013307.\n\n[53] Kharmanda, G., Mohamed, A., and Lemaire, M.,\n2002. \u201cEfficient reliability-based design optimization\nusing a hybrid space with application to finite element\nanalysis\u201d. Structural and Multidisciplinary Optimiza-\ntion, 24(3), Sept., pp. 233\u2013245.\n\n[54] Kogiso, N., Hirano, Y., Nishiwaki, S., Izui, K.,\n\nYoshimura, M., and Min, S., 2010. \u201cReliability-Based\nTopology Optimization of Frame Structures for Multi-\nple Criteria Using SLSV Method\u201d. Journal of Compu-\ntational Science and Technology, 4(3), pp. 172\u2013184.\n\n[55] Chen, X., Hasselman, T., Neill, D., Chen, X., Hassel-\nman, T., and Neill, D., 1997. \u201cReliability based struc-\ntural design optimization for practical applications\u201d.\nIn 38th Structures, Structural Dynamics, and Materi-\nals Conference, American Institute of Aeronautics and\nAstronautics.\n\n[56] Lopez, R. H., and Beck, A. T., 2012. \u201cReliability-\nbased design optimization strategies based on FORM:\na review\u201d. Journal of the Brazilian Society of Mechan-\nical Sciences and Engineering, 34(4), Dec., pp. 506\u2013\n514.\n\n[57] Zhao, Q., Chen, X., Ma, Z.-D., and Lin, Y.,\n2015. \u201cReliability-Based Topology Optimization Us-\ning Stochastic Response Surface Method with Sparse\nGrid Design\u201d. Mathematical Problems in Engineer-\ning, 2015, pp. 1\u201313.\n\n[58] Zhao, Q., Chen, X., Ma, Z., and Lin, Y., 2016.\n\u201cA Comparison of Deterministic, Reliability-Based\nTopology Optimization under Uncertainties\u201d. Acta\nMechanica Solida Sinica, 29(1), Feb., pp. 31\u201345.\n\n[59] Wang, G. G., and Shan, S., 2007. \u201cReview of Meta-\nmodeling Techniques in Support of Engineering De-\nsign Optimization\u201d. Journal of Mechanical Design,\n129(4), p. 370.\n\n[60] Patel, J., and Choi, S.-K., 2012. \u201cClassification ap-\nproach for reliability-based topology optimization us-\ning probabilistic neural networks\u201d. Structural and\nMultidisciplinary Optimization, 45(4), Apr., pp. 529\u2013\n543.\n\n[61] Du, X., Sudjianto, A., and Chen, W., 2004. \u201cAn In-\ntegrated Framework for Optimization Under Uncer-\ntainty Using Inverse Reliability Strategy\u201d. Journal of\nMechanical Design, 126(4), p. 562.\n\n[62] Youn, B. D., Choi, K. K., and Yi, K., 2005. \u201cPerfor-\nmance Moment Integration (PMI) Method for Quality\nAssessment in Reliability-Based Robust Design Opti-\nmization\u201d. Mechanics Based Design of Structures and\nMachines, 33(2), Apr., pp. 185\u2013213.\n\n[63] Mourelatos, Z. P., and Liang, J., 2006. \u201cA Method-\nology for Trading-Off Performance and Robustness\nUnder Uncertainty\u201d. Journal of Mechanical Design,\n128(4), p. 856.\n\n[64] Tang, Y., Chen, J., and Wei, J., 2012. \u201cA Sequential\nAlgorithm for Reliability-Based Robust Design Opti-\nmization Under Epistemic Uncertainty\u201d. Journal of\nMechanical Design, 134(1), p. 014502.\n\n[65] Forouzandeh Shahraki, A., and Noorossana, R., 2014.\n\u201cReliability-based robust design optimization: A gen-\neral methodology using genetic algorithm\u201d. Comput-\ners & Industrial Engineering, 74, Aug., pp. 199\u2013207.\n\n[66] Rathod, V., Yadav, O. P., Rathore, A., and Jain,\nR., 2013. \u201cOptimizing reliability-based robust de-\nsign model using multi-objective genetic algorithm\u201d.\nComputers & Industrial Engineering, 66(2), Oct.,\n\n15 Copyright \u00a9 by ASME\n\n\n\npp. 301\u2013310.\n[67] Lee, I., Choi, K., Du, L., and Gorsich, D., 2008.\n\n\u201cDimension reduction method for reliability-based ro-\nbust design optimization\u201d. Computers & Structures,\n86(13-14), July, pp. 1550\u20131562.\n\n[68] Youn, B. D., Xi, Z., Wells, L. J., and Lamb,\nD. A., 2006. \u201cStochastic Response Surface Using the\nEnhanced Dimension-Reduction (eDR) Method for\nReliability-Based Robust Design Optimization\u201d. In III\nEuropean Conference on Computational Mechanics,\nC. A. Motasoares, J. A. C. Martins, H. C. Rodrigues,\nJ. A. C. Ambro\u0301sio, C. A. B. Pina, C. M. Motasoares,\nE. B. R. Pereira, and J. Folgado, eds. Springer Nether-\nlands, Dordrecht, pp. 388\u2013388.\n\n[69] Youn, B. D., and Xi, Z., 2009. \u201cReliability-based ro-\nbust design optimization using the eigenvector dimen-\nsion reduction (EDR) method\u201d. Structural and Multi-\ndisciplinary Optimization, 37(5), Feb., pp. 475\u2013492.\n\n[70] Keshavarzzadeh, V., Fernandez, F., and Tortorelli,\nD. A., 2017. \u201cTopology optimization under uncer-\ntainty via non-intrusive polynomial chaos expansion\u201d.\nComputer Methods in Applied Mechanics and Engi-\nneering, 318, May, pp. 120\u2013147.\n\n[71] Taflanidis, A. A., and Beck, J. L., 2008. \u201cAn effi-\ncient framework for optimal robust stochastic system\ndesign using stochastic simulation\u201d. Computer Meth-\nods in Applied Mechanics and Engineering, 198(1),\nNov., pp. 88\u2013101.\n\n[72] Keshavarzzadeh, V., Meidani, H., and Tortorelli,\nD. A., 2016. \u201cGradient based design optimization\nunder uncertainty via stochastic expansion methods\u201d.\nComputer Methods in Applied Mechanics and Engi-\nneering, 306, July, pp. 47\u201376.\n\n[73] Bends\u00f8e, M. P., and Sigmund, O., 1999. \u201cMate-\nrial interpolation schemes in topology optimization\u201d.\nArchive of Applied Mechanics (Ingenieur Archiv),\n69(9-10), Nov., pp. 635\u2013654.\n\n[74] Svanberg, K., 1987. \u201cThe method of moving asymp-\ntotes\u2014a new method for structural optimization\u201d. In-\nternational Journal for Numerical Methods in Engi-\nneering, 24(2), Feb., pp. 359\u2013373.\n\n[75] Svanberg, K., 2002. \u201cA Class of Globally Convergent\nOptimization Methods Based on Conservative Convex\nSeparable Approximations\u201d. SIAM Journal on Opti-\nmization, 12(2), Jan., pp. 555\u2013573.\n\n[76] Sigmund, O., and Petersson, J., 1998. \u201cNumer-\nical instabilities in topology optimization: A sur-\nvey on procedures dealing with checkerboards, mesh-\ndependencies and local minima\u201d. Structural Opti-\nmization, 16(1), Aug., pp. 68\u201375.\n\n[77] Sigmund, O., 2007. \u201cMorphology-based black and\nwhite filters for topology optimization\u201d. Structural\nand Multidisciplinary Optimization, 33(4-5), Feb.,\npp. 401\u2013424.\n\n[78] Bruns, T. E., and Tortorelli, D. A., 2001. \u201cTopol-\nogy optimization of non-linear elastic structures and\ncompliant mechanisms\u201d. Computer Methods in Ap-\nplied Mechanics and Engineering, 190(26-27), Mar.,\n\npp. 3443\u20133459.\n[79] Bourdin, B., 2001. \u201cFilters in topology optimization\u201d.\n\nInternational Journal for Numerical Methods in En-\ngineering, 50(9), Mar., pp. 2143\u20132158.\n\n[80] Andreassen, E., Clausen, A., Schevenels, M.,\nLazarov, B. S., and Sigmund, O., 2011. \u201cEfficient\ntopology optimization in MATLAB using 88 lines of\ncode\u201d. Structural and Multidisciplinary Optimization,\n43(1), Jan., pp. 1\u201316.\n\n[81] Lee, S. H., and Chen, W., 2009. \u201cA comparative\nstudy of uncertainty propagation methods for black-\nbox-type problems\u201d. Structural and Multidisciplinary\nOptimization, 37(3), Jan., pp. 239\u2013253.\n\n[82] Xiu, D., 2010. Numerical Methods for Stochastic\nComputations: A Spectral Method Approach. Prince-\nton University Press.\n\n[83] Xiong, F., Greene, S., Chen, W., Xiong, Y., and Yang,\nS., 2010. \u201cA new sparse grid based method for uncer-\ntainty propagation\u201d. Structural and Multidisciplinary\nOptimization, 41(3), Apr., pp. 335\u2013349.\n\n[84] Gerstner, T., and Griebel, M., 1998. \u201cNumerical in-\ntegration using sparse grids\u201d. Numerical Algorithms,\n18, Jan., pp. 209\u2013232.\n\n[85] Smolyak, S. A., 1963. \u201cQuadrature and interpolation\nformulas for tensor products of certain classes of func-\ntions\u201d. Dokl. Akad. Nauk SSSR, 148(5), pp. 1042\u2013\n1045.\n\n[86] Xiu, D., and Hesthaven, J. S., 2005. \u201cHigh-Order Col-\nlocation Methods for Differential Equations with Ran-\ndom Inputs\u201d. SIAM Journal on Scientific Computing,\n27(3), Jan., pp. 1118\u20131139.\n\n[87] Maitre, O., and Knio, O., 2010. Spectral Methods\nfor Uncertainty Quantification: With Applications to\nComputational Fluid Dynamics. Scientific Computa-\ntion. Springer Netherlands.\n\n[88] Davis, P., and Rabinowitz, P., 2007. Methods of Nu-\nmerical Integration. Dover Books on Mathematics Se-\nries. Dover Publications.\n\n[89] Li, C., and Der Kiureghian, A., 1993. \u201cOptimal Dis-\ncretization of Random Fields\u201d. Journal of Engineer-\ning Mechanics, 119(6), June, pp. 1136\u20131154.\n\n[90] Loe\u0300ve, M., 2017. Probability Theory: Third Edition.\nDover Books on Mathematics. Dover Publications.\n\n[91] Ray, S. S., and Sahu, P. K., 2013. \u201cNumerical Meth-\nods for Solving Fredholm Integral Equations of Sec-\nond Kind\u201d. Abstract and Applied Analysis, 2013,\npp. 1\u201317.\n\n[92] Wang, L., 2008. \u201cKarhunen\u2212\u2013Loe\u0300ve Expansions and\ntheir Applications\u201d. PhD thesis, London School of\nEconomics and Political Science.\n\n[93] Missoum, S., Lacaze, S., Boroson, E., and Jiang, P.,\n2015. CODES Toolbox. Computational Optimal De-\nsign of Engineering Systems Laboratory. University\nof Arizona.\n\n[94] Yin, X., and Chen, W., 2006. \u201cEnhanced sequen-\ntial optimization and reliability assessment method for\nprobabilistic optimization with varying design vari-\nance\u201d. Structure and Infrastructure Engineering, 2(3-\n\n16 Copyright \u00a9 by ASME\n\n\n\n4), Sept., pp. 261\u2013275.\n[95] Huang, S., and Kou, X., 2007. \u201cAn extended stochas-\n\ntic response surface method for random field prob-\nlems\u201d. Acta Mechanica Sinica, 23(4), Aug., pp. 445\u2013\n450.\n\n[96] Isukapalli, S., Balakrishnan, S., and Georgopoulos, P.,\n2004. \u201cComputationally efficient uncertainty propa-\ngation and reduction using the stochastic response sur-\nface method\u201d. IEEE, pp. 2237\u20132243 Vol.2.\n\n[97] Frecker, M. I., Ananthasuresh, G. K., Nishiwaki,\nS., Kikuchi, N., and Kota, S., 1997. \u201cTopologi-\ncal Synthesis of Compliant Mechanisms Using Multi-\nCriteria Optimization\u201d. Journal of Mechanical De-\nsign, 119(2), p. 238.\n\n[98] Marler, R. T., and Arora, J. S., 2010. \u201cThe weighted\nsum method for multi-objective optimization: new in-\nsights\u201d. Structural and Multidisciplinary Optimiza-\ntion, 41(6), June, pp. 853\u2013862.\n\n[99] Alexanderian, A., 2015. A brief note on the\nKarhunen-Loe\u0300ve expansion.\n\n[100] Youn, B. D., Choi, K. K., and Park, Y. H., 2003.\n\u201cHybrid Analysis Method for Reliability-Based De-\nsign Optimization\u201d. Journal of Mechanical Design,\n125(2), p. 221.\n\n17 Copyright \u00a9 by ASME\n\n\n\t1 Introduction\n\t2 Background\n\t3 Topology Optimization under Uncertainty\n\t3.1 Deterministic Topology Optimization\n\t3.2 Robust Reliability-based Topology Optimization\n\t3.2.1 Problem Formulation\n\t3.2.2 Smolyak-type Sparse Grid\n\t3.2.3 Karhunen-\u2013Lo\u00e8ve Expansion\n\t3.2.4 Inverse Reliability Analysis and SORA\n\t3.2.5 Stochastic Response Surface Method\n\t3.2.6 Solution Algorithm\n\n\n\t4 Results\n\t4.1 The Cantilever Beam\n\t4.2 The L-shaped Beam\n\n\t5 Discussions\n\t6 Conclusions\n\n"}
{"Title": "A Literature Review on Length of Stay Prediction for Stroke Patients using Machine Learning and Statistical Approaches", "Authors": "Ola Alkhatib, Ayman Alahmar", "Abstract": "  Hospital length of stay (LOS) is one of the most essential healthcare metrics that reflects the hospital quality of service and helps improve hospital scheduling and management. LOS prediction helps in cost management because patients who remain in hospitals usually do so in hospital units where resources are severely limited. In this study, we reviewed papers on LOS prediction using machine learning and statistical approaches. Our literature review considers research studies that focus on LOS prediction for stroke patients. Some of the surveyed studies revealed that authors reached contradicting conclusions. For example, the age of the patient was considered an important predictor of LOS for stroke patients in some studies, while other studies concluded that age was not a significant factor. Therefore, additional research is required in this domain to further understand the predictors of LOS for stroke patients.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00005", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Title (use style: paper title)\n\n\nA Literature Review on Length of Stay Prediction for Stroke \n\nPatients using Machine Learning and Statistical Approaches \n\nOla Alkhatib1 and Ayman Alahmar2 \n\n1Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada \n2Department of Software Engineering, Lakehead University, Thunder Bay, Ontario, Canada \n\nAbstract Hospital length of stay (LOS) is one of the most essential healthcare metrics that \n\nreflects the hospital quality of service and helps improve hospital scheduling and management. \n\nLOS prediction helps in cost management because patients who remain in hospitals usually do \n\nso in hospital units where resources are severely limited. In this study, we reviewed papers on \n\nLOS prediction using machine learning and statistical approaches. Our literature review \n\nconsiders research studies that focus on LOS prediction for stroke patients. Some of the \n\nsurveyed studies revealed that authors reached contradicting conclusions. For example, the age \n\nof the patient was considered an important predictor of LOS for stroke patients in some studies, \n\nwhile other studies concluded that age was not a significant factor. Therefore, additional \n\nresearch is required in this domain to further understand the predictors of LOS for stroke \n\npatients. \n\nKeywords: Length of Stay, Stroke, Machine Learning, Data Mining, Statistical Analysis. \n\n1. INTRODUCTION\n\nEALTHCARE sectors show increasing costs in most regions around the world. Healthcare\n\nexpenditure constitutes a significant share of the gross domestic product for many \n\ncountries. There are many challenges associated with growth in the healthcare sector, including \n\nincreased pressure on the limited resources of hospitals. This issue has motivated researchers \n\nto conduct further research related to hospital resource optimization. Since hospitalization \n\nconstitutes a significant cost of patient care, many researchers have been investigating the \n\nproblem of patient Length of Stay (LOS) prediction. LOS is defined as the duration of a patient \n\nhospitalization, and it is determined as the difference between the timestamp of a patient \n\nhospital discharge and the timestamp of their hospital admission [1], [2]. LOS prediction is an \n\nimportant topic for many reasons, such as: \n\n\u2022 Knowledge of LOS allows hospitals to manage their bed and room capacities so that\n\nthey can know how long a patient is expected to occupy hospital space.\n\n\u2022 Information about LOS allows hospitals to determine the number of staff that must be\n\nscheduled over the day/night shifts to properly accommodate the patients.\n\n\u2022 Patients and their families can estimate the cost of a stay in paid hospitalizations.\n\nBy investigating the existing literature, we found that LOS prediction papers used machine \n\nlearning/statistical approaches and can be divided into the type of disease under consideration. \n\nSome authors studied LOS prediction in general (i.e. without specifying a specific disease), \n\nwhile other researchers focused on LOS prediction pertinent to a specific disease (e.g., stroke, \n\nH \n\n1 \n\n\n\n2 \n\ndiabetes). Fig. 1 depicts this categorization and includes example references to research articles. \n\nFig. 1. Classification of LOS prediction research articles. \n\nIn this survey, we review papers that predict the patients\u2019 LOS in general and then we focus \n\non LOS prediction for stroke patients. We focused on stroke patients because they face many \n\nchallenges with definite need for hospitalization, and also because strokes have an enormous \n\ncost on healthcare systems around the world. Using popular research search engines (e.g., IEEE \n\nXplore, Springer, Science Direct, etc.), we searched phrases such as \u201clength of stay\u201d, \u201chospital \n\nlength of stay\u201d, \u201cprediction\u201d, \u201cmachine learning\u201d, \u201cstroke\u201d, \u201cischemic stroke\u201d, \u201cdata mining\u201d, \n\nand \u201cstatistical analysis\u201d in order to find existing work on this topic (up to mid 2020). \n\nStroke is a disease that affects the arteries leading to and within the brain. It can be a \n\nsignificant financial and health burden for patients, medical staff, and healthcare systems. \n\nStroke is associated with prolonged LOS in hospitals and rehabilitation facilities [1] and is a \n\nleading cause of death and disability worldwide. According to Statistics Canada, in 2018, stroke \n\nwas the third largest cause of death in Canada after cancer and heart disease \n\n(https://www.statcan.gc.ca). Stroke, also known as cerebrovascular accident (or CVA), is a \n\nsudden and devastating illness that is characterized by the rapid loss of the functions of the brain \n\ndue to a disruption of blood flow to the brain (see Fig. 2). This disruption is caused by: lack of \n\nblood flow (ischemic strokes), which account for more than 80% of all strokes; blockage of \n\nblood flow; or hemorrhage [3]. \n\nFig. 2. Illustration of stroke (Source: Mayo Clinic (mayoclinic.org)). \n\nThe remainder of the paper is organized as follows. Below we present our literature review on \n\n\n\n \n\n \n\n \n\n \n\n \n\n3 \n\n \n\nLOS prediction for general patients. Next we consider stroke patients. Finally, the paper ends \n\nwith a discussion and conclusions section. \n\n2. LOS PREDICTION FOR GENERAL PATIENTS \n\nKabir et al. [4] proposed a non-linear feature selection method using artificial neural networks \n\n(ANNs) to determine the most essential features for LOS prediction. The study evaluates the \n\nperformance of (ANNs), support vector machines (SVM), and logistic regression (LR) on \n\nselected subsets of features to predict the LOS class and identify the best subset of features. The \n\nstudy used a dataset from the National Surgical Quality Improvement Program database. The \n\ndataset, based on data from 2015, included 273 features of more than 880,000 surgical patients \n\nadmitted to hospital for various surgical procedures to address different diseases and medical \n\nconditions. The authors reduced the features from 273 to 40 based on consultation with domain \n\nexperts (anesthesiologists). After preprocessing the dataset, 715,143 patient records were \n\nselected for further analysis. The patients were categorized using their medical group into the \n\nfollowing nine surgical categories: (1) general surgery, (2) vascular, (3) urology, (4) plastics, \n\n(5) otolaryngology, (6) orthopedics, (7) gynecology, (8) neurosurgery, and (9) other surgical \n\nconditions (including thoracic, cardiac surgery, and interventional radiology patients). An \n\nadditional category that includes all patients was added as group (10) for comparison purposes. \n\nThe authors presented the normalized importance score of features for each patient category. In \n\ngeneral, features 16, 20, and 21 showed the most significant contribution to the prediction of \n\nLOS. Feature 16 indicates the period from admission to surgery, feature 20 denotes whether the \n\npatient is an outpatient or inpatient, and feature 21 represents the estimated probability of \n\nmorbidity computed by the hospital using LR. These features had a strong correlation with LOS \n\nwhich validates the performance of the non-linear approach of this study in obtaining \n\nconsiderable features. Another important factor presented in this research is the specific \n\ncorrelation of features with their categories. For example, feature 38, which represents the \n\nsituation of a patient\u2019s wound, was important in predicting the LOS for otolaryngology patients, \n\nwhile it had less importance in LOS predicting for other patient categories. By comparing the \n\nimportance of features computed for all patients (group 10) with other categories, the authors \n\nshowed that grouping patients based on their disease can improve the accuracy of LOS \n\npredictive models. The final results revealed that ANNs, as non-linear classifiers, beat SVMs \n\nand LR in the achieved accuracy for LOS prediction. This proves that the relationship between \n\nLOS and its predictors is highly non-linear. The ANNs model improves accuracy and eliminates \n\nthe number of required features. \n\nAzari et al. [5] used a multi-tiered data mining approach for predicting hospital LOS to \n\ndecrease the uncertainty related with the LOS for inpatients. Their prediction approach was \n\nbased on clustering (i.e., k-means clustering) to create the training sets that train various \n\nclassification algorithms. The number of clusters was determined based on the disease \n\nconditions or by using the Charlson index which provides the general categories of the diseases. \n\nFig. 3 describes the approach used in this study. Several classifiers were used to predict the \n\nLOS such as: K-nearest neighbors, LR, naive Bayes, SVMs, Bayesian networks (Bnets), J48 \n\ndecision tree, classification rules (JRip), bagging, random forest, and boosting. The paper \n\nconsidered various performance metrics such as accuracy, Kappa statistic, precision, recall, and \n\narea under the curve (AUC). In order to rank the classifiers, researchers used the Friedman test \n\nto determine the classifier with the best outcome for a certain level of clustering. The dataset \n\n\n\n \n\n \n\n \n\n \n\n \n\n4 \n\n \n\nused the Heritage Health prize data. The dataset contains 1,048,576 records of hospital claims \n\nwithin a 3-year period. The results showed that using clustering as a precursor to form the \n\ntraining set provides better results compared to non-clustering based training sets. The results \n\nalso showed that Bnets, SVMs, JRip, Bagging, and J48 had better overall performance than the \n\nother classifiers. The outcomes of the paper were validated by a domain expert from Emergency \n\nMedicine. \n\n \n\n \n \n\nFig. 3. LOS prediction approach of Azari et al. [5]. \n\n \n\nNouaouri et al. [6] proposed the application of data mining techniques to predict the LOS for \n\npatients without considering a specific disease. They introduced the Evidential LOS prediction \n\nAlgorithm (ELOSA) that allows the prediction of the LOS of a new patient. Their approach \n\nhandles the imprecision, uncertainty, and missing data within the dataset of patients. The \n\nELOSA algorithm is based on the precise support and association rule confidence measures [6]. \n\nThe LOS experiments were conducted on a real hospital dataset that contains the data for 270 \n\npatients. To predict the inpatient LOS, the authors considered age, sex, physiological conditions \n\n(emergency degree), and operation length. The emergency degree column in the dataset was a \n\ncategorical attribute that contained values from the following set {A, R, D}. A indicates an \n\nabsolute emergency, R is for relative emergency, and D represents delayed emergency. The \n\nlength of stay was classified as Short (S), approximately 3 days, Medium (M), approximately \n\n10 days, and Long (L), approximately 20 days, with a small overlap between the ranges as \n\nshown in Fig. 4. They compared their results with other algorithms in similar studies and \n\nconcluded that their approach showed better results. \n\nRathor et al. [7] used a clustering algorithm (i.e., Density Based Spatial Clustering of \n\nApplications with Noise (DB- SCAN)) and K-Apriori, which is a combination of Apriori and \n\nK-means algorithms. The algorithms were applied to a dataset of 9,052 patients (the source of \n\nthe dataset was not disclosed). The execution time of the algorithms were compared, showing \n\nDBSCAN to be faster than the K-Apriori; although, DBSCAN took exponentially longer as the \n\nnumber of inputs increased. The prediction was based on the current symptoms and medical \n\nhistory of the patients, which was provided by the patient at the time of admission. For \n\nprediction of LOS, the medical data underwent a pre-processing phase, which had three steps:  \n\n \n\n \n\n\n\n \n\n \n\n \n\n \n\n \n\n5 \n\n \n\n \n \n\nFig. 4. LOS classes in terms of days [6]. \n\n \n\n \n\ndata cleaning, data integration and transformation, and data reduction. Then, using the \n\nprocessed data, symptoms for a particular disease were grouped together and used for LOS \n\nprediction. The study determined the times of execution of K-apriori and DBSCAN \n\nindependently and subsequently compared them. Both algorithms were treated with the same \n\nnumber of inputs and with the same values. The authors concluded that the execution time of \n\nDBSCAN was comparatively much shorter than K-Apriori, but as the number of inputs increase \n\nto high values, the execution time of DBSCAN increased exponentially whereas there was no \n\nchange in K-Apriori. \n\n \n\n3. LOS PREDICTION FOR STROKE PATIENTS \n\nIn stroke, the brain is prevented from getting oxygen and nutrients from the blood. Without \n\noxygen and nutrients, brain cells begin to die within minutes. Sudden bleeding in the brain can \n\nalso cause a stroke if it damages brain cells. A stroke is a medical emergency that can cause \n\nlasting brain damage, long-term disability, or even death. Signs of a stroke can range from mild \n\nweakness to paralysis or numbness on one side of the face or body. Other signs include a sudden \n\nand severe headache, sudden weakness, trouble seeing, and trouble speaking or understanding \n\nspeech (https://www.nhlbi.nih.gov/health-topics/stroke). \n\nAl Taleb et al. [3] introduced a machine learning method for early prediction of LOS of stroke \n\npatients. They tested their approach at the Stroke Unit of King Fahad Bin Abdul- Aziz Hospital \n\nin Saudi Arabia. The study was based on 866 stroke patients, whose data was retrieved from \n\nthe Neurology Department database. For data cleaning, each set of patient data was manually \n\nexamined for invalid or erroneous inputs. Records with missing values in more than 50% of the \n\nattributes were deleted. For the records with missing values in less than 50% of attributes, \n\nmissing values were replaced with the average value of the respective attributes for numeric \n\nattributes, and with the mode value for the categorical attributes. The approach involved a \n\nfeature selection step based on Information Gain (IG) followed by a prediction model \n\ndevelopment step using different machine learning algorithms as explained below. \n\n \n\nThe original dataset contained 105 attributes, out of which 54 attributes were manually \n\neliminated due to being irrelevant or redundant, such as time of arrival, date of MRI, and cause \n\nof death. The remaining 51 attributes were ranked based on their IG with respect to LOS, and \n\nthen an iterative process of elimination was applied where the researchers began processing all \n\n\n\n \n\n \n\n \n\n \n\n \n\n6 \n\n \n\nof the features. Then features were eliminated one at a time, starting with the least ranked one, \n\nand the IG was recalculated. The repetitive process stopped when there was no further \n\nimprovement in IG. Finally, 16 remaining attributes (including LOS) were selected for the \n\nprediction steps. The selected attributes and their IG values are listed in Fig. 5. \n\n \n\n \n\n \n \n\nFig. 5. Selected attributes and their IG values with respect to the class attribute (LOS) [3].  \n\n \n\nPrediction results were compared to identify the algorithm with the best performance. Several \n\nexperiments were performed in various settings. The authors found that the most accurate model \n\nin their study was the Bnet model with accuracy of 81.28%. \n\nIn another study, Neto et al. [8] proposed a neural network LOS prediction method based on \n\nthe information available on the stroke neurological events, the patient\u2019s health status, and \n\nsurgery details. The neural network was trained to test with three attribute subsets of different \n\nsizes. The first subset contained 33 attributes, the second 14, and the third subset consisted of \n\nonly 7 attributes. By testing the three subsets, it was possible to define an optimal neural \n\nnetwork configuration where the lowest error values were registered as Root Mean Squared \n\nError, 5.9451, and Mean Absolute Error, 4.6354. They concluded that the third use case (the \n\none with fewer variables) obtained better results than the other attribute sets. \n\nZhang et al. [1] aimed to develop a risk prediction model of prolonged LOS in stroke patients \n\nfor 50 inpatient rehabilitation centers in 20 provinces across mainland China, based on the \n\nInternational Classification of Functioning, Disability, and Health Generic Set case mix on \n\nadmission. The study was conducted on 383 stroke patients. The independent predictors of \n\nprolonged LOS were identified using Multivariate Logistic Regression (MLR) analysis. A \n\nprediction model was established and then evaluated by receiver operating characteristic curve \n\nanalysis, and the Hosmer-Lemeshow test. The results showed that the type of medical insurance \n\nand the performance of daily activities were associated with prolonged LOS. Age and mobility \n\nlevel demonstrated no significant predictive value. The prediction model revealed acceptable \n\ndiscrimination shown by an AUC of 0.699. The researchers concluded that the scores for the \n\ntype of medical insurance and the performance of daily activities on admission were \n\n\n\n \n\n \n\n \n\n \n\n \n\n7 \n\n \n\nindependent predictors of prolonged LOS for stroke patients. Their study proved that prediction \n\nmodels allow stakeholders to quantitatively estimate the risk of prolonged LOS upon admission, \n\nand to facilitate financial planning. They can also determine any required treatment regimens \n\nduring hospitalization, the need for referral after discharge, and reimbursement of costs. \n\nMinaeian et al. [9] sought to determine whether a longer emergency LOS was associated with \n\na poor 90-day outcome following an ischemic stroke. Their method was based on a \n\nretrospective analysis of a single-center cohort of consecutive ischemic stroke patients. There \n\nwere 325 patients in the study. They constructed multivariable linear and LR models to \n\ndetermine factors independently associated with emergency LOS as well as a poor 90-day \n\noutcome. The results revealed that the median LOS in the cohort was 5.8 hours of time spent in \n\nemergency. For patients admitted to the inpatient stroke ward (160 patients) versus \n\nneurointensive care unit (NICU) (165 patients), the median LOS was 8.2 hours versus 3.7 hours, \n\nrespectively. On multivariable linear regression, NICU admission, endovascular stroke therapy, \n\nand thrombolysis were inversely associated with the LOS. Evening shift presentation was \n\nassociated with a longer LOS. On MLR, a greater admission stroke severity, worse pre-\n\nadmission modified Rankin scale, hemorrhagic conversion, and a shorter LOS were associated \n\nwith a poor 90-day outcome. Early initiation of statin therapy, endovascular stroke therapy, \n\nNICU admission, and evening shift presentation were associated with a good 90-day outcome. \n\nThe authors stressed in their conclusion that in contrast to prior studies, a shorter emergency \n\nLOS was associated with a worse 90-day functional outcome, possibly reflecting prioritized \n\nadmission of more severely affected stroke patients who were at high risk for a poor functional \n\noutcome. \n\nChang et al. [10] aimed to determine the clinical and demographic predictors of LOS of acute \n\ncare hospital stay for patients with first-ever ischemic stroke. In the study, a group of 330 \n\npatients who had their first-ever ischemic stroke and were admitted to a medical center in \n\nsouthern Taiwan were followed prospectively. The researchers evaluated only the factors that \n\ncould be known at the time of admission. Univariate analysis and multiple regression analysis \n\nwere used to identify the LOS main predictors. \n\nIn the reported results, the median LOS was 7 days, average LOS was 11 days, and the LOS \n\nrange was 1 to 122 days. Among the prespecified demographic and clinical characteristics, the \n\nNational Institutes of Health Stroke Scale (NIHSS) score at admission, the quadratic term of \n\nthe initial NIHSS score, the modified Barthel Index score at admission, small-vessel occlusion \n\nstroke, smoking, and sex were the main predictors for LOS. In particular, for each 1-point \n\nincrease in the score of NIHSS, LOS increased by approximately 1 day for patients with mild \n\nor moderate neurological impairments (score 0 to 15 points), while LOS decreased \n\napproximately 1 day for patients with severe neurological impairments (score 15 points). The \n\nauthors concluded that the severity of acute stroke, as scored by the total score on NIHSS, was \n\nan important factor influencing LOS after acute stroke hospitalization.  \n\nAppelros et al. [11] examined the factors that influence acute and total LOS for stroke \n\npatients. The basis of their investigation was a population-based cohort of first-ever stroke \n\npatients (388 patients). Patient data included age, sex, risk factors, social factors, dementia, \n\nstroke type, and stroke severity, measured using the NIHSS. The results showed a mean acute \n\nLOS of 12 days and mean total LOS of 29 days. Independent predictors of acute LOS were \n\nstroke severity, lacunar stroke, pre-stroke dementia, and smoking. Independent predictors of \n\ntotal LOS were stroke severity and pre-stroke activities of daily living dependency. The NIHSS \n\n\n\n \n\n \n\n \n\n \n\n \n\n8 \n\n \n\nelements that best correlated with LOS included paresis, unilateral neglect, and level of \n\nconsciousness. The conclusion was that stroke severity is a strong and reliable predictor of LOS. \n\nThe results can be used as a baseline for evaluating cost-effectiveness of stroke care changes, \n\nsuch as assessment of new drugs and organizational modifications. \n\nThe study conducted by Okere et al. [12] was designed to evaluate predictors of hospital LOS \n\nand re-admissions among non-surgical ischemic stroke patients. The patients in this study were \n\nadult patients (\u2265 18 years) with a diagnosis of non-surgical ischemic stroke, who were \n\nhospitalized between November 2007 and March 2013. The results of the statistical analyses \n\n(multivariate and bivariate analyses), revealed that insurance type was a significant predictor of \n\nLOS, with Medicare patients having a longer LOS compared to patients with private insurance. \n\nSeverity of illness was also a predictor of LOS, whereby patients prescribed statins and patients \n\naged less than 80 years old had a lower 30-day hospital re-admission rate compared to patients \n\nwho were not prescribed statins and who were older than 80 years of age, respectively. \n\nChoi et al. [13] considered LOS prediction for acute stroke patients and extracted their dataset \n\nfrom 2013 and 2014 discharge injured patient data. The data was classified as 60% for training \n\nand 40% for evaluation. In their model, they used the multiple regression analysis method \n\ncombined with machine learning techniques (such as decision tree and neural network) to create \n\nan ensemble technique that integrates all methods. They evaluated their model using root \n\nabsolute error index. Considering the used methods, the error index was 23.7 for multiple \n\nregression, 23.7 for decision tree, 22.7 for neural network, and 22.7 for the ensemble technique. \n\nThey concluded that the neural network technique was found to be superior (even reaching the \n\nlevel of ensemble methods). \n\nIn the study carried out by Svendsen et al. [14], the author\u2019s objective was to determine \n\nwhether healthcare quality was associated with LOS among stroke patients. They performed a \n\npopulation-based study that included 2,636 stroke patients between 2003 and 2005 from a \n\nstroke unit in Denmark. In this study, quality of care was measured as fulfillment of twelve (12) \n\ncriteria: \u201cearly admission to a stroke unit, early antiplatelet therapy, early anticoagulant therapy, \n\nearly computed tomography/magnetic resonance imaging scan, early water swallowing test, \n\nearly mobilization, early intermittent catheterization, early deep venous thromboembolism \n\nprophylaxis, early assessment by a Physiotherapist and an Occupational Therapist, and early \n\nassessment of nutritional and constipation risk\u201d [14]. The authors\u2019 analyzed the patients\u2019 data \n\nusing linear regression clustered at the stroke units by multilevel modeling. The results showed \n\nthat the median length of stay was 13 days. Fulfilling each quality of care criterion was \n\nassociated with shorter LOS. The authors found that \u201cthe association between meeting more \n\nquality of care criteria and LOS followed a dose-response effect, that is, patients who fulfilled \n\nbetween 75% and 100% of the quality of care criteria were hospitalized only one-half as long \n\nas patients who fulfilled between 0% and 24% of the criteria\u201d. The study concluded that the \n\ncare in the early phase of stroke is very important as a high initial quality of care was associated \n\nwith shorter length of stay among stroke patients. \n\nGarza-Ulloa [15] used neural network algorithms to predict rehabilitation LOS for stroke \n\npatients along with other stroke metrics (i.e., the need for surgery and rehabilitation need). The \n\nstudy objective was to find an optimal neural network configuration using three different \n\navailable software: one manual (with no automatic stepwise functions and limited diagnostic \n\ncapability), another semi-automatic (allows step- wise function with good diagnostics), and \n\nneuro-intelligence (uses genetic algorithm to find the best neural network (NN) configuration). \n\n\n\n \n\n \n\n \n\n \n\n \n\n9 \n\n \n\nBased on the 14 stroke input variables and the 3 output target stroke values, the paper suggested \n\nthat the forecasting of: surgery, rehab and days of rehabilitation were possible using neural \n\nnetwork tools. Fig. 6 (from [15]) outlines the 14-group variables for the proposed neural \n\nnetwork . \n\n \n\n \nFig. 6. 14-Group variables for the proposed NN [15]. \n\n \n\nThe study of Ng et al. [16] aimed to investigate LOS characteristics and identify the predictors \n\nof post-stroke acute, rehabilitation and total LOS. The study divided the stroke patients (1,277 \n\npatients) into two subgroups of short LOS and long LOS, and compared the two subgroups \n\nregarding complication rates and functional outcomes. The authors considered stroke patients \n\nwithin a 5-year period from 2004 to 2009 in a dedicated rehabilitation unit within a tertiary \n\nacademic acute hospital in Singapore. The primary outcome measure considered in the \n\nrehabilitation phase was the functional independence measure (FIM). Short acute LOS patients \n\nwere defined as patients who stayed less than 7 days. Most patients in the study were ischemic \n\nstroke patients (1,019 patients (80%)), while the remaining patients were haemorrhagic stroke \n\npatients (20%). The results of the study showed that the average acute and rehabilitation LOS \n\nwere 9-7 days and 18-10 days, respectively. \u201cHaemorrhagic strokes and anterior circulation \n\ninfarcts had significantly longer acute, rehabilitation and total LOS compared to posterior \n\ncirculation and lacunar infarcts\u201d [16]. Patients that were admitted after 2007 had significantly \n\nshorter acute, rehabilitation and total LOS. The authors found poor correlation between the \n\nacute and rehabilitation LOS (r = 0.12). In multivariate analysis, considering rehabilitation \n\nLOS, admission FIM scores were significantly associated with LOS, while, in acute LOS, \n\nstroke type was strongly associated with LOS. \u201cPatients in the short acute LOS group had fewer \n\nmedical complications and similar FIM efficacies compared to the longer acute LOS group.\u201d \n\n[16]. The authors concluded that it is very important to transfer appropriate patients as early as \n\npossible to rehabilitation units as this ensures that the development of clinical complications is \n\nminimized, while rehabilitation efficacy is maintained. \n\nBindawas et al. [17] aimed to investigate the association between LOS and functional \n\noutcomes among patients with stroke discharged from a rehabilitation facility in Saudi Arabia. \n\nThere were 409 adult patients in the study (age 18) admitted between 2008 and 2014, with no \n\ndeaths during the study period. Patients were divided into 4 different groups based on the days \n\n\n\n \n\n \n\n \n\n \n\n \n\n10 \n\n \n\nof rehabilitation: \u2264 30 days (n=114), 31\u201360 days (n=199), 61\u201390 days (n=72), and > 90 days \n\n(n=24). Multivariate regression analyses were used to evaluate functional outcomes using the \n\nFIM. The results of the study showed that higher FIM scores were significantly associated with \n\na LOS \u2264 30 days and 31\u201360 days, compared to > 90 days. The authors concluded that \u201ca short \n\nor intermediate LOS is not necessarily associated with worse outcomes, assuming adequate care \n\nis provided.\u201d [17]. \n\nArboix et al. [18] considered the identification of clinical predictors of prolonged hospital \n\nstay after acute stroke. They considered a long study period of 17 years for patients in Spain \n\nwho have had their first-ever ischemic stroke and primary intracerebral hemorrhage. Prolonged \n\nLOS stay was defined as LOS longer than 12 days after admission. The attributes considered \n\nincluded demographic data, cardiovascular risk factors, neuroimaging findings, clinical factors, \n\nand outcome. LR analysis was used to evaluate the independent influence of statistically \n\nsignificant variables in the duration of hospitalization. The results of 3,112 acute stroke patients \n\nshowed that prolonged hospital stay was recorded in 1,536 (49.4%) cases. Furthermore, males, \n\nlimb weakness, vascular complications, urinary complications, and infectious complications \n\nwere independently associated with longer LOS, whereas being symptom free at hospital \n\ndischarge and lacunar infarction were inversely associated with prolonged LOS. The authors \n\nconcluded that \u201cin-hospital medical complications (vascular, urinary, and infectious) are \n\nrelevant factors influencing duration of hospitalization after acute stroke. Therefore, prevention \n\nof potentially modifiable risk factors for medical complications is an important aspect of the \n\nearly management of patients who experienced stroke\u201d [18]. \n\nThe objective of the study conducted by Koton et al. [19] was to derive a simple score for the \n\nassessment of the risk of prolonged length of stay for acute stroke patients. Prolonged LOS was \n\ndefined as LOS \u2265 7 days. The results showed that the severity of stroke was the strongest \n\nmultivariable predictor of prolonged LOS. The study concluded that a simple prolonged LOS \n\nscore, based on available baseline information (stroke severity), may be useful for developing \n\npolicies aimed at better use of resources and optimal discharge planning of acute stroke patients \n\n[19]. \n\nHung et al. [20] aimed to consider the factors that influence LOS for stroke patients in \n\nTaiwan. The researchers explored how intravenous thrombolysis (IVT) affects LOS in an acute \n\ncare hospital setting. The study considered adult patients with ischemic stroke who presented \n\nwithin 48 hours of stroke onset. The relationship between IVT and prolonged length of stay \n\n(LOS \u2265 7 days) was studied by both classification and regression tree, as well as MLR analyses. \n\nFig. 7 illustrates the risk stratification for prolonged LOS by means of the classification and \n\nregression tree analysis. Among the study population of 3,054 patients, 1,110 presented within \n\n4.5 hours. The median LOS was 7 days (ranging from 4 to 11 days), and 1,619 patients had \n\nprolonged LOS. MLR revealed that IVT was an independent factor that reduced the risk of \n\nprolonged LOS, whereas age, NIHSS score, diabetes mellitus, and leukocytosis at admission \n\npredicted prolonged LOS. Decision tree analysis identified four variables (NIHSS score, IVT, \n\nleukocytosis at admission, and age) as important factors and they were used to partition the \n\npatients into six subgroups (see Fig. 7). The patient subgroup that had an NIHSS score of 5 to \n\n7 and received IVT had the lowest probability (19%) of prolonged LOS [20]. The authors \n\nconcluded that IVT minimized the risk of prolonged length of stay in patients with acute \n\nischemic stroke. They recommended that measures to increase the rate of IVT be encouraged. \n\n \n\n\n\n \n\n \n\n \n\n \n\n \n\n11 \n\n \n\n \nFig. 7. Risk stratification for prolonged LOS by means of the classification \n\nand regression tree analysis [20]. \n\n 4. DISCUSSION AND CONCLUSIONS \n\nThe topic of hospital LOS is an important topic for hospital resource utilization and \n\noptimization [21][22]. Although many researchers have conducted research on LOS prediction, \n\nmore research is needed to further enrich this domain of study. We noticed from our literature \n\nreview that researchers occasionally reached contradicting conclusions about LOS for stroke \n\npatients. For example, some researchers (e.g., [1]) found that the age of the patient was not a \n\nsignificant predictor of prolonged LOS, whereas, others (e.g., [20]) concluded that a patient\u2019s \n\nage was an important predictor for LOS for stroke patients. This shows how LOS prediction is \n\na complex phenomenon that requires more studies and careful investigation. On the other hand, \n\nmost researchers (implicitly or explicitly) agreed that stroke severity (e.g., NIHSS) is a major \n\npredictor of LOS in stroke patients. \n\nAnother observation from our literature review is that not all researchers teamed up with \n\ndomain experts while conducting machine learning studies on LOS prediction. We view this as \n\na limitation in such studies because LOS prediction is a topic that is highly related to the medical \n\nfield as well as to patients\u2019 medical data and characteristics. This implies that in future research, \n\ndomain experts should be consulted before finalizing and publishing such LOS prediction \n\nstudies. Domain experts enrich the studies and make them more realistic. \n\nAnother point is that some researchers did not specifically mention the attributes that were \n\neffective in LOS prediction at the end of their studies. However, this particular information is \n\nhighly important for the readers of such research articles so that new research can build on \n\nprevious studies. We also recommend more future cooperation between machine learning \n\nresearchers in this field because of its importance in hospital resource utilization, decreasing \n\nhealthcare costs, and achieving healthier people and an overall healthier society.  \n\n\n\n \n\n \n\n \n\n \n\n \n\n12 \n\n \n\n \n\nREFERENCES \n\n[1] X. Zhang, H. Qiu, S. Liu, J. Li, and M. Zhou, \u201cPrediction of prolonged length of stay for stroke \n\npatients on admission for inpatient rehabilitation based on the international classification of \n\nfunctioning, disability, and health (ICF) generic set: A study from 50 centers in china,\u201d Medical \n\nScience Monitor: International Medical Journal of Experimental and Clinical Research, vol. 26, \n\npp. e918 811\u20131, 2020. \n\n[2] I. E. Livieris, I. F. Dimopoulos, T. Kotsilieris, and P. Pintelas, \u201cPredicting length of stay in \n\nhospitalized patients using ssl algorithms,\u201d in Proceed- ings of the 8th International Conference on \n\nSoftware Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, \n\n2018, pp. 16\u201322. \n\n[3] A. R. Al Taleb, M. Hoque, A. Hasanat, and M. B. Khan, \u201cApplication of data mining techniques \n\nto predict length of stay of stroke patients,\u201d in 2017 International Conference on Informatics, \n\nHealth & Technology (ICIHT). IEEE, 2017, pp. 1\u20135. \n\n[4] S. Kabir and L. Farrokhvar, \u201cNon-linear feature selection for prediction of hospital length of stay,\u201d \n\nin 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA). \n\nIEEE, 2019, pp. 945\u2013950. \n\n[5] A. Azari, V. P. Janeja, and A. Mohseni, \u201cPredicting hospital length of stay (PHLOS): A multi-\n\ntiered data mining approach,\u201d in 2012 IEEE 12th International Conference on Data Mining \n\nWorkshops. IEEE, 2012, pp. 17\u201324. \n\n[6] I. Nouaouri, A. Samet, and H. Allaoui, \u201cEvidential data mining for length of stay (LOS) prediction \n\nproblem,\u201d in 2015 IEEE International Conference on Automation Science and Engineering \n\n(CASE). IEEE, 2015, pp. 1415\u20131420. \n\n[7]    R. Rathor and P. Agarkar, \u201cLosh prediction using data mining,\u201d Inter- national Journal of \n\nComputer Applications, vol. 119, no. 2, 2015. \n\n[8]    C. Neto, M. Brito, H. Peixoto, V. Lopes, A. Abelha, and J. Machado, \u201cPrediction of length of \n\nstay for stroke patients using artificial neural networks,\u201d in World Conference on Information \n\nSystems and Technolo- gies. Springer, 2020, pp. 212\u2013221. \n\n[9]    A. Minaeian, A. Patel, B. Essa, R. P. Goddeau Jr, M. Moonis, and N. Henninger, \u201cEmergency \n\ndepartment length of stay and outcome after ischemic stroke,\u201d Journal of Stroke and \n\nCerebrovascular Diseases, vol. 26, no. 10, pp. 2167\u20132173, 2017. \n\n[10] K.-C. Chang, M.-C. Tseng, H.-H. Weng, Y.-H. Lin, C.-W. Liou, and T.-Y. Tan, \u201cPrediction of \n\nlength of stay of first-ever ischemic stroke,\u201d Stroke, vol. 33, no. 11, pp. 2670\u20132674, 2002. \n\n\n\n \n\n \n\n \n\n \n\n \n\n13 \n\n \n\n[11] P. Appelros, \u201cPrediction of length of stay for stroke patients,\u201d Acta Neurologica Scandinavica, vol. \n\n116, no. 1, pp. 15\u201319, 2007. \n\n[12] A. N. Okere, C. M. Renier, and A. Frye, \u201cPredictors of hospital length of stay and readmissions \n\nin ischemic stroke patients and the impact of inpatient medication management,\u201d Journal of Stroke \n\nand Cerebrovascular Diseases, vol. 25, no. 8, pp. 1939\u20131951, 2016. \n\n[13] B. K. Choi, S. W. Ham, C. H. Kim, J. S. Seo, M. H. Park, and S. H. Kang, \u201cDevelopment of \n\npredictive model for length of stay (los) in acute stroke patients using artificial intelligence,\u201d \n\nJournal of Digital Convergence, vol. 16, no. 1, pp. 231\u2013242, 2018. \n\n[14] M. L. Svendsen, L. H. Ehlers, G. Andersen, and S. P. Johnsen, \u201cQuality of care and length of \n\nhospital stay among patients with stroke,\u201d Medical care, pp. 575\u2013582, 2009. \n\n[15] J. Garza-Ulloa, \u201cArtificial intelligence analysis using neural network to predict three stroke \n\nparameters: Surgery needed, treatment, and length of stay for rehabilitation.\u201d Unpublished. \n\n[16] Y. S. Ng, K. H. Tan, C. Chen, G. C. Senolos, E. Chew, and G. C. Koh, \u201cPredictors of acute, \n\nrehabilitation and total length of stay in acute stroke: a prospective cohort study,\u201d Ann Acad Med \n\nSingapore, vol. 45, no. 9, pp. 394\u2013403, 2016. \n\n[17] S. M. Bindawas, V. Vennu, H. Mawajdeh, H. M. Alhaidary, and E. Mof- tah, \u201cLength of stay and \n\nfunctional outcomes among patients with stroke discharged from an inpatient rehabilitation facility \n\nin saudi arabia,\u201d Medical science monitor: international medical journal of experimental and \n\nclinical research, vol. 24, p. 207, 2018. \n\n[18] A. Arboix, J. Massons, L. Garc\u00b4\u0131a-Eroles, C. Targa, M. Oliveres, and E. Comes, \u201cClinical predictors \n\nof prolonged hospital stay after acute stroke: relevance of medical complications,\u201d 2012. \n\n[19] S. Koton, N. Bornstein, R. Tsabari, D. Tanne et al., \u201cDerivation and validation of the prolonged \n\nlength of stay score in acute stroke patients,\u201d Neurology, vol. 74, no. 19, pp. 1511\u20131516, 2010. \n\n[20] L.-C. Hung, Y.-H. Hu, and S.-F. Sung, \u201cExploring the impact of intravenous thrombolysis on length \n\nof stay for acute ischemic stroke: a retrospective cohort study,\u201d BMC health services research, vol. \n\n15, no. 1, p. 404, 2015. \n\n[21] A. Alahmar, E. Mohammed, and R. Benlamri. \"Application of data mining techniques to predict \n\nthe length of stay of hospitalized patients with diabetes.\" In 2018 4th International Conference on \n\nBig Data Innovations and Applications (Innovate-Data), pp. 38-43. IEEE, 2018. \n\n[22] A. Alahmar and R. Benlamri, Optimizing Hospital Resources using Big Data Analytics with \n\nStandardized e-Clinical Pathways. In 2020 IEEE Intl Conf on Cloud and Big Data Computing, \n\n(CBDCom), pp. 650-657. IEEE, August 2020. \n\n \n\n \n\n\n"}
{"Title": "Knowledge intensive state design for traffic signal control", "Authors": "Liang Zhang, Qiang Wu, Jianming Deng", "Abstract": "  There is a general trend of applying reinforcement learning (RL) techniques for traffic signal control (TSC). Recently, most studies pay attention to the neural network design and rarely concentrate on the state representation. Does the design of state representation has a good impact on TSC? In this paper, we (1) propose an effective state representation as queue length of vehicles with intensive knowledge; (2) present a TSC method called MaxQueue based on our state representation approach; (3) develop a general RL-based TSC template called QL-XLight with queue length as state and reward and generate QL-FRAP, QL-CoLight, and QL-DQN by our QL-XLight template based on traditional and latest RL models.Through comprehensive experiments on multiple real-world datasets, we demonstrate that: (1) our MaxQueue method outperforms the latest RL based methods; (2) QL-FRAP and QL-CoLight achieves a new state-of-the-art (SOTA). In general, state representation with intensive knowledge is also essential for TSC methods. Our code is released on Github.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00006", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge intensive state design for traffic signal control\n\nLiang Zhang1, Qiang Wu2, Jianming Deng1*\n1 School of Life Sciences, Lanzhou University, Lanzhou 730000, China\n\n2 Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China, Chengdu\n611731, China\n\nAbstract\n\nThere is a general trend of applying reinforcement learning\n(RL) techniques for traffic signal control (TSC). Recently,\nmost studies pay attention to the neural network design and\nrarely concentrate on the state representation. Does the design\nof state representation has a good impact on TSC? In this pa-\nper, we (1) propose an effective state representation as queue\nlength of vehicles with intensive knowledge; (2) present a\nTSC method called MaxQueue based on our state representa-\ntion approach; (3) develop a general RL-based TSC template\ncalled QL-XLight with queue length as state and reward and\ngenerate QL-FRAP, QL-CoLight, and QL-DQN by our QL-\nXLight template based on traditional and latest RL models.\nThrough comprehensive experiments on multiple real-world\ndatasets, we demonstrate that: (1) our MaxQueue method out-\nperforms the latest RL based methods; (2) QL-FRAP and QL-\nCoLight achieves a new state-of-the-art (SOTA). In general,\nstate representation with intensive knowledge is also essential\nfor TSC methods. Our code is released on Github1.\nKeywords: intensive knowledge, traffic signal control, rein-\nforcement learning, state design, effective state\n\n1 Introduction\nWith population and economic growth, automobiles increase\nrapidly, and traffic congestion has become an emergent prob-\nlem. Traffic congestion causes fuel waste, environmental\npollution, economic losses, and waste of time. Mitigating\ntraffic congestion and improving transportation efficiency is\nof great urgency.\n\nIn many modern cities, FixedTime[5], GreenWave[12],\nSCOOT[4], and SCATS[7] are the most common traffic\nsignal control systems, which relys on pre-designed traffic\nsignal plans. These methods can\u2019t adapt to dynamic traf-\nfic flows. In addition, some traditional traffic signal control\n(TSC) methods such as MaxPressure[14] and SOTL[2] have\ngood performance but takes much efforts to deploy.\n\nRecently, reinforcement learning (RL) has drawn increas-\ning attention, and people have begun to use RL to solve TSC\nproblems. RL models can directly learn from the environ-\nment through trial-and-error without requiring assumptions\nlike traditional TSC methods. Furthermore, RL models can\n\n*Jianming Deng is the corresponding author. Email:\ndengjm@lzu.edu.cn\n\n1https:github.com/LiangZhang1996/QL XLight\n\nhandle complex and dynamic environments with a deep neu-\nral network[8]. RL-based TSC methods[16, 1, 16] become\na promising solution for realizing intelligent transportation\nsystems. PressLight[16] can realize large-scale traffic sig-\nnal control. Furthermore, MPLight[1] and CoLight[17] have\ndemonstrate the ability to handle city-level TSC. In addi-\ntion, MPLight uses a decentralized RL paradigm and is eas-\nier for large-scale deployment. PressLight[16] and MPLight\nall demonstrate the essential role of the state and reward de-\nsign.\n\nIn RL-based approach, the state representations vary in\nterms of queue length[9, 18], number of vehicles[18, 23, 20,\n16, 22, 20, 17, 19], traffic image[13, 18]; the reward rep-\nresentations vary in terms of queue length[22, 16, 17, 19] ,\npressure[1], total wait time[18, 9, 13, 19], and delay[18, 13,\n19]. Some methods can perform better with simple state and\nreward. However, some methods with complex state and re-\nward designs get limited results. However, most studies con-\ncentrate on developing novel network structures to improve\nTSC performance. Few of the studies have deeply explored\nwhy some methods have great performance with simple state\nand reward design. More attention should be paid to the state\ndesign for TSC.\n\nIn summary, the main contribution of this article as fol-\nlows:\n1. Propose an effective state representation as queue length\n\nwith intensive-knowledge;\n2. Propose one transportation method, namely MaxQueue,\n\nwhich has superior performance than previous state-of-\nthe-art RL methods;\n\n3. With effective state design, we develop an RL-based TSC\ntemplate: QL-XLight with queue length as state and re-\nward;\n\n4. Based on QL-XLight, we generate three RL-based meth-\nods: QL-DQN, QL-FRAP, QL-MPLight, which all have\nsuperior performance than the latest methods;\n\n5. Demonstrate that state design with intensive knowledge\nis as essential as network structure design.\n\nThe remainder of this paper is organized as follows:\nSection 2 introduces the related works, including typi-\ncal transprotation and RL-based approaches for TSC; Sec-\ntion 3 depicts the definitions of TSC; Section 4 system-\natically analyzes the typical used state representation with\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n6v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\nhttps:github.com/LiangZhang1996/QL_XLight\n\n\nintensive-knowledge, and develop the MaxQueue algorithm\nand QL-XLight template. Section 5 conducts experiments\nand demonstrates the results. Section 6 concludes the paper\nand discusses future work.\n\n2 Related work\n2.1 Conventional transportation methods\nConventional transportation methods can be mainly catego-\nrized into the four categories: fixed-time control[5, 12], actu-\nated control[3, 2], adaptive control [4, 7], and optimization-\nbased control[14, 6, 10]. All the methods mentioned above\nhighly rely on expert knowledge. Fixed-time and adaptive\ncontrol rely on predefined signal plans (i.e., cycle length,\nphase split, and offset). Actuated control relies on the prede-\nfined threshold, which highly influences the control perfor-\nmance; optimization-based control also relies on the prede-\nfined signal plan (i.e., cycle length), turn ratios, and satura-\ntion flow rates. Therefore, these conventional transportation\nmethods have limited capacity to adapt to dynamic traffic.\n\n2.2 RL based methods\nRL models can learn their policy directly from environments\nthrough trial-and-error, and deep neural networks make\nthem adapt to various conditions. The RL-based method is a\npromising solution for traffic signal control. PressLight[16]\ncan achieve multi-intersection traffic signal control. MP-\nLight and CoLight can realize city-level TSC. HiLight also\nachieves superior performance than MPLight and CoLight\nwith hierarchical RL models. The state, reward, and neu-\nral network design play an essential role in RL models. We\nsummarize some typical RL-based methods and category\nthem into the following classes:\n\n\u2022 The methods that introduce the novel neural network\nstructure. GCN[9] adopt graph convolution neural net-\nwork for TSC control; IntelliLight[18] develops a com-\nplex neural network with phase selector; FRAP[22] uses\na modified network structure to capture the phase com-\npetition relation between different traffic movements;\nCoLight[17] uses graph attention networks to learn inter-\nsection cooperation; HiLight[19] adopts hierarchical RL\napproach for TSC.\n\n\u2022 The methods that introduce effective state and reward de-\nsign. PressLight[16] incorporates pressure into state and\nreward design; MPLight[1] uses traffic movement pres-\nsure as state, intersection pressure as reward.\n\nWe can know that most people try to develop an effective\nnetwork structure from the above. The concentration on state\ndesign is rare.\n\n2.3 State design\nIn other RL fields, the state representation is clear, and peo-\nple can directly use images as a state. However, in the TSC\nfield, the state is dynamic and complex, and the state rep-\nresentation should be dealt carefully. The state design for\nTSC has not been deeply studied. LIT[23] finds that: as a\nreward representation, queue length is better than delay; as a\n\nstate representation, number of vehicles is better than wait-\ning time and traffic image. PressLight finds pressure is better\nthan queue length as a reward representation. MPLight intro-\nduces pressure into state design and finds the improvement\nin the model. However, none of them systematically explain\nwhy some state and reward is better. The state representation\nfor TSC needs to be further discussed.\n\n3 Preliminary\nIn this section, we summarize the definition for recent TSC\nmethods[1, 17].\n\nFigure 1: The illustration of an intersection with four phases.\nIn this case, phase #2 is activated.\n\nDefinition 1 (Traffic network). Each traffic network is de-\nscribed as a directed graph, in which each node represents\nthe intersection, and each edge represents the road. Each\nroad consists of several lanes. An incoming lane for an inter-\nsection is where the vehicles enter the intersection. An out-\ngoing lane for an intersection is where the vehicles leave the\nintersection. We denote the set of incoming lanes and outgo-\ning lanes of intersection i as Lini and L\n\nout\ni respectively. We\n\nuse l,m, k to denote the lanes.\nDefinition 2 (Traffic movement). A traffic movement is\n\ndefined as the traffic traveling across an intersection towards\na certain direction, i.e., left turn, go straight, and right turn.\nFollowing the traffic rules in most cities, right turn traffic can\npass regardless of the signal, but it needs to yield on a red\nlight. In Figure 1 (a), there are 12 traffic movements.\n\nDefinition 3(Signal phase). Each signal phase is a set of\npermissible traffic movements, denoted by d, andDi denotes\nthe set of all the phases at intersection i. As shown in Figure\n1, the intersection has 4 phases with phase #2 activated.\n\nDefinition 4 (Phase queue length). The queue length of\neach phase is the sum queue length of the incoming lanes of\nthe phase, denoted by\n\nq(d) =\n\u2211\n\nq(l), l \u2208 d (1)\n\nin which q(l) is the queue length of lane l.\nDefinition 5 (Intersection queue length). The queue\n\nlength of each intersection is defined as the total queue\n\n\n\nlength of the incoming lanes of the intersection, denoted by\n\nQi =\n\u2211\n\nq(l), l \u2208 Lini (2)\n\nin which q(l) represents the queue length of lane l.\nDefinition 6 (Phase duration). The minimum duration for\n\neach phase is denoted by tduration. It can also represent the\naction interval of RL-based models.\n\nProblem (Multi-intersection traffic signal control). Each\nintersection is controlled by a RL agent. At time step t,\nagent i views the environment as its observation oti. Every\ntduration, the action ati is taken to control the signal of inter-\nsection i. The goal of the agent is to take an optimal action\nati (i.e. which phase to set) to maximize the throughput of\nthe systems and minimize the average travel time.\n\nTable 1: Summary of notation.\n\nNotation Meaning\n\nLini set of incoming lanes of intersection i\nLouti set of outgoing lanes of intersection i\nl,m, k lanes\nq(l) queue length of lane l\nd signal phase which is set of traffic movements\nDi set of all phases at intersection i\nQi total queue length of intersection i\n\ntduration minimal phase duration or said action interval\n\n4 Method\nIn this section, we first propose an effective state representa-\ntion as queue length with intensive knowledge. Next, we dis-\ncuss why queue length is more effective than some typical\nused state representation. Then, we propose a transportation\nmethod MaxQueue based on intensive knowledge inspired\nby MaxPressure. Finally, we develop an RL-based TSC tem-\nplate: QL-XLight and generate QL-DQN, QL-FRAP, and\nQL-COLight.\n\n4.1 Queue length as the state\nFor TSC, each vehicle in the traffic network has two states:\nrunning and queueing. Queueing vehicles can directly re-\nsult in congestion while running vehicles potentially result\nin congestion. Almost all the queueing vehicles stop near\nthe intersection and have the demand for a green signal.\nMP[14] maximizes the throughput of the traffic by balanc-\ning the queue length in the network. The queueing vehicles\nplay an essential role in the traffic condition representation.\nFrom empirical knowledge, the queue length is considered\nadequate.\n\nIn the traffic network, the phase signal can only directly\nchange the state of the queuing vehicles. Any consequent\nchanges such as the number of vehicles, vehicle position,\nspeed score are full of uncertainty. Therefore, we choose to\nuse queue length as the traffic state representation.\n\nDiscussion According to the existing studies, various state\nrepresentations are used in TSC, while some state represen-\ntation is more effective than others. We will summarize the\ntypically used state representations and give a systematical\nanalysis to answer which state is a effective traffic state rep-\nresentation.\n\nThe RL agents learn from the environment through trial-\nand-error and learn the state-action value through explo-\nration. Suppose the state representation does not include crit-\nical contents of traffic movement. In that case, the agent will\nbe confused about the state and can\u2019t learn an appropriate\npolicy.\n\nIf one phase is activated, the queue length of the phase\nchanges to zero, while the queue length for other phases may\ngrow gradually, depending on the arrival from upstream.\nThere is a deterministic change when each phase is acti-\nvated, and is considered effective.\n\nThen, we analyze the following traffic state representation\nand explain why they are as effective as queue length.\n\n\u2022 Number of vehicles: it is described as the total vehicle\nnumber of the incoming lanes. If one phase is activated,\nthe vehicles near the intersection pass through gradually,\nbut vehicles also arrive gradually from upstream. The to-\ntal number of the corresponding lanes probably:(1) be-\ncomes larger if the number of entering is larger than exit-\ning;(2) do not change if the number of entering is equal to\nexit; (3) become smaller if a number of entering smaller\nthan exiting. In addition, if there is no vehicle near the in-\ntersection, the traffic state can\u2019t change even if the phase\nchanges. Therefore, the change of state is vague and can\u2019t\nbe explicitly captured, which makes the agent \u201dconfus-\ning.\u201d\n\n\u2022 Vehicle position. The position of vehicles is usually in-\ntegrated as an image representation, which is defined as\na matrix, with \u201d1\u201d indicating the presence of vehicles on\na location, and \u201d0\u201d the absence of vehicles on that loca-\ntion. Each lane is usually divided into small segments,\nand some use the total vehicle number to replace \u201d1\u201d and\n\u201d0\u201d. This is similar to a number of vehicles that do not\nhave explicit changes after one phase be activated.\n\n\u2022 Speed score. The speed score is calculated by the aver-\nage speed divided by the speed limit. If one phase is acti-\nvated, the speed score change degree relies on the accel-\neration. In addition, if there are only queueing vehicles,\nthe speed score grows proportional to the acceleration; if\nthere are lots of running vehicles and few queueing vehi-\ncles, the speed score may change, not obvious. It is also\nconfusing for the RL agents.\n\n\u2022 Traffic movement pressure calculated by a number of ve-\nhicles. It is calculated by a number of vehicles and has\nsimilar properties to it.\n\n4.2 MaxQueue control\nBased on MaxPressure[14] and the property of queue length,\nwe propose a TSC method called MaxQueue. Like MaxPres-\nsure, MaxQueue control selects the phase with maximum\nqueue length in a greedy manner. At intersection i, the phase\n\n\n\nqueue length is calculated (by equation(1)), then activate the\nphase with maximum pressure every tduration, denoted by\n\nd\u0302 = argmax (q(d))|d \u2208 Di) (3)\nThe MaxQueue method is formally summarized in Algo-\nrithm 1.\n\nAlgorithm 1: MaxQueue Control\nParameter: Current phase time t, minimum phase duration\ntduration\n\nfor (time step) do\nt = t+ 1;\nif t = tduration then\n\nFor each intersection, get q(d) by equation (1);\nActivate the phase according to equation (3);\nt = 0\n\nend if\nend for\n\nComparison of MaxQueue and MaxPressure MaxPres-\nsure control selects the phase with maximum pressure,\nwhich is the difference of queue length between upstream\nand downstream, indicating the balance of the queue length.\nOnly consider the control logic, MaxQueue(MQ) and Max-\nPressure(MP) are highly similar, and both use a greedy man-\nner to select the phase. For the case of single intersection\ncontrol, MP and MQ are the same. There are no queueing\nvehicles on the outgoing lanes of the single intersection be-\ncause it is assumed that the outgoing is infinite. Thus, the\ncalculated pressure is exactly the queue length.\n\nMP considers the neighbor influence, stabilizes the queue\nlength, and maximizes the throughput by selecting the phase\nwith maximum pressure. The key idea of MP is that ensure\nthe vehicles can\u2019t be stopped by the queue vehicle of the up-\nstream. Therefore, if a phase has a large pressure, the queue\nlength can only be larger. The MP method is really effective\nwhen the traffic road length is small because the neighbor\nvehicles can fast influence the current intersection.\n\nHowever, when the traffic road length is longer, the influ-\nence may come after several tduration, and the pressure is\nnot effective. For example, set tduration = 15s and vehi-\ncles\u2019 maximum velocity is 10m/s; if the road is 100m, then\nit takes 10s to the neighbor, and the neighbor condition in-\nfluences the policy; if the road is 300m, then it takes at least\n30s to the neighbor, and the policy can\u2019t be influenced by the\nneighbor condition.\n\nIn summary, if the traffic road is relatively long, the MQ\nwill perform better; if the traffic road is relatively short, the\nMP will perform better.\n\n4.3 QL-XLight\nWe develop an RL-based TSC methods template with queue\nlength as the traffic state and reward, QL-XLight. Based on\nQL-XLight, DQN, FRAP, and CoLight are introduced as\nthe based model, and we get QL-DQN, QL-FRAP, and QL-\nCoLight.\n\u2022 State The current phase and queue length are used as the\n\nstate representation(agent observations).\n\n\u2022 Action At time t, each agent choose a phase d\u0302 according\nto the state, and the traffic signal will be changed to d\u0302.\n\n\u2022 Reward Negative intersection queue length is used as the\nreward. The reward for the agent controlling intersection\ni is denoted by\n\nri = \u2212Qi = \u2212|\n\u2211\n\nq(l)|, l \u2208 Lini (4)\n\nin which q(l) is the queue length at lane l. By maximizing\nthe reward, the agent is trying to maximize the through-\nput in the system.\n\nDeep Q-learning The DQN agents are updated by the\nBellman Equation:\n\nQ(st, at) = R(st, at) + \u03b3maxQ(st+1, at+1) (5)\n\nin which st and st+1 are the state, at and at+1 are the action.\n\nBase model The following base models are introduced to\nget QL-DQN, QL-FRAP, QL-CoLight:\n\u2022 DQN based model. A simple DQN[8] with only two\n\nfully connected layers. The neural network structure is\nstraightforward and basic. Besides, we also adopt the de-\ncentralized approach from MPLight to train the model.\nWe refer to a simple DQN based approach as QL-DQN.\n\n\u2022 FRAP-based model. FRAP[22] is adopted as one of the\nbase models. FRAP can learn the phase competition\nin TSC with a specially designed architecture. It has a\nfast training process compared with other TSC methods.\nFRAP has been used as the base model by MPLight. We\nrefer to FRAP based approach as QL-FRAP.\n\n\u2022 CoLight based model. CoLight[17] is graph attention\nnetwork[15] based method, and learns intersection com-\nmunication and cooperation for TSC. CoLight is capable\nof large-scale TSC. We will adopt CoLight as one of the\nbase models. We refer to CoLight based model in this\narticle as QL-CoLight.\n\nTheoretically, we could build QL-LIT and QL-HiLight.\nHowever, because the code of HiLight is not available,\nwe implement QL-FRAP, QL-CoLight, and QL-DQN first,\nwithout the loss of validity of our conclusion.\n\nParameter Sharing Parameters of the network are shared\namong all the agents. It is essential to improve model\nperformance[1]. Besides, the replay memory is also shared\nso that all the intersections can benefit from the experiences\nof others. Note that the CoLight based model does not need\nparameter sharing. Some baseline models are also trained\nunder parameter sharing for fair model comparison.\n\nDiscussion We are not the first that introduce queue\nlength into both state and reward, but we are the first to\npropose queue length as an effective state representation.\nIntelliLight[18] uses complex state and reward representa-\ntion apart from queue length. GCN[9] uses queue length and\naverage velocity as state, total wait time as a reward. Tan et\nal.[11] uses queue length as state, queue length and a num-\nber of running vehicles as a reward. Although these studies\nhave used queue length as state representation, they do not\nemphasize queue length property.\n\n\n\nThe results of FRAP[22] and CoLight[17] demonstrates\nthe poor performance of IntelliLight and GCN. In addition,\nthe reward in [11] indicates the smaller queue length and\nrunning number, the better results, which is unreasonable\nbecause for the number of running vehicles, the larger, the\nbetter. Therefore, the reward is also essential for RL-based\nTSC, and only queue length is more reliable than that used\nin IntelliLight, GCN, and [11].\n\n5 Experiment\n5.1 Settings\nSimulator We conduct the experiments on an open-source\nsimulator called CityFlow2[21], which supports large-scale\ntraffic signal control and has faster speed than SUMO.\nThe simulator provides the environment observations to the\nagent and receives the command from the agent. In the ex-\nperiments, each green signal is followed by three-second\nyellow time and two-second all red time to prepare the tran-\nsition.\n\nTable 3: Average arrival rate of the two datasets\n\nDataset Arrival rate(vehicles/s)\nDJiNan1 1.75\nDJiNan2 1.21\nDJiNan3 1.53\nDHangZhou1 0.83\nDHangZhou2 1.94\n\nDatasets We use five real-world datasets3 in the exper-\niment, three from Jinan and two from Hangzhou. These\ndatasets have been wildly used by various methods such as\nMPLight, CoLight, and HiLight.\n\nEach traffic dataset consists of two parts: (1) traffic road-\nnet dataset; (2) traffic flow dataset. The traffic road-net\ndataset describes the traffic network, including lanes, roads,\nand intersections. The traffic flow dataset contains vehicles\ntravel information, which is described as (t, u), where t is\nthe time that each vehicle starts entering the traffic network,\nu is the pre-planned route from its original location to desti-\nnation.\n\n\u2022 Jinan datasets: The road network has 12 intersections\n(3 \u00d7 4). Each intersection is four-way, with two 400-\nmeter road segments (East-West) and two 800-meter\nroad segments (South-North). There are three traffic flow\ndatasets, and they have different average arrival rates (Ta-\nble 3).\n\n\u2022 Hangzhou datasets. The road network has 16 intersec-\ntions (4 \u00d7 4). Each intersection is four-way, with two\n800-meter road segments (East-West) and two 600-meter\nroad segments (South-North). There are two traffic flow\ndatasets, and they also have different average arrival rates\n(Table 3).\n2https://cityflow-project.github.io\n3https://traffic-signal-control.github.io\n\nEvaluation metric Based on existing studies in traffic sig-\nnal control[17], we choose average travel time as the eval-\nuation metric, which is the mostly used metric to evaluate\ncontrol performance in the TSC. The travel time of each ve-\nhicle is the time speed between entering and leaving the traf-\nfic network. We use all the vehicles\u2019 average travel time to\nevaluate the model performance.\n\nCompared methods We compare our methods with the\nfollowing baseline methods, including both transportation\nand RL methods. For a fair comparison, the phase num-\nber is set as four, and the action interval (phase duration) is\nset as 15 seconds. All the RL methods are learned with the\nsame hyper-parameters. Each episode is a 60-minutes sim-\nulation, and we adopt one result as the average of the last\nten episodes of testing. Each reported result is the average\nof three independent results.\n\nTransportation Methods:\n\u2022 Fixed-Time[5]: a policy uses fixed cycle length with pre-\n\ndefined phase split among all the phases.\n\u2022 Max-Pressure[14]: the max-pressure control selects the\n\nphase with maximum pressure.\nRL Methods:\n\n\u2022 PressLight[16]: incorporates pressure in the state and\nreward design for the RL model and has shown supe-\nrior performance in multi-intersection control problems.\nPressLight is trained with parameter sharing for fairly\ncomparison.\n\n\u2022 FRAP[22]: uses a novel network structure to cap-\nture phase competition relation between different traffic\nmovements. FRAP is trained with parameter sharing like\nMPLight for fair comparison.\n\n\u2022 MPLight[1]: a FRAP[22] based decentralized model, in-\ncorporates pressure in the state and reward design and has\nshown superior performance in city-level TSC. It is one\nstate-of-the-art RL-based TSC method.\n\n\u2022 CoLight[17]: another state-of-the-art method uses a\ngraph attention network to realize intersection coopera-\ntion and has shown superior performance in large-scale\nTSC.\n\nOur Proposed Methods:\n\u2022 MaxQueue: the MaxQueue control selects the phase\n\nwith maximum queue length.\n\u2022 QL-DQN: adopts a two-layer network as the base model,\n\nuses queue length and current phase as state, intersection\nqueue length as a reward.\n\n\u2022 QL-FRAP: a FRAP-based model, uses queue length and\ncurrent phase as state, intersection queue length as a re-\nward.\n\n\u2022 QL-CoLight: a CoLight based model, uses queue length\nand current phase as state, intersection queue length as a\nreward.\n\n5.2 Overall Performance\nTable 2 reports our experimental results under JiNan and\nHangZhou real-world datasets with respect to the average\ntravel time. We have the following findings:\n\n\n\nTable 2: Overall performance. For average travel time, the smaller the better.\n\nMethod\nJiNan HangZhou\n\n1 2 3 1 2\nFixedTime 428.11(+56.29%) 368.77(+50.29%) 383.01(+55.82%) 495.57(+71.75%) 406.65(+16.53%)\nMaxPressure 273.96 245.38 245.81 288.54 348.98\nPressLight 314.63(+14.85%) 264.62(+7.84%) 258.12(+5.01%) 385.71(+33.68%) 458.12(+31.27%)\nFRAP 296.46(+8.21%) 266.93(+8.78%) 269.64(+9.69%) 309.60(+7.30%) 356.47(+2.15%)\nMPLight 297.46(+8.58%) 270.05(+10.05%) 276.15(+12.34%) 314.60(+9.03%) 357.61(+2.47%)\nCoLight 272.06(\u22120.69%) 252.44(+2.88%) 249.56(+1.53%) 297.02(+2.94%) 347.27(\u22120.49%)\nMaxQueue 268.21(\u22122.10%) 238.91(\u22122.64%) 237.8(\u22123.26%) 283.12(\u22121.88%) 324.38(\u22127.05%)\nQL-DQN 260.74(\u22124.83%) 245.32(0.02%) 239.33(\u22122.64%) 284.74(\u22121.32%) 333.44(\u22124.45%)\nQL-FRAP 255.53(\u22126.73%) 238.74(\u22122.71%) 236.04(\u22123.97%) 282.28(\u22122.17%) 315.03(\u22129.73%)\nQL-CoLight 254.94(\u22126.94%) 239.05(\u22122.58%) 236.25(\u22123.89%) 282.17(\u22122.21%) 322.75(\u22127.52%)\n\n(1) Our proposed MaxQueue consistently outperforms all\nother previous methods. MaxQueue has a significant im-\nprovement as a conventional transportation method com-\npared to MaxPressure. In addition, MaxQueue has superior\nperformance than MPLight and CoLight. The conventional\ntransportation methods are still powerful.\n\n(2) Our proposed QL-DQN, QL-FRAP, and QL-CoLight\noutperform all other previous methods. With only changing\nthe state and reward compared to MPLight and CoLight, the\nimprovement of QL-FRAP and QL-CoLight is significant,\nproving the importance of state representation for RL-based\nTSC.\n\n(3) QL-FRAP and QL-CoLight are state-of-the-art among\ntraditional and RL-based TSC methods. CoLight and MP-\nLight are the previous state-of-the-art methods, and QL-\nFRAP and QL-CoLight have a better performance. Besides,\nQL-XLight only uses queue length information of a particu-\nlar intersection, which has the advantage of deployment than\nCoLight and MPLight.\n\n(4) Parameter sharing is essential for RL-based models.\nMPLight[1] has shown better performance than FRAP and\naddresses the importance of parameter sharing. However,\nwhen FRAP is trained with parameter sharing same to MP-\nLight, it has slightly better performance than MPLight.\n\n5.3 State representation is also essential\n\nBoth the neural network structure and the state representa-\ntion play an important role in the performance improvement.\nHowever, most studies pay attention to the network design.\nWe will demonstrate that the state representation is also es-\nsential.\n\nQL-DQN uses a simple neural network structure, but\neffective state representation. FRAP and CoLight use ad-\nvanced neural network structure, but the state representation\nis not effective. In addition, FRAP, CoLight, and QL-DQN\nuse the same reward. Compare the performance of QL-DQN\nwith FRAP and CoLight, QL-DQN is consistently better\nover all the datasets.\n\nTherefore, we can conclude that state representation is\nalso essential as neural network structure for TSC. The state\nrepresentation should be paid more attention in TSC.\n\nFigure 2: Model performance under different phase duration.\n\n5.4 Performance under different phase duration\nExperiments are also conducted under different phase du-\nration for further model comparison. Figure 2 reports the\nmodel performance under different phase duration. QL-\nDQN, QL-FRAP, and QL-CoLight consistently perform bet-\nter than CoLight and MPLight over all the datasets and\nphase duration. MaxQueue performs better than MPLight\nand CoLight in most cases, except at JiNan1 and JiNan3\nwhen tduration = 10s. MaxQueue also perform better than\nQL-DQN in most cases. The performance of MaxQueue ad-\ndresses that the transportation method is still powerful and\nessential.\n\n5.5 Reward comparison\nPressLight and MPLight have demonstrated that RL ap-\nproaches perform better under pressure than queue length.\nWe will re-test the impact of reward settings with queue\nlength as the state representation. The FRAP and CoLight\nare used as the base model; experiments are conducted un-\nder the following configurations:\n\n\u2022 Config1: queue length and current phase are used as the\nstate, intersection queue length as the reward. This is ex-\nactly QL-XLight.\n\n\u2022 Config2: queue length and current phase are used as the\nstate, intersection pressure as the reward.\n\nExperiments are conducted over all the datasets, and Fig-\nure 3 reports the model performance with a different reward.\n\n\n\nFigure 3: Model performance under different reward w.r.t\naverage travel time, the smaller the better.\n\nQL-FRAP performs better under queue length than pressure.\nThe performance difference is not promising. QL-CoLight\nhas significantly better performance under queue length than\npressure. The CoLight based model has poor performance\nunder pressure, maybe the property of GAT that already con-\nsiders the neighbor influence and optimizes the global queue\nlength in the network.\n\nConsidering the calculation of state and reward, the queue\nlength is easier to get because pressure requires complex\ncalculation and neighbor information. Queue length can di-\nrectly get from the traffic environment. In summary, using\nthe queue length as state and reward is a better choice.\n\n6 Conclusion\nIn this paper, we propose an effective state representation\nas queue length. Based on queue length, we developed a\ntransportation method: MaxQueue and an RL template: QL-\nXLight. Our proposed methods have demonstrated supe-\nrior performance than the previous state-of-the-art method,\nand QL-CoLight achieves state-of-the-art performance. The\nimportance of transportation methods is also addressed by\nMaxQueue. The comparison of QL-DQN with FRAP and\nCoLight demonstrates that state representation is as essen-\ntial as a neural network structure. In a word, we should pay\nmore attention to the state design apart from the neural net-\nwork design.\n\nHowever, only queue length as the state representation is\nnot enough for the complex traffic conditions, and more in-\nformation about the traffic conditions should be added to\nthe state representation. In future research, we will try to\nadd more information about the traffic conditions to the RL\nagent observations. In addition, a more complex reward and\nnovel network structure are also taken into consideration to\nimprove the performance of TSC.\n\n7 Acknowledgments\nReferences\n\n[1] Chen, C.; Wei, H.; Xu, N.; Zheng, G.; Yang, M.;\nXiong, Y.; Xu, K.; and Li, Z. 2020. Toward a thousand\nlights: Decentralized deep reinforcement learning for\nlarge-scale traffic signal control. In Proceedings of the\n\nAAAI Conference on Artificial Intelligence, volume 34,\n3414\u20133421.\n\n[2] Cools, S.-B.; Gershenson, C.; and D\u2019Hooghe, B. 2013.\nSelf-organizing traffic lights: A realistic simulation. In\nAdvances in applied self-organizing systems, 45\u201355.\nSpringer.\n\n[3] Gershenson, C. 2004. Self-organizing traffic lights.\narXiv preprint nlin/0411066.\n\n[4] Hunt, P.; Robertson, D.; Bretherton, R.; and Royle,\nM. C. 1982. The SCOOT on-line traffic signal op-\ntimisation technique. Traffic Engineering & Control,\n23(4).\n\n[5] Koonce, P.; and Rodegerdts, L. 2008. Traffic signal\ntiming manual. Technical report, United States. Fed-\neral Highway Administration.\n\n[6] Le, T.; Kova\u0301cs, P.; Walton, N.; Vu, H. L.; Andrew,\nL. L.; and Hoogendoorn, S. S. 2015. Decentralized\nsignal control for urban road networks. Transportation\nResearch Part C: Emerging Technologies, 58: 431\u2013\n450.\n\n[7] Lowrie, P. 1992. SCATS: A traffic responsive method\nof controlling urban traffic control. Roads and Traffic\nAuthority.\n\n[8] Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.;\nVeness, J.; Bellemare, M. G.; Graves, A.; Ried-\nmiller, M.; Fidjeland, A. K.; Ostrovski, G.; et al.\n2015. Human-level control through deep reinforce-\nment learning. nature, 518(7540): 529\u2013533.\n\n[9] Nishi, T.; Otaki, K.; Hayakawa, K.; and Yoshimura,\nT. 2018. Traffic signal control based on reinforce-\nment learning with graph convolutional neural nets.\nIn 2018 21st International conference on intelligent\ntransportation systems (ITSC), 877\u2013883. IEEE.\n\n[10] Sun, X.; and Yin, Y. 2018. A simulation study on max\npressure control of signalized intersections. Trans-\nportation research record, 2672(18): 117\u2013127.\n\n[11] Tan, T.; Bao, F.; Deng, Y.; Jin, A.; Dai, Q.; and Wang,\nJ. 2019. Cooperative deep reinforcement learning for\nlarge-scale traffic grid signal control. IEEE transac-\ntions on cybernetics, 50(6): 2687\u20132700.\n\n[12] To\u0308ro\u0308k, J.; and Kerte\u0301sz, J. 1996. The green wave\nmodel of two-dimensional traffic: Transitions in the\nflow properties and in the geometry of the traffic jam.\nPhysica A: Statistical Mechanics and its Applications,\n231(4): 515\u2013533.\n\n[13] Van der Pol, E.; and Oliehoek, F. A. 2016. Coordi-\nnated deep reinforcement learners for traffic light con-\ntrol. Proceedings of Learning, Inference and Control\nof Multi-Agent Systems (at NIPS 2016).\n\n[14] Varaiya, P. 2013. Max pressure control of a network of\nsignalized intersections. Transportation Research Part\nC: Emerging Technologies, 36: 177\u2013195.\n\n[15] Velic\u030ckovic\u0301, P.; Cucurull, G.; Casanova, A.; Romero,\nA.; Lio, P.; and Bengio, Y. 2017. Graph attention net-\nworks. arXiv preprint arXiv:1710.10903.\n\n\n\n[16] Wei, H.; Chen, C.; Zheng, G.; Wu, K.; Gayah, V.; Xu,\nK.; and Li, Z. 2019. Presslight: Learning max pres-\nsure control to coordinate traffic signals in arterial net-\nwork. In Proceedings of the 25th ACM SIGKDD Inter-\nnational Conference on Knowledge Discovery & Data\nMining, 1290\u20131298.\n\n[17] Wei, H.; Xu, N.; Zhang, H.; Zheng, G.; Zang, X.; Chen,\nC.; Zhang, W.; Zhu, Y.; Xu, K.; and Li, Z. 2019. Co-\nlight: Learning network-level cooperation for traffic\nsignal control. In Proceedings of the 28th ACM In-\nternational Conference on Information and Knowledge\nManagement, 1913\u20131922.\n\n[18] Wei, H.; Zheng, G.; Yao, H.; and Li, Z. 2018. In-\ntellilight: A reinforcement learning approach for intel-\nligent traffic light control. In Proceedings of the 24th\nACM SIGKDD International Conference on Knowl-\nedge Discovery & Data Mining, 2496\u20132505.\n\n[19] Xu, B.; Wang, Y.; Wang, Z.; Jia, H.; and Lu, Z. 2021.\nHierarchically and Cooperatively Learning Traffic Sig-\nnal Control. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 35, 669\u2013677.\n\n[20] Zang, X.; Yao, H.; Zheng, G.; Xu, N.; Xu, K.; and Li,\nZ. 2020. Metalight: Value-based meta-reinforcement\nlearning for traffic signal control. In Proceedings of the\nAAAI Conference on Artificial Intelligence, volume 34,\n1153\u20131160.\n\n[21] Zhang, H.; Feng, S.; Liu, C.; Ding, Y.; Zhu, Y.; Zhou,\nZ.; Zhang, W.; Yu, Y.; Jin, H.; and Li, Z. 2019.\nCityflow: A multi-agent reinforcement learning envi-\nronment for large scale city traffic scenario. In The\nWorld Wide Web Conference, 3620\u20133624.\n\n[22] Zheng, G.; Xiong, Y.; Zang, X.; Feng, J.; Wei, H.;\nZhang, H.; Li, Y.; Xu, K.; and Li, Z. 2019. Learning\nphase competition for traffic signal control. In Pro-\nceedings of the 28th ACM International Conference on\nInformation and Knowledge Management, 1963\u20131972.\n\n[23] Zheng, G.; Zang, X.; Xu, N.; Wei, H.; Yu, Z.; Gayah,\nV.; Xu, K.; and Li, Z. 2019. Diagnosing reinforce-\nment learning for traffic signal control. arXiv preprint\narXiv:1905.04716.\n\n\n\t1 Introduction\n\t2 Related work\n\t2.1 Conventional transportation methods\n\t2.2 RL based methods\n\t2.3 State design\n\n\t3 Preliminary\n\t4 Method\n\t4.1 Queue length as the state\n\t4.2 MaxQueue control\n\t4.3 QL-XLight\n\n\t5 Experiment\n\t5.1 Settings\n\t5.2  Overall Performance \n\t5.3 State representation is also essential\n\t5.4 Performance under different phase duration\n\t5.5 Reward comparison\n\n\t6 Conclusion\n\t7 Acknowledgments\n\n"}
{"Title": "Confidence-Aware Multi-Teacher Knowledge Distillation", "Authors": "Hailin Zhang, Defang Chen, Can Wang", "Abstract": "  Knowledge distillation is initially introduced to utilize additional supervision from a single teacher model for the student model training. To boost the student performance, some recent variants attempt to exploit diverse knowledge sources from multiple teachers. However, existing studies mainly integrate knowledge from diverse sources by averaging over multiple teacher predictions or combining them using other various label-free strategies, which may mislead student in the presence of low-quality teacher predictions. To tackle this problem, we propose Confidence-Aware Multi-teacher Knowledge Distillation (CA-MKD), which adaptively assigns sample-wise reliability for each teacher prediction with the help of ground-truth labels, with those teacher predictions close to one-hot labels assigned large weights. Besides, CA-MKD incorporates intermediate layers to further improve student performance. Extensive experiments show that our CA-MKD consistently outperforms all compared state-of-the-art methods across various teacher-student architectures.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00007", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCONFIDENCE-AWARE MULTI-TEACHER KNOWLEDGE DISTILLATION\n\nHailin Zhang Defang Chen Can Wang?\n\nZhejiang University, China.\n{zzzhl, defchern, wcan}@zju.edu.cn\n\nABSTRACT\n\nKnowledge distillation is initially introduced to utilize addi-\ntional supervision from a single teacher model for the student\nmodel training. To boost the student performance, some re-\ncent variants attempt to exploit diverse knowledge sources\nfrom multiple teachers. However, existing studies mainly in-\ntegrate knowledge from diverse sources by averaging over\nmultiple teacher predictions or combining them using other\nvarious label-free strategies, which may mislead student in\nthe presence of low-quality teacher predictions. To tackle\nthis problem, we propose Confidence-Aware Multi-teacher\nKnowledge Distillation (CA-MKD), which adaptively assigns\nsample-wise reliability for each teacher prediction with the\nhelp of ground-truth labels, with those teacher predictions\nclose to one-hot labels assigned large weights. Besides, CA-\nMKD incorporates intermediate layers to further improve\nstudent performance. Extensive experiments show that our\nCA-MKD consistently outperforms all compared state-of-the-\nart methods across various teacher-student architectures.\n\nIndex Terms\u2014 knowledge distillation, multiple teachers,\nconfidence-aware weighting\n\n1. INTRODUCTION\n\nNowadays, deep neural networks have achieved unprece-\ndented success in various applications [1, 2, 3]. However,\nthese complex models requiring huge memory footprint and\ncomputational resources are difficult to be applied on embed-\nded devices. Knowledge distillation (KD) is thus proposed as\na model compression technique to resolve this issue, which\nimproves the accuracy of a lightweight student model by dis-\ntilling the knowledge from a pre-trained cumbersome teacher\nmodel [4]. The transferred knowledge was originally formal-\nized as softmax outputs (soft targets) of the teacher model\n[4] and latter extended to the intermediate teacher layers for\nachieving more promising performance [5, 6, 7].\n\nAs the wisdom of the masses exceeds that of the wisest in-\ndividual, some multi-teacher knowledge distillation (MKD)\n\n?Corresponding author\nThis work is supported by National Key R&D Program of China (Grant\n\nNo: 2019YFB1600700) and National Natural Science Foundation of China\n(Grant No: U1866602).\n\nFig. 1. Comparison of the previous average direction (green\nline) and our proposed confidence-aware direction (red line).\n\nmethods are proposed and have been proven to be benefi-\ncial [8, 9, 10, 11, 12]. Basically, they combine predictions\nfrom multiple teachers with the fixed weight assignment [8,\n9, 10] or other various label-free schemes, such as calculat-\ning weights based on a optimization problem or entropy crite-\nrion [11, 12], etc. However, fixed weights fail to differentiate\nhigh-quality teachers from low-quality ones [8, 9, 10], and\nthe other schemes may mislead the student in the presence of\nlow-quality teacher predictions [11, 12]. Figure 1 provides an\nintuitive illustration on this issue, where the student trained\nwith the average weighting strategy might deviate from the\ncorrect direction once most teacher predictions are biased.\n\nFortunately, we actually have ground-truth labels in hand\nto quantify our confidence about teacher predictions and then\nfilter out low-quality predictions for better student training.\nTo this end, we propose Confidence-Aware Multi-teacher\nKnowledge Distillation (CA-MKD) to learn sample-wise\nweights by taking the prediction confidence of teachers into\nconsideration for adaptive knowledge integration. The con-\nfidence is obtained based on the cross entropy loss between\nprediction distributions and ground-truth labels. Compared\nwith previous label-free weighting strategies, our technique\nenables the student to learn from a relatively correct direction.\n\nNote that our confidence-aware mechanism not only is\nable to adaptively weight different teacher predictions based\non their sample-wise confidence, but also can be extended to\nthe student-teacher feature pairs in intermediate layers. With\nthe help of our generated flexible and effective weights, we\ncould avoid those poor teacher predictions dominating the\nknowledge transfer process and considerably improve the stu-\ndent performance on eight teacher-student architecture com-\nbinations (as shown in Table 1 and 3).\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n7v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2. RELATED WORK\n\nKnowledge Distillation. Vanilla KD aims to transfer knowl-\nedge from a complex network (teacher) to a simple network\n(student) with the KL divergence minimization between their\nsoftened outputs [13, 4]. Mimicking the teacher representa-\ntions from intermediate layers was latter proposed to explore\nmore knowledge forms [5, 6, 14, 15, 7]. Compared to these\nmethods that require pre-training a teacher, some works si-\nmultaneously train multiple students and encourage them to\nlearn from each other instead [16, 17]. Our technique dif-\nfers from these online KD methods since we attempt to distill\nknowledge from multiple pre-trained teachers.\nMulti-teacher Knowledge Distillation. Rather than employ-\ning a single teacher, MKD boosts the effectiveness of distil-\nlation by integrating predictions from multiple teachers. A\nbunch of methods are proposed, such as simply assigning av-\nerage or other fixed weights for different teachers [8, 9, 10],\nand calculating the weights based on entropy [12], latent fac-\ntor [18] or multi-objective optimization in the gradient space\n[11]. However, these label-free strategies may mislead the\nstudent training in the presence of low-quality predictions.\nFor instance, entropy-based strategy will prefer models with\nblind faith since it favors predictions with low variance [12];\noptimization-based strategy favors majority opinion and will\nbe easily misled by noisy data [11]. In contrast, our CA-MKD\nquantifies the teacher predictions based on ground-truth labels\nand further improves the student performance.\n\n3. METHODOLOGY\n\nWe denote D = {xi,yi}Ni as a labeled training set, N is\nthe number of samples, K is the number of teachers. F \u2208\nRh\u00d7w\u00d7c is the output of the last network block. We denote\nz = [z1, ..., zC ] as the logits output, where C is the category\nnumber. The final model prediction is obtained by a softmax\nfunction \u03c3 (zc) = exp(z\n\nc/\u03c4)\u2211\nj\nexp(zj/\u03c4)\n\nwith temperature \u03c4 . In the\nfollowing sections, we will introduce our CA-MKD in detail.\n\n3.1. The Loss of Teacher Predictions\n\nTo effectively aggregate the prediction distributions of multi-\nple teachers, we assign different weights which reflects their\nsample-wise confidence by calculating the cross entropy loss\nbetween teacher predictions and ground-truth labels\n\nLkCEKD = \u2212\nC\u2211\nc=1\n\nyc log\n(\n\u03c3\n(\nzcTk\n))\n, (1)\n\nwkKD =\n1\n\nK \u2212 1\n\n\uf8eb\n\uf8ed1\u2212 exp (LkCEKD)\u2211\n\nj exp\n(\nLjCEKD\n\n)\n\uf8f6\n\uf8f8 , (2)\n\nwhere Tk denotes the kth teacher. The less LkCEKD corre-\nsponds to the larger wkKD. The overall teacher predictions are\n\nFig. 2. An overview of our CA-MKD. The weight calculation\nof teacher predictions and intermediate teacher features are\ndepicted as the red lines and green lines, respectively.\n\nthen aggregated with calculated weights\n\nLKD = \u2212\nK\u2211\nk=1\n\nwkKD\n\nC\u2211\nc=1\n\nzcTk log (\u03c3 (z\nc\nS)) . (3)\n\nAccording to the above formulas, the teacher whose pre-\ndiction is closer to ground-truth labels will be assigned larger\nweight wkKD, since it has enough confidence to make accu-\nrate judgement for correct guidance. In contrast, if we simply\nacquire the weights by calculating the entropy of teacher pre-\ndictions [12], the weight will become large when the output\ndistribution is sharp regardless of whether the highest prob-\nability category is correct. In this case, those biased targets\nmay misguide the student training and further hurt its distilla-\ntion performance.\n\n3.2. The Loss of Intermediate Teacher Features\n\nIn addition to KD Loss, inspired by FitNets [5], we believe\nthat the intermediate layers are also beneficial for learning\nstructural knowledge, and thus extend our method to interme-\ndiate layers for mining more information. The calculation of\nintermediate feature matching is presented as follows\n\nzS\u2192Tk =WTkhS , (4)\n\nLkCEinter = \u2212\nC\u2211\nc=1\n\nyc log\n(\n\u03c3\n(\nzcS\u2192Tk\n\n))\n, (5)\n\nwkinter =\n1\n\nK \u2212 1\n\n\uf8eb\n\uf8ed1\u2212 exp (LkCEinter)\u2211\n\nj exp\n(\nLjCEinter\n\n)\n\uf8f6\n\uf8f8 . (6)\n\nwhere WTk is the final classifier of the kth teacher. hS \u2208 R\nc\n\nis the last student feature vector, i.e, hS = AvgPooling(FS).\nLkCEinter is obtained by passing hS through each teacher clas-\nsifier. The calculation of wkinter is similar to that of w\n\nk\nKD.\n\n\n\nTable 1. Top-1 test accuracy of MKD methods by distilling the knowledge on multiple teachers with the same architectures.\n\nTeacher\nWRN40-2 ResNet56 VGG13 VGG13 ResNet32x4 ResNet32x4 ResNet32x4\n\n76.62\u00b10.26 73.28\u00b10.30 75.17\u00b10.18 75.17\u00b10.18 79.31\u00b10.14 79.31\u00b10.14 79.31\u00b10.14\nEnsemble 79.62 76.00 77.07 77.07 81.16 81.16 81.16\n\nStudent\nShuffleNetV1 MobileNetV2 VGG8 MobileNetV2 ResNet8x4 ShuffleNetV2 VGG8\n71.70\u00b10.43 65.64\u00b10.19 70.74\u00b10.40 65.64\u00b10.19 72.79\u00b10.14 72.94\u00b10.24 70.74\u00b10.40\n\nAVER [8] 76.30\u00b10.25 70.21\u00b10.10 74.07\u00b10.23 68.91\u00b10.35 74.99\u00b10.24 75.87\u00b10.19 73.26\u00b10.39\nFitNet-MKD [5] 76.59\u00b10.17 70.69\u00b10.56 73.97\u00b10.22 68.48\u00b10.07 74.86\u00b10.21 76.09\u00b10.13 73.27\u00b10.19\n\nEBKD [12] 76.61\u00b10.14 70.91\u00b10.22 74.10\u00b10.27 68.24\u00b10.82 75.59\u00b10.15 76.41\u00b10.12 73.60\u00b10.22\nAEKD [11] 76.34\u00b10.24 70.47\u00b10.15 73.78\u00b10.03 68.39\u00b10.50 74.75\u00b10.28 75.95\u00b10.20 73.11\u00b10.27\nCA-MKD 77.94\u00b10.31 71.38\u00b10.02 74.30\u00b10.16 69.41\u00b10.20 75.90\u00b10.13 77.41\u00b10.14 75.26\u00b10.32\n\nTable 2. Top-1 test accuracy of CA-MKD compared to\nsingle-teacher knowledge distillation methods.\n\nTeacher\nWRN40-2 ResNet32x4 ResNet56\n\n76.62\u00b10.26 79.31\u00b10.14 73.28\u00b10.30\n\nStudent\nShuffleNetV1 VGG8 MobileNetV2\n71.70\u00b10.19 70.74\u00b10.40 65.64\u00b10.43\n\nKD [4] 75.77\u00b10.14 72.90\u00b10.34 69.96\u00b10.14\nFitNet [5] 76.22\u00b10.21 72.55\u00b10.66 69.02\u00b10.28\n\nAT [6] 76.44\u00b10.38 72.16\u00b10.12 69.79\u00b10.26\nVID [14] 76.32\u00b10.08 73.09\u00b10.29 69.45\u00b10.17\nCRD [15] 76.58\u00b10.23 73.57\u00b10.25 71.15\u00b10.44\nCA-MKD 77.94\u00b10.31 75.26\u00b10.13 71.38\u00b10.02\n\nWe utilize wkinter instead of w\nk\nKD for the knowledge ag-\n\ngregation in intermediate layers, which achieves better results\nas shown in our ablation study. Perhaps this is due to the ex-\nistence of the last classifier will affect the whole knowledge\ntransfer process and should be taken into account.\n\nLinter =\nK\u2211\nk=1\n\nwkinter||FTk \u2212 r (FS) ||\n2\n2, (7)\n\nwhere r(\u00b7) is a function for aligning the student and teacher\nfeature dimensions. The `2 loss function is used as distance\nmeasure of intermediate features. Finally, the overall training\nloss between feature pairs will be aggregated by wkinter.\n\nIn our work, only the output features of the last block are\nadopted to avoid incurring too much computational cost.\n\n3.3. The Overall Loss Function\n\nIn addition to the aforementioned two losses, a regular cross\nentropy with the ground-truth labels is calculated\n\nLCE = \u2212\nC\u2211\nc=1\n\nyc log (\u03c3(zcS)) . (8)\n\nThe overall loss function of our CA-MKD is summarize as\n\nL = LCE + \u03b1LKD + \u03b2Linter, (9)\n\nwhere \u03b1 and \u03b2 are hyper-parameters to balance the effect of\nknowledge distillation and standard cross entropy losses.\n\n4. EXPERIMENT\n\nIn this section, we conduct extensive experiments on CIFAR-\n100 dataset [19] to verify the effectiveness of our proposed\nCA-MKD. We adopt eight different teacher-student combi-\nnations based on popular neural network architectures. All\ncompared multi-teacher knowledge distillation (MKD) meth-\nods use three teachers except for special declarations.\n\nCompared Methods. Besides the na\u0131\u0308ve AVER [8], we\nreimplement a single-teacher based method FitNet [5] on\nmultiple teachers and denote it as FitNet-MKD. FitNet-MKD\nwill leverage extra information coming from averaged inter-\nmediate teacher features. We also reimplement an entropy-\nbased MKD method [12], which has achieved remarkable\nresults in acoustic experiments, on our image classification\ntask and we denote it as EBKD. As for AEKD, we adopt its\nlogits-based version with the author provided code [11].\n\nHyper-parameters. All neural networks are optimized\nby stochastic gradient descent with momentum 0.9, weight\ndecay 0.0001. The batch size is set to 64. As the previous\nworks do [15, 7], the initial learning rate is set to 0.1, ex-\ncept MobileNetV2, ShuffleNetV1 and ShuffleNetV2 are set\nto 0.05. The learning rate is multiplied by 0.1 at 150, 180 and\n210 of the total 240 training epochs. For the sake of fairness,\nthe temperature \u03c4 is set to 4 and the \u03b1 is set to 1 in all methods.\nFurthermore, we set the \u03b2 of our CA-MKD to 50 throughout\nthe experiments. All results are reported in means and stan-\ndard deviations over 3 runs with different random seeds.\n\n4.1. Results on the Same Teacher Architectures\n\nTable 1 shows the top-1 accuracy comparison on CIFAR-100.\nWe also include the results of teacher ensemble with the ma-\njority voting strategy. We can find that CA-MKD surpasses\nall competitors cross various architectures. Specifically, com-\npared to the second best method (EBKD), CA-MKD out-\n\n\n\nTable 3. Top-1 test accuracy of MKD approaches by distilling the knowledge on multiple teachers with different architectures.\nVGG8 AVER FitNet-MKD EBKD AEKD CA-MKD ResNet8x4 ResNet20x4 ResNet32x4\n\n70.74\u00b10.40 74.55\u00b10.24 74.47\u00b10.21 74.07\u00b10.17 74.69\u00b10.29 75.96\u00b10.05 72.79 78.39 79.31\n\nFig. 3. The visualization results of learned weights by CA-\nMKD on each training sample.\n\nperforms it with 0.81% average improvement1, and achieves\n1.66% absolute accuracy improvement in the best case.\n\nTo verify the benefits of diverse information brought by\nmultiple teachers, we compare CA-MKD with some excellent\nsingle-teacher based methods. The results in Table 2 show the\nstudent indeed has the potential to learn knowledge from mul-\ntiple teachers, and its accuracy is further improved compared\nwith the single-teacher methods to a certain extent.\n\n4.2. Results on the Different Teacher Architectures\n\nTable 3 shows the results of training a student (VGG8)\nwith three different teacher architectures, i.e., ResNet8x4,\nResNet20x4 and ResNet32x4. We find the student accu-\nracy becomes even higher than that of training with three\nResNet32x4 teachers, which may be attributed to that the\nknowledge diversity is enlarged in different architectures.\n\nSince the performance of ResNet20x4/ResNet32x4 is bet-\nter than that of ResNet8x4, we could reasonably believe that\nfor most training samples, the student will put larger weights\non predictions from the former two rather than the latter one,\nwhich is verified in Figure 3. Moreover, our CA-MKD can\ncapture those samples on which the predictions are more con-\nfident by ResNet8x4, and assign them dynamic weights to\nhelp the student model achieve better performance.\n\n4.3. Impact of the Teacher Number\n\nAs shown in Figure 4, the student model trained with CA-\nMKD generally achieves satisfactory results. For example,\non the \u201cResNet56 & MobileNetV2\u201d setting, the accuracy of\n\n1Average Improvement= 1\nn\n\n\u2211n\ni\n\n(\nAcci\n\nCA\u2212MKD \u2212Acc\ni\nEBKD\n\n)\n, where\n\nthe accuracies of CA-MKD, EBKD in the i-th teacher-student combination\nare denoted as Acci\n\nCA\u2212MKD, Acc\ni\nEBKD\n\n, respectively.\n\nFig. 4. The effect of different teacher numbers.\n\nTable 4. Ablation study with VGG13 & MobileNetV2.\navg weight w/o Linter w/o wkinter CA-MKD\n67.74\u00b10.87 68.11\u00b10.02 68.82\u00b10.63 69.41\u00b10.20\n\nCA-MKD increases continually as the number of teachers in-\ncreases and it surpasses the competitors with three teachers\neven those competitors are trained with more teachers.\n\n4.4. Ablation Study\n\nWe summarize the observations from Table 4 as follows:\n(1) avg weight. Simply averaging multiple teachers will\n\ncause 1.67% accuracy drop, which confirms the necessity of\ntreating different teachers based on their specific quality.\n\n(2) w/o Linter. The accuracy will appear considerably\nreduction as we remove the Equation (7), demonstrating the\nintermediate layer contains useful information for distillation.\n\n(3) w/o wkinter. we directly use the w\nk\nKD obtained from\n\nthe last layer to integrate intermediate features. The lower\nresult indicates the benefits of designing a separate way of\ncalculating weights for the intermediate layer.\n\n5. CONCLUSION\n\nIn this paper, we introduce confidence-aware mechanism on\nboth predictions and intermediate features for multi-teacher\nknowledge distillation. The confidence of teachers is calcu-\nlated based on the closeness between their predictions or fea-\ntures and the ground-truth labels for the reliability identifica-\ntion on each training sample. With the guidance of labels,\nour technique effectively integrates diverse knowledge from\nmultiple teachers for the student training. Extensive empiri-\ncal results show that our method outperforms all competitors\nin various teacher-student architectures.\n\n\n\n6. REFERENCES\n\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun, \u201cDeep residual learning for image recognition,\u201d in\nProceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770\u2013778.\n\n[2] David Silver, Julian Schrittwieser, Karen Simonyan,\nIoannis Antonoglou, Aja Huang, Arthur Guez, Thomas\nHubert, Lucas Baker, Matthew Lai, Adrian Bolton,\net al., \u201cMastering the game of go without human knowl-\nedge,\u201d Nature, vol. 550, no. 7676, pp. 354\u2013359, 2017.\n\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova, \u201cBERT: pre-training of deep bidi-\nrectional transformers for language understanding,\u201d in\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies,\n2019, pp. 4171\u20134186.\n\n[4] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean, \u201cDistill-\ning the knowledge in a neural network,\u201d arXiv preprint\narXiv:1503.02531, 2015.\n\n[5] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Ka-\nhou, Antoine Chassang, Carlo Gatta, and Yoshua Ben-\ngio, \u201cFitnets: Hints for thin deep nets,\u201d in International\nConference on Learning Representations, 2015.\n\n[6] Sergey Zagoruyko and Nikos Komodakis, \u201cPaying more\nattention to attention: improving the performance of\nconvolutional neural networks via attention transfer,\u201d in\nInternational Conference on Learning Representations,\n2017.\n\n[7] Defang Chen, Jian-Ping Mei, Yuan Zhang, Can Wang,\nZhe Wang, Yan Feng, and Chun Chen, \u201cCross-layer\ndistillation with semantic calibration,\u201d in Proceedings\nof the AAAI Conference on Artificial Intelligence, 2021,\nvol. 35, pp. 7028\u20137036.\n\n[8] Shan You, Chang Xu, Chao Xu, and Dacheng Tao,\n\u201cLearning from multiple teacher networks,\u201d in Proceed-\nings of the 23rd ACM SIGKDD International Confer-\nence on Knowledge Discovery and Data Mining, 2017,\npp. 1285\u20131294.\n\n[9] Takashi Fukuda, Masayuki Suzuki, Gakuto Kurata,\nSamuel Thomas, Jia Cui, and Bhuvana Ramabhadran,\n\u201cEfficient knowledge distillation from an ensemble of\nteachers.,\u201d in Interspeech, 2017, pp. 3697\u20133701.\n\n[10] Meng-Chieh Wu, Ching-Te Chiu, and Kun-Hsuan Wu,\n\u201cMulti-teacher knowledge distillation for compressed\nvideo action recognition on deep neural networks,\u201d in\nICASSP 2019-2019 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2019, pp. 2202\u20132206.\n\n[11] Shangchen Du, Shan You, Xiaojie Li, Jianlong Wu, Fei\nWang, Chen Qian, and Changshui Zhang, \u201cAgree to\ndisagree: Adaptive ensemble knowledge distillation in\ngradient space,\u201d Advances in Neural Information Pro-\ncessing Systems, vol. 33, 2020.\n\n[12] Kisoo Kwon, Hwidong Na, Hoshik Lee, and Nam Soo\nKim, \u201cAdaptive knowledge distillation based on en-\ntropy,\u201d in ICASSP 2020-2020 IEEE International Con-\nference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, 2020, pp. 7409\u20137413.\n\n[13] Jimmy Ba and Rich Caruana, \u201cDo deep nets really need\nto be deep?,\u201d in Advances in Neural Information Pro-\ncessing Systems, 2014, pp. 2654\u20132662.\n\n[14] Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D\nLawrence, and Zhenwen Dai, \u201cVariational information\ndistillation for knowledge transfer,\u201d in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition, 2019, pp. 9163\u20139171.\n\n[15] Yonglong Tian, Dilip Krishnan, and Phillip Isola, \u201cCon-\ntrastive representation distillation,\u201d in International\nConference on Learning Representations, 2020.\n\n[16] Xu Lan, Xiatian Zhu, and Shaogang Gong, \u201cKnowl-\nedge distillation by on-the-fly native ensemble,\u201d arXiv\npreprint arXiv:1806.04606, 2018.\n\n[17] Defang Chen, Jian-Ping Mei, Can Wang, Yan Feng, and\nChun Chen, \u201cOnline knowledge distillation with diverse\npeers.,\u201d in Proceedings of the AAAI Conference on Arti-\nficial Intelligence, 2020, pp. 3430\u20133437.\n\n[18] Yuang Liu, Wei Zhang, and Jun Wang, \u201cAdaptive multi-\nteacher multi-level knowledge distillation,\u201d Neurocom-\nputing, vol. 415, pp. 106\u2013113, 2020.\n\n[19] Alex Krizhevsky and Geoffrey Hinton, \u201cLearning mul-\ntiple layers of features from tiny images,\u201d Technical Re-\nport, 2009.\n\n\n\t1  Introduction\n\t2  RELATED WORK\n\t3  METHODOLOGY\n\t3.1  The Loss of Teacher Predictions\n\t3.2  The Loss of Intermediate Teacher Features\n\t3.3  The Overall Loss Function\n\n\t4  EXPERIMENT\n\t4.1  Results on the Same Teacher Architectures\n\t4.2  Results on the Different Teacher Architectures\n\t4.3  Impact of the Teacher Number\n\t4.4  Ablation Study\n\n\t5  CONCLUSION\n\t6  References\n\n"}
{"Title": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting", "Authors": "Guanyao Li, Shuhan Zhong, Letian Xiang, S.-H. Gary Chan, Ruiyuan Li, Chih-Chieh Hung, Wen-Chih Peng", "Abstract": "  We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency between regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t-1, we predict the traffic at time t at any region. Prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner or are rather computationally intensive in training with a large number of hyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate Spatial-Temporal Transformer with information fusion and region sampling for traffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion module captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency and prediction accuracy, cutting the computation complexity for dependency learning from $O(n^2)$ to $O(n\\sqrt{n})$, where n is the number of regions. With far fewer parameters than state-of-the-art models, the offline training of our model is significantly faster in terms of tuning and computation (with a reduction of up to $90\\%$ on training time and network parameters). Notwithstanding such training efficiency, extensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an average improvement of up to $9.5\\%$ on RMSE, and $12.4\\%$ on MAPE).      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00008", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\nA Lightweight and Accurate Spatial-Temporal\nTransformer for Traffic Forecasting\n\nGuanyao Li, Shuhan Zhong, Letian Xiang, S.-H. Gary Chan\nRuiyuan Li, Chih-Chieh Hung, Wen-Chih Peng\n\nAbstract\u2014We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency\nbetween regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t\u2212 1, we predict the traffic at\ntime t at any region. Prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner, or are rather\ncomputationally intensive in training with a large number of hyper-parameters to tune.\nWe propose ST-TIS, a novel, lightweight and accurate Spatial-Temporal Transformer with information fusion and region sampling for\ntraffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion\nmodule captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency\nand prediction accuracy, cutting the computation complexity for dependency learning from O(n2) to O(n\n\n\u221a\nn), where n is the number of\n\nregions. With far fewer parameters than state-of-the-art models, ST-TIS\u2019s offline training is significantly faster in terms of tuning and\ncomputation (with a reduction of up to 90% on training time and network parameters). Notwithstanding such training efficiency,\nextensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an\naverage improvement of 9.5% on RMSE, and 12.4% on MAPE compared to STDN and DSAN).\n\nIndex Terms\u2014spatial-temporal forecasting; spatial-temporal data mining; efficient Transformer; joint spatial-temporal dependency;\nregion sampling.\n\nF\n\n1 INTRODUCTION\n\nTraffic forecasting is to predict the inflow (i.e., the number\nof arriving objects per unit time) and outflow (i.e., the\nnumber of departing objects per unit time) of any region\nin a city at the next time slot. The objects can be people,\nvehicles, goods/items, etc. Traffic forecasting has important\napplications in transportation, retails, public safety, city\nplanning, etc [1], [2]. For example, with traffic forecasting, a\ntaxi company may dispatch taxis in a timely manner to meet\nthe supply and demand in different regions of a city. Yet\nanother example is bike sharing, where the company may\nwant to balance bike supply and demand at dock stations\n(regions) based on such forecasting.\n\nAlthough there has been much effort on deep learning to\nimprove the prediction accuracy of the state-of-the-art fore-\ncasting models, progressive improvements on benchmarks\nhave been correlated with an increase in the number of\nparameters and the amount of training resources required\nto train the model, making it costly to train and deploy\nlarge deep learning models [3]. Therefore, a lightweight\n\n\u2022 Guanyao Li, Shuhan Zhong, Letian Xiang, andd S.-H. Gary Chan are\nwith the Department of Computer Science and Engineering, The Hong\nKong University of Science and Technology.\nE-mail: {gliaw, szhongaj, lxiangab, gchan}@cse.ust.hk\n\n\u2022 Ruiyuan Li is with College of Computer Science, Chongqing University.\nE-mail: liruiyuan@cqu.edu.cn\n\n\u2022 Chih-Chieh Hung is with Department of Computer Science and Engineer-\ning, National Chung Hsing University.\nE-mail: smalloshin@email.nchu.edu.tw\n\n\u2022 Wen-Chih Peng is with Department of Computer Science, National Yang\nMing Chiao Tung University.\nE-mail: wcpeng@g2.nctu.edu.tw\n\nand training-efficient model is essential for fast delivery and\ndeployment.\n\nIn this work, we study the following spatial-temporal\ntraffic forecasting problem: Given the historical (aggregated)\ninflow and outflow data of different regions from time slots\n0 to t \u2212 1 (with slot size of, say, 30 minutes), what is the\ndesign of a training-efficient model to accurately predict the\ninflow and outflow of any region at time t? (Note that even\nthough we consider predicting for the next time slot, our\nwork can be straightforwardly extended to any future time\nslot by successive application of the algorithm.) We seek\na \u201csmall\u201d training model with substantially fewer parame-\nters, which naturally leads to efficiency in tuning, memory,\nand computation time. Despite its training efficiency, our\nlightweight model lightweight, it should also achieve higher\naccuracy than the state-of-the-art approaches in its online\npredictions.\n\nIntuitively, region traffic is spatially and temporally cor-\nrelated. As an example, the traffic of a region could be\ncorrelated with that of another with some temporal lag\ndue to the travel time between them. Moreover, such de-\npendency may be dynamic over different time slots, and it\nmay have temporal periodic patterns. This is the case for the\ntraffic of office regions, which exhibit high correlation with\nthe residence regions in workday morning but much less\nthan at night or weekend. To accurately predict the region\ntraffic, it is hence significantly crucial to account for the\ndynamic, possibly periodical, and joint spatial-temporal (ST)\ndependency between regions, no matter how far the regions\nis apart.\n\nMuch effort has been devoted to capturing the de-\npendency between regions for traffic forecasting. While\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n8v\n2 \n\n [\ncs\n\n.L\nG\n\n] \n 4\n\n J\nan\n\n 2\n02\n\n2\n\n\n\n2\n\nFig. 1. Visualization of attention scores between a target region (6,4)\nand other regions. The color of a cell (xi, yi) indicates the dependency\nof (6, 4) on (xi, yi), where a darker color indicates stronger dependency.\n\ncommendable, most works consider spatial and temporal\ndependency separately with independent processing mod-\nules [4]\u2013[9], which can hardly capture their joint nature\nin our current setting. Some recent works apply canonical\nTransformer [10] to capture region dependency [11]\u2013[14].\nWhile impressive, canonical Transformer limits the train-\ning efficiency because it learns a region\u2019s embedding as\nthe weighted aggregation of all the other regions based\non their computed attention scores. This results in O(n2)\ncomputation complexity per layer, where n is the number of\nregions. Moreover, it has been observed that the attention\nscores from the canonical Transformer have a long tail\ndistribution [15]. We illustrate this in Figure 1 using a taxi\ndataset collected in New York City. We split New York City\ninto 10\u00d720 regions and visualize the attention scores (after a\nSoftMax operation) between a target region (i.e., the region\n(6, 4)) and other regions. Clearly, most regions have very\nsmall attention scores (i.e., the long-tail phenomenon), with\nthe attention scores of more than 60% of regions being less\nthan 0.004. Such a long-tail effect may introduce noise for\nthe region embedding learning and degrade the prediction\nperformance.\n\nWe propose ST-TIS, a novel, small, efficient and accurate\nSpatial-Temporal Transformer with information fusion and\nregion sampling for traffic forecasting. Given the histor-\nical (aggregated) inflow and outflow of regions from 0\nto t \u2212 1, ST-TIS predicts the inflow and outflow of any\nregion at t, without relying on the transistion data between\nregions. With a small set of parameters, ST-TIS is efficient\nto train (offline phase). It extends the canonical Transformer\nwith novel information fusion and region sampling strate-\ngies to learn the dynamic and possibly periodical spatial-\ntemporal dependency between regions in a joint manner,\nhence achieving high prediction accuracy (online phase).\n\nST-TIS makes the following contributions:\n\n\u2022 A data-driven Transformer scheme for dynamic, possibly\nperiodical, and joint spatial-temporal dependency learn-\ning. ST-TIS jointly considers the spatial-temporal de-\npendencies between regions, rather than considering\nthe two dependencies sequentially in a decoupled\nmanner. In particular, ST-TIS considers the dynamic\nspatial-temporal dependency for any individual time\nslot with an information fusion module, and also the\npossibly periodical characteristic of spatial-temporal\n\ndependency from multiple time slots using an atten-\ntion mechanism. Moreover, the dependency learning\nis data-driven, without any assumption on spatial\nlocality. Due to its design, ST-TIS is small (in parame-\nter footprint), fast (in training time), and accurate (in\nprediction).\n\n\u2022 A novel region sampling strategy for computationally effi-\ncient dependency learning. ST-TIS leverages the Trans-\nformer framework [10] to learn region dependency.\nTo address the quadratic computation issue and\nmitigate the long-tail effect, it employs a novel re-\ngion sampling strategy to generate a connected re-\ngion graph and learns the dependency based on\nthe graph. The dependencies between any pair of\nregions (both close and distant dependencies) are\nguaranteed to be considered in ST-TIS via informa-\ntion propagation, and the computational complexity\nis reduced from O(n2) to O(n\n\n\u221a\nn), where n is the\n\nnumber of regions.\n\u2022 Extensive experimental validation: We evaluate ST-TIS\n\non two large-scale real datasets of taxi and bike\nsharing. Our results shows that ST-TIS is substan-\ntially more accurate than the state-of-the-art ap-\nproaches, with a significant improvement in RMSE\nand MAPE (an average improvement of 9.5% on\nRMSE, and 12.4% on MAPE compared to STDN and\nDSAN). Furthermore, it is much more lightweight\nthan most state-of-the-art models, and is ultra fast for\ntraining (with a reduction of 46% \u223c 95% on training\ntime and 23% \u223c 98% on network parameters).\n\nThe remainder of this paper is organized as follows. We\nfirst discuss related works in Section 2. After preliminaries\nin Section 3, we detail ST-TIS in Section 4. We present the\nexperimental settings and results in Section 5, and conclude\nin Section 6.\n\n2 RELATED WORKS\nTraffic forecasting has raised much attention in both\nacademia and industry due to its social and commercial\nvalues. Some early traffic forecasting works propose using\nregression models, such as auto-regressive integrated mov-\ning average (ARIMA) models [16]\u2013[19] and non-parametric\nregion models [20], [21]. All of these works consider tem-\nporal dependency, but they have not considered the spatial\ndependency between regions. Some other works extract fea-\ntures from heterogeneous data sources (e.g., POI, weather,\netc.), and use machine learning models such as Support\nVector Machine [22], Gradient Boosting Regression Tree [23],\nand linear regression model [24]. Despite of the encouraging\nresults, they rely on manually defined features and have not\nconsidered the joint spatial-temporal dependency.\n\nIn recent years, deep learning techniques have been\nemployed to study spatial and temporal correlations for\ntraffic forecasting. Most existing works consider the spa-\ntial and temporal dependency in a decouple manner [4]\u2013\n[9], which can hardly capture their joint effect. For spatial\ndependency, Convolution Neural Network (CNN), Graph\nNeural Network (GNN), and Transformer have been widely\napplied. Regarding temporal dependency, Recurrent Neural\nNetwork (RNN) and its variants such as Long Short Term\n\n\n\n3\n\nMemory (LSTM) and Gated Recurrent Unit (GRU) have\nbeen extensively studied. Compared with these works, ST-\nTIS considers the spatial and temporal dependency in a joint\nmanner.\n\nCNN has been applied in many works to capture depen-\ndencies between close regions [4]\u2013[7], [25]. In these works,\na city is divided into some connected but non-overlapping\ngrids, and the traffic in each grid is then predicted. However,\nthese works cannot be used for fine-grained flow forecasting\nat an individual location [26], such as predicting flow for a\ndocked bike-sharing station or a subway station. Moreover,\nCNN can hardly capture distant traffic dependency due to\nits relatively small receptive field [27], [28].\n\nSome other works use GCN to capture spatial depen-\ndency [8], [9], [29]\u2013[35]. In these works, a city is represented\nas a graph structure, and convolution operations are ap-\nplied to aggregate spatially distributed information in the\ngraph. In each aggregation layer, a region would aggregate\nthe embedding of its neighbouring regions in the graph.\nHowever, these works highly rely on the graph structure for\ndependency learning. Prior works usually construct graphs\nbased on the distance between regions or road network,\nbased on the locality assumption (i.e., close regions have\nhigher dependency). They have to stack more layers to\nlearn dependency if the distance between two regions in the\ngraph is long, and it ends up with an inefficient and over-\nsmoothing model [31]. In recent years, Transformer [10] has\nbeen applied for traffic forecasting [11]\u2013[14]. The canonical\nTransformer can be seen as a special graph neural network\nwith a complete graph, in which any pair of regions are\nconnected. Consequently, the dependencies between both\nclose and distant regions could be considered. Moreover,\nthe self-attention mechanism and the network structure of\nTransformer have been demonstrated to be powerful in\nmany prior works. However, the computational complexity\nof each aggregation round isO(n2) for Transformer where n\nis the number of regions, while that for GNN is O(E) where\nE is the number of edges in the graph (E \u2264 n2). Further-\nmore, as a region may only have a strong dependency on a\nsmall portion of regions, aggregating the embedding of all\nregions would introduce noise and degrade its performance.\nIn ST-TIS, we propose a region connected graph (i.e., there\nexists a path between any pair of regions in the graph), in\nwhich the degree of any node (i.e., region) is O(\n\n\u221a\nn) and\n\nthe distance between any two regions in the graph is no\nmore than 2. We extend the canonical Transformer with the\nproposed region connected graph, so that it can inherit the\nadvantage of efficiency and effectiveness from both GNN\nand Transformer.\n\nRNN and its variants such as LSTM and GRU [36], [37]\nhave been used to capture temporal dependency [6], [34],\n[35], [38]. However, the performance of RNN-based models\ndeteriorates rapidly as the length of the input sequence\nincreases [39]. Some works incorporate the attention mecha-\nnism [40] to improve their capability of modeling long-term\ntemporal correlations [7], [9], [29], [41]. Nevertheless, RNN-\nbased networks are widely known to be difficult to train and\nare computationally intensive [8]. As recurrent networks\ngenerate the current hidden states as a function of the\nprevious hidden state and the input for the position, they are\nin general more difficult to be trained in parallel. To address\n\nthe issue, the self-attention mechanism is proposed as the\nreplacement of RNN to model sequential data [10]. It has\nenjoyed success in capturing temporal correlations for traf-\nfic forecasting [11]\u2013[13], [42]. Compared with RNN-based\nmodels, self-attention models can directly model long-term\ntemporal interactions, but the computational complexity of\nusing self-attention for temporal dependency learning in\nexisting works is O(q2), where q is the number of historical\ntime slots. Compared with them, ST-TIS is conditional on\nthe spatial-temporal dependency at any individual slot to\ngenerate weights for different time slots, so its computa-\ntional complexity is O(q) in our work. In addition, the\ntemporal dependency is jointly considered with the spatial\ndependency in ST-TIS, instead of in a decouple manner.\n\nSome variants of Transformer have been proposed to\naddress the efficiency issues of the canonical Transformer,\nsuch as LogSparse [43], Reformer [44], Informer [15], etc.\nWhile impressive, these approaches cannot be used in the\nscenario of capturing spatial-temporal dependency between\nregions for traffic forecasting we are considering in this\nwork.\n\n3 PRELIMINARIES\n\n3.1 Problem formulation\n\nDefinition 1. (Region) The area (e.g., a city or subway route)\nis partitioned into n non-overlapping regions. We use R =\n{r1, r2, . . . , rn} to denote the partitioned regions, in which ri\ndenotes the i-th region.\n\nThe way to partition an area is flexible for ST-TIS, e.g.,\ngrid map, road network, clustering, or train/bus/bike sta-\ntions, etc.\n\nDefinition 2. (Traffic data) We use I and O to denote the inflow\nand outflow data of all regions over time, respectively. Specifically,\nIt \u2208 R1\u00d7n and Ot \u2208 R1\u00d7n is the inflow and outflow of the\nn regions at time t. Moreover, Iti and O\n\nt\ni is the inflow and\n\noutflow of region ri at time t (i.e., the number of objects arriving\nat/departing from the region ri at time slot t). Furthermore, we use\nIt\n\n\u2032:t\ni = [I\n\nt\u2032\n\ni , I\nt\u2032+1\ni , . . . , I\n\nt\ni ] to denote the inflow of ri from t\n\n\u2032 to\nt. Similarly, Ot\n\n\u2032:t\ni = [O\n\nt\u2032\n\ni ,O\nt\u2032+1\ni , . . . ,O\n\nt\ni ] indicates the outflow\n\nof ri from t\u2032 to t.\n\nThe formal formulation of the traffic forecasting problem\nis as follows:\n\nDefinition 3. (Traffic Forecasting) Given the traffic data of\nregions from 0 to t \u2212 1, namely I0:t\u22121 and O0:t\u22121, the traffic\nforecasting problem is to predict the inflow and outflow of any\nregion at t, namely It and Ot.\n\n3.2 ST-TIS Overview\n\nWe overview the proposed ST-TIS in Figure 2. Given the\ntraffic data of all regions from time slots 0 to t \u2212 1, ST-\nTIS is an end-to-end model to capture the spatial-temporal\ndependency and predict the inflow and outflow for any\nregion at t. There are five modules in ST-TIS. We explain\nthe design goals and the relationship among modules as\nfollows:\n\n\n\n4\n\nFig. 2. ST-TIS overview.\n\n\u2022 Information Fusion Module: A key to accurately pre-\ndicting the traffic for regions is capturing the dy-\nnamic spatial-temporal (ST) dependency between re-\ngions in a joint manner. To this end, ST-TIS employs\na information fusion module to learn the spatial-\ntemporal-flow (STF) embedding by encoding its spa-\ntial, temporal, and flow information for any individ-\nual region at a time slot.\n\n\u2022 Region Sampling Module: To address the issues of\nquadratic computational complexity and long tail\ndistribution of attention scores for the canonical\nTransformer, ST-TIS uses a novel region sampling\nstrategy to generate a region connected graph. The\ndependency learning would be based on the gener-\nated graph.\n\n\u2022 Dependency Learning for Individual Time Slot (DLI):\nGiven the STF embedding at a time slot and the\nregion connected graph, ST-TIS extends the canonical\nTransformer to jointly capture the dynamic spatial-\ntemporal dependency between regions at the time\nslot. As the spatial and temporal information has\nbeen both encoded in the STF embedding, the joint\neffect of spatial-temporal dependencies between re-\ngions could be captured. Moreover, with the region\nconnected graph, only the attention scores between\nneighbouring nodes (i.e., regions) are computed,\nand only the embedding of one\u2019s neighbouring re-\ngions are aggregated. Dependency between non-\nneighbouring nodes is considered via information\npropagation between multiple layers in the network.\nConsequently, it cuts the computational complexity\nof a layer from O(n2) to O(n \u00d7\n\n\u221a\nn) where n is the\n\nnumber of regions, and addresses the issue of the\nlong-tail effect for dependency learning.\n\n\u2022 Dependency Learning over Multiple Time Slots (DLM):\nGiven the region embedding from DLI at multi-\nple time slots, DLM captures the periodic patterns\n\nof spatial-temporal dependency using the attention\nmechanism. The influence of spatial-temporal de-\npendency at historical time slots on the predicted\ntime slot is hence considered in ST-TIS. The learning\nprocess is data-driven, without any prior assumption\nof traffic periods.\n\n\u2022 Prediction Network (PN): Given the results from DLM,\nST-TIS uses a fully connected neural network to\npredict the inflow and outflow of regions (It and\nOt) simultaneously.\n\n4 ST-TIS DETAILS\nWe present the details of ST-TIS in this section. We first elab-\norate the information fusion module in Section 4.1, followed\nby the region sampling module in Section 4.2. After that,\nwe introduce the dependency learning for individual time\nslot (DLI) in Section 4.3, and the dependency learning over\nmultiple time slots (DLM) in Section 4.4. Finally, we present\nthe prediction network (PN) in Section 4.5.\n\n4.1 Information Fusion Module\nTo capture the dynamic joint spatial-temporal dependency\nfor traffic forecasting, it is essential to fuse the spatial-\ntemporal information for each region at any individual time\nslot. To this end, ST-TIS employs the information fusion\nmodule to learn one\u2019s spatial-temporal-flow (STF) embed-\nding by fusing its position, time slot, and flow information.\n\nGiven n regions, we first use a one-hot vector Si \u2208 R1\u00d7n\nto represent a region ri, in which only the i-th element in\nSi is 1 and otherwise 0. After that, we encode the position\ninformation for a region ri as follows,\n\nS\u0302i = Si \u00b7WS + bS . (1)\n\nwhere S\u0302i \u2208 R1\u00d7d is the spatial embedding of ri, WS \u2208\nRn\u00d7d and bS \u2208 R1\u00d7d are learnable parameters, and d is a\nhyperparameter.\n\nIn terms of temporal information, we first split a day\ninto o time slots and represent the i-th time slot using a\none-hot vector Ti \u2208 R1\u00d7o. After that, we learn the temporal\nembedding by\n\nT\u0302i = Ti \u00b7WT + bT , (2)\n\nwhere T\u0302i \u2208 R1\u00d7d is the temporal embedding of the i-th time\nslot in a day, WT \u2208 Ro\u00d7d and bT \u2208 R1\u00d7d are learnable\nparameters.\n\nRecall that the traffic of one region at ti may depend on\nthat of another region at previous time slots due to the travel\ntime between two regions. Thus, we use one\u2019s surrounding\nobservations instead of solely using a snapshot to learn the\ndependency [43]. We define the surrounding observations\nof a region at a time slot tj as follows:\n\nDefinition 4. (Surrounding observations) For a region\nri at a time slot tj , its surrounding observations are\ndefined as the flow in the w previous time slots:\n{Itj\u2212wi , \u00b7 \u00b7 \u00b7 , I\n\ntj\u22122\ni , I\n\ntj\u22121\ni ,O\n\ntj\u2212w\ni , \u00b7 \u00b7 \u00b7 ,O\n\ntj\u22122\ni ,O\n\ntj\u22121\ni }.\n\nNote that by employing the surrounding observations,\nthe temporal lag of the dependency between regions could\nbe considered. Given the surrounding observations of ri at\ntj , we first apply the 1-D convolution of kernel size 1 \u00d7\n\n\n\n5\n\nFig. 3. Information propagation in a graph.\n\nFig. 4. The process of connected graph generation.\n\np (p < w) with stride 1 and f output channels on its inflow\nand outflow surrounding observations to extract different\npatterns. The flow embedding F tji \u2208 R\n\n1\u00d7d of ri at tj is\ncomputed as\n\nF tji = (Conv\nI(Itj\u2212w:tj\u22121i )||Conv\n\nO(Otj\u2212w:tj\u22121i ))\u00b7W\nF +bF ,\n\n(3)\nwhere || is the concatenation operation, ConvI(\u00b7) and\nConvO(\u00b7) are the convolutional operation for inflow and\noutflow data respectively, WF \u2208 Rl\u00d7d, bF \u2208 R1\u00d7d are\nlearnable parameters, and l = 2\u00d7 f \u00d7 (w \u2212 k + 1).\n\nFinally, we fuse the position, time slot and flow informa-\ntion to learn the STF embedding of a region ri at time tj . We\ndefine that tj is the M(tj)-th time slot in a day, where M(\u00b7)\nis an matching function. The fusion process is defined as\n\nLtji = (S\u0302i + T\u0302M(tj) + F\ntj\ni ) \u00b7W\n\nL + bLi , (4)\n\nwhere Lji \u2208 R\n1\u00d7d is the STF embedding, WL \u2208 Rd\u00d7d and\n\nbLi \u2208 R\n1\u00d7d are learnable parameters.\n\n4.2 Region Sampling\n\nTo capture a region\u2019s dependency on others (both nearby\nand distant), a canonical Transformer computes the atten-\ntion scores between the target region and all other regions,\nand aggregats the embedding of all other regions based\non the computed attention scores. However, this results in\n\nthe issues of quadratic computation and long-tail effect for\ndependency learning.\n\nFortunately, prior works have showed that information\ncould be propogated between nodes in a graph via a multi-\nlayer network structure [45]. Hence, with a proper graph\nstructure and network structure, a region can aggregate\nthe embedding of another even without directly evaluating\ntheir attention score. We present a toy example in Figure\n3, in which regions are represented as nodes in the graph\nand connected with egdes. In the first aggregation layer,\nr1 would capture the information from r2, while r2 would\ncapture the information from r3. Since the information of r3\nhas been aggregated in r2, r1 could also capture it in the\nsecond aggregation layer without computing the attention\nscore between r1 and r3. From this example, we conclude\nthat a node\u2019s information can reach another with a \u03b2-layer\naggregation operation if their distance is not more than \u03b2 in\nthe graph.\n\nTo address the limitations of the canonical Transformer,\nwe propose to generate a connected graph (i.e., there exists\nat least a path between any two nodes in the graph), in\nwhich the degree of any node (i.e., region) is not more\nthan c \u00d7\n\n\u221a\nn and the distance between any pair of nodes\n\nare not more than 2. In this way, for a target region, we\nonly have to aggregate the embedding of O(\n\n\u221a\nn) regions\n\nin an aggregation layer, and the influence from other re-\ngions can be captured in a two-layer aggregation process\nby information propagation. With such design, we do not\nhave to compute the attention scores between any pairs of\nregions and aggregate the embedding of all n regions for a\ntarget region, so that the computation complexity is reduced\nto O(n\n\n\u221a\nn) for each layer, and the long-tail issue is also\n\naddressed.\nIn this work, we present a heuristic approach for region\n\nconnected graph generation. We first calculate the traffic\nsimilarity between any pair of regions. The calculation of\nthe traffic similarity is flexible and it could be any similarity\nmetric. As an example, we use DTW in this work to measure\nthe similarity in terms of the average traffic over time slots\nof a day. We use M \u2208 Rn\u00d7n to represent the similarity\nmatrix, in which Mi,j is the similarity between ri and rj .\nBased onM, the process of the connected graph generation\nis illustrated in Figure 4.\n\nWe first select top b\n\u221a\nnc regions without replacement,\n\nwhich have the largest sum of similarity with other regions,\nrepresented as {r1,1, r1,2, \u00b7 \u00b7 \u00b7 , r1,b\u221anc}. For any region r1,i,\nwe then select b\n\n\u221a\nnc \u2212 1 regions without replacement,\n\nwhich have the largest similarity between them and r1,i,\nrepresented as {r2,i,1, r2,i,2, \u00b7 \u00b7 \u00b7 , r2,i,b\u221anc\u22121}, and we con-\nnect r1,i to r2,i,j (j = 1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc \u2212 1). After that, we\n\nconnect a region r2,i,j to regions r2,i,k and r2,u,j , where k \u2208\n{{1, 2, ..., b\n\n\u221a\nnc \u2212 1}\\{j}} and u \u2208 {{1, 2, ..., b\n\n\u221a\nnc}\\{i}}.\n\nFinally, if\n\u221a\nn /\u2208 Z, the remaining regions woule be con-\n\nnected to r1,i where i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}, represented\n\nas {r3,1, r3,2, \u00b7 \u00b7 \u00b7 , r3,n\u2212b\u221anc2}. If\n\u221a\nn \u2208 Z, we randomly\n\nselect a region from r1,i, and connect it to r1,j , where\nj \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc}\\{i}, represented as r\u2217.\n\nTheorem 1. The degree of any node in the region connected graph\nis O(\n\n\u221a\nn), and the distance between any two nodes in the graph\n\nis less than 2.\n\n\n\n6\n\nProof. The generation of the region connected graph ensures\nthat a node is connected to at most max(2\u00d7 b\n\n\u221a\nnc \u2212 2, n\u2212\n\nb\n\u221a\nnc2 + b\n\n\u221a\nnc \u2212 1) other nodes, and hence the degree is\n\nO(\n\u221a\nn).\n\nThe distance of (r3,i, r1,j) (or (r\u2217, r1,j)) and (r1,j , r2,j,k)\nis both 1, where i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , n \u2212 b\n\n\u221a\nnc2}, j \u2208\n\n{1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}, and k \u2208 {1, 2, ..., b\n\n\u221a\nnc \u2212 1}. Thus, the\n\ndistance between r3,i (or r\u2217) and any other region is no more\nthan 2 in the graph.\n\nFor region r1,j , since the distance of (r1,j , r2,j,k) and\n(r2,j,k, r2,m,k) is both 1 where k \u2208 {1, 2, ..., b\n\n\u221a\nnc \u2212 1} and\n\nm \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}\\{j}, the distance of (r1,j , r2,m,k) is\n\nhence 2. Thus, the distance between r1,j and any other\nregion is also no more than 2.\n\nIn terms of r2,j,k, as the distance of (r2,j,k, r2,m,k) and\n(r2,j,k, r2,j,v) is 1, where m \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc}\\{j} and v \u2208\n\n{1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc \u2212 1}\\{k}, the distance between r2,j,k and\n\nany other regions is hence no more than 2. Therefore, the\ndistance between any two regions in the graph is less than\n2.\n\nBecause the distance between any two regions in the\nproposed graph is less than 2, the dependencies between\nany two regions could be considered if the layer number of\nthe aggregation network is larger than 2.\n\n4.3 Dependency Learning for Individual Time Slot (DLI)\nGiven the STF embedding of regions for time tj and the gen-\nerated region connected graph, ST-TIS captures the spatial-\ntemporal dependencies between regions based on an ex-\ntended Transformer encoder. Following the canonical Trans-\nformer, ST-TIS employs an multi-head attention mechanism,\nso that it could account for different dependencies between\nregions. For the m-th head, the attention score between ri\nand rv at tj is defined as\n\nAm(ri, rv, tj) =\n(Ltji \u00b7WQm) \u00b7 (L\n\ntj\nv \u00b7WKm)T\u221a\n\nd\n, (5)\n\nwhere Ltji \u2208 R\n1\u00d7d and Ltjv \u2208 R1\u00d7d are the STF embedding\n\nof regions ri and rv at tj (Equation 4), WQm \u2208 Rd\u00d7d\nand WKm \u2208 Rd\u00d7d are learnable parameters, and d is a\nhyperparameter for the embedding size.\n\nUnlike the canonical Transformer, we do not evaluate the\nattention scores between one region and all other regions.\nInstead, we only compute one\u2019s attention scores with its\nneighbouring regions in the region connected graph, and\naggregate their embedding in terms of their attention score\nto update the region\u2019s embedding. For the m-th head, the\nembedding of a region ri at time tj is then updated as\n\nL\u0302tji,m =\n\u2211\n\nrv\u2208Neigh(ri)\n\nsoftmax(Am(ri, rv, tj)) \u00b7 Ltjv\n\n=\n\u2211\n\nrv\u2208Neigh(ri)\n\nexp(Am(ri, rv, tj))\u2211\nru\u2208Neigh(ri) exp(Am(ri, ru, tj))\n\n\u00b7 Ltjv ,\n\n(6)\n\nwhere L\u0302tji,m \u2208 R\n1\u00d7d is the output of the m-th head,\n\nNeigh(ri) is the neighbouring regions of ri in the graph,\nAm(ri, rv, tj) is the attention score defined in Equation 5.\nAs the degree of any node is O(\n\n\u221a\nn), the computation\n\nFig. 5. Processing of dependency learning for individual time slot.\n\ncomplexity of attention score evaluation and embedding\naggregation is hence O(n\n\n\u221a\nn) for all regions in a layer.\n\nFinally, we concatenate the results of multi-heads and\nthe embedding of ri is computed as\n\nL\u0302tji = Concat(L\u0302\ntj\ni,1, \u00b7 \u00b7 \u00b7 , L\u0302\n\ntj\ni,M ) \u00b7W\n\nO, (7)\n\nwhere Concat(\u00b7) is the concatenation operation, L\u0302ti \u2208 R\n1\u00d7d\n\nis the embedding of ri, WO \u2208 R(d\u00d7M)\u00d71 are learnable\nparameters and M is the number of heads.\n\nFollowing the structure of Transformer [10], the output\nof the multi-head region attention layers L\u0302tji is then passed\nto a fully connected neural network (Figure 5). We also em-\nploy a residual connection between each of the two layers.\nAs we discussed in Section 4.2, the information propagation\nis achieved with a multi-layer network structure. Thus, we\nstack the layers \u03b1 times (the effect of \u03b1 will be discussed\nin Section 5.7). We denote the final output of the DLI as\nRtj = {Rtj1 ,R\n\ntj\n2 , \u00b7 \u00b7 \u00b7 ,R\n\ntj\nn }, where R\n\ntj\ni is the embedding of\n\nregion ri at tj .\nCompared with the canonical Transformer, we only need\n\nto compute the attention scores and aggregate the embed-\nding between adjacent nodes in the region connected graph.\nThe computation complexity is hence reduced from O(n2)\nto O(n\n\n\u221a\nn) for each layer.\n\n4.4 Dependency Learning over Multiple Time\nSlots (DLM)\nConsidering the spatial-temporal dependency may have pe-\nriorical characteristic, DLM learns the periodic dependency\nby evaluating the correlation between Rtn and the depen-\ndency at other historical time slots Rt\u0302i (where t\u0302 < t). After\nthat, it generates a new embedding for ri by aggregating\nthe embedding at different time slots according to their\ncorrelations.\n\nSpecifically, we consider the short-term and long-term\nperiod for traffic data in this work. The spatial-temporal\ndependency at the following historical time slots are used\nas the model input to predict the inflow and outflow of\n\n\n\n7\n\nregions at t: spatial-temporal dependency in the recent h\ntime slots (i.e., short-term period); the same time interval in\nthe recent l days (i.e.,long-term period).\n\nWe employ a point-wise aggregation with self-attention\nto evaluate their correlations and aggregate the embedding\naccordingly. To capture the multiple periodic dependency,\nwe use an multi-head attention network in DLM.\n\nGiven a set of historical time slot Q, the z-th dependency\non a historical time slot t\u0302 \u2208 Q is calculated as follows:\n\nez(t, t\u0302) =\n(Rti \u00b7W\n\nT\nQz\n\n) \u00b7 (Rt\u0302i \u00b7W\nT\nKz\n\n)T\n\u221a\nd\n\n, (8)\n\nwhere W TQz \u2208 R\nd\u00d7d and W TKz \u2208 R\n\nd\u00d7d are learnable param-\neters.\n\nWe use a softmax function to normalize the dependency\nand aggregate the context of each time slot by weight:\n\n\u03b2z(t, t\u0302) = softmax(ez(t, t\u0302)) =\nexp(ez(t, t\u0302))\u2211\n\ntp\u2208Q exp(ez(t, tp))\n. (9)\n\nThe aggregation of the z-th head is hence\n\nR\u0302ti,z = (\n\u2211\nt\u0302\u2208Q\n\n(\u03b2z(t, t\u0302) \u00b7 Rt\u0302i) \u00b7W\nT\nV , (10)\n\nwhere Q is the set of historical time slots, R\u0302ti,z is the\naggregation result of the z-th head, and W TV \u2208 R\n\nd\u00d7d are\nlearnable parameters. Finally, we concatenate the results of\ndifferent heads with\n\nR\u0302ti = Concat(R\u0302\nt\ni,1, R\u0302\n\nt\ni,2, \u00b7 \u00b7 \u00b7 , R\u0302\n\nt\ni,Z) \u00b7WT , (11)\n\nwhere Concat(\u00b7) is the concatenation operation, and WT \u2208\nR(Z\u00d7d)\u00d7d are learnable parameters. We then pass R\u0302ti to\na fully connected neural network to obtain the spatial-\ntemporal embedding of ri at t. Note that we also employ a\nresidual connection between each of the two layers to avoid\ngradient exploding or vanishing. The output of the DLM is\ndenoted as \u2126ti for region ri at t.\n\nDifferent from prior works, the periodic dependency\nlearning is conditional on the spatial-temporal dependency\nat each individual time slot. Consequently, the spatial and\ntemproal dependencies are jointly considered during the\nperiodic dependency learning. The computation complexity\nis O(|Q|), where |Q| is the number of historical time slots\nused for learning.\n\n4.5 Prediction Network (PN)\nGiven the spatial-temporal embedding T tri of a region, the\nprediction network predicts the inflow and outflow using\nthe fully connected network. The forecasting function is\ndefined as\n\n[I\u0302ti , O\u0302\nt\ni ] = \u03c3(\u2126\n\nt\ni \u00b7W\n\nP + bP ), (12)\n\nwhere I\u0302ti and O\u0302\nt\ni is the forecasting inflow and outflow\n\nrespectively, \u03c3(\u00b7) is the ReLU activation function and WP \u2208\nRd\u00d72, and bP \u2208 R1\u00d72 are learnable parameters.\n\nWe simultaneously forecast the inflow and outflow in\nour work, and define the loss function as follows:\n\nLOSS =\n\n\u221a\u2211n\ni=1(I\n\nt\ni \u2212 I\u0302\n\nt\ni )\n\n2 +\n\u2211n\n\ni=1(O\nt\ni \u2212 O\u0302\n\nt\ni)\n\n2\n\n2n\n, (13)\n\nwhere n is the number of regions.\n\n5 ILLUSTRATIVE EXPERIMENTAL RESULTS\nIn this section, we first introduce the datasets and the data\nprocessing approaches in Section 5.1, and the evaluation\nmetrics and baseline approaches in Section 5.2. Then, we\ncompare the accuracy and training efficiency of ST-TIS with\nthe state-of-the-art methods in Sections 5.3 and 5.4, respec-\ntively. After that, we evaluate the performance of variants\nof ST-TIS and the effect of surrounding observations in\nSections 5.6 and 5.5, respectively, followed by the discussion\non the hyperparameters of layer number in Section 5.7 and\nhead number in Section 5.8.\n\n5.1 Datasets\nWe conduct extensive traffic study and model evaluations\nbased on two real-world traffic flow datasets collected in\nNew York City (NYC), the NYC-Taxi dataset and the NYC-\nBike dataset. Each dataset contains trip records, each of\nwhich consists of origin, destination, departure time, and\narrival time. The NYC-Taxi dataset contains 22, 349, 490\ntaxi trip records of NYC in 2015, from 01/01/2015 to\n03/01/2015. The NYC-Bike dataset was collected from the\nNYC Citi Bike system from 07/01/2016 to 08/29/2016, and\ncontains 2, 605, 648 trip records.\n\nThe city is split into 10 \u00d7 20 regions with a size of\n1km\u00d71km. The time interval is set as 30 minutes for both\ndatasets. The two datasets were pre-processed and released\nonline1 by the prior work [7].\n\nIn both of the taxi dataset and bike dataset, we use\ndata from the previous 40 days as the training data, and\nthe remaining 20 days as the testing data. In the training\ndata, we select 80% of the training data to train our model\nand the remaining 20% for validation. We use the Min-Max\nnormalization to rescale the range of volume value in [0, 1],\nand recover the result for evaluation after forecasting. In\nour experiments, we exclude the results of those regions the\ninflow or outflow of which is less than 10 when evaluating\nthe model. It is a common practice used in industry and\nmany prior works [6], [7], [42].\n\n5.2 Performance Metrics and Baseline Methods\nWe use Root Mean Squared Errors (RMSE) and Mean Av-\nerage Percentage Error (MAPE) as the evaluation metrics,\nwhich are defined as follows:\n\nRMSE =\n\n\u221a\u2211N\ni=1(yi \u2212 y\u0302i)2\n\nN\n, (14)\n\nMAPE =\n1\n\nN\n\nN\u2211\ni=1\n\n|yi \u2212 y\u0302i|\nyi\n\n, (15)\n\nwhere yi and y\u0302i are the ground-truth and forecasting result\nof the i-th sample, and N is the total number of samples.\n\nWe compare our model with the following state-of-the-\nart approaches:\n\n\u2022 Historical average (HA): It uses the average of traffic at\nthe same time slots in historical data for prediction.\n\n\u2022 ARIMA: It is a conventional approach for time series\ndata forecasting.\n\n1. https://github.com/tangxianfeng/STDN/blob/master/data.zip\n\n\n\n8\n\nTABLE 1\nComparison with the state-of-the-art methods.\n\nDataset Method\nInflow Outflow\n\nRMSE MAPE RMSE MAPE\n\nNYC-Taxi\n\nHA 33.83 21.14% 43.82 23.18%\nARIMA 27.25 20.91% 36.53 22.21%\nRidge 24.38 20.07% 28.51 19.94%\n\nXGBoost 21.72 18.70% 26.07 19.35%\nMLP 22.08\u00b10.50 18.31\u00b10.83% 26.67\u00b10.56 18.43\u00b10.62%\n\nConvLSTM 23.67\u00b10.20 20.70\u00b10.20% 28.13\u00b10.25 20.50\u00b10.10%\nST-ResNet 21.63\u00b10.25 21.09\u00b10.51% 26.23\u00b10.33 21.13\u00b10.63%\n\nSTDN 19.05\u00b10.31 16.25\u00b10.26% 24.10\u00b10.25 16.30\u00b10.23%\nASTGCN 22.05\u00b10.37 20.25\u00b10.26% 26.10\u00b10.25 20.30\u00b10.31%\nSTGODE 21.46\u00b10.42 19.22\u00b10.36% 27.24\u00b10.46 19.30\u00b10.34%\nSTSAN 23.07\u00b10.64 22.24\u00b11.91% 27.83\u00b10.30 25.90\u00b11.67%\nDSAN 18.32\u00b10.39 16.07\u00b10.31% 24.27\u00b10.30 17.70\u00b10.35%\nST-TIS 17.73\u00b10.23 14.65\u00b10.32% 21.96\u00b10.13 14.83\u00b10.76%\n\nNYC-Bike\n\nHA 11.93 27.06% 12.49 27.82%\nARIMA 11.25 25.79% 11.53 26.35%\nRidge 10.33 24.58% 10.92 25.29%\n\nXGBoost 8.94 22.54% 9.57 23.52%\nMLP 9.12\u00b10.24 22.40\u00b10.40% 9.83\u00b10.19 23.12\u00b10.24%\n\nConvLSTM 9.22\u00b10.19 23.20\u00b10.47% 10.40\u00b10.17 25.10\u00b10.45%\nST-ResNet 8.85\u00b10.13 22.98\u00b10.53% 9.80\u00b10.12 25.06\u00b10.36%\n\nSTDN 8.15\u00b10.15 20.87\u00b10.39% 8.85\u00b10.11 21.84\u00b10.36%\nASTGCN 9.05\u00b10.31 22.25\u00b10.36% 9.34\u00b10.24 23.13\u00b10.30%\nSTGODE 8.58\u00b10.38 23.33\u00b10.26% 9.23\u00b10.31 23.99\u00b10.23%\nSTSAN 8.20\u00b10.45 20.42\u00b11.33% 9.87\u00b10.23 23.87\u00b10.71%\nDSAN 7.97\u00b10.25 20.23\u00b10.18% 10.07\u00b10.58 23.92\u00b10.39%\nST-TIS 7.57\u00b10.04 18.64\u00b10.23% 7.73\u00b10.10 18.58\u00b10.19%\n\n\u2022 Ridge Regression: A regression approach for time se-\nries data forecasting.\n\n\u2022 XGBoost [46]: A powerful approach for building su-\npervised regression models.\n\n\u2022 Multi-Layer Perceptron (MLP): A three-layer fully-\nconnected neural network.\n\n\u2022 Convolutional LSTM (ConvLSTM) [47]: It is a special\nrecurrent neural network with a convolution struc-\nture for spatial-temporal prediction.\n\n\u2022 ST-ResNet [5]: It uses multiple convolutional net-\nworks with residual structures to capture spatial cor-\nrelations from different temporal periods for traffic\nforecasting. It also considers external data such as\nweather, holiday events, and metadata.\n\n\u2022 STDN [7]: It considers the dynamic spatial correla-\ntion and temporal shifted problem using the com-\nbination of CNN and LSTM. External data such as\nweather and event are considered in the work.\n\n\u2022 ASTGCN [48]: It is an attention-based spatial-\ntemporal graph convolutional network (ASTGCN)\nmodel to solve traffic flow forecasting problem.\n\n\u2022 STGODE [31]: It uses a spatial-temporal graph ordi-\nnary differential equation network to predict traffic\nflow based on two predefine graph, namely a spatial\ngraph in terms of distance, and a semantic graph in\nterms of flow similarity.\n\n\u2022 STSAN [12]: It uses CNN to capture spatial infor-\nmation and the canonical Transformer to consider\nthe temporal dependencies over time. In particular,\ntransition data between regions are used to indicate\nthe correlation between regions.\n\n\u2022 DSAN [13]: It uses the canonical Transformer to\ncapture the spatial-temporal correlations for spatial-\ntemporal prediction, in which transition data be-\n\ntween regions are used for correlation modeling.\n\nWe use the identical datasets and data process approach\nas the work STDN [7], and use the results of the work [7] as\nthe benchmark for discussion. The experiment results of (1)\n\u223c (8) in Table 1 are reported in the work [7]. The evaluation\nof ASTGCN, STGODE, STSAN, and DSAN is based on the\ncode from their authors\u2019 GitHubs.\n\nWe implement our model using PyTorch. Data and code\ncan be found in https://github.com/GuanyaoLI/ST-TIS.\nWe use the following data as the model input since they\nachieve the best performance on the validation datasets:\ndata in the recent past 3 hours (i.e., h = 6 as the slot duration\nis 30 minutes); the same time slot in the recent past 10\ndays (i.e., l = 10). The other default hyperparameter settings\nare as follows. The default length w of the surrounding\nobservations is 6 (i.e. 3 hours), the number of convolution\nkernels F is 4, and the dimension d is set as 8. The number\nof k for DLI in Figure 5 is set as 3, and the number of heads\nis set as 6 for the two modules. Furthermore, the dropout\nrate is set as 0.1, the learning rate is set as 0.001, and the\nbatch size is set to be 32. Adam optimizer is used for model\ntraining. We trained our model on a machine with a NVIDIA\nRTX2080 Ti GPU.\n\n5.3 Prediction Accuracy\nWe compared the accuracy of ST-TIS with the state-of-the-\nart methods using the metrics RMSE and MAPE. The results\nfor the two datasets are presented in Table 1. Each approach\nwas run 10 times, and the mean and standard deviation are\nreported. As shown in the table, ST-TIS significantly outper-\nforms all other approaches on both metrics and datasets.\n\nSpecifically, the performance of the conventional time\nseries forecasting approaches (HA and ARIMA) is poor for\n\n\n\n9\n\nTABLE 2\nComparison of training time.\n\nDataset Method\nAverage time\nper epoch (s) Total time (s)\n\nNYC-Taxi\n\nST-ResNet 7.31 3077.51\nSTDN 445.47 34746.66\n\nASTGCN 25.31 6272.88\nSTGODE 18.53 3423.48\nSTSAN 426.75 33769.32\nDSAN 386.17 29390.75\nST-TIS 10.21 1231.5\n\nNYC-Bike\n\nST-ResNet 7.25 2921.75\nSTDN 480.21 23066.43\n\nASTGCN 25.68 5084.64\nSTGODE 18.76 3752.89\nSTSAN 426.28 31216.28\nDSAN 434.03 26476.20\nST-TIS 10.37 1556.8\n\nboth datasets because these approaches do not consider\nthe spatial dependency. Conventional machine learning\napproaches (Ridge, XGBoost, and MLP), which consider\nspatial dependency as features, have better performance\nthan HA and ARIMA. However, they fail to consider the\njoint spatial-temporal dependencies between regions. Most\ndeep learning-based models have further improvements\nthan conventional works, illustrating the ability of deep\nneural networks to capture the complicated spatial and\ntemporal dependency. ST-TIS is substantially more accurate\nthan state-of-the-art approaches (i.e., ConvLSTM, STResNet,\nSTDN, ASTGCN and STGODE). For example, it has an\naverage improvement of 9.5% on RMSE and 12.4% on\nMAPE compared to STDN and DSAN. The reasons for\nthe improvements are that it can capture the correlations\nbetween both nearby and distant regions, and it considers\nthe spatial and temporal dependency in a joint manner.\nWe find that the improvement is more significant on the\nNYC-Taxi dataset than on the NYC-Bike dataset. The reason\ncould be that people prefer using taxis instead of bikes for\nlong-distance travel, and so the correlations with distant\nregions are more important for the prediction task on the\ntaxi dataset. The significant improvement demonstrates that\nST-TIS has a better ability to capture the correlations for\ndistant regions than the other approaches which have the\nspatial locality assumption. ST-TIS also outperforms other\nTransformer-based approaches (such as STSAN and DSAN).\nThe reason is that with the information fusion and region\nsampling strategies in ST-TIS, the long-tail issue of the\ncanonical Transformer is addressed and the joint spatial-\ntemporal correlations are considered. The significant im-\nprovements demonstrate the effectiveness of our proposed\nmodel.\n\n5.4 Training Efficiency\n\nTraining and deploying large deep learning models is costly.\nFor example, the cost of trying combinations of different\nhyper-parameters for a large model is computationally ex-\npensive and it highly relies on training resources [3]. Thus,\nwe compare the training efficiency of ST-TIS with some\nstate-of-the-art deep learning based approaches (i.e., ST-\nResNet, STDN, ASTGCN, STGODE, STSAN, and DSAN) in\nterms of training time and number of learnable parameters.\n\nTABLE 3\nComparison of the number of parameters.\n\nMethod Number of parameters\nST-ResNet 4,917,041\n\nSTDN 9,446,274\nASTGCN 450,031\nSTGODE 433,073\n\nDSAN 1,621,634\nSTSAN 34,327,298\nST-TIS 139,506\n\n 16\n\n 18\n\n 20\n\n 22\n\n 24\n\n 26\n\nInflow Outflow\n\nR\nM\n\nS\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n18%\n\n19%\n\nInflow Outflow\n\nM\nA\n\nP\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(b) MAPE.\n\nFig. 6. Performance of variants on the NYC-Taxi dataset.\n\nThe results of the average training time per epoch and\nthe total training time are presented in Table 2. ST-ResNet\nachieves the least training time among all comparison ap-\nproaches because it solely employs simple CNN and does\nnot rely on RNN for temporal dependency learning. The\naverage time per epoch of ST-TIS is close to ST-ResNet. In\naddition, ST-TIS is trained significantly faster than other\napproaches (with a reduction of 46% \u223c 95%). STDN uses\nLSTM to capture temporal correlation, which is in general\nmore difficult to be trained in parallel. STSAN and DSAN\nalso employ Transformer with self-attention for spatial and\ntemporal correlation learning, but our proposed approach is\nsignificantly efficient than them, illustrating the efficiency of\nthe proposed region graph for model training.\n\nFurthermore, we also compare the number of learnable\nparameters of each model in Table 3. More parameters may\nlead to difficulties in model training, and it requires more\nmemory and training resources. Compared with other state-\nof-the-art approaches, ST-TIS is much more lightweight\nwith fewer parameters for training (with a reduction of\n23% \u223c 98%). The comparison results in Tables 1, 2 and 3\ndemonstrate that our proposed ST-TIS is faster and more\nlightweight than other deep learning based baseline ap-\nproaches, while achieving even better prediction accuracy.\n\n5.5 Design Variations of ST-TIS\nWe compare ST-TIS with its variants to evaluate the effec-\ntiveness of the proposed modules. The following variants\nare discussed:\n\n\u2022 NoIFM: We remove the information fusion module\nfrom ST-TIS. Only the surrounding observation of a\ntime slot is used as the input of the model instead of\nthe fusion result.\n\n\u2022 NoRSM: We remove the region sampling module\nfrom ST-TIS. The canonical Transformer is used to\ncapture the dependencies between regions without\nregion sampling.\n\n\n\n10\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 9.5\n\nInflow Outflow\n\nR\nM\n\nS\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(a) RMSE.\n\n17%\n\n18%\n\n19%\n\n20%\n\n21%\n\n22%\n\n23%\n\n24%\n\n25%\n\nInflow Outflow\n\nM\nA\n\nP\nE\n\n NoIFM\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(b) MAPE.\n\nFig. 7. Performance of variants on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 25\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nw\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nw\n\n inflow\n\n outflow\n\n(b) MAPE.\n\nFig. 8. Impact of surrounding observations on the NYC-Taxi dataset.\n\n\u2022 NoDLM: We remove the module of dependency\nlearning over multiple time slots, and only use Rti\nas the input of the prediction network for prediction.\n\nThe RMSE and MAPE on the NYC-Taxi dataset are\npresented in Figures 6(a) and 6(b), respectively. After tak-\ning the information fusion module away, the performance\ndegrades significantly. The reason is that the information\nfusion module plays a fundermental role in jointly con-\nsidering the spatial-temporal dependency. Without such\nmodule, our approach would degenerate to consider the\nspatial and temporal dependency in a decouple manner.\nThe experimental results demonstrate the importance of\nconsidering spatial-temporal dependency jointly and the\neffective of the proposed information fusion module. More-\nover, without the region sampling module, our approach\nstill achieve a good prediction performance because the\ncanonical Transformer is good at capturing dependencies\nbetween regions. The performance is further improved with\nthe region sampling since it could address the long-tail issue\nof the canonical Transformer for embedding aggregation.\nFurthermore, the RMSE and MAPE increase when the peri-\nodical characteristic of spatial-temporal dependency is not\nconsidered (i.e., NoDLM), which indicates the necessity of\nconsidering the period of spatial-temporal dependency and\ndemonstrates the effectiveness and rationality of our model\ndesign. Similar and consistent findings can be observed on\nthe NYC-Bike dataset in Figures 7(a) and 7(b).\n\n5.6 Surrounding Observations\nRecall that the dependency between two regions may have\ntemporal lagging due to the travel time between them. To\ncapture such lagging dependency, ST-TIS uses the surround-\ning observations to learn the region correlations for each\ntime slot, which contains the inflow and outflow in the\nprevious w time slots. We thus evaluate the impact of w\non the performance of our model.\n\n 7\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nw\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n19%\n\n20%\n\n20%\n\n20%\n\n21%\n\n22%\n\n22%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nw\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 9. Impact of surrounding observations on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 1  2  3  4  5  6\n\nR\nM\n\nS\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n 1  2  3  4  5  6\n\nM\nA\n\nP\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 10. Impact of layer number on the NYC-Taxi dataset.\n\nFigures 8(a) and 8(b) show the RMSE and MAPE versus\ndifferent lengths on the NYC-Taxi dataset. A larger length\nw indicates that more information is encoded from the sur-\nrounding observations. When w = 1, only the observation\nat a time slot is used for dependency learning, and the\nmodel fails to capture the lagging characteristic of depen-\ndency. As the length increases, the RMSE and MAPE of\nboth inflow and outflow forecasting decrease (w \u2264 5). The\nperformance improvement demonstrates the importance of\nusing the surrounding observations to learn the dependen-\ncies between regions. RMSE and MAPE increase slightly\nbut remain stable when the length is large (w \u2265 5). The\npotential reason is that, when w is larger than the travel time\nbetween regions, increasing w would not introduce more\ninformation for dependency learning. On the other hand, a\nlarger w may introduce some noise and more parameters for\nthe model, leading to difficulties in model training [13]. The\nRMSE and MAPE versus different lengths of surrounding\nobservations on the NYC-Bike dataset are shown in Figures\n9(a) and 9(b), which are consistent with the results for the\nNYC-Taxi dataset. When the length is small (w \u2264 4), RMSE\nand MAPE decrease as the length becomes larger, but they\nslightly increase when the length is large (w \u2265 4).\n\n5.7 Layer Number\n\nIn ST-TIS, DLI is stacked \u03b1 times to ensure the informa-\ntion propagtion between regions and improve the model\nrobustness. We evaluate the effect of \u03b1 on the prediction\nperformance using RMSE and MAPE. The results for the taxi\ndataset are presented in Figure 10. When \u03b1 = 1, only the\ndependencies on one\u2019s neighbouring regions in the graph\nare considering, resulting in the worst prediction accuracy.\nWhen \u03b1 \u2265 2, the dependencies on all other regions could be\ncaptured. We find that with the layer number \u03b1 increases,\nthe RMSE and the MAPE declines for both inflow and out-\nflow, indicating the performance improvement. However,\n\n\n\n11\n\n 7\n\n 7.5\n\n 8\n\n 8.5\n\n 1  2  3  4  5  6\n\nR\nM\n\nS\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n18%\n\n19%\n\n20%\n\n21%\n\n 1  2  3  4  5  6\n\nM\nA\n\nP\nE\n\n\u03b1\n\n inflow\n\n outflow\n\n(b) MAPE.\n\nFig. 11. Impact of layer number on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 25\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nM\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n18%\n\n19%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nM\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 12. Impact of head number on the NYC-Taxi dataset.\n\nwe find that when the layer number is too large (\u03b1 > 5\nin our experiments), the performance on RMSE and MAPE\ndegrades, because too many layers may result in difficulties\nof model training. Similar results are observed on the bike\ndataset (Figure 11).\n\n5.8 Head Number\n\nWe use the multi-head attention mechanism in ST-TIS for\ndependency learning, so that different heads could capture\ndifferent patterns from the historical data. In our experi-\nments, we evaluate the impact of the head number M on\nthe prediction performance. The results of RMSE and MAPE\nversus the head number M on the taxi and bike datasets are\npresented in Figures 12 and 13, respectively. As shown in\nFigures 12(a) and 13(a), with the head number increases,\nthe RMSE on the two datasets declines, demonstrating\nthe multi-head mechanism could benefit the dependency\nlearning and improve the prediction accuracy. We also ob-\nserve that when the head number become larger (M > 4\non the taxi dataset while M > 6 on the bike dataset),\nthe improvements are not significant. The reason could\nbe that some heads may focus on the same pattern when\nthere are many heads. In terms of MAPE, similar findings\ncould be observed in Figures 12(b) and 13(b). Moreover, the\nMAPE increases slightly when the head number becomes\nlarge (M > 6). It is because increasing the head number\nleads to more learnable parameters, which would result in\ndifficulties for model training.\n\n6 CONCLUSION\nWe propose ST-TIS, a novel, small (in parameters), com-\nputationally efficient and highly accurate model for traffic\nforecasting. ST-TIS employs a spatial-temporal Transformer\nwith information fusion and region sampling to jointly\nconsider the dynamic spatial and temporal dependencies\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nM\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n18%\n\n19%\n\n20%\n\n21%\n\n22%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nM\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 13. Impact of head number on the NYC-Bike dataset.\n\nbetween regions at any individual time slots, and also the\npossibly periodic spatial-temporal dependency from multi-\nple time slots. In particular, ST-TIS boosts the efficiency and\naddresses the long-tail issue of the canonical Transformer\nusing a novel region sampling strategy, which reduces the\ncomplexity from O(n2) to O(n\n\n\u221a\nn), where n is the number\n\nof regions. We have conducted extensive experiments to\nevaluate ST-TIS, using a taxi and a bike sharing datasets.\nOur experimental results show that ST-TIS significantly out-\nperforms the state-of-the-art approaches in terms of training\nefficiency (with a reduction of 46% \u223c 95% on training time\nand 23% \u223c 98% on network parameters), and hence is\nefficient in tuning, training and memory. Despite its small\nsize and fast training, it achieves higher accuracy in its\nonline predictions than other state-of-the-art works (with\nimprovement of up to 9.5% on RMSE, and 12.4% on MAPE).\n\nREFERENCES\n[1] Y. Zheng, L. Capra, O. Wolfson, and H. Yang, \u201cUrban computing:\n\nconcepts, methodologies, and applications,\u201d ACM Transactions on\nIntelligent Systems and Technology (TIST), vol. 5, no. 3, pp. 1\u201355,\n2014.\n\n[2] W. Jiang and J. Luo, \u201cGraph neural network for traffic forecasting:\nA survey,\u201d arXiv preprint arXiv:2101.11174, 2021.\n\n[3] G. Menghani, \u201cEfficient deep learning: A survey on making\ndeep learning models smaller, faster, and better,\u201d arXiv preprint\narXiv:2106.08962, 2021.\n\n[4] J. Zhang, Y. Zheng, D. Qi, R. Li, and X. Yi, \u201cDnn-based prediction\nmodel for spatio-temporal data,\u201d in Proceedings of the 24th ACM\nSIGSPATIAL International Conference on Advances in Geographic\nInformation Systems. California, USA: ACM, 2016, pp. 1\u20134.\n\n[5] J. Zhang, Y. Zheng, and D. Qi, \u201cDeep spatio-temporal residual\nnetworks for citywide crowd flows prediction,\u201d in Thirty-First\nAAAI Conference on Artificial Intelligence. California USA: AAAI,\n2017, pp. 1655 \u2013 1661.\n\n[6] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye,\nand Z. Li, \u201cDeep multi-view spatial-temporal network for taxi\ndemand prediction,\u201d in Thirty-Second AAAI Conference on Artificial\nIntelligence. Louisiana, USA: AAAI, 2018, pp. 2588 \u2013 2595.\n\n[7] H. Yao, X. Tang, H. Wei, G. Zheng, and Z. Li, \u201cRevisiting spatial-\ntemporal similarity: A deep learning framework for traffic predic-\ntion,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence,\nvol. 33. New York, USA: AAAI, 2019, pp. 5668\u20135675.\n\n[8] B. Yu, H. Yin, and Z. Zhu, \u201cSpatio-temporal graph convolutional\nnetworks: a deep learning framework for traffic forecasting,\u201d in\nProceedings of the 27th International Joint Conference on Artificial\nIntelligence. Stockholm, Sweden: IJCAI, 2018, pp. 3634\u20133640.\n\n[9] X. Geng, Y. Li, L. Wang, L. Zhang, Q. Yang, J. Ye, and Y. Liu,\n\u201cSpatiotemporal multi-graph convolution network for ride-hailing\ndemand forecasting,\u201d in Proceedings of the AAAI Conference on\nArtificial Intelligence, vol. 33. Hawaii, USA: AAAI, 2019, pp. 3656\u2013\n3663.\n\n[10] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d\nin Advances in neural information processing systems. Long Beach,\nCA, USA: ACM, 2017, pp. 5998\u20136008.\n\n\n\n12\n\n[11] Y. Zhou, J. Li, H. Chen, Y. Wu, J. Wu, and L. Chen, \u201cA spatiotem-\nporal attention mechanism-based model for multi-step citywide\npassenger demand prediction,\u201d Information Sciences, vol. 513, pp.\n372\u2013385, 2020.\n\n[12] H. Lin, W. Jia, Y. You, and Y. Sun, \u201cInterpretable crowd flow\nprediction with spatial-temporal self-attention,\u201d arXiv preprint\narXiv:2002.09693, vol. [cs.LG], 2020.\n\n[13] H. Lin, R. Bai, W. Jia, X. Yang, and Y. You, \u201cPreserving dynamic\nattention for long-term spatial-temporal prediction,\u201d in Proceedings\nof the 26th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining. Virtual Conference: ACM, 2020, pp.\n36\u201346.\n\n[14] M. Xu, W. Dai, C. Liu, X. Gao, W. Lin, G.-J. Qi, and H. Xiong,\n\u201cSpatial-temporal transformer networks for traffic flow forecast-\ning,\u201d arXiv preprint arXiv:2001.02908, 2020.\n\n[15] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and\nW. Zhang, \u201cInformer: Beyond efficient transformer for long se-\nquence time-series forecasting,\u201d in Proceedings of AAAI, 2021.\n\n[16] S. Shekhar and B. M. Williams, \u201cAdaptive seasonal time series\nmodels for forecasting short-term traffic flow,\u201d Transportation Re-\nsearch Record, vol. 2024, no. 1, pp. 116\u2013125, 2007.\n\n[17] B. Pan, U. Demiryurek, and C. Shahabi, \u201cUtilizing real-world\ntransportation data for accurate traffic prediction,\u201d in 2012 IEEE\n12th International Conference on Data Mining. Brussels, Belgium:\nIEEE, 2012, pp. 595\u2013604.\n\n[18] L. Moreira-Matias, J. Gama, M. Ferreira, J. Mendes-Moreira, and\nL. Damas, \u201cPredicting taxi\u2013passenger demand using stream-\ning data,\u201d IEEE Transactions on Intelligent Transportation Systems,\nvol. 14, no. 3, pp. 1393\u20131402, 2013.\n\n[19] A. Abadi, T. Rajabioun, and P. A. Ioannou, \u201cTraffic flow prediction\nfor road transportation networks with limited traffic data,\u201d IEEE\ntransactions on intelligent transportation systems, vol. 16, no. 2, pp.\n653\u2013662, 2014.\n\n[20] B. L. Smith, B. M. Williams, and R. K. Oswald, \u201cComparison of\nparametric and nonparametric models for traffic flow forecasting,\u201d\nTransportation Research Part C: Emerging Technologies, vol. 10, no. 4,\npp. 303\u2013321, 2002.\n\n[21] R. Silva, S. M. Kang, and E. M. Airoldi, \u201cPredicting traffic volumes\nand estimating the effects of shocks in massive transportation\nsystems,\u201d Proceedings of the National Academy of Sciences, vol. 112,\nno. 18, pp. 5643\u20135648, 2015.\n\n[22] Y. Zhang and Y. Xie, \u201cForecasting of short-term freeway volume\nwith v-support vector machines,\u201d Transportation Research Record,\nvol. 2024, no. 1, pp. 92\u201399, 2007.\n\n[23] Y. Li, Y. Zheng, H. Zhang, and L. Chen, \u201cTraffic prediction in a\nbike-sharing system,\u201d in Proceedings of the 23rd SIGSPATIAL Inter-\nnational Conference on Advances in Geographic Information Systems.\nSeattle, Washington: ACM, 2015, pp. 1\u201310.\n\n[24] Y. Tong, Y. Chen, Z. Zhou, L. Chen, J. Wang, Q. Yang, J. Ye, and\nW. Lv, \u201cThe simpler the better: a unified approach to predicting\noriginal taxi demands based on large-scale online platforms,\u201d in\nProceedings of the 23rd ACM SIGKDD international conference on\nknowledge discovery and data mining. Halifax, NS, Canada: ACM,\n2017, pp. 1653\u20131662.\n\n[25] T. Li, J. Zhang, K. Bao, Y. Liang, Y. Li, and Y. Zheng, \u201cAutost: Ef-\nficient neural architecture search for spatio-temporal prediction,\u201d\nin Proceedings of the 26th ACM SIGKDD International Conference on\nKnowledge Discovery & Data Mining. Virtual Conference: ACM,\n2020, pp. 794\u2013802.\n\n[26] S. He and K. G. Shin, \u201cTowards fine-grained flow forecasting: A\ngraph attention approach for bike sharing systems,\u201d in Proceedings\nof The Web Conference 2020. Taiwan: ACM, 2020, pp. 88\u201398.\n\n[27] H. Yao, C. Zhang, Y. Wei, M. Jiang, S. Wang, J. Huang, N. V.\nChawla, and Z. Li, \u201cGraph few-shot learning via knowledge\ntransfer,\u201d in Thirty-Forth AAAI Conference on Artificial Intelligence.\nNew York, USA: AAAI, 2020, pp. 6656 \u2013 6663.\n\n[28] G. Li, M. Muller, A. Thabet, and B. Ghanem, \u201cDeepgcns: Can\ngcns go as deep as cnns?\u201d in Proceedings of the IEEE International\nConference on Computer Vision. Seoul, Korea: IEEE, 2019, pp. 9267\u2013\n9276.\n\n[29] Z. Pan, Y. Liang, W. Wang, Y. Yu, Y. Zheng, and J. Zhang, \u201cUrban\ntraffic prediction from spatio-temporal data using deep meta\nlearning,\u201d in Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining. Anchorage,\nAK, USA: ACM, 2019, pp. 1720\u20131730.\n\n[30] X. Wang, Y. Ma, Y. Wang, W. Jin, X. Wang, J. Tang, C. Jia, and\nJ. Yu, \u201cTraffic flow prediction via spatial temporal graph neural\n\nnetwork,\u201d in Proceedings of The Web Conference 2020. Taiwan:\nACM, 2020, pp. 1082\u20131092.\n\n[31] Z. Fang, Q. Long, G. Song, and K. Xie, \u201cSpatial-temporal graph\node networks for traffic flow forecasting,\u201d in Proceedings of the\n27th ACM International Conference on knowledge Discovery and Data\nMining. Singapore: ACM, 2021.\n\n[32] M. Li and Z. Zhu, \u201cSpatial-temporal fusion graph neural net-\nworks for traffic flow forecasting,\u201d in Proceedings of the 27th ACM\nInternational Conference on knowledge Discovery and Data Mining.\nSingapore: ACM, 2021.\n\n[33] C. Song, Y. Lin, S. Guo, and H. Wan, \u201cSpatial-temporal syn-\nchronous graph convolutional networks: A new framework for\nspatial-temporal network data forecasting,\u201d in Proceedings of the\nAAAI Conference on Artificial Intelligence, vol. 34, no. 01, 2020, pp.\n914\u2013921.\n\n[34] H. Shi, Q. Yao, Q. Guo, Y. Li, L. Zhang, J. Ye, Y. Li, and Y. Liu,\n\u201cPredicting origin-destination flow via multi-perspective graph\nconvolutional network,\u201d in 2020 IEEE 36th International Conference\non Data Engineering (ICDE). IEEE, 2020, pp. 1818\u20131821.\n\n[35] H. Yuan, G. Li, Z. Bao, and L. Feng, \u201cAn effective joint prediction\nmodel for travel demands and traffic flows,\u201d in 2021 IEEE 37th\nInternational Conference on Data Engineering (ICDE). IEEE, 2021,\npp. 348\u2013359.\n\n[36] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d\nNeural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n\n[37] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, \u201cEmpirical evalua-\ntion of gated recurrent neural networks on sequence modeling,\u201d\narXiv preprint arXiv:1412.3555, 2014.\n\n[38] Y. Li, R. Yu, C. Shahabi, and Y. Liu, \u201cDiffusion convolutional\nrecurrent neural network: Data-driven traffic forecasting,\u201d in In-\nternational Conference on Learning Representations. Vancouver, BC,\nCanada: ICLR, 2018, pp. 1 \u2013 16.\n\n[39] K. Cho, B. van Merrie\u0308nboer, D. Bahdanau, and Y. Bengio, \u201cOn\nthe properties of neural machine translation: Encoder\u2013decoder\napproaches,\u201d in Proceedings of SSST-8, Eighth Workshop on Syntax,\nSemantics and Structure in Statistical Translation. Doha, Qatar:\nAssociation for Computational Linguistics, Oct. 2014, pp. 103\u2013111.\n[Online]. Available: https://www.aclweb.org/anthology/W14-\n4012\n\n[40] D. Bahdanau, K. Cho, and Y. Bengio, \u201cNeural machine translation\nby jointly learning to align and translate,\u201d in 3rd International\nConference on Learning Representations. San Diego, CA, USA: ICLR,\n2015, pp. 7 \u2013 9.\n\n[41] Y. Liang, S. Ke, J. Zhang, X. Yi, and Y. Zheng, \u201cGeoman: Multi-\nlevel attention networks for geo-sensory time series prediction.\u201d\nin Proceedings of the 27th International Joint Conference on Artificial\nIntelligence. Stockholm, Sweden: IJCAI, 2018, pp. 3428\u20133434.\n\n[42] Y. Li and J. M. Moura, \u201cForecaster: A graph transformer for fore-\ncasting spatial and time-dependent data,\u201d in European Conference\non Artificial Intelligence (ECAI). Pitesti, Arges, Romania: EurAI,\n2020, p. 274.\n\n[43] S. Li, X. Jin, Y. Xuan, X. Zhou, W. Chen, Y.-X. Wang, and X. Yan,\n\u201cEnhancing the locality and breaking the memory bottleneck of\ntransformer on time series forecasting,\u201d Advances in Neural Infor-\nmation Processing Systems, vol. 32, pp. 5243\u20135253, 2019.\n\n[44] N. Kitaev, L. Kaiser, and A. Levskaya, \u201cReformer: The efficient\ntransformer,\u201d in International Conference on Learning Representations,\n2019.\n\n[45] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, \u201cA\ncomprehensive survey on graph neural networks,\u201d IEEE transac-\ntions on neural networks and learning systems, vol. 32, no. 1, pp. 4\u201324,\n2020.\n\n[46] T. Chen and C. Guestrin, \u201cXgboost: A scalable tree boosting\nsystem,\u201d in Proceedings of the 22nd acm sigkdd international conference\non knowledge discovery and data mining. San Francisco: ACM, 2016,\npp. 785\u2013794.\n\n[47] S. Xingjian, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c.\nWoo, \u201cConvolutional lstm network: A machine learning approach\nfor precipitation nowcasting,\u201d in Advances in neural information\nprocessing systems. Montreal, Quebec, Canada: ACM, 2015, pp.\n802\u2013810.\n\n[48] S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan, \u201cAttention based\nspatial-temporal graph convolutional networks for traffic flow\nforecasting,\u201d in Proceedings of the AAAI Conference on Artificial\nIntelligence, vol. 33, no. 01, 2019, pp. 922\u2013929.\n\n\n"}
{"Title": "Improving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI", "Authors": "Erico Tjoa, Hong Jing Khok, Tushar Chouhan, Guan Cuntai", "Abstract": "  This paper quantifies the quality of heatmap-based eXplainable AI methods w.r.t image classification problem. Here, a heatmap is considered desirable if it improves the probability of predicting the correct classes. Different XAI heatmap-based methods are empirically shown to improve classification confidence to different extents depending on the datasets, e.g. Saliency works best on ImageNet and Deconvolution on ChestX-Ray Pneumonia dataset. The novelty includes a new gap distribution that shows a stark difference between correct and wrong predictions. Finally, the generative augmentative explanation is introduced, a method to generate heatmaps maps capable of improving predictive confidence to a high level.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00009", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Deep Neural Network Classification Confidence using\nHeatmap-based eXplainable AI\n\nErico Tjoa 1 2 Hong Jing Khok 1 Tushar Chouhan 1 Guan Cuntai 1\n\nAbstract\nThis paper quantifies the quality of heatmap-based\neXplainable AI methods w.r.t image classification\nproblem. Here, a heatmap is considered desir-\nable if it improves the probability of predicting\nthe correct classes. Different XAI heatmap-based\nmethods are empirically shown to improve classi-\nfication confidence to different extents depending\non the datasets, e.g. Saliency works best on Ima-\ngeNet and Deconvolution on Chest X-Ray Pneu-\nmonia dataset. The novelty includes a new gap\ndistribution that shows a stark difference between\ncorrect and wrong predictions. Finally, the gen-\nerative augmentative explanation is introduced,\na method to generate heatmaps maps capable of\nimproving predictive confidence to a high level.\n\n1. Introduction\nArtificial intelligence (AI) and machine learning (ML) mod-\nels have been developed with various levels of transparency\nand interpretability. Recent issues related to the responsible\nusage of AI have been highlighted by large companies like\nGoogle (Lakshmanan, 2021) and Meta (Pesenti, 2021); this\nmay reflect the increasing demand for transparency and in-\nterpretability, hence the demand for eXplainable Artificial\nIntelligence (XAI). In particular, the blackbox nature of a\ndeep neural network (DNN) is a well-known problem in\nXAI. Many attempts to tackle the problem can be found in\nsurveys like (Adadi & Berrada, 2018; Dos\u030cilovic\u0301 et al., 2018;\nGilpin et al., 2018; Tjoa & Guan, 2020a).\n\nPopular XAI methods include post-hoc methods such as\nLocal Interpretable Model-agnostic Explanations (LIME)\n(Ribeiro et al., 2016) and SHapley Additive exPlanations\n(SHAP) that uses a game-theoretical concept (Lundberg &\n\n*Equal contribution 1Nanyang Technological University, Sin-\ngapore 2Alibaba Inc. Correspondence to: Erico Tjoa <eri-\ncotjoa@gmail.com>.\n\nPaper is under review. This format is borrowed from Proceedings\nof the 39 th International Conference on Machine Learning, Balti-\nmore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the\nauthor(s).\n\nLee, 2017). Many heatmap-generating XAI methods have\nalso been developed for DNN, in particular Class Activation\nMappings (CAM) (Zhou et al., 2016; Selvaraju et al., 2016),\nLayerwise Relevance Propagation (LRP) (Bach et al., 2015)\nand many other well-known methods, as listed in afore-\nmentioned surveys papers. These methods are appealing\nbecause heatmap-like attributions are intuitive and easy to\nunderstand. Although there are other remarkable ways to\ninvestigate interpretability and explainability e.g. methods\nthat directly attempt to visualize the inner working of a DNN\n(Zeiler & Fergus, 2014; Olah et al., 2017; 2020), we do not\ncover them here. This paper focuses on heatmap-based\nmethods.\n\nQuantifying the quality of heatmap-based XAI meth-\nods. Several existing efforts have also been dedicated to\nquantitatively measure the quality of heatmaps and other ex-\nplanations. For example, heatmaps have been measured by\ntheir potentials to improve object localization performance\n(Zhou et al., 2016; Selvaraju et al., 2016). The pointing\ngame (Fong & Vedaldi, 2017; Rebuffi et al., 2020) is an-\nother example where localization concept is used to quan-\ntify XAI\u2019s performance. The \u201cmost relevant first\u201d (MORF)\nframework has also been introduced to quantify the explain-\nability of heatmaps by ordered removal of pixels based on\ntheir importance (Samek et al., 2017); the MORF paper\nalso emphasizes that there is a difference between compu-\ntational relevance and human relevance i.e. objects which\nalgorithms find salient may not be necessarily salient for a\nhuman observer. Others can be found e.g. in (Tjoa & Guan,\n2020b). This paper quantifies the quality of a heatmap\nbased on how much the heatmap improves classification\nconfidence.\n\nUsing heatmaps to improve the classification confidence\nof DNN. Heatmaps have been said to not \u201c[tell] us anything\nexcept where the network is looking at\u201d (Rudin, 2019). In\nthis work, we would like to refute such claims and show\nthat heatmaps can be computationally useful. To test the\nusefulness of heatmaps in a direct way, we perform the Aug-\nmentative eXplanation (AX) process: combine an image x\nwith its heatmap h to obtain higher probability of predict-\ning the correct class, e.g. if f(x) gives a 60% probability\nof making a correct prediction, we consider using h such\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n9v\n2 \n\n [\ncs\n\n.L\nG\n\n] \n 8\n\n J\nan\n\n 2\n02\n\n2\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nthat f(x+ h) yields 65%. We empirically show that such\nimprovement is possible for existing XAI methods but it\ndoes not happen in general since heatmaps are usually not\ndesigned to explicitly improve prediction computationally.\nThis improvement is quantified through a metric we call the\nConfidence Optimization (CO) score. Briefly speaking, CO\nscore is a weighted difference between raw output values\nbefore and after heatmaps/attributions modify the images\nx+ h. The metric assigns a positive/negative score if x+ h\nincreases/decreases the probability of making the correct\nprediction.\n\nThis paper is arranged as the following. In the next sec-\ntion, AX and Generative AX (GAX) are demonstrated\nthrough a two-dimensional toy example. Explicit form\nof heatmaps/attribution values can be obtained in the toy\nexample, useful for lower level analysis and direct ob-\nservation. The following section describes dataset pre-\nprocessing, computation of CO scores for AX process\non existing XAI methods, formal definition GAX process\nand the results. We then present our results, starting with\nthe novel finding: distribution gap as correctness indica-\ntors, CO scores distribution for common XAI methods,\nfollowed by high scores attained by GAX heatmaps and\nfinally qualitative aspects of the methods. All codes are\navailable in https://github.com/ericotjo001/\nexplainable_ai/tree/master/gax.\n\n2. Formulation in Low Dimensional Space\n\nFigure 1. Solid red (blue) lines are x1(x2) components of sample\ndata x. Dotted red (blue) lines are h1(h2) components of heatmaps\nh with k\u03b7 = 1.2. Heatmap values or attribute importances are\nassigned large values when either (1) the true components a1, a2\ndiffer significantly (2) the W transforms the data heterogenously\ni.e. not \u03b8 \u2248 (2k + 1)\u03c0\n\n4\n. See interpretations in the main text for\n\nmore details.\n\nThe application presented in this paper is based on the fol-\nlowing concept. We illustrate the idea using binary clas-\nsification of data sample x \u2208 R2, a 2D toy example. Let\ny = W\u22121x where y \u2208 R2 and W \u2208 R2\u00d72 is invertible. Let\nthe true label/category of sample x be c = argmaxiyi so\nthat it is compatible with one-hot encoding usually used in\na DNN classification task. Conventions:\n\n1. Output space Y . Let the output variable be y =\na1\n(\n1\n0\n\n)\n+ a2\n\n(\n0\n1\n\n)\n, clearly an element of a vector space.\n\nThe shape of this vector is the same as the output\nshape of the last fully connected layer for the stan-\ndard binary classification. Class prediction can be per-\nformed in the winner-takes-all manner, for example, if\na1 = 1, a2 = 0, then the label is c = argmaxiyi = 1.\nIf a1 = 0.1, a2 = 0.5, then c = 2. Basis of Y is\nBY =\n\n{\ny(1) =\n\n(\n1\n0\n\n)\n, y(2) =\n\n(\n0\n1\n\n)}\n.\n\n2. Sample space X is a vector space with the correspond-\ning basis BX = {Wy : y \u2208 BY } = {x(1) =\nWy(1), x(2) = Wy(2)} so x = a1x(1) + a2x(2) \u2208 X .\n\n3. Pixelwise sample space is the same sample space, but\nwe specifically distinguish it as the sample space with\nthe canonical basis. We will need this later, because\npixelwise space has \u201chuman relevance\u201d, since human ob-\nservers perceive the components (pixels) directly, rather\nthan automatically knowing the underlying structure (i.e.\nwe cannot see a1, a2 directly). We denote a sample in\nthis basis with x = x1\n\n(\n1\n0\n\n)\n+ x2(\n\n0\n1 ).\n\n4. A heatmap or attribute vector h in this paper has the\nsame shape as x and can be operated directly with x\nvia component-wise addition. Thus, they also belong to\nsample space or the pixelwise sample space. Writing\na heatmap in the sample space h = Ax(1) + Bx(2) is\nuseful for obtaining a closed form expression later.\n\nThe perfect classifier, f . Define f(x,\u0398) = \u03c3(\u0398x) as\na trainable classifier with parameters \u0398 \u2208 R2\u00d72. Let\n\u0398 = W\u22121 and the activation \u03c3 be any strictly monotonic\nfunction, like the sigmoid function. Then, the classifier\nf(x) = \u03c3(W\u22121x) \u2208 R2 is perfect, in the sense that,\nif a1 > a2, then c = argmaxifi(x) = 1; likewise if\na1 < a2, then c = 2 and, for a1 = a2 either decision\nis equally probable. This is easily seen as the following:\nf(x) = \u03c3(W\u22121(a1x\n\n(1)+a2x\n(2))) = \u03c3(a1\n\n(\n1\n0\n\n)\n+a2\n\n(\n0\n1\n\n)\n) =(\n\n\u03c3(a1)\n\u03c3(a2)\n\n)\n.\n\nConfidence optimization score (CO score), sco. In this\nsection, we show a simple explicit form of CO score for\nbetter illustration; in the experimental method section, for-\nmal definition will be given. The score increases if x + h\nleads to an improvement in the probability of correctly pre-\ndicting label c, hence the score\u2019s definition depends on the\ngroundtruth label. Throughout this section, for illustration,\nwe use x = a1x(1) + a2x(2) with groundtruth label c = 1,\ni.e. a1 > a2. Define the CO score as\n\nsco(x, h) =\n(\n\n1\n\u22121\n)\n\u00b7\n[\nf(x+ h)\u2212 f(x)\n\n]\n(1)\n\nFor the perfect classifier, see that f1(x + h) > f1(x) and\nf2(x + h) < f2(x) contribute to a larger sco. In other\n\nhttps://github.com/ericotjo001/explainable_ai/tree/master/gax\nhttps://github.com/ericotjo001/explainable_ai/tree/master/gax\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nwords, increasing the probability of predicting the correct\nlabel c = 1 increases the score. For c = 2, replace\n\n(\n1\n\u22121\n)\n\nwith\n(\n\u22121\n1\n\n)\n.\n\nAugmentative explanation. AX is defined here as any\nmodification on x by h that is intended to yield positive\nthe CO score, i.e to increase the probability of making a\ncorrect classification. This paper mainly considers the sim-\nplest implementation, namely x+ h. Let us consider a few\npossibilities. Suppose \u03c3 = LeakyReLU and h = x. We\nget sco =\n\n(\n1\n\u22121\n)\n\u00b7\n(\n\u03c3(2a1)\u2212\u03c3(a1)\n\u03c3(2a2)\u2212\u03c3(a2)\n\n)\n= a1 \u2212 a2 > 0. In other\n\nwords, choosing the image as the heatmap itself improves\nthe score. However, as a heatmap or attribute vector, h is\nuseless, since it does not provide us with any information\nabout the relative importance of the components of x in\ncanonical basis, which is the part of data directly visible to\nthe observer. Even so, h = x has computational relevance\nto the model, since a1, a2 are modified in the correct direc-\ntion. Our aim is to find computationally relevant h that does\nnot score zero in \u201chuman relevance\u201d, figuratively speak-\ning. We therefore rule out obviously uninformative heatmap\nin the upcoming sections. Further, consider similar situa-\ntion but set \u03c3 to sigmoid function. Simply setting h = x\nwill no longer increase the score significantly all the time.\nSince sigmoid is asymptotic, when a1, a2 are sufficiently\nfar away from zero, the increase will be so negligible, the\nheatmap will be uninformative even though the magnitude\nof |a1 \u2212 a2| may be large. Hence, we use the raw DNN\noutput in our main experiment, without sigmoid, softmax\netc.\n\nGenerative Augmentative EXplanation (GAX) is an AX\nprocess where the heatmap h = w \u2217 x is generated by\ntuning the trainable parameter w so that sCO is optimized;\n\u2217 denotes component/pixel-wise multiplication. Here we\nwill define \u2206 = s1 as the term that we maximize by hand,\nfor clarity and illustration. By comparison, in the main\nexperiment, we directly perform gradient descent on \u2212s1\n(plus regularization terms) to generate GAX heatmaps, i.e.\nwe minimize a total loss. To start with GAX, recall our\nchoice of heatmap written in sample space basis,\n\nh = w \u2217 x = Ax(1) +Bx(2) (2)\n\nThis form is desirable as it can be manipulated more easily\nthan the pixelwise sample space form h = (w1x1w2x2 ), as the\nfollowing. From RHS of eq. (2), get AWy(1) +BWy(2) =\nW\n(\nA\nB\n\n)\n. We thus have ( AB ) = W\n\n\u22121(w \u2217 x). To increase\nCO score, the aim is to find parameter w that maximizes\nA\u2212B, i.e. find w\u2217 = argmaxw(A\u2212B). Expanding the\nterms in w \u2217x of eq. (2), we obtain (w1w2 ) \u2217\n\n(\na1W11+a2W12\na2W21+a2W22\n\n)\n.\n\nTaking the difference between the components gives us\n\n\u2206 \u2261A\u2212B\n=w1(W\n\n\u22121\n11 \u2212W\n\n\u22121\n21 )(a1W11 + a2W12)\n\n\u2212 w2(W\u2212122 \u2212W\n\u22121\n12 )(a1W21 + a2W22)\n\n(3)\n\nMaximizing \u2206 to a large \u2206 > 0 will clearly optimize\nsco(x, h) = \u03c3(a1)\u2212 \u03c3(a2) + \u03c3(A)\u2212 \u03c3(B), assuming \u03c3 is\nstrictly monotonously increasing.\n\nHeatmap obtained through optimization using gradient\nascent. Recall that gradient ascent is done by \u2206 \u2192\n\u2206 + dw \u00b7 \u2207w\u2206 with the choice dw = \u03b7\u2207w\u2206, hence\n\u2206 + \u03b7||\u2207w\u2206||2 \u2265 \u2206. Hence, the heatmap after k steps\nof optimization is given by\n\nh =(w + kdw) \u2217 x\n\n=\n[\nw + k\u03b7\n\n(\n(W\n\n\u22121\n11 \u2212W\n\n\u22121\n21 )(a1W11+a2W12)\n\n\u2212(W\u2212122 \u2212W\n\u22121\n12 )(a1W21+a2W22)\n\n)]\n\u2217 x\n\n(4)\n\nTo visualize the heatmap, here we use the example where\nW is the rotation matrix W =\n\n(\ncos\u03b8 \u2212sin\u03b8\nsin\u03b8 cos\u03b8\n\n)\n. Examples\n\nof heatmaps plotted along with the input x are shown in\nfig. 1, to be discussed in the next subsection. If \u03b8 = 0, x\nare identical to y, so binary classification is straightforward\nand requires no explanation. Otherwise, consider \u03b8 being\na small deviation from 0. Such slightly rotated system is a\ngood toy-example for the demonstration of component-wise\n\u201cimportance attribution\u201d. This is because if x belongs to\ncategory c = 1 with high a1 component, then it still has a\nmore significant first component x1 after the small rotation.\nThus, a heatmap that correspondingly gives a higher score to\nthe first component is \u201ccorrect\u201d in the sense that it matches\nthe intuition of attribute importance: high h1 emphasizes\nthe fact that high x1 literally causes high y1. Furthermore,\nif the system rotates by \u03c0/4, we see that the classification\nbecomes harder. This is because the components x1 and\nx2 start to look more similar because cos\n\n\u03c0\n4\n\n= sin\u03c0\n4\n\n, and\nconsequently, the attribution values will be less prominent\nas well.\n\n2.1. Interpretability\n\nDISCLAIMER: for the benefit of readers who are used to\nregard heatmaps as the explanation or a method to perform\nlocalization, we must emphasize that this paper does not\nappeal to that ideal. To reiterate, in this paper, heatmaps are\nthe maps of pixel intensity that computationally optimize\nthe classification confidence.\n\nHomogenous and Heterogenous transformations. For the\nlack of better words, we refer to transformations like \u03b8 \u2248\n\u03c0/4 or more generally (2k+ 1)\u03c0\n\n4\nfor k = ...,\u22121, 0, 1, ... as\n\nhomogenous transformations, since the components become\nmore indistinguishable (recall: cos\u03c0\n\n4\n= sin\u03c0\n\n4\n). Otherwise,\n\nthe transformation is called heterogenous. These defini-\ntions are given here with the intention of drawing parallels\nbetween (1) the toy data that have been homogenously trans-\nformed (hence hard to distinguish) and (2) samples in real\ndatasets that look similar to each other, but are categorized\ndifferently due to a small, not obvious difference.\n\nInterpretation of attribute values for distinct non-negative\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\ncomponents. In the pixelwise sample space, we will be more\ninterested in non-negative data sample x1, x2 \u2265 0 since we\nonly pass [0, 1]-normalized images for GAX. Fig. 1 left\nshows a data sample with distinct components, indicated\nby high a1 = 0.95 component and low a2. Non-negative\ndata samples are found around \u03b8 \u2208 [0, \u03c0/2]. High x1 value\nis given high h1 attribution score while low x2 is given a\nsuppressed value of h2 near \u03b8 = 0, matching our intuition as\ndesired. As rotation proceeds to \u03c0/4, there is a convergence\nbetween x1 and x2, making the components more indistin-\nguishable. At \u03b8 = \u03c0/4 exactly, we still see high h1 that\npicks up high signal due to high a1, also as desired. Between\n\u03c0/4 and \u03c0/2, rotation starts to flip the components; in fact,\nat \u03c0/2, x = [0, 1] is categorized as c = 1 and x = [1, 0] as\nc = 2. The attribution value h2 becomes more prominent,\nhighlighting x2, also as desired for our prediction of class\nc = 1. In fig. 1 middle, decreased/increased a1, a2 are\nassigned less prominent h1, h2 respectively than fig. 1 left,\nsince the model becomes less confident in its prediction,\nalso consistent with our intuition.\n\nThe other extreme. Fig. 1 right shows a1 and a2 that do\nnot differ significantly. At homogeneous transformation\n\u03b8 \u2248 \u00b1\u03c0\n\n4\n, heatmaps are almost equal to the input x. As\n\nexpected, it will be difficult to pick up signals that are very\nsimilar, although very close inspection might reveal small\ndifferences that could probably yield some information (not\nin the scope of this paper). Other interpretations can be\nfound in appendix More interpretations in low dimensional\nexample.\n\n3. Experimental Method and Datasets\nIn the previous section, we described how heatmap h can be\nused to improve classification probability. More precisely,\nx+h yields higher confidence in making a correct prediction\ncompared to x alone when used as the input to the model f .\nWe apply the same method to real dataset ImageNet (Deng\net al., 2009) and Chest X-Ray Images (Pneumonia) from\nKaggle (Mooney, 2018). The Pneumonia dataset needs\nreshuffling, since Kaggle\u2019s validation dataset consists of\nonly of 16 images for healthy and pneumonia cases com-\nbined. We combined the training and validation datasets and\nthen randomly draw 266/1083 healthy and 790/3093 pneu-\nmonia images for validation/training. There are 234/390\nhealthy/pneumonia images in the test dataset. Images are\nall resized to 256 \u00d7 256. The X-Ray images are black\nand white, so we stack them to 3 channels. Images from\nImageNet are normalized according to suggestion in the py-\ntorch website, with mean = [0.485, 0.456, 0.406], std =\n[0.229, 0.224, 0.225].\n\nFor both datasets, we use pre-trained models Resnet34 (He\net al., 2016) and AlexNet (Krizhevsky, 2014) available in\nPytorch. The models are used on ImageNet without fine-\n\nTable 1. Fine-tuning results for pre-trained models on Chest X-\nRay Pneumonia test dataset. The architectures marked with sub\nare deliberately trained to achieve lower validation accuracy for\ncomparison.\n\nResnet34 1 Resnet34 sub Alexnet sub\n\naccuracy 0.800 0.636 0.745\nprecision 0.757 0.632 0.726\n\nrecall 1.000 1.000 0.951\nval. acc. 0.99 0.8 0.8\n\ntuning. Resnet34 is fine-tuned for Pneumonia binary classi-\nfications, where the first 8 modules of the pre-trained model\n(according to pytorch\u2019s arrangement) are used, plus a new\nfully-connected (FC) layer with two output channels at the\nend. Similarly, for Alexnet, the first 6 modules are used\nwith a two-channel FC at the end. For Resnet34, we will\nuse Resnet34 1 and Resnet34 sub respectively trained to\nachieve 99% and 80% validation accuracies for comparison.\nThe same targets were specified for Alexnet, but only 80%\nvalidation accuracy was achieved, thus only Alexnet sub\nwill be used. Adam optimizer is used with learning rate\n0.001, \u03b2 = (0.5, 0.999). The usual weight regularization\nis not used during optimization i.e. in pytorch\u2019s Adam op-\ntimizer, weight decay is set to zero because we allow zero\nattribution values in large patches of the images. No number\nof epochs are specified. Instead, training is stopped after the\nmax number of iterations (240000) or the specified valida-\ntion accuracy is achieved after 2400 iterations have passed.\nAt each iteration, samples are drawn uniform-randomly with\nbatch size 32.\n\nCO scores on existing XAI methods via AX process. De-\nnote the deep neural network as DNN, define the CO score\nas the weighted difference between the predictive scores\naltered by AX process and the original predictive scores,\n\nsco(x, h) = \u03ba \u00b7\n[\nDNN(x+ h)\u2212DNN(x)\n\n]\n(5)\n\nwhere \u03ba \u2208 RC is defined as the score constants, C the\nnumber of classes, \u03baj = 1 if the groundtruth belongs to\nlabel/category j and \u03bai = \u22121/(C \u2212 1) for all i 6= j.\nThis equation is the general form of eq. (1). In our im-\nplementation, each DNN\u2019s output is raw, i.e. last layer\nis FC with C channels without softmax layer etc. A\nheatmap h that yields sco = 0 is uninformative (see ap-\npendix). We compute CO scores for heatmaps gener-\nated by six different existing heatmap-based XAI meth-\nods (all available in Pytorch Captum), namely, Saliency\n(Simonyan et al., 2014), Input*Gradient (Shrikumar et al.,\n2016), Layer GradCAM (Selvaraju et al., 2016), Decon-\nvolution (Zeiler & Fergus, 2014), Guided Backpropaga-\ntion (Springenberg et al., 2015) and DeepLift (Shrikumar\net al., 2017). Each heatmap is generated w.r.t predicted\ntarget, not groundtruth e.g. if y pred=DNN(x) predicts\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 2. Distribution of CO scores obtained through AX process on existing XAI methods. Classification probability is improved if the\nscore is positive. All distributions show gaps between CO scores of data whose classes are correctly and wrongly predicted (e.g. red\narrows); correct prediction tends to yield higher CO scores. The result is obtained using Resnet34 1 on Pneumonia dataset. [sum] denotes\nAX process with x+ h.\n\nclass n, then h=DeepLIFT(net).attribute(input, target=n)\nin Pytorch Captum notation. Then normalization is applied\nh\u2192 h/max(|h|) before we perform the AX process. Note:\nFor ImageNet, C = 1000, chest X-Ray, C = 2. We also\nconsider f(x \u2217 h), where \u2217 denotes component-wise multi-\nplication. The idea is generally to interact h with x so that,\nfor any interaction g, higher probability of correct predic-\ntion is achieved by f(g(x, h)); see appendix for their results.\nGradCAM of \u2018conv1\u2019 layer is used in this paper. Other meth-\nods and different arbitrary settings are to be tested in future\nworks.\n\nAchieving high sco with GAX. Here, GAX is the x+h AX\nprocess where heatmaps h = tanh(w \u2217 x) are generated by\ntraining parameters w to maximize sco. Maximizing sco in-\ndefinitely is impractical, and thus we have chosen sco = 48\nfor ImageNet dataset, a score higher than most sco attained\nby existing XAI methods we tested in this experiment. Tanh\nactivation is used both to ensure non-linearity and to en-\nsure that the heatmap is normalized to [\u22121, 1] range, so\nthat we can make a fair comparison with existing heatmap-\nbased XAI methods. For ImageNet, 10000 data samples are\nrandomly drawn from the validation dataset for evaluating\nGAX. For pneumonia, all data samples are used. Optimiza-\ntion is done with Adam optimizer with learning rate 0.1,\n\u03b2 = (0.9, 0.999). This typically takes less than 50 steps of\noptimization, a few seconds per data sample using a small\nGPU like NVIDIA GeForce GTX 1050.\n\nSimilarity loss and GAX bias. In our implementation,\nwe minimize \u2212sco. However, this is prone to producing\nheatmaps that are visually imperceptible from the image.\nSince w is initialized as an array of 1s with exactly the same\nshape (c, h, w) = (3, 256, 256) as x, the initial heatmap is\n\nsimply h = w \u2217 x = x. Possibly, small changes in w over\nthe entire pixel space is enough to cause large changes in\nthe prediction, reminiscent of adversarial attack (Szegedy\net al., 2014; Akhtar & Mian, 2018). We solve this prob-\nlem by adding the similarity loss, penalizing h = x. The\noptimization is now done by minimizing the modified loss,\nwhich is negative CO score plus similarity loss\n\nloss = \u2212sco + ls\n\u2329 (h\u2212 x+ \ufffd)2\n\nx+ \ufffd\n\n\u232a\u22121\n(6)\n\nwhere ls = 100 is the similarity loss factor. \u3008X\u3009 computes\nthe average over all pixels. Division / and square 2 are\nperformed component/pixel-wise. Pixel-wise division by x\nnormalizes the pixel magnitude, so that small pixel values\ncan contribute more significantly to the average value. The\nsmall term \ufffd = 10\u22124 is to prevent division by zero and pos-\nsibly helps optimization by ensuring that zero terms do not\nmake the gradients vanish. Furthermore, for X-Ray images,\nwith many zeros (black region), the similarity factor seems\ninsufficient, resulting in heatmaps that mirror the input im-\nages. GAX bias isa dded for the optimization to work, so\nthat h = w \u2217 x+ b, where b is 0.01 array of the same shape\n(c, h, w) as well. Note: the similarity loss is positive, since x\nused here is [0, 1] normalized (by comparison, the standard\nResnet34 normalization can result in negative pixels).\n\n4. Results and Discussions\nRecall that we use pre-trained models for ImageNet. For\npneumonia dataset, the predictive results of fine-tuning mod-\nels are shown in table 1. AX and GAX processes will be\napplied on top of these models.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 3. Similar to fig. 2, but results are obtained from (A) Resnet34 architecture on Pneumonia dataset, but with less fine-tuning\n(Resnet34 sub). (B) Resnet34 on ImageNet.\n\n4.1. Gaps in CO Scores Distribution\n\nHere, we present the main novel finding: the gap in CO\ndistribution. AX process neither specifies any formulas nor\noptimizes any losses to distinguish correct predictions from\nthe wrong ones, but fig. 2 shows distinct gaps between\nthem (shown by the red arrows). Possible reason: heatmaps\nused in AX process are generated for the class predicted\nby the DNN. If the prediction is correct, there is a match\nbetween cpred in e.g. h=DeepLIFT(net).attribute(input,\ntarget=cpred) (recall: we use Pytorch Captum notation) and\nthe groundtruth label c that that affects CO score through \u03ba.\nThe different distributions found in fig. 2 and 3 indicate that\nsome existing XAI methods possess more information to\ndistinguish between correct and wrong predictions than the\nothers. With this, we might be able to debunk some claims\nthat heatmaps are not useful (Rudin, 2019): regardless of the\nsubjective assessment of heatmap shapes, heatmaps might\nbe relatively informative after some post-processing. In the\nabsence of such information, we expect to see uniformly\nrandom distribution of scores. Since we have observed dis-\ntinct distributional gaps on top of general difference in the\nstatistics, we have shown that some heatmap-based XAI\nmethods combined with CO score might be a new indicator\nto help support classification decision made by the particular\nDNN architecture.\n\nFurthermore, the extent of CO score distribution gap is\nclearly dependent on the dataset and DNN architecture. As\nit is, the discriminative capability of different XAI methods\nis thus comparable only within the same system of archi-\ntecture and dataset. ImageNet dataset shows a smaller gap\ncompared to pneumonia dataset and the largest gap in Im-\nageNet is produced by the Saliency method, as seen in fig.\n3(B). By comparison, the largest gap in pneumonia dataset is\nproduced by Deconvolution. Comparing fig. 2 and fig. 3(A),\nthe gaps appear to be wider when DNN is better trained.\nFurther investigation is necessary to explain the above obser-\nvations, but, to leverage this property, users are encouraged\nto test AX process on different XAI methods to find the\nparticular method that shows the largest gap. Once the XAI\nmethod is determined, it can be used as a supporting tool\nand indicator for the correctness of prediction.\n\nFigure 4. CO score optimization through GAX x+ tanh(w \u2217 x)\non ImageNet data using pre-trained Resnet34 (blue) and Alexnet\n(red), where each curve corresponds to a single image. The target\nsco is set to 48, exceeding most CO scores of other methods.\n\n4.2. Improvement in Predictive Probability with GAX\n\nThe higher the CO scores are, the better is the improvement\nin predictive probability. Is it possible to achieve even higher\nimprovement, i.e. higher CO score? Fig. 2 and 3 show the\nboxplots of CO scores for AX process applied on all six XAI\nmethods we tested in this experiment; histograms applied on\nselect XAI methods are also shown. Different XAI methods\nachieve different CO scores. For pneumonia dataset, very\nhigh CO scores (over 80) are attained by Deconvolution\nmethods. For ImageNet, highest CO scores attained are\naround 10. To attain even higher scores, Generative AX\n(GAX) will be used.\n\nUsing GAX on ImageNet, sco \u2265 48 can be attained as\nshown in fig. 4, where the time evolution of CO score for\neach image is represented by a curve. For Resnet34, most\nof the images attains sco \u2265 48 within 50 iterations. Alexnet\nGAX optimization generally takes more iterations to achieve\nthe target. High sco implies high confidence in making the\ncorrect prediction. We have thus obtained heatmaps and\nattribution values with computational relevance i.e. they can\nbe used to improve the model\u2019s performance. Note: (1) all\nimages tested do attain the target sco (not shown), although\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 5. (A) GAX dynamic heatmaps displayed with a slider for users to observe the evolution of heatmaps through time steps. (B-E)\nGAX heatmaps generated on Resnet34 for (B) healthy chest X-Ray and (C) chest X-Ray of a patient with bacterial pneumonia; and for\nImageNet images (D) a sheep dog image and (E) a planetarium image. (F) An instance of bacterial pneumonia chest X-Ray showing\nan irregular posture with heavy noise (top right). The empty space might have been used as a false distinct feature for pneumonia\nclassification. Three heatmaps for each image correspond to the attribution values assigned to R, G and B color channels respectively.\n\u201cAbs max\u201d specifies the maximum absolute value attained by the heatmap throughout all three channels (max is 1, due to Tanh activation).\nPositive/negative heatmap or attribution values (red/blue) indicate pixels to be increased/reduced in intensity to attain higher prediction\nconfidence. At higher CO scores, negative values emerge.\n\nsome of the images took a few hundreds iterations (2) we\nexclude images where predictions are made incorrectly by\nthe pre-trained or fine-tuned model. By comparison, in\ngeneral, using heatmaps derived from existing methods for\nAX process does not yield positive CO scores i.e. does\nnot improve predictive probability for the correct class (see\nespecially fig. 3(B)). Furthermore, for ImageNet, typically,\nsco \u2264 10. Other boxplots are shown in appendix fig. 7.\n\n4.3. Qualitative Assessment of GAX Heatmaps\n\nHeatmaps in GAX are obtained through a process optimiza-\ntion through a finite number of time steps. We provide\nmatplotlib-based graphic user interface (GUI) for users to\nobserve the evolution of heatmap pixels through GAX; see\nfig. 5(A). This provides users some information about the\nway the DNN architecture perceives input images. But, how\nexactly can user interpret this? Recall that the main premise\nof this paper is the computational relevance: GAX is de-\nsigned to generate heatmaps that improve the confidence in\npredicting the correct label numerically. Hence, the visual\n\ncues generated by the GAX heatmaps show which pixels\ncan be increased or decreased in intensity to give higher\nprobability of making the correct prediction.\n\nDNN optimizes through extreme intensities. Heatmaps in\nfig. 5(B-E) show that predictive confidence is improved\ngenerally through optimizing regions of extreme intensity.\nFor example, to improve CO scores through GAX, the pix-\nels corresponding to white hair of the dog in fig. 5(D)\nare assigned positive values (red regions in the heatmaps).\nDark region of healthy chest X-Ray in (B) are subjected to\nstronger optimization (intense red or blue) to achieve better\npredictive confidence. The DNN architecture seems to be\nmore sensitive to changes in extreme values in the image.\nIn a positive note, this property might be exploited during\ntraining: this is probably why normalization to [\u22121, 1] range\nin the standard practice of deep learning optimization works\ncompared to [0, 1]. On the other hand, this might be a prob-\nlem to address in the future as well: heatmaps that boost\nalgorithmic confidence are not intuitive to human viewers.\nWe can ask the question: is it possible to train DNN such\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nthat its internal structure is inherently explainable (e.g. if\nlocalization is accepted as an explanation, does there exist\nan architecture whose predictive confidence is tied directly\nto localization?). For comparison, existing XAI methods\ntypically specify extra settings to obtain these explanations.\nUnfortunately, the settings can be arbitrary, e.g. GradCAM\npaper (Selvaraju et al., 2016) sets an arbitrary 15% threshold\nof max intensity for binarization. To obtain explanation with\nbetter integrity, the settings might need to be specified in\ncontext beforehand. In this paper, we do NOT address such\narbitrary settings taylored to attain subjectively acceptable\nexplanation or to maximize high IoU for bounding boxes.\n\nDiscriminatory but unrefined patterns. Pneumonia dataset\nconsists of chest X-Ray of healthy patients and patients with\nseveral types of pneumonia with different recognizable pat-\nterns. Bacterial pneumonia has a focal lobar consolidation,\nwhile viral pneumonia has diffuse interstitial patterns; nor-\nmal chest X-Ray has neither. This turns out to affect the\nshape of GAX heatmaps. Fig. 5(B) shows a typical normal\nChest X-Ray pattern. By comparison, fig. 5(C) shows a\nheatmap generated on bacterial pneumonia. In the latter, we\nsee the drastic change in the heatmap features, especially\nhigh-intensity stripes around the lobar consolidation. There\nis a possibility that novel class-discriminatory patterns lie\nhidden within heatmaps generated by GAX. The heatmaps\nappear unrefined, but this might be related to the internal\nstructures of the DNN architecture itself, as described in the\nfollowing section.\n\nLimitations and Future works. We have offered some\nplausible explanations on heatmaps generated through our\nmethod GAX that are consistent with success of standard\ndeep learning training pipeline. Now, we discuss possible\nways to address the issues we briefly presented in the pre-\nvious sections and how they can be addressed in the future.\n(1) Optimized regions prefer extreme intensities (very bright\nor very dark regions). The heatmaps in fig. 5(B-E) indicate\nthat we are able to optimize predictive probability through\nrelative intensity manipulation of pixel patterns that are not\nhumanly intuitive. To truly capture variations in patterns\nand not rely heavily on large difference in intensity, a layer\nor module specifically designed to output very smooth repre-\nsentation might be helpful. Training might take longer, but\nwe hypothesize that skewed optimization through extreme\nintensity can be prevented. (2) Some optimized features\nare rife with artifact-looking patterns. An immediate hy-\npothesis that we can offer is the following. The internal\nstructure of the DNN (the set of weights) is noisy, thus, even\nif features are properly captured, they are amplified through\nnoisy channels, yielding artifacts. This is indicative of the\ninstability of high dimensional neuron activations in a DNN,\na sign of fragility against adversarial attack we previously\nmentioned. How should we address this? We need DNN\nthat are robust against adversarial attack; fortunately, many\n\nresearchers have indeed worked on this problem recently.\n(3) The regularity of data distribution is probably an impor-\ntant deciding factor in model training. In cases where the\nX-Ray images are not taken in a regular posture, the empty\nspace can become a false \u201cdistinct feature\u201d, as shown in fig.\n5(F). While this may indicate a worrying trend in the flawed\ntraining of DNN or data preparation (hence a misguided ap-\nplication) we believe GAX can be used to detect such issue\nbefore deployments. Related future studies may be aimed at\nquantifying the effect of skewed distribution on the appear-\nance of such \u201cfalse prediction\u201d cases. (4) Finally, depending\non the explanation context, ground-truth explanations might\nbe the most desirable features in XAI: we specify exactly\nwhat we want as the correct explanation. The ideal heatmaps\nmay for example resemble object-localization-mask or high-\nlight only relevant parts. Also see appendix for more, e.g.\nimplementation-specific limitations etc.\n\n5. Conclusion\nWe have investigated a method to use heatmap-based XAI\nmethods to improve DNN\u2019s classification performance. The\nmethod itself is called the AX process, and the improve-\nment is measured using a metric called the CO score. Some\nheatmaps can be directly used to improve model\u2019s predic-\ntion better than the others as seen by the boxplots of score\ndistribution. The distribution of scores shows a novel gap\ndistribution, an interesting feature that develops without any\nspecific optimization. GAX is also introduced to explicitly\nattain high improvement in predictive performance or help\ndetect issues. This work also debunks claims that heatmaps\nare not useful through the improvement of predictive confi-\ndence. We also give explanations on DNN behaviour con-\nsistent with the standard practice of deep learning training.\nFrom the results, we support the notion that computationally\nrelevant features are not necessarily relevant to human.\n\nSummary of novelties and contributions: (1) CO scores pro-\nvide empirical evidence for informative content of heatmaps\n(2) the distribution gap in CO scores may be a new indi-\ncator in predictive modelling (3) distinct (albeit unrefined)\nclass-dependent patterns that emerge on GAX-generated\nheatmaps could be used as discriminative signals. Overall,\nwe also provide insights into the DNN\u2019s behaviour.\n\nSoftware and Data\nAll codes are available; see main paper and also see ap-\npendix.\n\nAcknowledgements\nThis research was supported by Alibaba Group Holding Lim-\nited, DAMO Academy, Health-AI division under Alibaba-\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nNTU Talent Program. The program is the collaboration\nbetween Alibaba and Nanyang Technological University,\nSingapore.\n\nReferences\nAdadi, A. and Berrada, M. Peeking inside the black-box: A\n\nsurvey on explainable artificial intelligence (xai). IEEE\nAccess, 6:52138\u201352160, 2018. doi: 10.1109/ACCESS.\n2018.2870052.\n\nAkhtar, N. and Mian, A. Threat of adversarial attacks on\ndeep learning in computer vision: A survey. IEEE Ac-\ncess, 6:14410\u201314430, 2018. doi: 10.1109/ACCESS.2018.\n2807385.\n\nBach, S., Binder, A., Montavon, G., Klauschen, F., Mu\u0308ller,\nK.-R., and Samek, W. On pixel-wise explanations for\nnon-linear classifier decisions by layer-wise relevance\npropagation. PLOS ONE, 10(7):1\u201346, 07 2015. doi:\n10.1371/journal.pone.0130140. URL https://doi.\norg/10.1371/journal.pone.0130140.\n\nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and\nFei-Fei, L. Imagenet: A large-scale hierarchical\nimage database. In 2009 IEEE conference on com-\nputer vision and pattern recognition, pp. 248\u2013255.\nIeee, 2009. URL https://www.kaggle.com/c/\nimagenet-object-localization-challenge.\n\nDos\u030cilovic\u0301, F. K., Brc\u030cic\u0301, M., and Hlupic\u0301, N. Explainable arti-\nficial intelligence: A survey. In 2018 41st International\nConvention on Information and Communication Tech-\nnology, Electronics and Microelectronics (MIPRO), pp.\n0210\u20130215, 2018. doi: 10.23919/MIPRO.2018.8400040.\n\nFong, R. C. and Vedaldi, A. Interpretable explanations of\nblack boxes by meaningful perturbation. In 2017 IEEE\nInternational Conference on Computer Vision (ICCV), pp.\n3449\u20133457, 2017. doi: 10.1109/ICCV.2017.371.\n\nGilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M.,\nand Kagal, L. Explaining explanations: An overview of\ninterpretability of machine learning. In 2018 IEEE 5th\nInternational Conference on Data Science and Advanced\nAnalytics (DSAA), pp. 80\u201389, 2018. doi: 10.1109/DSAA.\n2018.00018.\n\nHe, K., Zhang, X., Ren, S., and Sun, J. Deep residual\nlearning for image recognition. 2016 IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), pp.\n770\u2013778, 2016.\n\nKrizhevsky, A. One weird trick for parallelizing convolu-\ntional neural networks. ArXiv, abs/1404.5997, 2014.\n\nLakshmanan, L. Why you need to explain\nmachine learning models, Jun 2021. URL\nhttps://cloud.google.com/blog/\nproducts/ai-machine-learning/\nwhy-you-need-to-explain-machine-learning-models.\n\nLundberg, S. M. and Lee, S.-I. A unified approach\nto interpreting model predictions. In Guyon, I.,\nLuxburg, U. V., Bengio, S., Wallach, H., Fer-\ngus, R., Vishwanathan, S., and Garnett, R. (eds.),\nAdvances in Neural Information Processing Sys-\ntems 30, pp. 4765\u20134774. Curran Associates, Inc.,\n2017. URL http://papers.nips.cc/paper/\n7062-a-unified-approach-to-interpreting-model-predictions.\npdf.\n\nMooney, P. Chest x-ray images (pneumo-\nnia), Mar 2018. URL https://www.\nkaggle.com/paultimothymooney/\nchest-xray-pneumonia.\n\nOlah, C., Mordvintsev, A., and Schubert, L. Feature\nvisualization. Distill, 2(11), November 2017. doi:\n10.23915/distill.00007. URL https://doi.org/10.\n23915%2Fdistill.00007.\n\nOlah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert,\nL., Ye, K., and Mordvintsev, A. The building blocks of\ninterpretability, Jan 2020. URL https://distill.\npub/2018/building-blocks.\n\nPesenti, J. Facebook\u2019s five pillars of responsible ai, Jun\n2021. URL https://ai.facebook.com/blog/\nfacebooks-five-pillars-of-responsible-ai/.\n\nRebuffi, S. A., Fong, R., Ji, X., and Vedaldi, A. There and\nback again: Revisiting backpropagation saliency methods.\nIn 2020 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 8836\u20138845, 2020. doi:\n10.1109/CVPR42600.2020.00886.\n\nRibeiro, M. T., Singh, S., and Guestrin, C. \u201cwhy\nshould i trust you?\u201d: Explaining the predictions of\nany classifier. In Proceedings of the 22nd ACM\nSIGKDD International Conference on Knowledge Dis-\ncovery and Data Mining, KDD \u201916, pp. 1135\u20131144,\nNew York, NY, USA, 2016. Association for Comput-\ning Machinery. ISBN 9781450342322. doi: 10.1145/\n2939672.2939778. URL https://doi.org/10.\n1145/2939672.2939778.\n\nRudin, C. Stop explaining black box machine learning\nmodels for high stakes decisions and use interpretable\nmodels instead. Nature Machine Intelligence, 1(5):206\u2013\n215, May 2019. ISSN 2522-5839. doi: 10.1038/\ns42256-019-0048-x. URL https://doi.org/10.\n1038/s42256-019-0048-x.\n\nhttps://doi.org/10.1371/journal.pone.0130140\nhttps://doi.org/10.1371/journal.pone.0130140\nhttps://www.kaggle.com/c/imagenet-object-localization-challenge\nhttps://www.kaggle.com/c/imagenet-object-localization-challenge\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://doi.org/10.23915%2Fdistill.00007\nhttps://doi.org/10.23915%2Fdistill.00007\nhttps://distill.pub/2018/building-blocks\nhttps://distill.pub/2018/building-blocks\nhttps://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/\nhttps://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/\nhttps://doi.org/10.1145/2939672.2939778\nhttps://doi.org/10.1145/2939672.2939778\nhttps://doi.org/10.1038/s42256-019-0048-x\nhttps://doi.org/10.1038/s42256-019-0048-x\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nSamek, W., Binder, A., Montavon, G., Lapuschkin, S., and\nMu\u0308ller, K. Evaluating the visualization of what a deep\nneural network has learned. IEEE Transactions on Neu-\nral Networks and Learning Systems, 28(11):2660\u20132673,\n2017.\n\nSelvaraju, R. R., Das, A., Vedantam, R., Cogswell,\nM., Parikh, D., and Batra, D. Grad-cam: Why\ndid you say that? visual explanations from deep\nnetworks via gradient-based localization. CoRR,\nabs/1610.02391, 2016. URL http://arxiv.org/\nabs/1610.02391.\n\nShrikumar, A., Greenside, P., Shcherbina, A., and Kun-\ndaje, A. Not just a black box: Learning important fea-\ntures through propagating activation differences. ArXiv,\nabs/1605.01713, 2016.\n\nShrikumar, A., Greenside, P., and Kundaje, A. Learn-\ning important features through propagating activa-\ntion differences. volume 70 of Proceedings of Ma-\nchine Learning Research, pp. 3145\u20133153, International\nConvention Centre, Sydney, Australia, 06\u201311 Aug\n2017. PMLR. URL http://proceedings.mlr.\npress/v70/shrikumar17a.html.\n\nSimonyan, K., Vedaldi, A., and Zisserman, A. Deep inside\nconvolutional networks: Visualising image classification\nmodels and saliency maps. In Workshop at International\nConference on Learning Representations, 2014.\n\nSpringenberg, J. T., Dosovitskiy, A., Brox, T., and Ried-\nmiller, M. A. Striving for simplicity: The all convolu-\ntional net. CoRR, abs/1412.6806, 2015.\n\nSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,\nD., Goodfellow, I., and Fergus, R. Intriguing properties\nof neural networks. CoRR, abs/1312.6199, 2014.\n\nTjoa, E. and Guan, C. A survey on explainable artificial in-\ntelligence (xai): Toward medical xai. IEEE Transactions\non Neural Networks and Learning Systems, pp. 1\u201321,\n2020a. doi: 10.1109/TNNLS.2020.3027314.\n\nTjoa, E. and Guan, C. Quantifying explainability of saliency\nmethods in deep neural networks. ArXiv, abs/2009.02899,\n2020b.\n\nZeiler, M. D. and Fergus, R. Visualizing and understanding\nconvolutional networks. In Fleet, D., Pajdla, T., Schiele,\nB., and Tuytelaars, T. (eds.), Computer Vision \u2013 ECCV\n2014, pp. 818\u2013833, Cham, 2014. Springer International\nPublishing. ISBN 978-3-319-10590-1.\n\nZhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba,\nA. Learning deep features for discriminative localization.\nIn 2016 IEEE Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pp. 2921\u20132929, June 2016. doi:\n10.1109/CVPR.2016.319.\n\nhttp://arxiv.org/abs/1610.02391\nhttp://arxiv.org/abs/1610.02391\nhttp://proceedings.mlr.press/v70/shrikumar17a.html\nhttp://proceedings.mlr.press/v70/shrikumar17a.html\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nA. Appendix\nAll codes are available in the supplementary materials. All instructions to reproduce the results can be found in README.md,\ngiven as command line input, such as:\n\n1. python main pneu.py \u2013mode xai collect \u2013model resnet34 \u2013PROJECT ID pneu256n 1 \u2013method Saliency \u2013split train\n\u2013realtime print 1 \u2013n debug 0\n\n2. python main pneu.py \u2013mode gax \u2013PROJECT ID pneu256n 1 \u2013model resnet34 \u2013label NORMAL \u2013split test \u2013\nfirst n correct 100 \u2013target co 48 \u2013gax learning rate 0.1\n\nThe whole experiment can be run on small GPU like NVIDIA GeForce GTX 1050 with 4 GB dedicated memory.\n\nThe codes are run on Python 3.8.5. The only specialized library used is Pytorch (specifically torch==1.8.1+cu102,\ntorchvision==0.9.1+cu102) and Pytorch Captum (captum==0.3.1). Other libraries are common python libraries.\n\nRegarding Captum. We replace Pytorch Captum \u201cinplace relu\u201d so that some attribution methods will work properly (see\nadjust for captum problem in model.py where applicable).\n\nWe also manually edit non-full backward hooks in the source codes to prevent the gradient propagation is-\nsues. For example, from Windows, see Lib \\site-packages \\captum \\attr \\ core \\guided backprop deconvnet.py,\nfunction def register hooks(self, module: Module). There is a need to change from hook = module. regis-\nter backward hook(self. backward hook) to hook = module. register full backward hook(self. backward hook).\n\nA.1. More interpretations in low dimensional example\n\nInterpretation of attribute values for non-negative less distinct components. Now, we consider data sample with lower\na1 = 0.7 (i.e. less distinct) but components are still non-negative. Fig. 1 middle shows that components are still non-\nnegative around \u03b8 \u2208 [\u03c0/8, 3\u03c0/8]. Similar attribution of h1 and suppression of h2 are observed similarly although with\nlower magnitude around \u03b8 \u2248 0. At \u03b8 \u2248 \u03c0/4, similar difficulty in distinguishing homogenous transformation is present,\nnaturally. Further rotation to 3\u03c0/8 will give higher h2 as well. Fig. 6 right shows similar behavior even for a1 \u2248 a2,\nthough non-negative values are observed for rotations around [\u2212\u03c0/4, \u03c0/4]. The sample is barely categorized as c = 1 since\na1 > a2. However, the resulting attribution values still highlights the positive contribution x1, primarily through higher h1\nattribution value, even though the magnitudes are lower compared to previous examples.\n\nInterpretation of attribute values for negative components. Beyond the rotation range that yields non-negative components,\nwe do see negative components xi < 0 assigned highly negative hi values. For example, fig. 6 left at \u03b8 \u2248 \u03c0 shows a rotation\nof the components to the negatives. In this formulation, negative attribution values are assigned to negative components\nnaturally, because w \u2217 x starts with wi = 1 and xi < 0, as wi is optimized, our example shows an instance where, indeed,\nwe need higher wi, very negative h1. Recall the main interpretation. In the end, this high negative attribution is aimed at\nimproving CO score. The large negative h1 component increases the likelihood of predicting c = 1; conversely, the relatively\nlow h2 magnitude increases the same likelihood. Therefore, we do not immediately conclude that negative attribution values\ncontribute \u201cnegatively\u201d to prediction, which is a term sometimes ambiguously used in XAI community. In practice, case by\ncase review may be necessary.\n\nA.2. Zero CO scores and other scores\n\nZero CO score might occur when when h yields uniform change to the output, i.e. DNN(x+ h) = DNN(x) + c for some\nconstant c. This is obtained by simply plugging into the CO score formula. Special case may occur when h is constant\nover all pixels, especially when N(g(x+ h)) = N(g(x)) for some intermediate normalization layer N and intermediate\npre-normalized composition of layers g = gk \u25e6 gk\u22121 \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 g1.\n\nPositive CO score indicates that the component [sco]i, where i corresponds to the groundtruth label, is increased by h at\na greater magnitude than the average of all other components, which in turn means that the component DNN(x + h)i\nis similarly increased at greater magnitude compared to the average of other components. Hence, the prediction favours\ncomponent i relatively more, i.e. the probability of predicting the correct class is increased. Negative CO score is simply the\nreverse: probability of predicting the correct class has been reduced relatively.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 6. Solid red (blue) lines are x1(x2) components of sample data x. Dotted red (blue) lines are h1(h2) components of heatmaps\nh with k\u03b7 = 1.2. Heatmap values or attribute importances are assigned large values when either (1) the true components a1, a2 differ\nsignificantly (2) the W transforms the data heterogenously i.e. not \u03b8 \u2248 (2k + 1)\u03c0\n\n4\n.\n\nA.3. More Boxplots of CO Scores.\n\nFig. 7 shows more variations of CO scores in our experiments, similar to the ones shown in the main text. Some scores\nclearly demonstrate distinct gaps in CO scores between the correct and wrong predictions.\n\nFrom fig. 8, AX process is applied to the heatmaps generated in different layers of ResNet34. We expect higher improvement\nof CO scores for AX process using heatmaps from deeper layers that are known to detect more features. We do observe a\ndifference in x \u2217 h AX process, but not in x+ h for Layer Grad CAM.\n\nA.4. More Considerations, Limitations and Future Works\n\nDifferent GAX and empirical choices in implementation. Parts of the implementations, such as the initialization of w to 1.0,\nare nearly arbitrary, though it is the first choice made from the 2D example that happens to work. Different implementations\ncome with various trade-offs. Most notably, the choice of learning rate 0.1 is manually chosen for its reliable and fast\nconvergence, although convergence is attainable for smaller learning rate like 0.001 after longer iterations. However, we\nneed to include more practical considerations. For example, saving heatmaps iteration by iteration will generally consume\naround 5-12 MB of memory for current choices. Longer optimization iterations may quickly cause a blow-up, and there is\nno known fixed number of iterations needed to achieve convergence to the target CO score. Saving heatmaps at certain\nCO scores milestones can be considered, though we might miss out on important heatmap changes in between. Parameter\nselection process is thus not straightforward. For practical purposes, learning rates can be tested in order of ten, 10n, and\nother parameters can be tested until a choice is found where each optimization process converges at a rate fast enough for\nnearly instantaneous, quick diagnosis. Other choices of optimizers with different parameters combination can be explored as\nwell, though we have yet to see dramatic changes.\n\nGAX, different DNN architectures and different datasets. Comparisons are tricky, since different architectures might behave\ndifferently at their FC end. For example, for Saliency method on ImageNet, Alexnet\u2019s boxplot of CO scores in appendix\nfig. 7(A) right (AX process x + w \u2217 x) shows a wider range of CO scores than that of Resnet34 in fig. ??. Comparison\nof CO scores on Chest X-Ray dataset shows even larger variability. Furthermore, recall that we illustrated using the 2D\nexample the reason we avoid sigmoid function: suppressed change in the CO score due to its asymptotic part. We have\navoided Softmax for similar reason, and a further study can be conducted to characterize the scores with Softmax or other\nmodifications. From here, the ideal vision is to develop a model that scales with CO score in not only a computationally\nrelevant way, but also in a human relevant way: we want a model that increases predictive probability when the heatmap\nhighlights exactly the correct localization of the objects or highly relevant features related to the objects. This is a tall effort,\nparticularly because explanations are highly context dependent. Transparent and trustworthy applications of DNN may\nbenefit from the combined improvements in humanly understandable context and computationally relevance attributions\nbuilt around that context.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 7. Boxplots of CO scores for existing XAI methods, including another GAX implementation x \u2217 h = x \u2217 (w \u2217 x)\n.\n\nFigure 8. Boxplots of CO scores for heatmaps from Layer GradCAM for ResNet34 and ImageNet dataset. CO scores of heatmaps\ngenerated from different layers (and resized accordingly) are shown.\n\n.\n\n\n"}
{"Title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes for Traffic Flow", "Authors": "Danielle C Maddix, Nadim Saad, Yuyang Wang", "Abstract": "  The transport of traffic flow can be modeled by the advection equation. Finite difference and finite volumes methods have been used to numerically solve this hyperbolic equation on a mesh. Advection has also been modeled discretely on directed graphs using the graph advection operator [4, 18]. In this paper, we first show that we can reformulate this graph advection operator as a finite difference scheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model that incorporates the dynamics of this graph advection operator into the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic flow and its uncertainty as an advective process on a directed graph.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00001", "Text": null}
{"Title": "Time-Dependent Duhamel Renormalization method with Multiple Conservation and Dissipation Laws", "Authors": "Sathyanarayanan Chandramouli, Aseel Farhat, Ziad Musslimani", "Abstract": "  The time dependent spectral renormalization (TDSR) method was introduced by Cole and Musslimani as a novel way to numerically solve initial boundary value problems. An important and novel aspect of the TDSR scheme is its ability to incorporate physics in the form of conservation laws or dissipation rate equations. However, the method was limited to include a single conserved or dissipative quantity. The present work significantly extends the computational features of the method with the (i) incorporation of multiple conservation laws and/or dissipation rate equations, (ii) ability to enforce versatile boundary conditions, and (iii) higher order time integration strategy. The TDSR method is applied on several prototypical evolution equations of physical significance. Examples include the Korteweg-de Vries (KdV), multi-dimensional nonlinear Schr\u00f6dinger (NLS) and the Allen-Cahn equations.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00002", "Text": null}
{"Title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes for Traffic Flow", "Authors": "Danielle C Maddix, Nadim Saad, Yuyang Wang", "Abstract": "  The transport of traffic flow can be modeled by the advection equation. Finite difference and finite volumes methods have been used to numerically solve this hyperbolic equation on a mesh. Advection has also been modeled discretely on directed graphs using the graph advection operator [4, 18]. In this paper, we first show that we can reformulate this graph advection operator as a finite difference scheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model that incorporates the dynamics of this graph advection operator into the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic flow and its uncertainty as an advective process on a directed graph.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00001", "Text": null}
{"Title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes for Traffic Flow", "Authors": "Danielle C Maddix, Nadim Saad, Yuyang Wang", "Abstract": "  The transport of traffic flow can be modeled by the advection equation. Finite difference and finite volumes methods have been used to numerically solve this hyperbolic equation on a mesh. Advection has also been modeled discretely on directed graphs using the graph advection operator [4, 18]. In this paper, we first show that we can reformulate this graph advection operator as a finite difference scheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model that incorporates the dynamics of this graph advection operator into the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic flow and its uncertainty as an advective process on a directed graph.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00001", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Advection on Directed Graphs using\nMat\u00e9rn Gaussian Processes for Traffic Flow\n\nDanielle C. Maddix\nAmazon Research\n\n2795 Augustine Dr.\nSanta Clara, CA 95054\ndmmaddix@amazon.com\n\nNadim Saad\nStanford University\n\n450 Serra Mall\nStanford, CA 94305\n\nnsaad31@stanford.edu\n\nYuyang Wang\nAmazon Research\n\n2795 Augustine Dr.\nSanta Clara, CA 95054\nyuyawang@amazon.com\n\nAbstract\n\nThe transport of traffic flow can be modeled by the advection equation. Finite\ndifference and finite volumes methods have been used to numerically solve this\nhyperbolic equation on a mesh. Advection has also been modeled discretely on\ndirected graphs using the graph advection operator [4, 18]. In this paper, we first\nshow that we can reformulate this graph advection operator as a finite difference\nscheme. We then propose the Directed Graph Advection Mat\u00e9rn Gaussian Process\n(DGAMGP) model that incorporates the dynamics of this graph advection operator\ninto the kernel of a trainable Mat\u00e9rn Gaussian Process to effectively model traffic\nflow and its uncertainty as an advective process on a directed graph.\n\n1 Introduction\n\nThe continuous linear advection equation models the flow of a scalar concentration along a vector\nfield. The solutions to this hyperbolic partial differential equation may develop discontinuities or\nshocks over time depending on the initial condition. These shocks can model the formation of traffic\njams, and their propagation along a road [20]. Figure 1 illustrates an example, where initially the\nfirst half of the road is 70% occupied with cars, and the second half of the road is empty. The traffic\npropagates to the right until the whole road is 70% occupied. Classical methods, such as finite\ndifferences and finite volumes, have been used to predict the flow of traffic along a road [15, 20].\nThese classical numerical methods do not incorporate any randomness into the model, and can be\nlimited in incorporating the uncertainty among different driver\u2019s behaviors [6].\n\nFigure 1: Propagation of cars on a road using an\nadvection process.\n\nGaussian processes (GPs) [19] can learn unknown\nfunctions that allow use of prior information about\ntheir properties and for uncertainty modeling.\nK\u00fcper and Waldherr [10] propose the Gaussian\nProcess Kalman Filter (GPKF) method to simu-\nlate spatiotemporal models, and test on the ad-\nvection equation. Raissi et al. [17] train GPs on\ndata to learn the underlying physics of non-linear\nadvection-diffusion equations. Additional physics-\nbased machine learning models [2] use the Mat\u00e9rn\ncovariance function given below:\n\nu \u223c N\n(\n0,\n(2\u03bd\n\n\u03ba2\n+ \u2206\n\n)\u2212\u03bd)\n, (1)\n\nwhere u denotes an unknown function, \u03bd <\u221e, \u03ba <\u221e and \u2206 denotes the laplacian [1]. The Mat\u00e9rn\n\nFourth Workshop on Machine Learning and the Physical Sciences (NeurIPS 2021).\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n1v\n2 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 3\n\n F\neb\n\n 2\n02\n\n2\n\n\n\nkernel captures physical processes due to its finite differentiability, and is also commonly used to\ndefine distances between two points that are d units distant from each other [2]. Gulian et al. [8]\npropose training joint Mat\u00e9rn GPs to model space-fractional differential equations, in which the\nadvection-diffusion equation is a special case.\n\nRecent works including [22] have studied solving partial differential equation (PDEs) on graphs.\nChapman and Mesbahi [4], Rak [18] propose discrete advection and consensus operators to model\nadvection and diffusion flows, respectively on directed graphs. Ho\u0161ek and Volek [9] study the\nadvection-diffusion equation on graphs using this discrete advection operator, and show that finite vol-\nume numerical discretizations can be reformulated as equations on graphs resulting in a corresponding\nmaximum principle for this operator. Additional works have also looked at combining scientific\ncomputing and machine learning on graphs for spatiotemporal traffic modeling [12]. Chamberlain\net al. [3] propose the Graph Neural Diffusion (GRAND) method, which combines traditional ODE\nsolvers with graph neural networks (GNNs) to model diffusion on a undirected graph. Borovitskiy\net al. [2] propose to replace the continuous laplacian \u2206 in (1) with the discrete graph laplacian\noperator L to model diffusion on undirected graphs, which can be limited for traffic modeling.\n\nThe goal of this paper is two-fold: to develop a model that effectively models traffic flow as an\nadvective process on a directed graph and its uncertainty. We propose a novel method, Directed Graph\nAdvection Mat\u00e9rn Gaussian Process (DGAMGP) that uses a symmetric positive definite variant of\nthe graph advection operator Ladv as a covariance matrix in the Mat\u00e9rn Gaussian Process. We use the\nsquare of the singular values of Ladv to model the advection dynamics, and train a Mat\u00e9rn Gaussian\nProcess to model the uncertainty. We also show the connection between consistent finite difference\nstencils for solving the linear advection equation and the graph advection operator. Our novel linkage\nhelps improve the understanding and interpretability of this graph advection operator.\n\n2 Understanding the directed graph advection operator\n\nWe aim to model the continuous advection equation for unknown scalar u under vector field v:\n\n\u2202u\n\n\u2202t\n= \u2212\u2207 \u00b7 (vu),\n\nstochastically on a directed graph. We define a directed, weighted graph G = (V,E,W ) with |V | = n\nnodes and |E| = |W | = m edges, where V denotes the vertex, E the edge, and W the edge weight\nsets, respectively. We discretize the flow vu along edge (i, j) \u2208 E with weight wji \u2208W as wjiui(t),\nwhere ui(t) denotes the concentration u at node i and time t.\n\nThe graph advection operator Ladv is defined so that the flow into a node equals the flow out of it [4]:\n\ndui(t)\n\ndt\n=\n\n\u2211\nj:(j,i)\u2208E\n\nwijuj(t)\u2212\n\u2211\n\nj:(i,j)\u2208E\n\nwjiui(t) = \u2212[Ladvu(t)]i, (2)\n\nwhere Ladv = Dout \u2212 Ain for diagonal out-degree matrix Dout and in-degree adjacency matrix\nAin. For general directed graphs, Ladv belongs to the square, non-symmetric with non-negative real\npart eigenvalues [18] class of matrices in [14]. By design, Ladv is conservative, unlike the related\ndiffusion or consensus operator Lcons = Din \u2212 Ain, where Din denotes the diagonal in-degree\nmatrix [4, 18]. A main motivating reason for using Ladv to model traffic flow is that it results in a\nconservative scheme.\n\nReformulation of Ladv as finite difference on balanced graphs. We notice that Ladv at node i\nis a weighted linear combination of the other nodes adjacent to it, which resembles finite difference\nstencils of the unknown and its neighbors. We make this connection precise, and then construct\nexample graphs where Ladv corresponds to common finite difference schemes for linear advection.\n\nTheorem 2.1. Ladv corresponds to a semi-discrete finite difference advection scheme, where the sum\nof the coefficients is zero if and only if the graph G is balanced, i.e. Ladv = Lcons.\nProof. A finite difference approximation to the gradient can be written as the following weighted\nlinear combination of its neighbors uj for arbitrary coefficients cij \u2208 R:\n\n\u2212(ux)i \u2248\n\u2211\nj 6=i\n\ncijuj + ciiui. (3)\n\n2\n\n\n\nA consistent finite difference scheme is at least zero-th order accurate [11]. Since the derivative of a\nconstant is 0, the coefficients must sum to 0, i.e cii = \u2212\n\n\u2211\nj 6=i cij . Combining (2) with (3) gives:\n\n(Dout)ii =\n\u2211\n\nj:(i,j)\u2208E\n\nwji = \u2212cii =\n\u2211\nj 6=i\n\ncij =\n\u2211\n\nj:(j,i)\u2208E\n\nwij = (Din)ii.\n\nThe graph G is balanced by definition, and it follows that Ladv = Lcons. The other direction follows\nsimilarly.\n\nApplying Ladv on the directed line graph in Figure 2(a) results in the first order upwind scheme\nwith spatial step size \u2206x for v > 0 in (5) (See Appendix A and Figure 6 for the convergence study).\nSimilarly, Figure 2(b) illustrates the directed graph in which Ladv gives the second order central\ndifference scheme, where (ux)i \u2248 (ui+1 \u2212 ui\u22121)/(2\u2206x) (See Appendix B for additional examples).\n\nui\u22121 ui ui+1\nv/\u2206x v/\u2206x\n\n(a) first order upwind scheme\n\nui\u22121 ui ui+1\nv/2\u2206x \u2212v/2\u2206x\n\n\u2212v/2\u2206x v/2\u2206x\n\n(b) second order central scheme\n\nFigure 2: Balanced graphs on which Ladv corresponds to finite difference stencils of linear advection.\n\n3 Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\n\nWe propose the novel Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP) model, which\nuses the dynamics of Ladv to model advection stochastically on a directed graph through a discrete\napproximation to the continuous Laplacian \u2206 of the Mat\u00e9rn Gaussian Process in (1). The covariance\nmatrix or kernel K of a Gaussian process needs to be symmetric and positive semi-definite. This\nleads to some challenges with the Ladv operator as it is not guaranteed in general to be symmetric or\npositive semi-definite (See Section 2). Note that using the graph Laplacian L in the covariance matrix\nin the undirected graph case is more straightforward since L is symmetric positive semi-definite.\n\nIn our directed graph case, we propose using LTadvLadv as the covariance matrix since it is symmetric\npositive definite, and hence orthogonally diagonalizable. Analogous to [2], we define a function \u03c6 of\na diagonalizable matrix through Taylor series expansion. Then we can define its eigendecomposition\nas LTadvLadv = Xadv\u039badvX\n\nT\nadv, so that \u03c6(LTadvLadv) = Xadv\u03c6(\u039badv)X\n\nT\nadv, where \u03c6(\u039badv) is\n\ncomputed by applying \u03c6 to the diagonal elements of \u039badv .\n\nWe compute the eigendecomposition of LTadvLadv = Vadv\u03a3\n2\nadvV\n\nT\nadv , using the singular value decom-\n\nposition (SVD) of Ladv = Uadv\u03a3advV\nT\nadv, where the eigenvalues and eigenvectors are the singular\n\nvalues squared and right singular vectors of Ladv, respectively. Hence, we model the advection\ndynamics using the square of the singular values of Ladv . Our approach can also be viewed as adding\nthe square of the singular values of Ladv to the diagonal for regularization. Computing the thin-SVD\nis more computationally efficient and numerically stable, since we avoid explicitly forming the\nmatrix-matrix product LTadvLadv , which has double the condition number of Ladv , and the numerical\nissues with then computing its eigendecomposition.\n\nWe chose \u03c6 to be the Mat\u00e9rn covariance function in (1), and our DGAMGP model is given by:\n\nu \u223c N\n(\n0,\n(\nVadv(\n\n2\u03bd\n\n\u03ba2\nI + \u03a32\n\nadv)\n\u2212\u03bdV Tadv\n\n))\n. (4)\n\nThis advective Gaussian Process is then trained on data by minimizing the negative log-likelihood of\nthe Gaussian Process to learn the kernel hyperparameters \u03bd and \u03ba, and predict u [7]. For inference,\nwe draw samples from the GP predictive posterior distribution with the learned hyperparameters [19].\nSee Algorithm 1 for details.\n\nChoice of LTadvLadv . There are alternate approaches to symmetrize Ladv . The first simple approach\nexplored is to utilize Lsym = (LTadv + Ladv)/2 . This operator is not positive semi definite except\n\n3\n\n\n\nin the balanced graph case. The second approach is to use the symmetrizer method in [21], which\ngenerates a symmetric matrix L\u2032sym with the same eigenvalues as Ladv but is not always positive\nsemi definite.\n\nAlgorithm 1 The Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\nGiven a directed graph G = (V,E,W ) and training data D = {(xi, yi)}ni=1.\n\n1. Compute Ladv(G) = Dout \u2212Ain.\n2. Compute the SVD of Ladv = Uadv\u03a3advV\n\nT\nadv .\n\n3. Generate a DGAMGP model in (4).\n4. Minimize the GP negative log marginal likelihood using D to learn \u03bd, \u03ba and \u03c3 [7].\n5. Given test data {x\u2217i }, draw samples from the GP predictive posterior distribution [19].\n\n4 Numerical Results\nIn this section, we utilize our DGAMGP model for traffic modeling on synthetic and real-\nworld directed traffic graphs. The data D = {(xi, yi)}ni=1 denotes the traffic flow speed in\nmiles per hour yi at location xi. We test our model\u2019s predictive ability to predict the veloci-\nties of cars on a road at different positions. We use hold-out cross validation to split the data\npoints generated into training (70% of the data) and testing data (30% of the data). We extend\nthe code in [2] to compute the singular value decomposition of Ladv to train our DGAMGP\nmodel on a directed graph. The code is available at https://github.com/advectionmatern/\nModeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes, and\nthe experiments are run on Amazon Sagemaker [13].\n\nRegression results on synthetic graphs. We generate synthetic data that models traffic along a\nroad, which has a relatively high density of cars in the first half and a low density of cars in the second\nhalf. We train and test our model on the upwind scheme in Figure 2(a), central scheme in Figure\n2(b), an intersecting lane graph, where two lanes merge into one lane in Figure 3(a) and a loop graph\nrepresenting the upwind scheme with periodic boundary conditions in Figure 3(b). Table 1 compares\nthe results to the consensus baseline model of using the singular value decomposition of Lcons in\nEqn. (4).\n\nModel Graph type n = 280 n = 325 n = 400 \u03bd \u03ba \u03c3\nAdvection Upwind 0.52 0.45 0.0005 0.65 8.09 7.75\nConsensus 0.51 0.44 0.0005 0.65 8.29 7.77\nAdvection Central 1.31 0.85 8.41e-05 0.67 9.00 8.03\nConsensus 0.97 0.8 8.02e-05 0.67 9.45 8.11\nAdvection Intersection 0.96 0.45 0.0005 0.65 8.19 7.75\nConsensus 0.52 0.46 0.0005 0.64 8.28 7.77\nAdvection Loop 0.47 0.41 0.00045 0.65 8.49 7.76\nConsensus 0.47 0.41 0.00045 0.65 8.49 7.76\n\nTable 1: Comparison of l2 test error on synthetic directed graphs with n nodes and the learned\nhyperparameters.\n\nui\u22122 ui\u22121 ui\n\nui\u22124 ui\u22123\n\nui+1\nv/\u2206x v/\u2206x\n\nv/\u2206x v/\u2206x\n\n2v/\u2206x\n\n(a) intersection graph\n\nu1 ui\u22121 ui un\nv/\u2206x v/\u2206x v/\u2206x\n\nv/\u2206x\n\n(b) loop graph\n\nFigure 3: Graphs representing two lanes merging into one (left) and a loop (right).\n\n4\n\nhttps://github.com/advectionmatern/Modeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes\nhttps://github.com/advectionmatern/Modeling-Advection-on-Directed-Graphs-using-Mat-e-rn-Gaussian-Processes\n\n\nRegression results on a real-world traffic graph. We test on the real-world traffic data from the\nCalifornia Performance Measurement System [5] with the road network graph from the San Jose\nhighways from Open Street Map [16] at a fixed time. Since our method supports directed graphs,\nwe do not need to convert the raw directed traffic data to an undirected graph as in [2]. We use the\nsame experimental setup from [2] to generate the train and test data. Figure 4 shows the resulting\npredictive mean and standard deviation of the speed on the San Jose highways using the visualization\ntools from [2]. We notice that the predictive standard deviation along the nodes is relatively small,\nand is larger on the points that are farther from the sensors.\n\nFigure 4: Traffic speed interpolation over a graph of San Jose highways using our DGAMGP method\nwith \u03bd = 0.35, \u03ba = 1002.8, \u03c3 = 1.14 and plotting tools from [2].\n\n5 Conclusions\n\nIn this paper, we propose a novel method DGAMGP to model an advective process on a directed\ngraph and its uncertainties. We show connections between finite differences schemes used to solve\nthe linear advection equation and the graph advection operator Ladv employed in our model. We\nexplore a regression problem on various graphs, and show that our proposed DGAMGP model\nperforms similarly to other state-of-the-art models. Future work includes adding a time-varying\ncomponent to our model, comparing our method to classical numerical methods for solving PDEs,\nand incorporating the behavior of the non-linear advection equation for traffic modeling.\n\nReferences\n\n[1] Bakka, H., Krainski, E., Bolin, D., Rue, H., and Lindgren, F. (2020). The diffusion-based\nextension of the mat\u00e9rn field to space-time. arXiv:2006.04917.\n\n[2] Borovitskiy, V., Azangulov, I., Terenin, A., Mostowsky, P., Deisenroth, M., and Durrande,\nN. (2021). Mat\u00e9rn gaussian processes on graphs. In Banerjee, A. and Fukumizu, K., editors,\nProceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume\n130 of Proceedings of Machine Learning Research, pages 2593\u20132601. PMLR.\n\n5\n\n\n\n[3] Chamberlain, B., Rowbottom, J., Gorinova, M. I., Bronstein, M., Webb, S., and Rossi, E. (2021).\nGrand: Graph neural diffusion. In Meila, M. and Zhang, T., editors, Proceedings of the 38th\nInternational Conference on Machine Learning, volume 139 of Proceedings of Machine Learning\nResearch, pages 1407\u20131418. PMLR.\n\n[4] Chapman, A. and Mesbahi, M. (2011). Advection on graphs. IEEE Conference on Decision and\nControl and European Control Confereence (CDC-ECC), 50:1461\u20131466.\n\n[5] Chen, C., Petty, K., Skabardonis, A., Varaiya, P., and Jia, Z. (2001). Freeway performance\nmeasurement system: mining loop detector data. Transportation Research Record, 1748(1):96\u2013\n102.\n\n[6] Chen, Y., Sohani, N., and Peng, H. (2018). Modelling of uncertain reactive human driving\nbehavior: a classification approach. In 2018 IEEE Conference on Decision and Control (CDC),\npages 3615\u20133621.\n\n[7] Gardner, J., Pleiss, G., Bindel, D., Weinberger, K., and Wilson, A. (2018). GPytorch: Blackbox\nmatrix-matrix gaussian process inference with gpu acceleration. 32nd Conference on Neural\nInformation Processing Systems (NIPS 2018) arXiv:1809.11165v2.\n\n[8] Gulian, M., Raissi, M., Perdikaris, P., and Karniadakis, G. (2019). Machine learning of space-\nfractional differential equations, SIAM Journal on Scientific Computing, Vol. 41, No. 4, Society\nfor Industrial and Applied Mathematics. pages A2485\u2013A2509.\n\n[9] Ho\u0161ek, R. and Volek, J. (2019). Discrete advection\u2013diffusion equations on graphs: Maximum\nprinciple and finite volumes. Applied Mathematics and Computation, 361(C):630\u2013644.\n\n[10] K\u00fcper, A. and Waldherr, S. (2020). Numerical gaussian process kalman filtering. 21st IFAC\nWorld Congress.\n\n[11] LeVeque, R. J. (2007). Finite Difference Methods for Ordinary and Partial Differential Equa-\ntions: Steady-State and Time-Dependent Problems. SIAM.\n\n[12] Li, Y., Yu, R., Shahabi, C., and Liu, Y. (2018). Diffusion convolutional recurrent neural network:\nData-driven traffic forecasting. International Conference on Learning Representations (ICLR).\n\n[13] Liberty, E., Karnin, Z., Xiang, B., Rouesnel, L., Coskun, B., Nallapati, R., Delgado, J.,\nSadoughi, A., Astashonok, Y., Das, P., Balioglu, C., Chakravarty, S., Jha, M., Gautier, P., Arpin,\nD., Januschowski, T., Flunkert, V., Wang, Y., Gasthaus, J., Stella, L., Rangapuram, S., Salinas, D.,\nSchelter, S., and Smola, A. (2020). Elastic machine learning algorithms in amazon sagemaker. In\n2020 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201920, New York,\nNY, USA. Association for Computing Machinery., pages 731\u2013737.\n\n[14] Liesen, J. and Parlett, B. N. (2008). On nonsymmetric saddle point matrices that allow conjugate\ngradient iterations. Numer. Math., 108:605\u2013624.\n\n[15] Lighthill, M. and Whitham, G. (1955). On kinematic waves ii. a theory of traffic flow on long\ncrowded roads. Proceedings of the Royal Society of London. Series A. Mathematical and Physical\nSciences, 229:317 \u2013 345.\n\n[16] OpenStreetMap (2017). https://www.openstreetmap.org.\n\n[17] Raissi, M., Perdikaris, P., and Karniadakis, G. (2019). Physics-informed neural networks: A\ndeep learning framework for solving forward and inverse problems involving nonlinear partial\ndifferential equations. Journal of Computational Physics, 378:686\u2013707.\n\n[18] Rak, A. (2017). Advection on graphs. http://nrs.harvard.edu/urn-3:HUL.InstRepos:\n38779537.\n\n[19] Rasmussen, C. and Williams, C. (2006). Gaussian Processes for Machine Learning. MIT Press.\n\n[20] Richards, P. (1956). Shock waves on the highway. Operation Res., pages 42 \u2013 51.\n\n[21] Sen, S. and Venkaiah, V. C. (1988). On symmetrizing a matrix. Indian J. pure appl. Math.,\n19(6):554\u2013561.\n\n[22] Solomon, J. (2015). PDE approaches to graph analysis. ArXiv, abs/1505.00185.\n\n6\n\nhttps://www.openstreetmap.org\nhttp://nrs.harvard.edu/urn-3:HUL.InstRepos:38779537\nhttp://nrs.harvard.edu/urn-3:HUL.InstRepos:38779537\n\n\nA Upwinding discretizations of linear advection\n\nWe discretize the 1D linear advection equation with velocity v:\nut + vux = 0,\n\nusing the standard first order upwinding scheme on a simple uniform Cartesian mesh with spatial step\nsize \u2206x. Then the classical finite difference first-order upwind scheme depends on the sign of v. For\nflow moving from left to right, v > 0, and we have the following semi-discrete discretization [11]:\n\ndui\ndt\n\n+ v\nui \u2212 ui\u22121\n\n\u2206x\n= 0, if v > 0,\n\ndui\ndt\n\n+ v\nui+1 \u2212 ui\n\n\u2206x\n= 0, if v < 0.\n\n(5)\n\nUpwinding schemes are useful in the advection case since information is moving from left to right.\nThe Courant-Friedrichs-Lewy (CFL) condition for stability of the first order upwinding scheme with\nForward Euler time-stepping discretization with time step \u2206t is given by:\u2223\u2223\u2223v\u2206t\n\n\u2206x\n\n\u2223\u2223\u2223 \u2264 1 \u21d0\u21d2 \u2206t \u2264\n\u2223\u2223\u2223 v\n\u2206x\n\n\u2223\u2223\u2223.\nA less diffusive second order upwind scheme is also known as linear upwind differencing (LUD),\nand is given by:\n\ndui\ndt\n\n= v\n\u2212ui\u22122 + 4ui\u22121 \u2212 3ui\n\n2\u2206x\n. (6)\n\nWe can show that the scheme is second-order accurate using Taylor expansions. It is designed to be\nless diffusive because the uxx term from the first-order upwinding scheme cancels. We have\n\nui\u22122 \u2212 4ui\u22121 + 3ui\n2\u2206x\n\n=\n1\n\n2\u2206x\n\n[(\nu\u2212 2\u2206xux +\n\n4\u2206x2\n\n2\nuxx \u2212\n\n8\u2206x3\n\n6\nuxxx +O(\u2206x4)\n\n)\n+\n(\n\u2212 4(u\u2212\u2206xux +\n\n\u2206x2\n\n2\nuxx \u2212\n\n\u2206x3\n\n6\nuxxx +O(\u2206x4))\n\n)\n+ 3u\n\n]\n\n= ux \u2212\n\u2206x2\n\n3\nuxxx +O(\u2206x4).\n\nHence, the scheme is second order accurate with a dispersive uxxx leading error term.\n\nB Examples of Ladv on balanced graphs resulting in finite difference\ndiscretizations of linear advection\n\nIn addition to the finite difference schemes provided in Section 2, we also provide an example of a\nnon-uniform mesh discretization:\n\ndui\ndx\n\u2248\n\n4\n3ui+1/2 \u2212 ui \u2212 1\n\n3ui\u22121\n\n\u2206x\n,\n\nwhich results in the following graph, where the in-going and out-going edges from ui:\n\nui\u22121 ui\u22121/2 ui ui+1/2 ui+1\n\nv/3\u2206x v/3\u2206x\n\n\u22124v/3\u2206x \u22124v/3\u2206x\u22124v/3\u2206x \u22124v/3\u2206x\n\nv/3\u2206x\n\nWe can obtain the less diffusive second order upwind scheme (LUD) in (6) using the following graph:\n\nui\u22122 ui\u22121 ui ui+1 ui+2\n\n\u2212v/2\u2206x\n\n2v/\u2206x 2v/\u2206x\n\n\u2212v/2\u2206x\n\n2v/\u2206x\n\n\u2212v/2\u2206x\n\n2v/\u2206x\n\n7\n\n\n\nC Additional Experiments\n\nC.1 Gaussian Process prior results with DGAMGP\n\nA main property of the Mat\u00e9rn Gaussian Process kernel is that it varies along Riemannian manifolds.\nThe variance of the kernel is a function of degree, and depends on a complex manner on the graph.\nWe show the results generated with a star graph directed towards the center node and a directed\ncomplete graph. Figure 5(a) shows that as expected for the complete graph, the nodes have the\nsame variability, since for a random walk starting from any node, there is equal probability to get to\nanother node. For the star graph in Figure 5(b), we observe that the center node has a variability of\napproximately 0 as starting from any node on the graph, the random walk always ends at the center.\n\n(a) complete graph prior. (b) star graph prior.\n\nFigure 5: Prior results using DGAMGP obtained using various graphs, and plotting tools from [2].\n\nC.2 Convergence Studies\n\nWe conduct a convergence study of applying Ladv on the upwind graph in Figure 2(a), and show that\nit has first order convergence matching the performance of the equivalent first order upwind scheme.\nWe use the same initial condition as in Figure 1. We then solve the resulting system of ODEs using\nthe RK5 ODE solver. Figure 6(a) shows the solution at different time steps, and we see how the\nsolution is propagating to the right. Figure 6(b) shows a loglog plot, where the error is decreasing\nlinearly with a slope of 1 as the number of nodes n is increasing, as expected.\n\n(a) Solution of the linear advection equation using (2) (b) Convergence study in a log-log plot\n\nFigure 6: Upwinding solution with RK5 to the linear advection equation over time and corresponding\nconvergence study.\n\n8\n\n\n\t1 Introduction\n\t2 Understanding the directed graph advection operator\n\t3 Directed Graph Advection Mat\u00e9rn Gaussian Process (DGAMGP)\n\t4 Numerical Results\n\t5 Conclusions\n\tReferences\n\tA Upwinding discretizations of linear advection\n\tB Examples of Ladv on balanced graphs resulting in finite difference discretizations of linear advection\n\tC Additional Experiments\n\tC.1 Gaussian Process prior results with DGAMGP\n\tC.2 Convergence Studies\n\n\n"}
{"Title": "Time-Dependent Duhamel Renormalization method with Multiple Conservation and Dissipation Laws", "Authors": "Sathyanarayanan Chandramouli, Aseel Farhat, Ziad Musslimani", "Abstract": "  The time dependent spectral renormalization (TDSR) method was introduced by Cole and Musslimani as a novel way to numerically solve initial boundary value problems. An important and novel aspect of the TDSR scheme is its ability to incorporate physics in the form of conservation laws or dissipation rate equations. However, the method was limited to include a single conserved or dissipative quantity. The present work significantly extends the computational features of the method with the (i) incorporation of multiple conservation laws and/or dissipation rate equations, (ii) ability to enforce versatile boundary conditions, and (iii) higher order time integration strategy. The TDSR method is applied on several prototypical evolution equations of physical significance. Examples include the Korteweg-de Vries (KdV), multi-dimensional nonlinear Schr\u00f6dinger (NLS) and the Allen-Cahn equations.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00002", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE\nCONSERVATION AND DISSIPATION LAWS\n\nSATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nABSTRACT. The time dependent spectral renormalization (TDSR) method was introduced by Cole and Musslimani as\na novel way to numerically solve initial boundary value problems. An important and novel aspect of the TDSR scheme\nis its ability to incorporate physics in the form of conservation laws or dissipation rate equations. However, the method\nwas limited to include a single conserved or dissipative quantity.\n\nThe present work significantly extends the computational features of the method with the (i) incorporation of multiple\nconservation laws and/or dissipation rate equations, (ii) ability to enforce versatile boundary conditions, and (iii) higher\norder time integration strategy. The TDSR method is applied on several prototypical evolution equations of physical\nsignificance. Examples include the Korteweg-de Vries (KdV), multi-dimensional nonlinear Schro\u0308dinger (NLS) and the\nAllen-Cahn equations.\n\nKeywords: Renormalization method, initial boundary value problems, partial differential equations, Duhamel\u2019s\nprinciple, nonlinear waves, soliton equations, Hamiltonian and dissipative systems.\n\n1. INTRODUCTION\n\nNumerical simulation of initial boundary value problems is of utmost importance in several engineering and\nscientific disciplines. Over the last few decades, several time-stepping methods have been developed and proposed\nto achieve this goal. Among them are the class of implicit/explicit Runge-Kutta methods [35], exponential time-\ndifferencing [12, 25, 37, 43] and the split-step operator splitting [40] to name a few. For evolution equations that\narise in physical applications, it is highly desirable to devise time-stepping schemes that reflect the underlying\nphysics at hand. Such structure preserving numerical schemes are of paramount importance for long-time integra-\ntion, where either it is necessary to ensure numerical stability (e.g., if the numerics could conserve the L2 norm of\nthe solution for the KdV/NLS), or preserve other features (such as capturing the correct shock speed in the con-\ntext of systems of hyperbolic partial differential equations).To date, there are various ways to input some physics\ninto the numerical time-integration. For example, the geometric/symplectic integrators that preserve the Hamil-\ntonian and symplectic structure [18], the operator splitting method that was used for the NLS equation to preserve\nthe power and the non-linear dispersion relation [40], the multi-symplectic schemes designed for the generalized\nSchro\u0308dinger equations [21\u201323], the Taha-Ablowitz [38], the Ablowitz-Ladik [6], and the Ablowitz-Musslimani\n[2, 4] schemes that preserve the integrable structure of the KdV, NLS and class of nonlocal NLS equations, re-\nspectively. Other relevant works correspond to the conservative finite volume Godunov schemes [16, 19, 28],\nfinite difference schemes that preserve the energy or dissipation property of the underlying model equation (see,\ne.g.,[15, 36]), as well as a finite volume scheme that conserve mass and momentum of the KdV equation (see, e.g.,\n[13]). Recently, Cole and Musslimani [11] proposed an alternative method to simulate dynamical systems that\nenables the inclusion of physics \u201con-demand\u201d. The core idea is to make use of the Duhamel\u2019s principle to recast\nthe underlying evolution equation as a space-time integral equation. The resulting system is then solved iteratively\nusing a novel time-dependent renormalization process that controls both the numerical convergence properties of\nthe scheme while at the same time preserving a single physical law.\n\nIn this paper, we extend the time-dependent spectral renormalization method to allow for multiple conserva-\ntion laws or dissipation rates to be simultaneously incorporated in the simulation. This is achieved by introducing\nas many time-dependent renormalization factors as the number of conservation/dissipation laws being enforced.\nThe solution sought is then written as a linear superposition of finite number of space-time dependent auxiliary\nwave functions with the time-dependent renormalization factors envisioned to play the role of \u201cexpansion coeffi-\ncients\u201d. When inserted into the corresponding Duhamel\u2019s formula, a finite set of \u201csub-Duhamel\u201d integral equations\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n2v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 1\n\n9 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nare obtained governing the space-time dynamics of each individual auxiliary function. These integral equations\nare then numerically solved using a novel space-time fixed point iteration. The importance of such a dynamic\nrenormalization process are twofold: (i) it provides convergence when needed and (ii) enables the inclusion of\nconservation/dissipation laws. The Duhamel integrals are numerically computed using a Cauchy-Filon-Simpson\nquadrature formula. The TDSR method is implemented on several prototypical evolution equations of physical\nsignificance. This includes the KdV, Allen-Cahn, multi-dimensional and the PT symmetric integrable nonlocal\nNLS equations.\n\nThe paper is organized as follows. In Sec. 2 we put forward a general framework for the TDSR scheme in\narbitrary space dimensions and show how to incorporate multiple conservation laws or dissipation rate equations\ninto the algorithm. The Cauchy-Filon Simpson time integration is derived in Sec. 3.1 for evolution equations\nsubject to either periodic or rapidly decaying boundary conditions. The TDSR scheme is applied on the KdV\nand NLS equations, with single and multiple conservation laws. In Sec. 3.2 the Cauchy-Filon trapezoidal time\nintegration is developed for evolution equations subject to non-periodic and non decaying boundary conditions. In\nthis regard, the Allen-Cahn equation is used as a test bed to assess the performance of the algorithm. We conclude\nin Sec. 7 with comments on future directions.\n\n2. TDSR AND DUHAMEL PRINCIPLE\n\nIn this section, we formulate the TDSR method using Duhamel\u2019s principle in conjunction with multiple conser-\nvation laws. Consider the evolution equation for the real (or complex) valued function u(x, t):\n\nut = L (u)+N (u), u(x,0) = u0(x), (2.1)\n\nwhere L is a linear, constant coefficient differential operator and N (u) is a nonlinear operator. The initial-\nboundary value problem (2.1) is posed on a spatial domain \u2126 that is either bounded or unbounded. Furthermore,\nEq. (2.1) is supplemented with either periodic, rapidly decaying, or other types of boundary conditions. As men-\ntioned above, we are interested in evolution equations that are either (i) conservative, in which case, there exists N\nconserved quantities given by\n\nQm(u)\u2261\n\u222b\n\n\u2126\n\nQm[u(x, t)]dx =\n\u222b\n\n\u2126\n\nQm[u0(x)]dx\u2261Cm , m = 1,2,3, \u00b7 \u00b7 \u00b7N, (2.2)\n\nor (ii) dissipative, so that there are N densities \u03c1m and fluxes Fm that obey the rate equations\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m[u(x, t)]dx =\u2212\n\u222b\n\n\u2126\n\nFm[u(x, t)]dx , m = 1,2,3, \u00b7 \u00b7 \u00b7 ,N. (2.3)\n\nEquation (2.1) is rewritten in an integral form using the Duhamel\u2019s principle:\n\nu(x, t) = etL [u0(x)]+\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [u(x,\u03c4)]d\u03c4. (2.4)\n\nRecall that for any periodic or L2 function w(x), the semi-group etL admits the spectral representation:\n\netL [w(x)] = F\u22121[exp(tL\u0302 )F [w(x)]], (2.5)\n\nwhere L\u0302 is the Fourier symbol associated with L and F , F\u22121 denote the d-dimensional forward and inverse\nFourier transforms, defined by\n\nw\u0302(k)\u2261F [w(x)] = (2\u03c0)\u2212d/2\n\u222b\nRd\n\nw(x)e\u2212ik\u00b7xdx, (2.6)\n\nF\u22121[w\u0302(k)] = (2\u03c0)\u2212d/2\n\u222b\nRd\n\nw\u0302(k)eik\u00b7xdk. (2.7)\n\nFor periodic functions defined on a bounded spatial domain the forward Fourier integral (2.6) represents the coef-\nficients of its Fourier series.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 3\n\nWe now outline in details how to incorporate multiple conservation laws or dissipation rate equations in the\nTDSR scheme. To this end, we seek a solution to Eq. (2.4) in the form\n\nu(x, t) =\nN\n\n\u2211\nj=1\n\nR j(t)v j(x, t), (2.8)\n\nwhere R j(t) are time-dependent renormalization factors to be determined from knowledge of the conservation or\ndissipation laws and v j(x, t) are space-time dependent auxiliary functions that satisfy the same boundary conditions\nas the solution u(x, t). Our extensive numerical experiments seem to indicate that in order for the TDSR iteration\nto converge, the initial condition u0(x) needs to be re-written as a sum of N (identically non-zero) functions f j(x)\n(here referred to as pseudo initial conditions). Namely, we write\n\nu0(x) =\nN\n\n\u2211\nj=1\n\nf j(x), (2.9)\n\nwhere each f j is chosen to be compatible with the underlying boundary conditions. The specific choice of the\nfunctions { f j(x)}, j = 1,2, \u00b7 \u00b7 \u00b7 ,N, is discussed in Sec. (5) when solving the KdV equation. Substituting Eqns. (2.8)\nand (2.9) into (2.4), we obtain an equation for the auxiliary functions v j(x, t), j = 1,2, \u00b7 \u00b7 \u00b7N:\n\nN\n\n\u2211\nj=1\n\nR j(t)v j(x, t) =\nN\n\n\u2211\nj=1\n\netL [ f j(x)]+\n\u222b t\n\n0\ne(t\u2212\u03c4)L N\n\n[\nN\n\n\u2211\nj=1\n\nR j(\u03c4)v j(x,\u03c4)\n\n]\nd\u03c4. (2.10)\n\nScrutinizing Eq. (2.10) reveals the existence of N\u22121 degrees of freedom for the variables v1,v2, \u00b7 \u00b7 \u00b7 ,vN\u22121. Next,\nwe outline how to eliminate each degree of freedom and derive a self-consistent set of equations that forms the\nbasis for the TDSR scheme. To begin with, we choose v1(x, t) such that\n\nv1(x, t) = M1[R1,v1]\u2261\n1\n\nR1(t)\n\n{\netL [ f1(x)]+\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)]d\u03c4\n\n}\n. (2.11)\n\nThe rationale behind this choice is rooted in the fact that Eq. (2.11) must reduce back to the case when only\none conservation or dissipation law is under consideration with f1(x) \u2261 u0(x). With this at hand, we next require\nv2(x, t) to satisfy\n\nv2(x, t) = M2[R1,R2,v1,v2]\n\n\u2261 1\nR2(t)\n\n(\netL [ f2(x)]+\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)+R2(\u03c4)v2(x,\u03c4)]d\u03c4\n\n)\n\u2212 1\n\nR2(t)\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [R1(\u03c4)v1(x,\u03c4)]d\u03c4, (2.12)\n\nand for general j = 3,4, \u00b7 \u00b7 \u00b7 ,N,\n\nv j(x, t) = M j[R1,R2, \u00b7 \u00b7 \u00b7 ,R j;v1,v2, \u00b7 \u00b7 \u00b7 ,v j] (2.13)\n\n\u2261 1\nR j(t)\n\netL [ f j(x)]+\n1\n\nR j(t)\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N\n\n[\nj\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]\nd\u03c4\n\n\u2212 1\nR j(t)\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N\n\n[\nj\u22121\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]\nd\u03c4,\n\n\n\n4 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nNote that Eqns. (2.11)-(2.13) are self-consistent with the Duhamel\u2019s formula (2.10). Indeed, multiplying (2.12)\nby R2 and (2.13) by R j and summing over all j = 2,3, \u00b7 \u00b7 \u00b7 ,N, we obtain\n\nN\n\n\u2211\nj=2\n\nR j(t)v j(x, t) = etL\n\n[\nN\n\n\u2211\nj=2\n\nf j(x)\n\n]\n\n+\n\u222b t\n\n0\ne(t\u2212\u03c4)L\n\nN\n\n\u2211\nj=2\n\n{\nN\n\n[\nj\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]}\nd\u03c4\n\n\u2212\n\u222b t\n\n0\ne(t\u2212\u03c4)L\n\nN\n\n\u2211\nj=2\n\n{\nN\n\n[\nj\u22121\n\n\u2211\n`=1\n\nR`(\u03c4)v`(x,\u03c4)\n\n]}\nd\u03c4. (2.14)\n\nThe last two terms on the right hand side of Eq. (2.14) satisfy\u222b t\n0 d\u03c4e(t\u2212\u03c4)L\n\n\u2211\nN\nj=2\n\n{\nN\n[\n\u2211\n\nj\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]\n\u2212N\n\n[\n\u2211\n\nj\u22121\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]}\n=\n\u222b t\n\n0 d\u03c4e(t\u2212\u03c4)L N\n[\n\u2211\n\nN\n`=1 R`(\u03c4)v`(x,\u03c4)\n\n]\n\u2212N [R1(\u03c4)v1(x,\u03c4)]. (2.15)\n\nThe conclusion is complete once we multiply Eq. (2.11) by R1(t); add the result to Eq. (2.15) and use the condition\n(2.9). In summary, Eqns. (2.11)-(2.13) give an implicit integral representation for the auxiliary functions v j. To\nclose the system, all we need is to compute the renormalization factors R j(t). Substituting Eq. (2.8) into Eqns. (2.2)\nand (2.3) gives:\n\nConservative case:\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n)\n\u2261\n\u222b\n\n\u2126\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n)\ndx =Cm, (2.16)\n\nDissipative case:\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m\n\n[\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\ndx =\u2212\n\n\u222b\n\u2126\n\nFm\n\n[\nN\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\ndx, (2.17)\n\nwhere m = 1,2, \u00b7 \u00b7 \u00b7 ,N. System (2.16) defines N algebraic equations for the time-dependent renormalization factors\nwhereas (2.17) a set of coupled nonlinear ordinary differential equations governing the evolution of R j(t). With\nthis at hand, the TDSR iterative process is summarized below:\n\nv(n+1)\n1 = M1[R\n\n(n)\n1 (t),v(n)1 ], (2.18)\n\nv(n+1)\n2 = M2[R\n\n(n)\n1 ,R(n)\n\n2 ,v(n)1 ,v(n)2 ], (2.19)\n\nv(n+1)\nj = M j[R\n\n(n)\n1 ,R(n)\n\n2 , \u00b7 \u00b7 \u00b7 ,R(n)\nj ,v(n)1 ,v(n)2 , \u00b7 \u00b7 \u00b7 ,v(n)j ] , j = 3, \u00b7 \u00b7 \u00b7 ,N, (2.20)\n\nwith R(n)\nj , j = 1,2, \u00b7 \u00b7 \u00b7 ,N given by (for conservative cases)\n\nQm\n\n(\nN\n\n\u2211\n`=1\n\nR(n)\n` (t)v(n)` (x, t)\n\n)\n\u2261Cm , (2.21)\n\nand\n\nd\ndt\n\n\u222b\n\u2126\n\n\u03c1m\n\n[\nN\n\n\u2211\n`=1\n\nR(n)\n` (t)v(n)` (x, t)\n\n]\ndx =\u2212\n\n\u222b\n\u2126\n\nFm\n\n[\nN\n\n\u2211\n`=1\n\nR(n)\n` (t)v(n)` (x, t)\n\n]\ndx, (2.22)\n\nfor the dissipative cases where m = 1,2, \u00b7 \u00b7 \u00b7 ,N. As a reminder, the functionals M1 and M j, j = 2,3, \u00b7 \u00b7 \u00b7 ,N are\nrespectively defined by Eqns. (2.11) - (2.13). A workflow for the TDSR algorithm is given below, clarifying the\nstructure of the iterative process:\n\n(1) Choose the pseudo initial conditions: The set of pseudo initial conditions f j(x), j = 1,2, \u00b7 \u00b7 \u00b7 N, are\nchosen in such a way that Eq. (2.9) is satisfied (see Sec.5 for further details). Note that they are used in\nthe Picard iterations defined by Eqs. (2.11)-(2.13).\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 5\n\n(2) Select initial guesses v(1)j (x, t) for j = 1,2, \u00b7 \u00b7 \u00b7 ,N: We seed Eqs. (2.11)-(2.13) with these initial guesses\nfor the space-time dependent auxiliary functions.\n\n(3) Compute the initial iterate of the set of renormalization factors: The set of auxiliary functions are used\nto evaluate the time-dependent renormalization factors R(1)\n\nj (t) , j = 1,2, \u00b7 \u00b7 \u00b7 ,N via the system of equations\n(2.21) or (2.22) depending on whether the underlying evolution equation is conservative or dissipative.\n\n(4) Compute the Duhamel integrals defined in Eqs. (2.18)-(2.20): The Duhamel integrals are computed\nusing v(1)j (x, t) and R(1)\n\nj (t), for j = 1,2, \u00b7 \u00b7 \u00b7 ,N.\n(5) Update the Duhamel iteration: The Duhamel integrals computed in the previous step are now used to\n\ncompute the second iterate of v(2)j (x, t) using Eqs. (2.18)-(2.20).\n\n(6) Update the renormalization factors: The updated {v(2)j (x, t)}\u2019s are now used to correct the the set of\n\nrenormalization factors {R(2)\nj (t)} , j = 1,2, \u00b7 \u00b7 \u00b7 ,N; from the system of equations given by (2.21) (for the\n\nconservative case), or (2.22) (for the dissipative case).\n(7) Iterative update: Repeat steps (5) and (6) till convergence is achieved.\n\n3. TIME INTEGRATION WITH VARIOUS BOUNDARY CONDITIONS\n\n3.1. Periodic and decaying boundary conditions. In this section, we detail the numerical approach used to\napproximate the Duhamel integral\n\nI(x, t)\u2261\n\u222b t\n\n0\ne(t\u2212\u03c4)L G(x,\u03c4)d\u03c4, (3.1)\n\nwith G(x,\u03c4) \u2261N [u(x,\u03c4)]. When subject to periodic or rapidly decaying boundary conditions, the action of the\nsemi-group exp(tL ) on G follows from its spectral representation F [exp(tL )G] = exp[tL\u0302 ]F [G] where L\u0302 is\nthe Fourier symbol associated with the constant coefficients linear operator L . Our approach in approximating the\nintegral Eq. (3.1) is based on the Filon-Simpson quadrature method [9, 20, 34]. To this end, we consider an NT\nequally spaced mesh points residing inside the time interval [0,T ] with ti = i\u2206t, i = 0,1,2, \u00b7 \u00b7 \u00b7 ,NT , labeling all grid\npoints. It can be shown that I\u0302(k, ti) satisfies the exact recurrence relation\n\nI\u0302(k, ti+1) = e2\u2206tL\u0302 (k)\n[\n\nI\u0302(k, ti\u22121)+\n\u222b ti+1\n\nti\u22121\n\ne(ti\u22121\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\n\n]\n. (3.2)\n\nAs a reminder, a hat over a quantity represents its Fourier transform (see definition (2.6)) or its Fourier series\ncoefficients. Next, we approximate the function G\u0302(k,\u03c4) by a quadratic polynomial defined in the interval [ti\u22121, ti+1]\n\nG\u0302(k,\u03c4) \u2248 G\u0302(k, ti\u22121)\n(\u03c4\u2212 ti)(\u03c4\u2212 ti+1)\n\n2(\u2206t)2 \u2212 G\u0302(k, ti)\n(\u03c4\u2212 ti\u22121)(\u03c4\u2212 ti+1)\n\n(\u2206t)2\n\n+ G\u0302(k, ti+1)\n(\u03c4\u2212 ti\u22121)(\u03c4\u2212 ti)\n\n2(\u2206t)2 . (3.3)\n\nSubstituting Eq. (3.3) back into (3.2) and integrating by parts gives a recursive formula for the Duhamel integral\n(3.1):\n\nI\u0302(k, ti+1) = e2\u2206tL\u0302 (k)[I\u0302(k, ti\u22121)+q1G\u0302(k, ti\u22121)+q2G\u0302(k, ti)+q3G\u0302(k, ti+1)]. (3.4)\nThe quadrature coefficients q j \u2261 q j(k,\u2206t), j = 1,2,3, depend on the Fourier wavenumber and the time step \u2206t but\nnot on the iteration index i. Thus, they are computed only once. The exact expressions for the q j\u2019s, j = 1,2,3, are\ngiven by (z\u2261 \u2206tL\u0302 (k))\n\nq1 = \u2206t(\u2212ze\u22122z\u22122e\u22122z +2z2\u22123z+2)/(2z3), (3.5a)\n\nq2 = \u2206t(2ze\u22122z +2e\u22122z +2z\u22122)/z3, (3.5b)\n\nq3 = \u2206t(\u22122z2e\u22122z\u22123ze\u22122z\u22122e\u22122z\u2212 z+2)/(2z3). (3.5c)\n\nFor linear operators satisfying L\u0302 (0) = 0 we find (in the limiting case k\u2192 0), q1(0,\u2206t) = q2(0,\u2206t)/4= q3(0,\u2206t)\u2261\n\u2206t/3. Equation (3.4) needs to be initialized with I\u0302(k, t = 0)= 0 and the quantity I\u0302(k,\u2206t)=\n\n\u222b\n\u2206t\n0 e(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\n\n\n\n6 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nwhich we next explain how to find. Note that in the interval [0,\u2206t], the values (in time) of the function G\u0302(k,\u03c4)\nare available only at two grid points: 0 and \u2206t. To maintain the same order of accuracy as was done at the other\ntemporal grid points, we apply a combination of two different quadrature rules to approximate I\u0302(k,\u2206t). First,\nconsider the following identity:\u222b 3\u2206t\n\n0\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4 =\n\n\u222b\n\u2206t\n\n0\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4\ufe38 \ufe37\ufe37 \ufe38\n\nI\u0302(k,\u2206t)\n\n+\n\u222b 3\u2206t\n\n\u2206t\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4. (3.6)\n\nThe second integral on the right-hand side of Eq. (3.6) is computed using a quadratic interpolation (in time) for\nG\u0302(k,\u03c4). Indeed, after some algebra, we find\u222b 3\u2206t\n\n\u2206t\ne(\u2206t\u2212\u03c4)L\u0302 (k)G\u0302(k,\u03c4)d\u03c4 \u2248 q1G\u0302(k,\u2206t)+q2G\u0302(k,2\u2206t)+q3G\u0302(k,3\u2206t). (3.7)\n\nTo obtain a similar order of accuracy for the integral on the left hand side of Eq. (3.6), we first represent G\u0302(k,\u03c4) as\na cubic polynomial (in time)\n\nG\u0302(k,\u03c4) \u2248 \u2212G\u0302(k,0)\n(\u03c4\u2212\u2206t)(\u03c4\u22122\u2206t)(\u03c4\u22123\u2206t)\n\n6(\u2206t)3 + G\u0302(k,\u2206t)\n\u03c4(\u03c4\u22122\u2206t)(\u03c4\u22123\u2206t)\n\n2(\u2206t)3\n\n\u2212 G\u0302(k,2\u2206t)\n\u03c4(\u03c4\u2212\u2206t)(\u03c4\u22123\u2206t)\n\n2(\u2206t)3 + G\u0302(k,3\u2206t)\n\u03c4(\u03c4\u2212\u2206t)(\u03c4\u22122\u2206t)\n\n6(\u2206t)3 . (3.8)\n\nSubstituting expressions (3.8) and (3.7) into Eq. (3.6) gives (after integration by parts)\n\nI\u0302(k,\u2206t) = q4e\u2206tL\u0302 (k)G\u0302(k,0)+\n(\n\nq5e\u2206tL\u0302 (k)\u2212q1\n\n)\nG\u0302(k,\u2206t) (3.9)\n\n+\n(\n\nq6e\u2206tL\u0302 (k)\u2212q2\n\n)\nG\u0302(k,2\u2206t)+\n\n(\nq7e\u2206tL\u0302 (k)\u2212q3\n\n)\nG\u0302(k,3\u2206t).\n\nHere, q j \u2261 q j(k,\u2206t), j = 4,5,6,7, denote the quadrature coefficients whose expressions are given by\n\nq4 = \u2206t(2z2e\u22123z +6ze\u22123z +6e\u22123z +6z3 +12z\u221211z2\u22126)/(6z4), (3.10a)\n\nq5 = \u2206t(\u22123z2e\u22123z\u22128ze\u22123z\u22126e\u22123z +6z2\u221210z+6)/(2z4), (3.10b)\n\nq6 = \u2206t(6z2e\u22123z +10ze\u22123z +6e\u22123z\u22123z2 +8z\u22126)/(2z4), (3.10c)\n\nq7 = \u2206t(\u22126z3e\u22123z\u221211z2e\u22123z\u221212ze\u22123z\u22126e\u22123z +2z2\u22126z+6)/(6z4). (3.10d)\n\nFor linear operators satisfying L\u0302 (0)= 0, and for wavenumber k\u2192 0, q4(0,\u2206t)= q7(0,\u2206t)\u2261 3\u2206t/8, and q5(0,\u2206t)=\nq6(0,\u2206t)\u2261 9\u2206t/8. To summarize, the Duhamel integral I(x, t) is determined from iterating Eq. (3.4) subject to the\ninitial conditions: I(x,0) = 0 and I(x,\u2206t) given in Fourier space by Eq. (3.9). Note that in some cases, the Filon\ncoefficients q j may exhibit a removable singularity in the variable z \u2261 \u2206tL\u0302 (k) at zero wave number that could\ntrigger numerical instability. To remedy this, we represent each quadrature term as a Cauchy integral that allows a\nstable and uniform approximation valid for all wavenumbers. This idea has been first implemented in the context\nof exponential time differencing fourth order Runge-Kutta (ETDRK4) [25]. For the sake of completeness, we\nshow how to implement this approach on the coefficient q1. The computation of the other quadrature coefficients\nfollow similar derivation. Since the function q1(\u03b6 ;\u2206t) is analytic in the \u03b6 complex plane, by the Cauchy integral\nformula we have\n\nq1(z;\u2206t) =\n1\n\n2\u03c0i\n\n\u222b\nC\n\nq1(\u03b6 ;\u2206t)\n\u03b6 \u2212 z\n\nd\u03b6 , (3.11)\n\nwhere C is a circle of constant radius centered at z. The above integral can be evaluated to spectral accuracy with\nthe use of the trapezoidal quadrature [14, 25].\n\n3.2. Time integration: non-periodic boundary conditions. So far, we have discussed the development and\napplication of the TDSR method to evolution equations subject to periodic or localized boundary conditions. Here,\nwe intend to extend the TDSR scheme to allow for non-periodic and non-decaying boundary conditions where the\nuse of Fourier analysis is not applicable. In such circumstances the matrix approximating the linear operator could\nbe banded (as is the case with finite differences) or dense, for example, in case of Chebyshev spectral method.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 7\n\nThe derivation of the Duhamel formula follows similar steps as outlined in Sec.2 with the exception of the use\nof trapezoidal scheme instead of Simpson. Using a Chebyshev basis function or other discretization methods we\nrepresent the differential operator L in Eq. (3.1) by a finite dimensional matrix L. The boundary conditions are\nincorporated within the matrix L. By creating a mesh in time domain, Eq.(3.1) can be put in the recursive form\n\nI(ti+1) = e\u2206tLI(ti)+ e\u2206tL\n\u222b ti+1\n\nti\ne(ti\u2212\u03c4)LG(\u03c4)d\u03c4, (3.12)\n\nwhere now I(ti) is the matrix representing the Duhamel integral at space meshgrid x and time level ti. Additionally,\nG(ti) is the matrix representing the nonlinear terms at ti = i\u2206t with i = 0,1, \u00b7 \u00b7 \u00b7NT . Using a linear interpolant to\napproximation G(\u03c4) in the interval [ti, ti+1] we find\n\nG(\u03c4)\u2248G(ti)+\nG(ti+1)\u2212G(ti)\n\n\u2206t\n(\u03c4\u2212 ti). (3.13)\n\nSubstituting Eq.(3.13) into (3.12) we obtain after some algebra\n\nI(ti+1) = e\u2206tL[I(ti)+AG(ti)+BG(ti+1)], (3.14)\n\nwhere the matrix valued quadrature coefficients A\u2261 A(L,\u2206t) and B\u2261 B(L,\u2206t) are defined by\n\nA\u2261 \u2206tA\u0303, A\u0303 = L\u0303\u22122\n(\n\ne\u2212L\u0303 + L\u0303\u2212I\n)\n, (3.15)\n\nB\u2261 \u2206tB\u0303, B\u0303 = L\u0303\u22122\n(\nI \u2212 L\u0303e\u2212L\u0303\u2212 e\u2212L\u0303\n\n)\n, (3.16)\n\nwith I being the identity matrix and L\u0303\u2261 \u2206tL. As was done in Sec. 3.1 for the periodic case [25], we again adopt\nthe Cauchy integral formula to represent each quadrature coefficient as a contour integral in the complex plane.\nThus we write :\n\nA\u0303(L\u0303) =\n1\n\n2\u03c0i\n\n\u222b\n\u0393\n\nA\u0303(\u03b6 )(\u03b6I \u2212 L\u0303)\u22121d\u03b6 , B\u0303(L\u0303) =\n1\n\n2\u03c0i\n\n\u222b\n\u0393\n\nB\u0303(\u03b6 )(\u03b6I \u2212 L\u0303)\u22121d\u03b6 (3.17)\n\nwith \u0393 being a circular contour that encloses all the eigenvalues of L\u0303. The integral in Eq.(3.17) is computed to a\nspectral accuracy with the use of the trapezoidal rule.\n\n4. NUMERICAL IMPLEMENTATION OF TDSR: ONE CONSERVATION OR DISSIPATION LAW WITH VARIOUS\nBOUNDARY CONDITIONS\n\n4.1. The KdV equation. In this section, we use the KdV equation as a testbed PDE model to examine various\nnumerical aspects related to the TDSR method such as convergence, accuracy and dependence on initial guesses.\nThe KdV equation is given by:\n\nut +\u03b1uux + \u03b5\n2uxxx = 0, (4.1)\n\nwhere \u03b1,\u03b5 are real and positive numbers. When considered on the whole real line with rapidly decaying boundary\nconditions, Eq.(4.1) admits a one parameter family of soliton solution given by (e.g. \u03b1 = 6,\u03b5 = 1)\n\nuex(x, t) = 2\u03b2\n2sech2(\u03b2 (x\u22124\u03b2\n\n2t)), \u03b2 > 0. (4.2)\n\nIt is noteworthy that the KdV equation is an integrable dynamical system admitting infinitely many conservation\nlaws. Among them are the physically relevant mass, momentum and Hamiltonian given for \u03b1 = 6,\u03b5 = 1 by\nEq. (2.2) with Q1 = u, Q2 = u2 and Q3 = \u2212u3 + 1\n\n2 u2\nx , respectively. All numerical simulations reported in this\n\nsection were performed on a spatial domain of size L = 100 or L = 800 (depending on the case at hand) with\ncorresponding number of spatial grid points (Fourier modes) NS = 2048, NS = 16384 respectively and time interval\n[0,T ] with T = 5,10,20,30 or 60. In this section, the renormalization factors were computed by enforcing a single\nconservation law. Numerical convergence and accuracy were quantified by monitoring the error between two\nsuccessive iterations\n\nmax\nx,t\n|u(n+1)(x, t)\u2212u(n)(x, t)|,\n\n\n\n8 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nand the quantities\n\n\u03b4u(t)\u2261max\nx\n|u(x, t)\u2212uex(x, t)|, (4.3)\n\n\u03b4Q j(t)\u2261Q j[u(x, t)]\u2212Q j[u0(x)] , j = 1,2,3, (4.4)\n\nwhere u0(x) = 2\u03b2 2sech2(\u03b2x) is the initial condition associated with Eq. (4.1), for the parameters \u03b1 = 6,\u03b5 = 1,\nwhere uex(x, t) is the one-parameter soliton solution for the KdV given in Eq. (4.2). For all simulations reported\nhere, convergence tolerance was set near 1\u00d7 10\u221216. All functionals Q j, j = 1,2,3, are defined in Eq. (2.2). We\nperform numerical experiments on the KdV equation while conserving one of the following quantities: mass,\nmomentum, or Hamiltonian. The renormalization factor R(t) in each case, is given by:\n\nmass: R(t) =\nQ1[u0(x)]\nQ1[v(x, t)]\n\n, (4.5)\n\nmomentum: R(t) =\n(\n\nQ2[u0(x)]\nQ2[v(x, t)]\n\n)1/2\n\n, (4.6)\n\nHamiltonian: A(t)R3(t)\u2212B(t)R2(t)\u2212C3 = 0, (4.7)\n\nwhere A(t) =\u2212\n\u222b\nR v3(x, t)dx, B(t) =\u2212 1\n\n2\n\u222b\nR v2\n\nx dx and C3 is the initial value of the Hamiltonian. All spatial integrals\nare computed to spectral accuracy with the use of fast Fourier transform. We initialize the TDSR algorithm with\na space-time random function v(1)(x, t) constructed by superimposing several Gaussians each being centered at a\nrandom location and having a random time-dependent amplitude. The centers and amplitudes are sampled from\na uniform distribution on the interval [\u2212L/2,L/2] and [\u22121,1] respectively. To ensure the initial guess v(1)(x, t)\nsatisfies the underlying boundary conditions, we mollify it with \u03c7(x). Thus, we have\n\nv(1)(x, t) =\n\u2211\n\nNG\nn=1 an(t)exp\n\n[\n\u2212\n( x\u2212cn\n\nd\n\n)2]\nmaxx,t |\u2211NG\n\nn=1 an(t)exp\n[\n\u2212\n( x\u2212cn\n\nd\n\n)2]|\u03c7(x), (4.8)\n\nwhere NG denotes the number of Gaussians with cn and an(t) representing their centres and time-varying ampli-\ntudes and d is the width. Here, \u03c7(x) is the mollifier with unit peak amplitude defined by:\n\n\u03c7(x) =\n\n\uf8f1\uf8f2\uf8f3exp\n(\n\nb\na2 \u2212 b\n\na2\u2212x2\n\n)\n, if x \u2208 (\u2212a,a)\n\n0, if |x|> a,\n(4.9)\n\nwith arbitrary mollifier parameters a and b. As expected, the numerical result agrees well with the exact solution.\nIn generating Fig. 1, conservation of momentum is imposed in which case the renormalization parameter R(t) is\ncomputed from Eq. (4.6). One could instead reach the same conclusion by using a different dynamic renormal-\nization process emanating from either conservation of mass or Hamiltonian. This numerical experiment reveals\nthe simplistic (albeit powerful) nature of our proposed method as measured by its easy formulation, actual im-\nplementation, robustness to initial guesses and its ability to impose conservation laws \u201con-demand\u201d. To further\ncharacterize the numerical performance of the TDSR scheme, we have investigated its temporal convergence prop-\nerties by measuring the space-time maximum error between the numerically obtained solution to the KdV equation\n(relative to its exact solution) and all conservation laws, as quantified by Eqs. (4.3) and (4.4), as a decreasing func-\ntion of time step \u2206t. It is evident from Fig. 2(a) that the maximum (over time) error in the solution decreases at\na fourth order rate. This trend seems to persist independently of the choice of specific conservation law. When\nconservation of mass is imposed, the error in the Hamiltonian and momentum reduces with decreasing \u2206t. Similar\nscenarios occur when imposing conservation of momentum or Hamiltonian \u2013 see Fig. 2 (b)-(d). We remark that\nto conserve the Hamiltonian structure, we need to solve a cubic equation defined by Eq. (4.7). As such, there are\nthree possible expressions for the renormalization factor, of which only one is feasible. It turns out that the right\nexpression yields R(0)v(x,0) = u0(x) at any Duhamel iteration, while the other two roots violate this criterion.\nFinally, for cases where the renormalization factor satisfies an associated equation that lacks exact solution, one\nneeds to resort to a root finding algorithms such as the Newton\u2019s method. It is interesting to note that when it\ncomes to long time simulations, the TDSR performs optimally when imposing conservation of momentum rather\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 9\n\n0 5 10 15 20\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\nj/\nu\n(t\n\n)j\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n#10 -10 (c)\n\nFIGURE 1. (a) A random space-time initial guess constructed from a linear superposition of randomly\ncentered Gaussians with random amplitudes \u2013 see Eq.(4.8). (b) Numerical solution for the KdV equation\nobtained from the TDSR algorithm after 30 Duhamel iterations. Parameters are: T = 20,\u2206t = 0.025,L =\n100,NS = 2048 (Fourier modes). Here, the wave speed is 4\u03b2 2 = 2/5. This figure was generated by impos-\ning conservation of momentum for which the renormalization parameter R(t) is computed from Eq. (4.6).\nThe soliton initial condition is u0(x) = 2\u03b2 2sech2(\u03b2x) with \u03b1 = 6 and \u03b5 = 1. (c) Time evolution of the\nrelative error between the TDSR and the exact solution. Mollifier parameters are a = 0.95\u00d7 L\n\n2 , b = 1.\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -10\n\n10 -5\n\n10 0\n\nm\na\nx\n\ntj/\nu\n(t\n\n)j=\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n(a)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -30\n\n10 -15\n\n10 0\n\nm\nax\n\ntj/\nQ\n\n1\n(t\n\n)j=\njQ\n\n1\n[u\n\n0\n]j\n\n(b)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -15\n\n10 -10\n\n10 -5\n\nm\nax\n\ntj/\nQ\n\n2\n(t\n\n)j=\njQ\n\n2\n[u\n\n0\n]j\n\n(c)\n\n10 -2 10 -1 10 0\n\n\"t\n\n10 -15\n\n10 -10\n\n10 -5\n\n10 0\n\nm\nax\n\ntj/\nQ\n\n3\n(t\n\n)j=\njQ\n\n3\n[u\n\n0\n]j\n\n(d)\n\nFIGURE 2. The relative error in (a) TDSR solution, (b) mass, (c) momentum, and (d) Hamiltonian. Pa-\nrameters are T = 10, L = 100, NS = 2048. The renormalization factor R(t) is computed by enforcing either\nconservation of mass (red), momentum (green), or Hamiltonian (blue).\n\nthan mass or Hamiltonian. Indeed, we have tested the TDSR method on the long-time evolution of the 1-soliton so-\nlution for the KdV equation while conserving momentum (the L2 norm of the solution). The numerical experiment\nwas performed with parameters T = 240,\u2206t = 0.1875,NS = 4096,L = 300 using the idea of multi-blocking with\nMb = 8 time blocks (see remark below). The relative error in the solution, mass and Hamiltonian at end time were\nin the order of 10\u22126, 10\u22127 and 10\u221210 respectively, while the relative error in momentum remained near machine\nprecision.\nRemark: Below, we describe the idea of multi-blocking used when the time interval is too large for the renor-\nmalized Picard iterations to converge (this is not due to a CFL-type restriction prevalent in generic time-stepping\nschemes). The idea is to divide the full time interval [0,T ] into Mb sub-intervals such that [0,T ] = \u222aMb\n\ni=1[Ti\u22121,Ti]\nwith T0 = 0. For a fixed i, the quantity Ti\u2212Ti\u22121 is chosen sufficiently large so that the spectral renormalization\nalgorithm is efficient and convergent. On the first segment [0,T1], the solution of the TDSR scheme with the initial\ncondition u0(x) is obtained from the iteration:\n\nv(n+1)(x, t) =\n1\n\nR(n)(t)\n\n(\netL [u0(x)]+\n\n\u222b t\n\n0\ne(t\u2212\u03c4)L N [R(n)(\u03c4)v(n)(x,\u03c4)]d\u03c4\n\n)\n,\n\n\n\n10 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nwhile on the second segment [T1,T2], from:\n\nv(n+1)(x, t) =\n1\n\nR(n)(t)\n\n(\ne(t\u2212T1)L [u(x,T1)]+\n\n\u222b t\n\nT1\n\ne(t\u2212T1\u2212\u03c4)L N [R(n)(\u03c4)v(n)(x,\u03c4)]d\u03c4\n\n)\n.\n\nThe renormalization factor R(n)(t) (corresponding to a single conservation law) is obtained from\n\nQm\n\n(\nR(n)(t)v(n)(x, t)\n\n)\n=Cm.\n\nThis process is repeated Mb times until final time T is reached. It should be pointed out that the number of\nsegment Mb is chosen such that the Duhamel fixed point iteration, without renormalization, would diverge on any\ngiven sub interval [Ti\u22121,Ti].\n\n4.2. Zabusky-Kruskal experiment. Our goal in this section is to reproduce the well-known numerical results\nof Zabusky and Kruskal on the KdV equation [44] using our algorithm. Their simulation displays rich nonlinear\ndynamics which, as such, represents a challenge for numerical methods as far as the choice of time-steps, long-\ntime accuracy and stability are concerned [10, 13, 15, 36]. To this end, we apply the TDSR method on the KdV\nEq. (4.1) with \u03b1 = 1 and \u03b5 = 0.022 subject to periodic boundary conditions u(x+2, t) = u(x, t) and initial condition\nu0(x) = cos(\u03c0x). Figure 3 (a) shows the Zabusky-Kruskal results while rigorously conserving the momentum\u222b 2\n\n0 u2dx. We compare our findings with those obtained using the ETDRK4 method [25]. Note that, in order to keep\nthe level of solution accuracy of the ETDRK4 method comparable with that of the TDSR scheme while conserving\nmomentum, the time step \u2206tET D (of the ETDRK4) has to be about one order of magnitude lesser than its TDSR\ncounterpart (\u2206tT DSR). This can be seen by gradually reducing the relative time step (\u2206tr = \u2206tET D/\u2206tT DSR) while\nmonitoring the relative difference between the two numerical solutions. At \u2206tr = 0.125, this difference was seen to\ndrop to O(10\u22126). Using the same spatio-temporal discretization as before, we checked the TDSR results\u2019 fidelity\nup to 20 recurrence times. This was done, by monitoring the time evolution of the first six conserved quantities of\nthe KdV equation with \u03b1 = 1 and \u03b5 = 0.022 given by:\n\nQ1 = u, Q2 = u2\n\nQ3 =\u2212\nu3\n\n6\n+\n\n\u03b52u2\nx\n\n2\n, Q4 =\n\nu4\n\n4\n\u22123\u03b5\n\n2uu2\nx +\n\n9\u03b54u2\nxx\n\n5\n,\n\nQ5 =\nu5\n\n5\n\u22126\u03b5\n\n2u2u2\nx +\n\n36\u03b54uu2\nxx\n\n5\n\u2212 108\u03b56u2\n\nxxx\n\n35\n,\n\nQ6 =\nu6\n\n6\n\u221210\u03b5\n\n2u3u2\nx +18\u03b5\n\n4u2u2\nxx\u22125\u03b5\n\n4u4\nx\u2212\n\n108\u03b56uu2\nxxx\n\n7\n+\n\n120\u03b56u3\nxx\n\n7\n+\n\n36\u03b58u2\nxxxx\n\n7\n.\n\nClearly, the relative error in the momentum remains close to machine precision, while at the same time resulting\nin the conservation of the mass as well. This can be explained by considering the Fourier series representations of\nthe KdV solution u(x, t) = \u2211\n\n\u221e\nm=\u2212\u221e u\u0302m(t)ei\u03c0mx, and its corresponding auxiliary function v(x, t) = \u2211\n\n\u221e\nm=\u2212\u221e v\u0302m(t)ei\u03c0mx.\n\nWith this at hand, the (n+1)th renormalized Duhamel iterate takes the form:\n\nv\u0302(n+1)\nm (t) =\n\n1\nR(n)(t)\n\n(\nei\u03b52m3\u03c03t u\u0302m(0)\u2212\n\n\u222b t\n\n0\nei\u03b52m3\u03c03(t\u2212\u03c4) im\u03c0\n\n2\n\n\u221e\n\n\u2211\nl=\u2212\u221e\n\nu\u0302(n)l u\u0302(n)m\u2212ld\u03c4\n\n)\n(4.10)\n\nwhere (R(n)(t))2 =C2/\n\n(\u222b 2\n0\n\n(\nv(n)(x, t)\n\n)2\ndx\n)\n\n. Substituting m = 0 in Eq. (4.10), we obtain:\n\nv\u0302(n+1)\n0 (t) =\n\nu\u03020(0)\nR(n)(t)\n\n. (4.11)\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 11\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\nu\n\n(b)\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\nu\n\n(c)\n\nTDSR\nETDRK4\n\n0 0.5 1 1.5 2\nx\n\n-1\n\n-0.5\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nu\n\n(e)\n\nFIGURE 3. (a) Space-time contour plot for the KdV solution with \u03b1 = 1,\u03b5 = 0.022 and initial condition\nu(x,0) = cos(\u03c0x). Other parameters are \u2206t \u2248 0.0008, L = 2, NS = 256 and the time block size T1 \u2248 0.016\n(multi-blocking with Mb sub-intervals of equal size). (b) The solution at T = 3.6/\u03c0 depicting the fission\nof the initial condition into an eight soliton train. (c) The solution at one recurrence time T = tR = 30.4/\u03c0\n\nobtained via TDSR Simpson showing good agreement with the fourth-order accurate (in time) ETDRK4\nsolution. A time step of \u2206t = 0.0001 (for the ETDRK4 scheme) was used to obtain a solution of comparable\naccuracy to ours. (d) A space-time contour plot for the solution obtained from the TDSR algorithm using\nthe same spatio-temporal discretization as in (a), over the time span [19tR,20tR]. The stable numerical\nsimulation produced accurate results, as evidenced by the minor relative errors in the first six conserved\nquantities (see Fig. 4). (e) The solution at T = 20tR obtained using TDSR Simpson.\n\nUsing the identity u\u0302(n+1)\n0 (t) = R(n+1)(t)v\u0302(n+1)\n\n0 (t) we find\n\nu\u0302(n+1)\n0 (t) =\n\n\u221a\u221a\u221a\u221a\u221a\u221a\n\u222b 2\n\n0\n\n(\nv(n)(x, t)\n\n)2\ndx\u222b 2\n\n0\n\n(\nv(n+1)(x, t)\n\n)2\ndx\n\nu\u03020(0). (4.12)\n\nFor the initial condition considered here u0(x) = cos(\u03c0x), one finds u\u03020(0) = 0, resulting in u\u0302(n+1)\n0 (t) \u2261 0, i.e.,\n\nthe mass is also preserved at every Duhamel iterate. Additionally, the relative errors of the other four conserved\nquantities are within O(10\u22125). In particular, some aspects of our scheme (such as solution accuracy) outperforms\nother well known conservative numerical methods to simulate the KdV equation, such as the one developed in [13].\nIn [13], the authors develop an operator splitting scheme in conjunction with a finite volume spatial discretization\nto locally conserve the mass and momentum. While their scheme demonstrates impressive long time stability\nproperties (Zabusky-Kruskal dynamics), there were some phase errors at T = 20tR, that arise from the global\n(absolute) errors in the conservation of the Hamiltonian (\u223c 10\u22123).\n\nPresently, it is unclear if there are other finite volume based schemes capable of incorporating more than two\nconserved quantities for the KdV equation. Also, it is worth to mention that the ETDRK4 scheme (which does not\nconserve momentum at the local or global level for the KdV), suffers from numerical instabilities (for \u2206t \u2248 0.0008)\nand for time integration up to T = 20tR.\n\nFinally, we examine the performance of the TDSR method by measuring the local errors in the mass and\nmomentum. Specifically, we compute the errors for mass and momentum at end time T = 20tR respectively\ndefined by\n\nE1(x,T ) = ut +\u03b1uux + \u03b5\n2uxxx, (4.13)\n\n\n\n12 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n50 100 150 200\n0\n\n0.5\n\n1\n\n1.5\n\nj/\nQ\n\n1\n(t\n\n)j\n\n#10 -15 (a)\n\n50 100 150 200\n2\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\nj/\nQ\n\n2\n(t\n\n)j=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -16 (b)\n\n50 100 150 200\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\nj/\nQ\n\n3\n(t\n\n)j=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -5 (c)\n\n50 100 150 200\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\nj/\nQ\n\n4\n(t\n\n)j=\njQ\n\n4\n[u\n\n0\n]j\n\n#10 -7 (d)\n\n50 100 150 200\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nQ\n\n5\n(t\n\n)j=\njQ\n\n5\n[u\n\n0\n]j\n\n#10 -5 (e)\n\n50 100 150 200\nt\n\n0\n\n2\n\n4\n\n6\n\n8\n\nj/\nQ\n\n6\n(t\n\n)j=\njQ\n\n6\n[u\n\n0\n]j\n\n#10 -7 (f)\n\nFIGURE 4. Errors in conserved quantities for the Zabusky-Kruskal test case monitored over the time-span\n[0, 20tR]; computational parameters for the simulation can be found in caption of Fig. 3: (a) absolute error\nin the mass (the initial mass Q1[u0] = 0), relative errors in (b) momentum (L2-norm), (c) Hamiltonian,\n(d) fourth conserved quantity (Q4[u0]), (e) fifth conserved quantity (Q5[u0]) and (f) sixth conserved quan-\ntity (Q6[u0]). By construction, the relative error in the conservation of momentum is kept near machine\nprecision, while the absolute error in mass remains at \u223c 10\u221215.\n\n0 1 2\nx\n\n-5\n\n0\n\n5\n\nE 1\n(x\n\n;t\n=\n\n20\nt R\n\n)\n\n#10 -5 (a)\n\n0 1 2\nx\n\n-5\n\n0\n\n5\n\nE 2\n(x\n\n;t\n=\n\n20\nt R\n\n)\n\n#10 -5 (b)\n\nFIGURE 5. A snapshot of the local errors in (a) conservation of mass (E1(x, t)) and (b) conser-\nvation of momentum (E2(x, t)) as a function of x at time T = 20tR.\n\nE2(x,T ) = (u2/2)t +\n\n(\n\u03b1\n\n3\nu3 + \u03b5\n\n2\n(\n\nuuxx\u2212u2\nx/2\n))\n\nx\n. (4.14)\n\nThe time derivatives are computed using the fourth-order backward differentiation formula [35]:\n\nut(xm,T )\u2248\n\n(\n25u(xm,T )\u221248u(xm,T \u2212\u2206t)+36u(xm,T \u22122\u2206t)\u221216u(xm,T \u22123\u2206t)+3u(xm,T \u22124\u2206t)\n\n)\n12\u2206t\n\n, (4.15)\n\nwhereas, all the spatial derivatives were computed to spectral accuracy with the use of fast Fourier transforms.\nFig. 5 shows the variations of E1 and E2 as a function of x at time T = 20tR. Remarkably, the local errors remain\nrelatively small even over such long time intervals.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 13\n\n0.01 0.015 0.02\nt\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nj/\nu\n(t\n\n)j\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n#10 -4 (b)\n\nFIGURE 6. (a) Travelling wave solution for the Allen-Cahn equation with simulation parameters: L = 4,\n\u03b5 = 0.05, NS = 1024, \u2206t = 0.000125, and end time T = 0.02. Solution advanced to the final time with the\nidea of multi-blocking with sub-interval size T1 = 0.01. The error in solution was restricted to 6.3\u00d710\u22124\n\nwith this parameter choice. (b) The absolute error, in time, between the TDSR numerical and the exact\nsolutions in the time interval [0.01,0.02].\n\n4.3. Travelling waves for the Allen-Cahn equation. In this section, we apply the TDSR method on the Allen-\nCahn equation, a prototypical reaction-diffusion type equation that arises in material science [8]. It is given by\n\nut = Duxx + \u03b3(u\u2212u3), (4.16)\n\nwhere D > 0 is the diffusion coefficient and \u03b3 measures the strength of reaction. The Allen-Cahn equation is\ndissipative in nature. In fact when subject to homogeneous Dirichlet/Neumann boundary conditions (considered\nin this paper), multiplying Eq. (4.16) by 2u and integrating over the whole domain leads to the dissipation rate\nEq. (2.3) with density and flux:\n\n\u03c1 = u2, F = 2Du2\nx\u22122\u03b3(u2\u2212u4). (4.17)\n\nIn this case, as we shall see later, the renormalization factor R(t) obeys a nonlinear ordinary differential equation.\nWe present numerical results on two canonical problems associated with the Allen-Cahn equation: (i) dynamics\nof traveling waves and (ii) observation of meta-stable dynamics. Both examples represent a departure from the\nperiodic case for which the linear operator L is diagonalizable. Indeed, for the Allen-Cahn equation, the discrete\nrepresentation of L is now dense as is the case when using spectral differentiation matrices. Thus, the semi-\ngroup exp(tL ) forms a rank-3 tensor. We implement the TDSR method on the Allen-Cahn Eq. (4.16) to compute\ntraveling waves with diffusion coefficient D = 1 and large reaction parameter \u03b3 that scales like \u03b5\u22122, with \u03b5 \ufffd 1.\nEquation (4.16) is subject to the initial condition u(x,0) = 0.5\u2212 0.5tanh\n\n(\nx/(2\n\u221a\n\n2\u03b5)\n)\n\nand Neumann boundary\nconditions: ux(x, t)\u2192 0 as |x| \u2192 \u221e. Interestingly enough, the Allen-Cahn Eq. (4.16) admits an exact travelling\nwave solution given by u(x, t) = 0.5\u2212 0.5tanh\u03be/(2\n\n\u221a\n2\u03b5), \u03be = x\u2212 3t/(\n\n\u221a\n2\u03b5) [24]. It is the aim of this section\n\nto reproduce this exact solution using the TDSR while enforcing the dissipation rate equation given in (2.3) and\n(4.17). We proceed by substituting the ansatz u(x, t) = R(t)v(x, t) into Eq. (4.16); multiply by 2u and integrate the\nresulting system over the whole computational domain to obtain a first order dynamical system for the variable\np(t)\u2261 r(t)R2(t):\n\nd p\ndt\n\n= (\u2212a(t)+2\u03b3)p\u2212b(t)p2, (4.18)\n\nwhere the expressions for the time-dependent coefficients r(t), a(t) and b(t)> 0 are given by (here \u2126 denotes the\nspatial domain of the Allen-Cahn equation)\n\nr(t) =\n\u222b\n\n\u2126\n\nv2(x, t)dx, a(t) =\n2D\n\u222b\n\n\u2126\nv2\n\nx(x, t)dx\nr(t)\n\n, b(t) =\n2\u03b3\n\u222b\n\n\u2126\nv4(x, t)dx\nr2(t)\n\n. (4.19)\n\nThe presence of the large coefficient \u03b3 \u223c \u03b5\u22122 in Eq.(4.18) causes the differential equation to become stiff,\nthus severely limiting the choice of time-steps. With this in mind, we use an implicit scheme (such as Crank-\nNicolson) to time-step (4.18) [35]. The coefficients r(t), a(t) and b(t) are computed to spectral accuracy using\n\n\n\n14 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\nFIGURE 7. (a) Spatio-temporal field distribution illustrating the meta-stable dynamics. Simulations were\nperformed using the idea of multi-blocking with block size T1 = 8 and final time T = 80. Computational\nparameters: NS = 256, \u2206t \u2248 0.016. (b) Comparison with the ETDRK4 scheme (at end time), showing a\ngood agreement with the TDSR trapezoidal result.\n\nClenshaw-Curtis quadrature method [39]. The spatial domain \u2126 is truncated, in which case, x \u2208 [\u2212L/2,L/2]\nand taking advantage of the spatial decay of ux to enforce homogeneous Neumann boundary conditions. Several\nremarks are in order: (i) The Chebyshev (Chebyshev-Lobatto) series representation is originally developed for\nfunctions defined on the interval [\u22121,1]. It can, nonetheless be applied on the interval [\u2212L/2,L/2] using a linear\ntransformation. (ii) We incorporate the homogeneous Neumann boundary conditions following similar procedure\nas outlined in [29]. For example, the second derivative is represented by the matrix product DD0 with D being\nthe standard first order spectral differentiation matrix while D0 is the first order differentiation matrix whose first\nand last rows have been replaced by the zero-vector respectively. This implicitly enforces the underlying boundary\nconditions. The numerical results obtained in this section are summarized in Fig. 6 where a surface plot describing\nthe time evolution of the traveling wave as well as its numerical accuracy are shown.\n\n4.4. Meta-stable dynamics of the Allen-Cahn equation. Our last example is concerned with the dynamics of\na meta-stable state associated with the Allen-Cahn Eq. (4.16) with parameters D = 0.01,\u03b3 = 1 and subject to the\nboundary conditions u(\u22121, t) =\u22121, u(1, t) = 1 and initial condition u(x,0) = 0.53x+0.47sin(\u22121.5\u03c0x). This test\nbed case is particularly interesting since the dynamics of an initial hump is observed to be meta-stable, i.e., it\nremains unchanged over long time, before abruptly vanishing. This type of rapid change in the wave profile over\nshort time scales inevitably creates numerical challenges. Such dynamic metastability was numerically observed\nby Kassam and Trefethen [25] using the modified ETDRK4 scheme. In this section, we demonstrate the robust-\nness of our TDSR method by reproducing this type of abrupt transition from a meta-stable state to another stable\nwavefunction profile. Here, the renormalization factor R(t) is governed by the same nonlinear ordinary differential\nequation Eq. (4.18) with the exception that now the parameters are D = 0.01,\u03b3 = 1 with a spatial domain [\u22121,1].\nFew remarks are in order: (i) To simplify the computation, we first homogenize the boundary conditions by de-\nriving a new evolution equation on which the TDSR method is implemented. (ii) To impose Dirichlet boundary\nconditions, the operator d2/dx2 is approximated by D2 where D is the first order spectral differentiation matrix\n[39]. The time evolution of the Allen-Cahn front is shown in Fig. 7 (a). As expected, our method is indeed ca-\npable of reproducing those well known results. We have also compared our results with those obtained using the\nETDRK4 scheme and found good agreement (see Fig. 7 (b) for a comparison at end time).\n\n5. NUMERICAL IMPLEMENTATION OF TDSR WITH MULTI-CONSERVATION LAWS\n\nSo far we have addressed several cases where a single conservation law is \u201cinjected\u201d into the numerical sim-\nulations. In this section, we shall present results when multiple conservation laws are enforced. There are three\nchoices that we considered: conservation of (i) mass and momentum; (ii) mass and Hamiltonian ; (iii) mass, mo-\nmentum and Hamiltonian. All numerical results reported in this section are for the KdV equation (4.1), subject to\nrapidly decaying boundary conditions with \u03b1 = 6 and \u03b5 = 1.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 15\n\nWe remark that the pseudo initial conditions f j(x), j = 1,2, \u00b7 \u00b7 \u00b7 ,N, introduced in the TDSR formulation (see\nEqs. 2.11-2.13) are crucial for the success of the method. They greatly control the scheme\u2019s convergence and allow\nthe renormalization factors to act as \u201cexpansion\u201d coefficients. Our numerical tests strongly indicate that taking none\nof the pseudo-initial conditions be identically equal to zero, (albeit satisfying the underlying boundary conditions),\nin order for the scheme to converge. With this in mind, a natural and important issue that immediately arises is\nhow to choose them? Our extensive numerical experiments seem to suggest that the natural choice f j(x)\u2261\u03b1 ju0(x)\nwith non-zero constant \u03b1 j\u2019s does not lead to convergence. However, several other possible choices for f j are given\nby f j(x) = \u03b1 j(x)u0(x) where \u03b1 j(x) are spatially localized functions. For evolution equations in (1+1)D subject\nto rapidly decaying boundary conditions (such as the KdV, NLS, mKdV), the algorithm seems to converge (at least\nover some time interval) when the first (N\u22121) f j(x) are chosen to belong to the class of bell-shaped, sign-definite\nfunctions. For example, f j \u2208 {sech(x),e\u2212x2\n\n,sech2(x)} for j = 1,2, \u00b7 \u00b7 \u00b7(N\u22121), while the entire set of pseudo-initial\nconditions is required to satisfy the normalization condition in Eq. (2.9). A full characterization on the choice of\nthe pseudo-initial conditions f j(x) is the subject for future work.\n\n5.1. Conservation of mass and momentum. Here the KdV solution is decomposed in the form: u(x, t) =\nR1(t)v1(x, t)+R2(t)v2(x, t), where R1(t) and R2(t) are computed from the coupled system\n\nQ j [R1(t)v1(x, t)+R2(t)v2(x, t)] = Q j\n[\n2\u03b2\n\n2sech2(\u03b2x)\n]\n, j = 1,2. (5.1)\n\nWe choose f1(x) = (1/300)sech\n(\n\nx/\n\u221a\n\n600\n)\n\n, and f2(x) = u0(x)\u2212 f1(x). The explicit expressions for R1(t) and\nR2(t) can be obtained from the coupled system\n\nR1(t) =\nC1\u2212A2(t)R2(t)\n\nA1(t)\n, and \u00b51(t)R2\n\n2 +\u00b52(t)R2 +\u00b53(t) = 0,\n\nwhere\n\u00b51(t) = A3A2\n\n2 +A4A2\n1\u22122A1A2A5, \u00b52(t) = 2A1A5C1\u22122A2A3C1, \u00b53(t) = A3C2\n\n1 \u2212C2A2\n1,\n\nand\n\nA1(t) =\n\u222b\nR\n\nv1(x, t)dx, A2(t) =\n\u222b\nR\n\nv2(x, t)dx, A3(t) =\n\u222b\n\n\u221e\n\n\u2212\u221e\n\nv2\n1(x, t)dx,\n\nA4(t) =\n\u222b\nR\n\nv2\n2(x, t)dx, A5(t) =\n\n\u222b\nR\n\nv1(x, t)v2(x, t)dx.\n\nNumerical tests indicate that the algorithm converges to the correct solution when using the root R2(t) = [\u2212\u00b52(t)+\u221a\n\u00b52\n\n2 (t)\u22124\u00b51(t)\u00b53(t)]/[2\u00b51(t)], while the other one causes the TDSR algorithm to diverge. The correct root was\nfound to always satisfy R2(0)v2(x,0) = f2(x) at any Duhamel iteration while the other consistently violated it.\nFigure 8 shows results of TDSR simulations where mass and momentum are both conserved. Another interesting\nnumerical experiment (discussed below), is related to interaction (or collision) between two 1-soliton solutions to\nthe KdV equation. The corresponding initial condition is\n\nu0(x) = 2\u03b2\n2\n1 sech2 (\u03b21x)+2\u03b2\n\n2\n2 sech2 (\u03b22(x\u2212 x0)) , (5.2)\n\nwith \u03b21 =\n1\u221a\n10\n, \u03b22 =\n\n1\n2\n\u221a\n\n10\nand an initial separation of x0 = 40. We simulated this to end time T = 200 using the idea\n\nof multi-blocking (see Fig. 9). The solitons interact elastically, mainly emerging unscathed from the interaction,\nsuffering only from a phase shift as expected. As before, we prescribed f1(x) = (1/300)sech\n\n(\nx/\n\u221a\n\n600\n)\n\n, while\nf2(x) = u0(x)\u2212 f1(x).\n\n\n\n16 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\nj/\nu\n(t\n\n)j=\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n#10 -4\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j=\njQ\n\n1\n[u\n\n0\n]j #10 -16\n\n0 50\nt\n\n0\n\n2\n\n4\n\n6\n\n8\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j=\njQ\n\n2\n[u\n\n0\n]j #10 -16\n\n0 50\nt\n\n0\n\n0.5\n\n1\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j=\njQ\n\n3\n[u\n\n0\n]j #10 -6\n\nFIGURE 8. (a) Time evolution of the relative error between the numerically obtained solution for the KdV\nequation compared to its exact solution given in Eq. (4.3). Time evolution of the conserved quantities given\nin Eq. (4.4): mass (b), momentum (c) and Hamiltonian (d). Note that the relative errors in conservation\nof mass and momentum stay close to machine precision. Parameters are: L = 800, \u2206t = 0.5, T = 60,\nNs = 16384 with the renormalization factors obtained from system (5.1) for j=1, 2. Note the renormalized\nDuhamel iterations converge over such a large time-span, a significant improvement over when a single\nquantity is conserved.\n\nFIGURE 9. Interaction between two 1-soliton solution for the KdV equation with \u03b1 = 6,\u03b5 = 1 and initial\ncondition u(x,0) = (1/5)sech2 (x/\u221a10\n\n)\n+(1/20)sech2 ((x\u221240)/2\n\n\u221a\n10\n)\n. Other parameters are \u2206t = 0.5,\n\nL= 800, NS = 16384 and the time block size T1 = 20. The renormalization factors are obtained by enforcing\nthe conservation of mass and momentum simultaneously. The relative error in Hamiltonian \u2248 7.86\u00d710\u22126\n\nat T = 200, while relative error in mass\u2248 1.9\u00d710\u221216 and momentum\u2248 5.9\u00d710\u221216 are kept near machine\nprecision.\n\n0 10 20 30\nt\n\n0\n\n0.5\n\n1\n\nj/\nu\n(t\n\n)j=\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n#10 -4\n\n0 10 20 30\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\nax\n\ntj/\nQ\n\n1\n(t\n\n)j=\njQ\n\n1\n[u\n\n0\n]j\n\n#10 -16\n\n0 10 20 30\nt\n\n0\n\n1\n\n2\n\n3\n\nm\nax\n\ntj/\nQ\n\n2\n(t\n\n)j=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -7\n\n0 10 20 30\nt\n\n0\n\n1\n\n2\n\n3\n\n4\n\nm\nax\n\ntj/\nQ\n\n3\n(t\n\n)j=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -16\n\nFIGURE 10. (a) Time evolution of the relative error between the numerically obtained (TDSR) solution\nto the KdV equation with conservation of mass and Hamiltomian compared to its exact solution given in\nEq. (4.3). Time evolution of the conserved quantities given in Eq. (4.4): mass (b), momentum (c) and\nHamiltonian (d). Note that the relative errors in conservation of mass and Hamiltonian now stay close to\nmachine precision. Parameters are: L = 800, \u2206t = 0.5, T = 30, Ns = 16384 with the renormalization factors\nobtained from system (5.1) for j=1, 3.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 17\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nu\n(t\n\n)j=\njju\n\nex\n(x\n\n;t\n)jj\n\n1\n\n#10 -4\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n1\n(t\n\n)j=\njQ\n\n1\n[u\n\n0\n]j\n\n#10 -16\n\n0 2 4\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nm\na\nx\n\ntj/\nQ\n\n2\n(t\n\n)j=\njQ\n\n2\n[u\n\n0\n]j\n\n#10 -16\n\n0 2 4\nt\n\n0\n\n2\n\n4\n\n6\n\nm\na\nx\n\ntj/\nQ\n\n3\n(t\n\n)j=\njQ\n\n3\n[u\n\n0\n]j\n\n#10 -16\n\nFIGURE 11. (a) Time evolution of the relative error between the numerically obtained solution, from\nTDSR with conservation of mass, momentum and Hamiltonian, for the KdV equation compared to its\nexact solution given in Eq. (4.3). Time evolution of the conserved quantities given in Eq. (4.4): mass\n(b), momentum (c) and Hamiltonian (d). Parameters are: \u2206t = 0.5, T = 5, Ns = 2048, L = 100 with the\nrenormalization factors obtained from Eqs.(5.3).\n\n5.2. Conservation of mass and Hamiltonian. In this case, the renormalization factors R1(t) and R2(t) are now\ncomputed from the coupled system of equations given in (5.1) with j taking the values 1 and 3. Like before,\nwe pick the pseudo-initial conditions to be f1(x) = (1/300)sech\n\n(\nx/\n\u221a\n\n600\n)\n\nand f2(x) = u0(x)\u2212 f1(x). We solved\nsystem (5.1) for j = 1,3 using the Newton\u2019s method. Our findings are similar to those reported for the simultaneous\nconservation of mass and momentum, i.e., conservation of mass and Hamiltonian are achieved (see Fig. 10).\n\n5.3. Conservation of mass, momentum and Hamiltonian. Lastly, we seek three renormalization factors R1(t),\nR2(t) and R3(t) that satisfy u(x, t) = \u2211\n\n3\nj=1 R j(t)v j(x, t) and obey the conservation laws\n\nQ j\n\n[\n3\n\n\u2211\n`=1\n\nR`(t)v`(x, t)\n\n]\n= Q j\n\n[\n2\u03b2\n\n2sech2(\u03b2x)\n]\n, j = 1,2,3. (5.3)\n\nUnlike the previous cases, of mass-momentum and mass-Hamiltonian conservation, two of the current conserved\nquantities now are nonlinear functionals further limiting the choices for the pseudo-initial conditions as far as\nthe convergence over large time intervals is concerned. It turns out that convergence over moderately long time\nintervals (T = 5) is achieved with pseudo-initial conditions in the Duhamel integral formulas Eqs. (2.11) and (2.13)\nas f3(x) = 0.15exp(\u2212x2), f2(x) = 0.05exp(\u2212x2) and f1(x) = u0(x)\u2212 f2(x)\u2212 f3(x). The renormalization factors\nare found from the coupled system of equations derived from enforcing the conservation of mass, momentum and\nconservation of Hamiltonian simultaneously Eq. (5.1) for j = 1,2,3, using the Newton\u2019s root finding method. The\nresults are depicted in Fig. 11 where the error in the momentum, Hamiltonian and mass are kept at the level of\nmachine precision.\n\n6. TDSR METHOD: MULTI-DIMENSIONAL TEST CASE\n\nThe nonlinear Schro\u0308dinger equation\n\niut +V (x)u+\u2207\n2u+ |u|2u = 0, (6.1)\n\nplays an important role in modeling fundamental physics ranging from photonics, Bose-Einstein condensation to\nfluid mechanics [1]. Depending on the physics at hand, \u22072 = \u2202 2/\u2202x2 +\u2202 2/\u2202y2 denotes wave diffraction, V is the\nrefractive index, photonic lattice or an external potential and |u|2 measuring the intensity or density of a complex\nvalued wavefunction u. As such, using the TDSR method to simulate the NLS equation would seem natural. In\nthe absence of any external potential (V (x) = 0), Eq. (6.1) admits a special class of solutions known as the Townes\n\n\n\n18 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n0 1 2\nt\n\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\nj/\nu\n(t\n\n)j=\njju\n\n0\n(x\n\n;y\n)jj\n\n1\n\n#10 -5 (a)\n\n0 1 2\nt\n\n0\n\n1\n\n2\n\n3\n\nm\nax\n\ntj/\nQ\n\n1\n(t\n\n)j=\njQ\n\n1\n[u\n\n0\n(x\n\n;y\n)]\nj #10 -16 (b)\n\nFIGURE 12. (a) The error in the TDSR solution, as defined relative to the initial profile of the Townes\nsoliton, (b) the relative error in the power as a function of time t. As one can see, it is kept close to machine\nprecision over the entire time span [0,2]. Parameters are: \u2206t = 0.05, a square spatial domain with L = 40 ,\nand a spatial discretization of 512\u00d7512 for the computations.\n\nsolitons. They are of the form u(x, t) = U\u03bb (x)ei\u03bb 2t ,\u03bb \u2208 R with real valued function U\u03bb satisfying the boundary\nvalue problem\n\n\u2207\n2U\u03bb +U3\n\n\u03bb\n= \u03bb\n\n2U\u03bb . (6.2)\n\nThe numerical computation of the Townes soliton is well documented in the literature and can be achieved with\nthe use of various boundary value problem solvers (Quasi-Newton methods, spectral renormalization, etc. [3, 26,\n27, 41]). While the implementation of the TDSR method on the NLS equation was first reported in [11] it was\nexemplified in one spatial dimension for which the semi-group exp(it\u2202 2/\u2202x2) lives in (1+ 1) dimensions. Here,\nthe (1+2)D NLS equation, subject to sufficiently rapidly decaying boundary conditions is chosen as a prototypical\nexample to demonstrate the applicability of the TDSR scheme in multiple spatial dimensions. The NLS Eq. (6.1)\nadmits three conservation laws: power Q1 = |u|2, Hamiltonian Q3 =\u2212 1\n\n4 |u|\n4 + 1\n\n2 |\u2207u|2 and momentum Q2 = u\u2207u\u2217.\nWe were able to reproduce the time evolution of the Townes soliton, to within a relative error of \u223c 1.8\u00d7 10\u22125,\nwhen the algorithm was implemented on time interval [0,2] using time step of size \u2206t = 0.05 and number of spatial\n(square) grid points NS = 512. We rigorously conserve the power Q1, and as can be seen in Fig. 12 (b), the relative\nerror in power stays close to machine precision.\n\n7. CONCLUSIONS AND FUTURE DIRECTIONS\n\nIn 2005 Ablowitz and Musslimani proposed the spectral renormalization method as a tool to numerically ap-\nproximate solutions to nonlinear boundary value problems. Since then, it has been successfully used in many\nphysical settings that include photonics [42], Bose-Einstein condensation [7], Kohn-Sham density functional the-\nory [17], and water waves [5]. In 2016, Cole and Musslimani proposed the time dependent spectral renormalization\nmethod to simulate evolution equations with periodic boundary conditions. This important idea brings two novel\naspects: (i) it extends the original steady state spectral renormalization method to the time domain, thus offering\na unifying approach by which time-independent as well as evolution equations are solved by the same numerical\nscheme, (ii) it allowed the inclusion of certain physics such as conservation and dissipation laws. In this paper we\nhave significantly empowered the computational capabilities of the TDSR method that allows the (i) enforcement\nof several conservation laws or dissipation rate equations, (ii) flexibility to apply other non-periodic boundary\nconditions. We have successfully demonstrated these ideas on prototypical dynamical systems of physical signif-\nicance. Examples include the Korteweg-de Vries equation and dynamics of fronts modeled by the Allen-Cahn\nequation. We conclude this section by making a remark regarding possible application of the TDSR to weak wave\nturbulence. Wave turbulence describes the chaotic interactions of dispersive wavetrains (analogs to eddies) when\nan external forcing term added to the underlying nonlinear evolution equations are mediated by dissipative forces\n(see [31\u201333] and references contained). Numerical investigations of these phenomena is a challenging task, requir-\ning very long time runs for statistical equilibrium to be reached. Carefully designed numerical integrators are used\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 19\n\n(see [30]) to integrate the potentially stiff, underlying nonlinear field equations over long time. In such scenarios,\na close control over the conserved quantities of the dynamical system can prove vital to ensure long time accuracy\nof the solution. The application of the TDSR to this field thus seems natural and is kept for future work.\n\nREFERENCES\n\n[1] Mark J Ablowitz. Nonlinear dispersive waves: asymptotic analysis and solitons, volume 47. Cambridge\nUniversity Press, 2011.\n\n[2] Mark J Ablowitz, Xu-Dan Luo, and Ziad H Musslimani. Discrete nonlocal nonlinear schro\u0308dinger systems:\nIntegrability, inverse scattering and solitons. Nonlinearity, 33(7):3653, 2020.\n\n[3] Mark J. Ablowitz and Ziad H. Musslimani. Spectral renormalization method for computing self-localized\nsolutions to nonlinear systems. Opt. Lett., 30(16):2140\u20132142, Aug 2005.\n\n[4] Mark J Ablowitz and Ziad H Musslimani. Integrable discrete p t symmetric model. Physical Review E,\n90(3):032912, 2014.\n\n[5] MJ Ablowitz, AS Fokas, and ZH Musslimani. On a new non-local formulation of water waves. Journal of\nFluid Mechanics, 562:313, 2006.\n\n[6] MJ Ablowitz and JF Ladik. A nonlinear difference scheme and inverse scattering. Studies in Applied Mathe-\nmatics, 55(3):213\u2013229, 1976.\n\n[7] Eric Akkermans, Sankalpa Ghosh, and Ziad H Musslimani. Numerical study of one-dimensional and in-\nteracting Bose\u2013Einstein condensates in a random potential. Journal of Physics B: Atomic, Molecular and\nOptical Physics, 41(4):045302, 2008.\n\n[8] Samuel M. Allen and John W. Cahn. A microscopic theory for antiphase boundary motion and its application\nto antiphase domain coarsening. Acta Metallurgica, 27(6):1085 \u2013 1095, 1979.\n\n[9] Uri M Ascher and Chen Greif. A first course on numerical methods. SIAM, 2011.\n[10] Uri M Ascher and Robert I McLachlan. On symplectic and multisymplectic schemes for the kdv equation.\n\nJournal of Scientific Computing, 25(1):83\u2013104, 2005.\n[11] Justin T Cole and Ziad H Musslimani. Time-dependent spectral renormalization method. Physica D: Non-\n\nlinear Phenomena, 358:15\u201324, 2017.\n[12] Steven M Cox and Paul C Matthews. Exponential time differencing for stiff systems. Journal of Computa-\n\ntional Physics, 176(2):430\u2013455, 2002.\n[13] Yanfen Cui and De-kang Mao. Numerical method satisfying the first two conservation laws for the korteweg\u2013\n\nde vries equation. Journal of Computational Physics, 227(1):376\u2013399, 2007.\n[14] Philip J Davis. On the numerical integration of periodic analytic functions. On numerical approximation,\n\npages 21\u201323, 1959.\n[15] Daisuke Furihata. Finite difference schemes for \u2202u\n\n\u2202 t = ( \u2202\n\n\u2202x )\n\u03b1 \u03b4g\n\n\u03b4u that inherit energy conservation or dissipation\nproperty. Journal of Computational Physics, 156(1):181\u2013205, 1999.\n\n[16] Sergei Konstantinovich Godunov. A difference scheme for numerical solution of discontinuous solution of\nhydrodynamic equations. Math. Sbornik, 47:271\u2013306, 1959.\n\n[17] Juri Grossi, Ziad H. Musslimani, Michael Seidl, and Paola Gori-Giorgi. Kohn-Sham equations with func-\ntionals from the strictly-correlated regime: Investigation with a spectral renormalization method. Journal of\nPhysics. Condensed matter, 32(47), 2020.\n\n[18] Ernst Hairer, Christian Lubich, and Gerhard Wanner. Geometric numerical integration: structure-preserving\nalgorithms for ordinary differential equations, volume 31. Springer Science & Business Media, 2006.\n\n[19] Charles Hirsch. Numerical computation of internal and external flows. vol. 2-computational methods for\ninviscid and viscous flows(book). Chichester, England and New York, John Wiley & Sons, 1990, 708, 1990.\n\n[20] Arieh Iserles. On the numerical quadrature of highly-oscillating integrals i: Fourier transforms. IMA Journal\nof Numerical Analysis, 24(3):365\u2013391, 2004.\n\n[21] AL Islas, DA Karpeev, and CM Schober. Geometric integrators for the nonlinear schro\u0308dinger equation.\nJournal of computational physics, 173(1):116\u2013148, 2001.\n\n\n\n20 SATHYANARAYANAN CHANDRAMOULI, ASEEL FARHAT, AND ZIAD MUSSLIMANI\n\n[22] A.L. Islas and C.M. Schober. Multi-symplectic methods for generalized schro\u0308dinger equations. Future\nGeneration Computer Systems, 19(3):403\u2013413, 2003. Special Issue on Geometric Numerical Algorithms.\n\n[23] A.L. Islas and C.M. Schober. Backward error analysis for multisymplectic discretizations of hamiltonian\npdes. Mathematics and Computers in Simulation, 69(3):290\u2013303, 2005. Nonlinear Waves: Computation and\nTheory III.\n\n[24] Darae Jeong, Seunggyu Lee, Dongsun Lee, Jaemin Shin, and Junseok Kim. Comparison study of numerical\nmethods for solving the Allen\u2013Cahn equation. Computational Materials Science, 111:131\u2013136, 2016.\n\n[25] Aly-Khan Kassam and Lloyd N Trefethen. Fourth-order time-stepping for stiff PDEs. SIAM Journal on\nScientific Computing, 26(4):1214\u20131233, 2005.\n\n[26] Panayotis G Kevrekidis, Dimitri J Frantzeskakis, and Ricardo Carretero-Gonza\u0301lez. Emergent nonlinear phe-\nnomena in Bose-Einstein condensates: theory and experiment, volume 45. Springer Science & Business\nMedia, 2007.\n\n[27] Yuri S Kivshar and Govind P Agrawal. Optical solitons: from fibers to photonic crystals. Academic press,\n2003.\n\n[28] Randall J LeVeque et al. Finite volume methods for hyperbolic problems, volume 31. Cambridge university\npress, 2002.\n\n[29] Yi-Xin Liu and Hong-Dong Zhang. Exponential time differencing methods with Chebyshev collocation for\npolymers confined by interacting surfaces. The Journal of chemical physics, 140(22):224101, 2014.\n\n[30] AJ Majda, DW McLaughlin, and EG Tabak. A one-dimensional model for dispersive wave turbulence.\nJournal of Nonlinear Science, 7(1):9\u201344, 1997.\n\n[31] Sergey Nazarenko. Wave turbulence, volume 825. Springer Science & Business Media, 2011.\n[32] Alan C Newell, Sergey Nazarenko, and Laura Biven. Wave turbulence and intermittency. Physica D: Non-\n\nlinear Phenomena, 152:520\u2013550, 2001.\n[33] Alan C Newell and Benno Rumpf. Wave turbulence. Annual review of fluid mechanics, 43:59\u201378, 2011.\n[34] Sheehan Olver. Numerical approximation of highly oscillatory integrals. PhD thesis, University of Cam-\n\nbridge, 2008.\n[35] Alfio Quarteroni, Riccardo Sacco, and Fausto Saleri. Numerical mathematics, volume 37. Springer Science\n\n& Business Media, 2010.\n[36] JM Sanz-Serna. An explicit finite-difference scheme with exact conservation properties. Journal of Compu-\n\ntational Physics, 47(2):199\u2013210, 1982.\n[37] A. Taflove. Advances in Computational Electrodynamics: The Finite-difference Time-domain Method. Artech\n\nHouse antenna library. Artech House, 1998.\n[38] Thiab R Taha and Mark I Ablowitz. Analytical and numerical aspects of certain nonlinear evolution equations.\n\niii. numerical, Korteweg-de Vries equation. Journal of Computational Physics, 55(2):231\u2013253, 1984.\n[39] Lloyd N Trefethen. Spectral methods in MATLAB, volume 10. Siam, 2000.\n[40] J. A. C. Weideman and B. M. Herbst. Split-step methods for the solution of the nonlinear Schro\u0308dinger\n\nequation. SIAM Journal on Numerical Analysis, 23(3):485\u2013507, 1986.\n[41] Jianke Yang. Newton-conjugate-gradient methods for solitary wave computations. Journal of Computational\n\nPhysics, 228(18):7007\u20137024, 2009.\n[42] Jianke Yang and Ziad H Musslimani. Fundamental and vortex solitons in a two-dimensional optical lattice.\n\nOptics letters, 28(21):2094\u20132096, 2003.\n[43] L Minah Yang, Ian Grooms, and Keith A Julien. The fidelity of exponential and IMEX integrators for\n\nwave turbulence: Introduction of a new near-minimax integrating factor scheme. Journal of Computational\nPhysics, page 109992, 2020.\n\n[44] Norman J Zabusky and Martin D Kruskal. Interaction of \u201csolitons\u201d in a collisionless plasma and the recur-\nrence of initial states. Physical review letters, 15(6):240, 1965.\n\n\n\nTIME-DEPENDENT DUHAMEL RENORMALIZATION METHOD WITH MULTIPLE CONSERVATION AND DISSIPATION LAWS 21\n\n(S. Chandramouli) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: schandra@math.fsu.edu\n\n(A. Farhat) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: afarhat@fsu.edu\n\n(Z. Musslimani) DEPARTMENT OF MATHEMATICS, FLORIDA STATE UNIVERSITY, TALLAHASSEE, FL 32306, USA\nEmail address: musliman@math.fsu.edu\n\n\n\t1. Introduction\n\t2. TDSR and Duhamel principle\n\t3. Time integration with various boundary conditions\n\t3.1. Periodic and decaying boundary conditions\n\t3.2. Time integration: non-periodic boundary conditions\n\n\t4. Numerical Implementation of TDSR: One conservation or dissipation law with various boundary conditions\n\t4.1. The KdV equation.\n\t4.2. Zabusky-Kruskal experiment \n\t4.3. Travelling waves for the Allen-Cahn equation.\n\t4.4. Meta-stable dynamics of the Allen-Cahn equation.\n\n\t5. Numerical Implementation of TDSR with multi-conservation laws\n\t5.1. Conservation of mass and momentum\n\t5.2. Conservation of mass and Hamiltonian\n\t5.3. Conservation of mass, momentum and Hamiltonian\n\n\t6. TDSR method: Multi-dimensional test case\n\t7. Conclusions and future directions\n\tReferences\n\n"}
{"Title": "Simulating local fields in carbon nanotube reinforced composites for infinite strip with voids", "Authors": "Mohamed Nasser, El Mostafa Kalmoun, Vladimir Mityushev, Natalia Rylko", "Abstract": "  We consider the steady heat conduction problem within a thermal isotropic and homogeneous infinite strip composite reinforced by uniformly and randomly distributed non-overlapping carbon nanotubes (CNTs) and containing voids. We treat the CNTs as thin perfectly conducting elliptic inclusions and assume the voids to be of circular shape and act as barriers to heat flow. We also impose isothermal conditions on the external boundaries by assuming the lower infinite wall to be a heater under a given temperature, and the upper wall to be a cooler that can be held at a lower fixed temperature. The equations for the temperature distribution are governed by the two-dimensional Laplace equation with mixed Dirichlet-Neumann boundary conditions. The resulting boundary value problem is solved using the boundary integral equation with the generalized Neumann kernel. We illustrate the performance of the proposed method through several numerical examples including the case of the presence a large number of CNTs and voids.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00003", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating local fields in carbon nanotube\nreinforced composites for infinite strip with voids\n\nMohamed Nassera, El Mostafa Kalmounb, Vladimir Mityushevc,\nand Natalia Rylkoc\n\naMathematics Program, Department of Mathematics, Statistics and Physics,\nCollege of Arts and Sciences, Qatar University, Doha, Qatar\n\nbSchool of Science and Engineering, Al Akhawayn University in Ifrane,\nPO Box 104, Ifrane 53000, Morocco\n\ncFaculty of Computer Science and Telecommunications,\nCracow University of Technology, Krako\u0301w, Poland\n\nAbstract\n\nWe consider the steady heat conduction problem within a thermal isotropic\nand homogeneous infinite strip composite reinforced by uniformly and ran-\ndomly distributed non-overlapping carbon nanotubes (CNTs) and containing\nvoids. We treat the CNTs as thin perfectly conducting elliptic inclusions and\nassume the voids to be of circular shape and act as barriers to heat flow. We\nalso impose isothermal conditions on the external boundaries by assuming the\nlower infinite wall to be a heater under a given temperature, and the upper\nwall to be a cooler that can be held at a lower fixed temperature. The equa-\ntions for the temperature distribution are governed by the two-dimensional\nLaplace equation with mixed Dirichlet-Neumann boundary conditions. The\nresulting boundary value problem is solved using the boundary integral equa-\ntion with the generalized Neumann kernel. We illustrate the performance of\nthe proposed method through several numerical examples including the case\nof the presence a large number of CNTs and voids.\n\nKeywords. Local fields in 2D composites, Boundary integral equation,\nCarbon nanotube composites\n\n1 Introduction\n\nNanofibers embedded in polymer matrices have attracted attention as one of the\nreinforcements for composite materials. Carbon nanotubes (CNTs) reinforced poly-\nmer nanocomposites are considered as conventional micro- and macro-composites\n[1]. Their thermal, mechanical, and electric properties are determined by experi-\nmental and theoretical investigations [2, 3, 4]. CNTs are considered as perfectly\nconducting inclusions, which suggests imposing Dirichlet boundary conditions on\nthe boundary of CNTs. On the other hand, the classical problems for materials\nwith holes in porous media and materials with voids and insulting inclusions are\nmodeled by the Neumann boundary condition [5, 6].\n\nThe present paper is devoted to the heat conduction within a 2D (two-dimensional)\nthermal isotropic and homogeneous nanocomposite, which takes the form of an infi-\nnite strip, when it is reinforced by non-overlapping and randomly distributed CNTs\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n3v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 2\n\n8 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2\n\nand contains defects and voids. In particular, we are interested in studying the\neffect of CNTs as well as of the presence of voids on the macroscopic conductive and\nmechanical properties of this composite. Owing to the superconductivity of CNTs\nand the extremely low conductivity of voids, we can assume that the conductiv-\nity of CNTs, of the polymer host and of voids to be governed by the inequalities\n\u03bbc \ufffd \u03bb \ufffd \u03bb0. Such an assumption leads to a mixed boundary value problem\nwhere the latter inequality becomes +\u221e \ufffd \u03bb \ufffd 0. The host conductivity can be\nnormalized to unity, i.e., \u03bb = 1.\n\nTheoretical investigation of mixed boundary value problems by integral equa-\ntions can be found in [7, 8]. In the same time, implementation of numerical methods\nfor large number of inclusions and holes is still a challenging problem of applied and\ncomputational mathematics. We propose in this work a fast and effective algorithm\nfor the numerical solution of the formulated mixed boundary value problem. The\nmethod is based on the boundary integral equation with the generalized Neumann\nkernel. The integral equation has been used in [8] to solve a similar mixed bound-\nary value problem related to the capacity of generalized condensers. The proposed\nmethod can be even employed when the number of perfectly conducting inclusions\nand holes is very large.\n\nAs a result of simulations, we first study the 2D local fields for three types of me-\ndia. In the first type, we consider the case of pure m void cracks with m = 5, 30, 50.\nThe second type consists of pure ` CNT inclusions with ` = 5 and 200. Finally, we\ntreat the case of a large number of combined inclusions and holes by considering\neither 2000 of one of the two or 1000 of each. Afterward, we take up the systematic\ninvestigation of the effective conductivity of the considered composites. It is im-\nportant in applications to predict the macroscopic properties of composites which\ndepend on the concentration of perfectly conducting CNTs as well as on the concen-\ntration of holes and voids. It is worth noting that the notation of concentration are\ndifferent for slit shapes of CNTs and circular shapes of holes. The performed sim-\nulations of local fields and computation of their averaged conductivities for various\nconcentrations allows to establish the dependence of the macroscopic conductivity\non the main geometrical parameters.\n\n2 Problem formulation\n\nLet us consider a channel medium embedding m inhomogeneities in the form of `\nnanofillers and p = m \u2212 ` holes (voids). As many nanofillers (e.g, carbon nanon-\ntubes [9]) have cross sections of elliptical shapes, we model them as ellipses C1, . . . , C`.\nFurthermore, we represent the non-conducting holes by inner circles C`+1, . . . , Cm.\nThe top and bottom infinite walls of the channel are denoted respectively by C \u20320\nand C \u2032\u20320 , which yields a multiply connected domain \u2126 of connectivity m + 1 with a\nboundary set C =\n\n\u22c3m\nk=0Ck where C0 = C \u20320 \u222aC \u2032\u20320 . An example of this domain for the\n\ncase of ` = 4 and m = 7 is illustrated in Figure 1.\nThe medium matrix without inhomogeneities is supposed to be homogeneous\n\nand isotropic with a constant thermal conductivity \u03bb = 1. We also assume that\nconduction is the only dominating mechanism of heat transfer in the medium. Ex-\ncept being non-overlapping, no other restriction is imposed on the inhomogeneities\nas they can be placed at random orientation and position.\n\nThe nanofillers are treated as heat superconductors with an almost uniform tem-\nperature distribution within each one. Therefore the temperature T is assumed to\n\n\n\n3\n\nbe fixed to an indeterminate constant value \u03b4k along each ellipse Ck for k = 1 . . . , `.\nThis assumption is consistent with the numerical results reported in [10] for CNT\nreinforced polymer composites. Furthermore, by the law of energy conservation in\nsteady-state heat conduction, there should be no net thermal flow through each\nnanofiller. This constraint is written by means of the net heat flux boundary con-\ndition (1e).\n\nOn the other hand, the curves C`+1, . . . , Cm are assumed to be perfect insulators\nand therefore they act as barriers to heat flow. Henceforth, the Neumann boundary\ncondition (1f) is imposed along the holes contours. Finally, isothermal conditions\nare imposed on the external boundaries by assuming that the lower infinite wall is\na heater of temperature T1, and the upper wall acts as a heat sink, which can be\nheld at a fixed temperature T0 < T1. Thee two values T0 and T1 of the temperature\non the external boundaries are normalized to 0 and 1, respectively.\n\nUnder steady-state conditions, Fourier\u2019s law of heat conduction and the above\nspecified heat boundaries conditions yield the temperature distribution T governed\nby the following mixed Dirichlet-Neumann boundary value problem:\n\n\u2206T = 0 in \u2126, (1a)\n\nT = 0 on C \u20320, (1b)\n\nT = 1 on C \u2032\u20320 , (1c)\n\nT = \u03b4k on Ck, k = 1, 2, . . . , `, (1d)\u222b\nCk\n\n\u2202T\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (1e)\n\n\u2202T\n\n\u2202n\n= 0 on Ck, k = `+ 1, `+ 2, . . . ,m, (1f)\n\nwhere \u2202T/\u2202n denotes the normal derivative of T , and \u03b41, . . . , \u03b4m are undetermined\nreal constants that need to be found alongside the distribution temperature T .\n\nFigure 1: Geometry of the problem (for ` = 4 and m = 7).\n\n3 The integral equation method\n\nThe boundary integral equation with the generalized Neumann kernel is not di-\nrectly applicable to the above boundary value problem (1) because of the external\nboundary component. However, the boundary value problem (1) is invariant under\n\n\n\n4\n\nconformal mapping. The mapping function\n\nz = \u03a6(\u03b6) =\n1\n\n\u03c0\nlog\n\n1 + \u03b6\n\n1\u2212 \u03b6\n+\n\ni\n\n2\n\nconformally maps the unit disk |\u03b6| < 1 onto the infinite strip 0 < Im z < 1. Thus,\nthe inverse mapping\n\n\u03b6 = \u03a6\u22121(z) = tanh\n\n(\n\u03c0z\n\n2\n\u2212 \u03c0i\n\n4\n\n)\nconformally maps the infinite strip 0 < Im z < 1 onto the unit disk |\u03b6| < 1, the real\naxis onto the lower half of the unit circle, the line Im z = 1 onto the upper half of\nthe unit circle, and satisfies \u03a6\u22121(\u00b1\u221e + 0i) = \u00b11. Consequently, the function \u03a6\u22121\n\nmaps the multiply connected domain \u2126 in the z-plane (the physical domain) onto a\nmultiply connected domain G in the \u03b6-plane interior of the unit circle and exterior\nof m smooth Jordan curves (the computational domain). In Figure 2, we display\nthe result of the conformal mapping of the example shown in Figure 1.\n\nFigure 2: The computational domain G corresponding to the physical domain in\nFigure 1.\n\nIt follows that the harmonic function T can be written as\n\nT (z) = U(\u03a6\u22121(z))\n\nin which the function U is the solution of the following boundary value problem in\nthe \u03b6-plane:\n\n\u2206U = 0 in G, (2a)\n\nU = 0 on \u0393\u20320, (2b)\n\nU = 1 on \u0393\u2032\u20320, (2c)\n\nU = \u03b4k on \u0393k, k = 1, 2, . . . , `, (2d)\u222b\n\u0393k\n\n\u2202U\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (2e)\n\n\u2202U\n\n\u2202n\n= 0 on \u0393k, k = `+ 1, `+ 2, . . . ,m, (2f)\n\n\n\n5\n\nwhere \u0393\u20320 = \u03a6\u22121(C \u20320), \u0393\u2032\u20320 = \u03a6\u22121(C \u2032\u20320 ), and \u0393k = \u03a6\u22121(Ck) for k = 1, 2, . . . ,m. Note\nthat the restriction of the function U(\u03b6) on the external boundary is discontinuous\nat \u03b6 = \u00b11. However, the function U can be cast into the form\n\nU(\u03b6) = u0(\u03b6) + u(\u03b6)\n\nwhere u(\u03b6) is a harmonic function in G, and\n\nu0(\u03b6) =\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b6\n1 + \u03b6\n\n+\n1\n\n2\n.\n\nThe function u0(\u03b6) is harmonic in G with u0(\u03b6) = 0 on the upper half of the unit\ncircle and u0(\u03b6) = 1 on the lower part. The function u(\u03b6) is the solution of the\nboundary value problem\n\n\u2206u(\u03b6) = 0 if \u03b6 \u2208 G, (3a)\n\nu(\u03b6) = 0 if \u03b6 \u2208 \u03930, (3b)\n\nu(\u03b6) = \u03b4k \u2212\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b6\n1 + \u03b6\n\n\u2212 1\n\n2\nif \u03b6 \u2208 \u0393k, k = 1, 2, . . . , `, (3c)\u222b\n\n\u0393k\n\n\u2202u\n\n\u2202n\nds = 0 k = 1, 2, . . . , `, (3d)\n\n\u2202u\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6\n\n= \u2212 \u2202u0\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6\n\nif \u03b6 \u2208 \u0393k, k = `+ 1, `+ 2, . . . ,m, (3e)\n\nwhere \u03930 is the unit circle.\nFor the orientation of the boundary components of G, we assume that \u03930 is\n\noriented counterclockwise and the other curves \u03931, . . . ,\u0393m are oriented clockwise.\nWe assume that each boundary component \u0393k, k = 0, 1, . . . ,m, is parametrized by a\n2\u03c0-periodic function \u03b7k(t), t \u2208 Jk := [0, 2\u03c0] such that \u03b7\u2032k(t) 6= 0. Let J be the disjoint\nunion of the m + 1 intervals J0, . . . , Jm, the whole boundary \u0393 is parametrized by\nthe complex function \u03b7 defined on J by [11, 12]\n\n\u03b7(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f3\n\u03b70(t), t \u2208 J0,\n\u03b71(t), t \u2208 J1,\n\n...\n\u03b7m(t), t \u2208 Jm.\n\nNote that the unit circle \u03930 is parametrized by \u03b70(t) = eit, t \u2208 J0 = [0, 2\u03c0].\nLet n(\u03b6) be the unit outward normal vector at \u03b6 \u2208 \u0393 and let \u03bd(\u03b6) be the angle\n\nbetween the normal vector n(\u03b6) and the positive real axis. Then, for \u03b6 = \u03b7(t) \u2208 \u0393,\n\nn(\u03b6) = ei\u03bd(\u03b6) = \u2212i\n\u03b7\u2032(t)\n\n|\u03b7\u2032(t)|\n. (4)\n\nThus\n\n\u2202u0\n\n\u2202n\n= \u2207u0 \u00b7 n = cos \u03bd\n\n\u2202u0\n\n\u2202x\n+ sin \u03bd\n\n\u2202u0\n\n\u2202y\n= Re\n\n[\nei\u03bd\n\n(\n\u2202u0\n\n\u2202x\n\u2212 i\n\n\u2202u0\n\n\u2202y\n\n)]\n. (5)\n\nThe harmonic function u0(\u03b6) is the real part of a single-valued analytic function\nf0(\u03b6), i.e., u0(\u03b6) = Re[f0(\u03b6)], where\n\nf0(\u03b6) =\n1\n\n\u03c0i\nlog\n\n1\u2212 \u03b6\n1 + \u03b6\n\n+\n1\n\n2\n, (6)\n\n\n\n6\n\nand the branch of the logarithm function is chosen such that log 1 = 0. Then by the\nCauchy-Riemann equations, we have\n\nf \u20320(\u03b6) =\n\u2202u0(\u03b6)\n\n\u2202x\n\u2212 i\n\n\u2202u0(\u03b6)\n\n\u2202y\n,\n\nwhich, in view of (4) and (5), implies that\n\n|\u03b7\u2032(t)| \u2202u0\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b7(t)\n\n= Re [\u2212i\u03b7\u2032(t) f \u20320(\u03b7(t))] , \u03b7(t) \u2208 \u0393k, k = `+ 1, . . . ,m. (7)\n\nSince\n\nf \u20320(\u03b6) =\ni\n\n\u03c0\n\n(\n1\n\n1\u2212 \u03b6\n+\n\n1\n\n1 + \u03b6\n\n)\n,\n\nit follows that for \u03b7(t) \u2208 \u0393k and k = `+ 1, . . . ,m,\n\n|\u03b7\u2032(t)| \u2202u0\n\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b6=\u03b7(t)\n\n=\n1\n\n\u03c0\nRe\n\n[\n\u03b7\u2032(t)\n\n1\u2212 \u03b7(t)\n+\n\n\u03b7\u2032(t)\n\n1 + \u03b7(t)\n\n]\n. (8)\n\nThe harmonic function u can be assumed to be a real part of an analytic function\nf(\u03b6), \u03b6 \u2208 G. The boundary conditions (3b) and (3c) give the real parts of the\nfunction f(\u03b6) on \u0393k for k = 0, 1, . . . , `. Specifically, we have\n\nRe[f(\u03b7(t))] = 0, \u03b7(t) \u2208 \u03930 (9)\n\nand\n\nRe[f(\u03b7(t))] = \u03b4k \u2212\n1\n\n\u03c0\nIm log\n\n1\u2212 \u03b7(t)\n\n1 + \u03b7(t)\n\u2212 1\n\n2\nif \u03b7(t) \u2208 \u0393k, k = 1, . . . , `. (10)\n\nFor the remaining boundary components \u0393k for k = ` + 1, . . . ,m, we use the con-\ndition (3e) to determine the boundary condition on f(\u03b7). By the Cauchy-Riemann\nequations, we can show using the same arguments as in (7) that\n\n|\u03b7\u2032(t)| \u2202u\n\u2202n\n\n\u2223\u2223\u2223\u2223\n\u03b7(t)\n\n= Re [\u2212i\u03b7\u2032(t) f \u2032(\u03b7(t))] (11)\n\nThus, for \u03b7(t) \u2208 \u0393k for k = `+ 1, . . . ,m, it follows from (3e), (8), and (11) that\n\nRe [\u2212i\u03b7\u2032(t) f \u2032(\u03b7(t))] = \u2212 1\n\n\u03c0\nRe\n\n[\n\u03b7\u2032(t)\n\n1\u2212 \u03b7(t)\n+\n\n\u03b7\u2032(t)\n\n1 + \u03b7(t)\n\n]\n.\n\nIntegrating with respect to the parameter t for t \u2208 Jk, k = `+ 1, . . . ,m, we obtain\n\nRe [\u2212if(\u03b7(t))] =\n1\n\n\u03c0\nlog\n\n\u2223\u2223\u2223\u22231\u2212 \u03b7(t)\n\n1 + \u03b7(t)\n\n\u2223\u2223\u2223\u2223+ \u03b4k, (12)\n\nwhere the integration constants \u03b4k are undetermined. The constants \u03b4k, k = 1, . . . ,m\nin (10) and (12) are determined so that f(z) is a single-valued analytic function.\n\nSince we are interested in the function u, the real part of f , we may assume that\nc = f(\u03b1) is real for some given point \u03b1 in G. Define an analytic function g(\u03b6) in\nthe domain G through\n\nf(\u03b6) = (\u03b6 \u2212 \u03b1)g(\u03b6) + c. (13)\n\n\n\n7\n\nDefine also\nA(t) = e\u2212i\u03b8(t)(\u03b7(t)\u2212 \u03b1), (14)\n\nwhere \u03b8(t) is the piecewise constant function given by\n\n\u03b8(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n0, t \u2208 J0,\n...\n\n0, t \u2208 J`,\n\u03c0/2, t \u2208 J`+1,\n\n...\n\u03c0/2, t \u2208 Jm.\n\n(15)\n\nThus\ne\u2212i\u03b8(t)f(\u03b7(t)) = A(t)g(\u03b7(t)) + e\u2212i\u03b8(t)c,\n\nwhich implies that\n\nRe[A(t)g(\u03b7(t))] = Re[e\u2212i\u03b8(t)f(\u03b7(t))]\u2212 c cos \u03b8(t).\n\nOn the basis of the conditions (9), (10), and (12), the function g(z) satisfies the\nRiemann-Hilbert problem\n\nRe[A(t)g(\u03b7(t))] = \u03b3(t) + h(t), (16)\n\nwhere\n\nh(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n\u2212c, t \u2208 J0,\n\u03b41 \u2212 1\n\n2\n\u2212 c, t \u2208 J1,\n\n...\n\u03b4` \u2212 1\n\n2\n\u2212 c, t \u2208 J`,\n\n\u03b4`+1, t \u2208 J`+1,\n...\n\n\u03b4m, t \u2208 Jl+p.\n\n, \u03b3(t) =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\n0, t \u2208 J0,\n\n\u2212 1\n\u03c0\n\nIm log 1\u2212\u03b7(t)\n1+\u03b7(t)\n\n, t \u2208 J1,\n...\n\n\u2212 1\n\u03c0\n\nIm log 1\u2212\u03b7(t)\n1+\u03b7(t)\n\n, t \u2208 Jl,\n1\n\u03c0\n\nlog\n\u2223\u2223\u22231\u2212\u03b7(t)\n\n1+\u03b7(t)\n\n\u2223\u2223\u2223 , t \u2208 J`+1,\n...\n\n1\n\u03c0\n\nlog\n\u2223\u2223\u22231\u2212\u03b7(t)\n\n1+\u03b7(t)\n\n\u2223\u2223\u2223 , t \u2208 Jm.\n\n(17)\n\nIt is clear that the function \u03b3 is known and the piecewise constant function h is\nunknown and should be determined. Let \u00b5(t) = Im[A(t)g(\u03b7(t))], i.e., the boundary\nvalues of an analytic function g are given by\n\ng(\u03b7(t)) =\n\u03b3(t) + h(t) + i\u00b5(t)\n\nA(t)\n, t \u2208 J. (18)\n\nThus, in order to find the boundary values of the analytic function g, we need to\ndetermine the two unknown functions \u00b5 and h. These two functions can be computed\nusing the boundary integral equation with the generalized Neumann kernel [11, 12,\n13].\n\nLet H be the space of all real Ho\u0308lder continuous functions on \u0393, let I be the\nidentity operator, and let the integral operators N and M are defined on H by\n\nN\u00b5(s) =\n\n\u222b\nJ\n\n1\n\n\u03c0\nIm\n\n(\nA(s)\n\nA(t)\n\n\u03b7\u2032(t)\n\n\u03b7(t)\u2212 \u03b7(s)\n\n)\n\u00b5(t)dt, s \u2208 J,\n\nM\u00b5(s) =\n\n\u222b\nJ\n\n1\n\n\u03c0\nRe\n\n(\nA(s)\n\nA(t)\n\n\u03b7\u2032(t)\n\n\u03b7(t)\u2212 \u03b7(s)\n\n)\n\u00b5(t)dt, s \u2208 J.\n\n\n\n8\n\nThe kernel of the operator N is known as the generalized Neumann kernel. For\nmore details, see [11, 12, 13]. On account of [13], we have \u00b5 is the unique solution\nof the integral equation\n\n(I\u2212N)\u00b5 = \u2212M\u03b3. (19)\n\nAdditionally, the piecewise constant function h is given by\n\nh = [M\u00b5\u2212 (I\u2212N)\u03b3]/2. (20)\n\nWe compute approximations to the functions \u00b5 in (19) and h in (20) by the\nMATLAB function fbie from [12]. This function employs a discretization of the\nintegral equation (19) by the Nystro\u0308m method using the trapezoidal rule [14] to\nobtain an algebraic linear system of size (m+1)n\u00d7(m+1)n where n is the number of\ndiscretization points in each boundary component. The resulting system is solved by\napplying the generalized minimal residual method through the MATLAB function\ngmres. The matrix-vector multiplication in gmres is computed using the MATLAB\nfunction zfmm2dpart from the FMMLIB2D MATLAB toolbox [15]. The values of the\nother parameters in the function fbie are chosen as in [16]. For more details, we\nrefer the reader to [12].\n\n4 Computing the temperature distribution and\n\nthe heat flux\n\nBy computing \u00b5 and h, we obtain the boundary values of the function g through (18).\nThe values of the function g(\u03b6) for \u03b6 \u2208 G can be computed by the Cauchy integral\nformula. For the numerical computation of g(\u03b6) for \u03b6 \u2208 G, we use the MATLAB\nfunction fcau from [12]. Then, the values of f(\u03b6) can be computed by (13) and\nhence the values of the solution of the boundary value problem (2) is given for\n\u03b6 \u2208 G by\n\nU(\u03b6) = Re [f(\u03b6) + f0(\u03b6)] .\n\nWe deduce the values of the temperature distribution T (z) for any z \u2208 \u2126 by\n\nT (z) = Re\n[\nf(\u03a6\u22121(z)) + f0(\u03a6\u22121(z))\n\n]\n.\n\nMoreover, by computing the piecewise constant function h, we can compute as well\nthe values of the undetermined real constants c, \u03b41, . . . , \u03b4m from (16).\n\nThe function T (z) is the real part of the function\n\nF (z) = f(\u03a6\u22121(z)) + f0(\u03a6\u22121(z)), z \u2208 \u2126.\n\nAccording to the Cauchy-Riemann equations, it follows that the derivative of the\ncomplex potential F (z) on \u2126 is given by\n\nF \u2032(z) =\n\u2202T\n\n\u2202x\n\u2212 i\n\n\u2202T\n\n\u2202y\n.\n\nOne the other hand,\n\nF \u2032(z) =\nf \u2032(\u03a6\u22121(z))\n\n\u03a6\u2032(\u03a6\u22121(z))\n+\nf \u20320(\u03a6\u22121(z))\n\n\u03a6\u2032(\u03a6\u22121(z))\n, z \u2208 \u2126, (21)\n\n\n\n9\n\nwhere the denominator does not vanish in the domain \u2126 since \u03a6 is a conformal\nmapping. Therefore the heat flux can be expressed for z \u2208 D in terms of F \u2032(z) by\nthe formula\n\nq(z) = \u2212\n(\n\u2202T\n\n\u2202x\n,\n\u2202T\n\n\u2202y\n\n)\u2223\u2223\u2223\u2223\nz\n\n\u2261 \u2212F \u2032(z). (22)\n\nHence\n\u2202T\n\n\u2202y\n= \u2212 ImF \u2032(z). (23)\n\nThe derivatives f \u20320(\u03a6\u22121(z) and \u03a6\u2032(\u03a6\u22121(z)) in (21) can be computed analytically.\nSo, the values of the heat flux q can be estimated on the domain \u2126 by first approx-\nimating the derivatives of the boundary values of the analytic function f on each\nboundary components. This can be done by approximating the function f(\u03b7(t))\nusing trigonometric interpolating polynomials then differentiating. The values of\nf \u2032(\u03a6\u22121(z)), in the right-hand side of (21), can be then computed for z \u2208 \u2126 using\nthe Cauchy integral formula.\n\n5 Computing the effective thermal conductivity\n\nThe medium matrix without inhomogeneities is assumed to be homogeneous and\nisotropic. We will assume that the CNTs and the circular voids are in the part of\nthe domain between x = \u22121 and x = 1. Thus, the effective conductivity of a layer\nin the y-direction \u03bby is calculated by the formula (3.2.33) from the book [6, p. 53],\nwhich in our case on account of (23) becomes\n\n\u03bby = \u22121\n\n2\n\n\u222b 1\n\n\u22121\n\n\u2202T\n\n\u2202y\n(x, 0) dx =\n\n1\n\n2\nIm\n\n[\u222b 1\n\n\u22121\n\nF \u2032(x) dx\n\n]\n. (24)\n\nSince\n\n\u03be0(t) = \u03a6(\u03b70(t)) = \u03a6(eit) =\n1\n\n\u03c0\nlog\n\n1 + eit\n\n1\u2212 eit\n+\n\ni\n\n2\n, 0 \u2264 t \u2264 2\u03c0,\n\nwhere for 0 < t < \u03c0, \u03be0(t) is on the line y = 1 and for \u03c0 < t < 2\u03c0, \u03be0(t) is on the\nreal line. Thus, for \u03c0 < t < 2\u03c0, we have\n\n\u03be0(t) =\n1\n\n\u03c0\nlog\n\n\u2223\u2223\u2223\u2223cot\nt\n\n2\n\n\u2223\u2223\u2223\u2223 .\nSince \u22121 = \u03be0(t1) and 1 = \u03be0(t2) where\n\n\u03c0 < t1 = 2\u03c0 \u2212 2 tan\u22121 (e\u03c0) < t2 = 2\u03c0 \u2212 2 tan\u22121\n(\ne\u2212\u03c0\n)\n< 2\u03c0. (25)\n\nConsequently, (24) can be written as\n\n\u03bby =\n1\n\n2\nIm\n\n[\u222b t2\n\nt1\n\nF \u2032(\u03be0(t))\u03be\u20320(t) dt\n\n]\n. (26)\n\nIn combining (21) with the fact that \u03be\u20320(t) = ieit\u03a6\u2032(eit), we can see that\n\nF \u2032(\u03be0(t)) =\nf \u2032(\u03a6\u22121(\u03be0(t)))\n\n\u03a6\u2032(\u03a6\u22121(\u03be0(t)))\n+\nf \u20320(\u03a6\u22121(\u03be0(t)))\n\n\u03a6\u2032(\u03a6\u22121(\u03be0(t)))\n=\nf \u2032(eit)\n\n\u03a6\u2032(eit)\n+\nf \u20320(eit)\n\n\u03a6\u2032(eit)\n.\n\n\n\n10\n\nHence,\n\n\u03bby =\n1\n\n2\nIm\n\n[\u222b t2\n\nt1\n\n[\nieit\n(\nf \u2032(eit) + f \u20320(eit)\n\n)]\ndt\n\n]\n, (27)\n\nwhich implies that\n\n\u03bby =\n1\n\n2\nIm\n[\nf(eit2)\u2212 f(eit1)\n\n]\n+\n\n1\n\n2\nIm\n[\nf0(eit2)\u2212 f0(eit1)\n\n]\n. (28)\n\nThe second term in the right-hand side of (27) does not depend on the CNTs or the\nvoids. In view of (6) and (25), we have\n\n1\n\n2\nIm\n[\nf0(eit2)\u2212 f0(eit1)\n\n]\n= 1,\n\nand hence\n\n\u03bby = 1 +\n1\n\n2\nIm\n[\nf(eit2)\u2212 f(eit1)\n\n]\n. (29)\n\nSince eit1 and eit2 are on the unit circle \u03930, the external boundary of G, and taking\ninto account (13), (14), (15), and (18), Equation (29) can be written as\n\n\u03bby = 1 +\n1\n\n2\n[\u00b5(t2)\u2212 \u00b5(t1)] . (30)\n\nBy solving the integral equation (19), we obtain approximate values of \u00b5 at the\ndiscretization points. These values are employed to interpolate the approximate\nsolution \u00b5 on J0 by a trigonometric interpolation polynomial, which is then used to\napproximate the values of \u00b5(t1) and \u00b5(t2).\n\n6 Numerical results\n\nThe above proposed method with n = 211 is applied to compute the temperature\nfield T and the heat flux q for several examples. We will choose the CNTs and the\ncircular voids within the part of the domain between x = \u22121 and x = 1. To compute\nthe values of the temperature distribution T and the heat flux q, we discretize part\nof the domain \u2126, namely for \u22121.5 \u2264 x \u2264 1.5 and 0.0001 \u2264 y \u2264 0.9999. Afterwards,\nwe compute the values of the temperature distribution T and the heat flux q at\nthese points as described in Section 4.\n\n6.1 The domain \u2126 with only circular voids\n\nIn this subsection, we consider the domain \u2126 with m non-overlapping circular holes\nand without any CNT (i.e., ` = 0). We also assume that all circular holes have the\nsame radius r with the parametrization\n\n\u03b7j(t) = zj + re\u2212it, 0 \u2264 t \u2264 2\u03c0, j = 1, 2, . . . ,m,\n\nwhere z1, z2, . . . , zm are the centers of the circular holes. As these circular holes\nare chosen in the part of the domain \u2126 between x = \u22121 and x = 1, we define the\nconcentration c(m, r) of these voids to be the area of these circular holes over the\narea of the rectangle {(x, y) : \u22121 \u2264 x \u2264 1, 0 \u2264 y \u2264 1}, i.e.,\n\nc(m, r) =\nmr2\u03c0\n\n2\n. (31)\n\n\n\n11\n\nThe Clausius-Mossotti approximation (CMA) also known as Maxwel\u2019s formula\ncan be applied for dilute composites when the concentration (31) is sufficiently small.\nBelow, we write this formula for a macroscopically isotropic media with insulators\nof identical circular holes within the precisely established precision in [17]\n\n\u03bbe =\n1\u2212 c\n1 + c\n\n+O(c3). (32)\n\nExample 1 We consider m = 5 circular holes with the radius r for 0 < r < 0.2.\nFor Case I, we assume the centers of the holes to be set to \u22120.8 + 0.5i, \u22120.4 + 0.5i,\n0.5i, 0.4 + 0.5i, and 0.8 + 0.5i. The contour plot of T and |q| for r = 0.1 are shown\nin Figure 3 (first row). The approximate value of the effective thermal conductivity\nfor r = 0.1 is\n\n\u03bby = 0.8533491.\n\nWhen r is close to 0.2, the circular holes become adjacent to each other. To show\nthe effects of the radius r on the effective thermal conductivity \u03bby, we compute the\nvalues of \u03bby for several values of r, 0.00001 \u2264 r \u2264 0.19999. The obtained results\nare presented in Figure 4 where, by (31), the concentration of these 5 holes is\nc = c(5, r) = 5r2\u03c0/2 \u2248 7.854r2 for 0 < c < \u03c0/10 and 0 < r < 0.2. The values of\nthe estimated effective conductivity \u03bbe is given also in Figure 4. As one can expect,\nthere is a good agreement between \u03bby and \u03bbe for small values of c. In the same time,\nthe divergence of \u03bby and \u03bbe is observed for the concentrations greater than 0.1.\n\nFor Case II, the centers of the holes become \u22120.8+0.5i, \u22120.4+0.3i, 0.5i, 0.4+0.7i,\nand 0.8 + 0.5i, which means the centers are not anymore horizontally aligned as the\nsecond and fourth centers are now shifted by 0.2 up and down, respectively. This is\ndisplayed in Figure 3 (second row). The curve showing the obtained values of \u03bby as\na function of the concentration is depicted in Figure 4.\n\nFigure 4 illustrates that the values of \u03bby depend on the position of the circular\nholes centers while the values of \u03bbe are the same for both cases since it depends only\non the concentration of the circular holes and not on their positions. We notice a\nbetter agreement between \u03bby and \u03bbe in Cases II when comparing to Case I.\n\nExample 2 We consider m = 30 circular holes with centers xk + 0.25i, xk + 0.5i,\nand xk + 0.75i, where xk = \u22120.9 + 0.2(k \u2212 1) for k = 1, 2, . . . , 10, and with radius r\nfor 0 < r < 0.1. The contour plot of T and |q| for r = 0.099 are shown in Figure 5.\nThe approximate value of the effective thermal conductivity for r = 0.099 is\n\n\u03bby = 0.1519156.\n\nWhen r is close to 0.1, the circular holes become adjacent to each other. We\ncompute the values of \u03bby for several values of r, 0.00001 \u2264 r \u2264 0.09999. The\nobtained results are depicted in Figure 6 (left) where, by (31), the concentration of\nthese 30 holes is c = c(30, r) = 30r2\u03c0/2 \u2248 47.124r2. Note that 0 < c < 3\u03c0/20 for\n0 < r < 0.1.\n\nExample 3 We take up here the case of m = 50 circular holes with centers xk+0.1i,\nxk + 0.3i, xk + 0.5i, xk + 0.7i, and xk + 0.9i, where xk = \u22120.9 + 0.2(k \u2212 1) for\nk = 1, 2, . . . , 10, and with radius r for 0 < r < 0.1. On the basis of (31), the\nconcentration of these 50 holes is c = c(50, r) = 50r2\u03c0/2 \u2248 78.54r2. For 0 < r < 0.1,\n\n\n\n12\n\nFigure 3: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with m = 5 circular holes (Example 1 for r = 0.1). First row for Case\nI and second row for Case II.\n\nFigure 4: The effective thermal conductivity \u03bby and the estimated effective con-\nductivity \u03bbe in (32) vs. the concentration c(m, r) = 5r2\u03c0/2 for the domain \u2126 with\nm = 5 circular holes for 0.00001 \u2264 r \u2264 0.19999. The vertical dotted line is c = \u03c0/10.\n\nwe have 0 < c < \u03c0/4. When r is close to 0.1, the circular holes become adjacent\nto each other, and the concentration is almost equal to \u03c0/4. The obtained results\nshowing the behavior of \u03bby as a function of the radius r, for 0.001 \u2264 r \u2264 0.099, are\npresented in Figure 6 (right).\n\n6.2 The domain \u2126 with only CNTs\n\nIn this subsection, we consider the domain \u2126 with m non-overlapping elliptic CNTs\nwithout any circular holes (i.e., m = `). We assume that all CNTs have equal sizes\nand are of elliptic shape where the ellipses have the parametrization\n\n\u03b7j(t) = zj + a cos t\u2212 ib sin t, 0 \u2264 t \u2264 2\u03c0, j = 1, 2, . . . ,m, (33)\n\nwhere zj is the center of the ellipse, 2a and 2b are the length of the ellipses axes\nin the x and y-directions, respectively. If a/b > 1, the major axis of the ellipses is\n\n\n\n13\n\nFigure 5: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with 30 circular holes (r = 0.099).\n\nFigure 6: The effective thermal conductivity \u03bby vs. the concentration c(m, r) =\nmr2\u03c0/2. On the left, the domain \u2126 with m = 30 circular holes (Example 2) and\n0.00001 \u2264 r \u2264 0.09999. The vertical dotted line is c = 3\u03c0/20. On the right, the\ndomain \u2126 with m = 50 circular holes (Example 3) and 0.001 \u2264 r \u2264 0.099. The\nvertical dotted line is c = \u03c0/4.\n\nhorizontal, if a/b < 1, the major axis of the ellipses is vertical, and if a/b = 1, the\nellipses reduced to circles. Here, we choose a and b such that their ratio satisfies\n0.1 \u2264 a/b \u2264 10. These elliptic shape CNTs are chosen in the part of the domain\n\u2126 between x = \u22121 and x = 1. So, we define the concentration c(m, a, b) of these\nCNTs to be\n\nc(m, a, b) =\nmab\u03c0\n\n2\n. (34)\n\nIf a\nb\n\ufffd 1, instead of (34) the plane slits density is considered in the theory of\n\ncomposites and porous media\n\n\u03c6 =\nmb2\n\n|\u2126|\n=\nmb2\n\n2\n, (35)\n\nFor a macroscopically isotropic media with only perfectly conducting identical\ncircular inclusions (CNTs), an approximation of the effective conductivity \u03bbe is given\nby the inverse to (32) value (see [17])\n\n\u03bbe =\n1 + c\n\n1\u2212 c\n+O(c3). (36)\n\nExample 4 We consider m = 5 elliptic CNTs with centers \u22120.8 + 0.5i, \u22120.4 + 0.5i,\n0.5i, 0.4 + 0.5i, and 0.8 + 0.5i, and where 0 < a < 0.2 and 0 < b < 0.5. Figure 7\n\n\n\n14\n\n(first row) presents the contour plot of T and |q| for a = 0.19 and b = 0.019 (the\nellipses are horizontal). For these values of a and b, the approximate value of the\neffective thermal conductivity is\n\n\u03bby = 1.0272480.\n\nFor a = 0.019 and b = 0.19, the contour plot of T and |q| are shown in Figure 7\n(second row). The approximate value of the effective thermal conductivity for these\nvalues of a and b is\n\n\u03bby = 1.2804116.\n\nThe CNTs in Figure 7 have the same concentration. However, the value of \u03bby is\nlarger for the vertical ellipses case.\n\nWhen a approaches 0.2, the ellipses get adjacent to each other. On the other\nhand, they come close to the upper and lower walls when b approaches 0.5. We\ncompute the values of \u03bby for several values of a, 0.0001 \u2264 a \u2264 0.1999, with b =\n0.1a. The obtained results are presented in Figure 8 (left) where, by (34), the\nconcentration of these 5 ellipses is c = c(5, a, b) = 5ab\u03c0/2 = a2\u03c0/4 \u2248 0.7854a2.\nNote that, for 0 < a < 0.2 and b = 0.1a, we have 0 < c < \u03c0/100.\n\nThe values of \u03bby are also computed for several values of b for 0.001 \u2264 b \u2264 0.499\nwith a = 0.1b. Since a/b = 0.1 is small, the obtained values of \u03bby are plotted versus\nthe values of \u03c6 = 2.5b2, given by (35), where 0 < \u03c6 < 5/8 for 0 < b < 0.5. The\nobtained results are presented in Figure 8 (right).\n\nFigure 7: A contour plot of the temperature distribution T and the heat flux |q| for\nthe domain \u2126 with m = 5 elliptic CNTs (Example 4), where a = 0.19 and b = 0.019\nfor the first row and a = 0.019 and b = 0.19 for the second row.\n\nExample 5 We consider m = 200 elliptic CNTs with centers xk + iyj for k =\n1, 2, . . . , 20 and j = 1, 2, . . . , 10 where xk = \u22120.95 + (k\u2212 1)/10 and yj = 0.05 + (j\u2212\n1)/10, and with 0 < a < 0.05 and 0 < b < 0.05.\n\nWe compute the values of \u03bby for several values of a, 0.0002 \u2264 a \u2264 0.0498,\nand a/b = 10 (i.e., the ellipses are horizontal) where the ellipses become close to\neach other when a approaches 0.05. The obtained results are presented in Figure 9\n\n\n\n15\n\nFigure 8: The effective thermal conductivity \u03bby for the domain \u2126 with m = 5\nelliptic CNTs (Example 4). On the left, the effective thermal conductivity \u03bby vs.\nthe concentration c = a2\u03c0/4 for 0.0001 \u2264 a \u2264 0.1999 and a/b = 10. The vertical\ndotted line is c = \u03c0/100. On the right, the effective thermal conductivity \u03bby vs.\nthe plane slits density \u03c6 = 2.5b2 for 0.001 \u2264 b \u2264 0.499 and a/b = 0.1. The vertical\ndotted line is \u03c6 = 0.625.\n\n(left) where the concentration of these 200 ellipses is c = 10a2\u03c0 \u2248 31.416a2. For\n0 < a < 0.05 and a/b = 10, we have 0 < c < \u03c0/40. Then, we compute the values\nof \u03bby for several values of b, 0.0002 \u2264 b \u2264 0.0498, and a/b = 0.1. The obtained\nresults for \u03bby versus the the plane slits density \u03c6 = mb2/2 = 100b2 are presented in\nFigure 9 (right) where 0 < \u03c6 < 1/4 for 0 < b < 0.05 and a/b = 0.1.\n\nWhen a/b = 1, the ellipses reduce to circles. We compute the values of \u03bby for\nseveral values of a, 0.0002 \u2264 a \u2264 0.0498. The obtained results are presented in\nFigure 10 where the concentration of these 200 ellipses is c = 100a2\u03c0 \u2248 314.16a2.\nFor 0 < a < 0.05 and a/b = 1, we have 0 < c < \u03c0/4. Figure 10 presents also the\nvalues of the estimated effective conductivity \u03bbe given by (36).\n\nFigure 9: The effective thermal conductivity \u03bby for the domain \u2126 with m = 200\nelliptic CNTs (Example 5). On the left, the effective thermal conductivity \u03bby vs.\nthe concentration c = 10a2\u03c0 for 0.0002 \u2264 a \u2264 0.0498 with a/b = 10. The vertical\ndotted line is c = \u03c0/40. On the right, the effective thermal conductivity \u03bby vs. the\nplane slits density \u03c6 = 100b2 for 0.0002 \u2264 b \u2264 0.0498, with a/b = 0.1. The vertical\ndotted line is \u03c6 = 1/4. The vertical dotted line is c = 1/4.\n\n\n\n16\n\nFigure 10: The effective thermal conductivity \u03bby (for the domain \u2126 with m = 200\ncircular CNTs obtained by setting b = a in Example 5) and the estimated effective\nconductivity \u03bbe in (36) vs. the concentration c = 100a2\u03c0 for 0.0002 \u2264 a \u2264 0.0498.\nThe vertical dotted line is c = \u03c0/4.\n\n6.3 The domain \u2126 with 2000 CNTs and/or circular voids\n\nWe are concerned in this section with the study of a large number of perfect con-\nductors and/or insulators. We consider two example where in the first both perfect\nconductors and insulators have the same circular shape, while in the second, con-\nductors have an elliptic shape and insulators have a circular shape. The present\ninvestigation is useful when studying the impact of geometric shapes on the macro-\nscopic properties of three-phases high contrast media.\n\nExample 6 We take m = 2000 circular holes of equal size with radius r = 0.0075.\nIn this example, the concentration c = c(m, r) = 1000r2\u03c0 \u2248 0.1767 is constant\nand the locations of these holes are chosen randomly. In this case, the following\nextension of CMA may be used\n\n\u03bbe =\n1 + c1 \u2212 c2\n\n1\u2212 c1 + c2\n\n+O(c3), (37)\n\nwhere c1 denotes the conductor concentration, c2 the insulator concentration, and\nc = c1 + c2. Three cases are considered:\n\nCase I: We assume that half of the holes are CNTs and the other half are voids (see\nFigure 11). For this case, c1 and c2 are given by c1 = c2 = 500r2\u03c0 \u2248 0.0884.\n\nCase II: All holes are voids, and hence c1 = 0 while c2 = 1000r2\u03c0 \u2248 0.1767.\n\nCase III: All holes are CNTs, and hence c1 = 1000r2\u03c0 \u2248 0.1767 while c2 = 0.\n\nFor each case, we run the code for 20 times, so that to get 20 different locations\nfor these circular holes. In each of these 20 experiments, we compute the value of\nthe effective thermal conductivity \u03bby by the presented method and the values of the\nestimated effective conductivity \u03bbe by (32). As we can see from Figure 12, \u03bbe is a\nconstant and the values of \u03bby depend on the locations of the holes.\n\n\n\n17\n\nFigure 11: The domain \u2126 with m = 2000 circular holes. Case I: We have p = 1000\nvoids (blue circles) and ` = 1000 CNTs (red circles).\n\nExample 7 We consider m = 2000 elliptic and circular holes with ` = 1000 elliptic\nperfect conductors and p = 1000 circular insulators of equal area \u03c0r2 (see Figure 13).\nThe radius r is chosen to be the same as in the previous example, i.e., r = 0.0075.\nThe locations of both elliptic and circular holes are chosen randomly. For the ellipses,\nwe assume that the ratio between the length of the major axis and the minor axis\nis 4, and the angles between the major axis and the x-axis are chosen randomly.\nAs in the previous example, we run the code for 20 times. In each of these 20\nexperiments, we compute the value of the effective thermal conductivity \u03bby by the\npresented method. The computed values are shown in Figure 13 (left).\n\nSince we have the same number of elliptic perfect conductors and circular insu-\nlators of equal area \u03c0r2, the conductor concentration c1 and the insulator concen-\ntration c2 are equal and given by c1 = c2 = 500r2\u03c0 \u2248 0.0884. Although c1 and c2\n\nhere are the same as in Case I of the previous example, it is clear from Figures 12\n(first row) and 13 (right) that the values \u03bby in this example (elliptic conductors) are\nlarger than those in the previous example (circular conductors).\n\n\n\n18\n\nFigure 12: The values of the effective thermal conductivity \u03bby and the estimated\neffective conductivity \u03bbe in (37) (for the domain \u2126 with m = 2000 circular holes in\nExample 6) vs. the number of the experiment for Case I (first row), Case II (second\nrow, left), and Case III (second row, right).\n\nFigure 13: On the left, the domain \u2126 in Example 7 with m = p + ` = 2000 holes,\np = 1000 circular voids (blue) and ` = 1000 elliptic CNTs (red). On the right, the\nvalues of the effective thermal conductivity \u03bby vs. the number of the experiment.\n\n\n\n19\n\n6.4 The dependence of \u03bby on \u03c6 and c\n\nWe consider now a domain domain \u2126 with m = ` = 276 non-overlapping elliptic\nCNTs without any void. We assume that all CNTs are of equal size and elliptic\nshape. The ellipses are parametrized by (33) with a < b, which means they are\ntaken to be vertical.\n\nFirst we assume that the concentration c = c(m, a, b) is constant and we choose\nthe values of the parameters a and b such that the plane slits density \u03c6 = \u03c6(m, a, b) \u2208\n[0.4, 1.3]. The domain \u2126 for c = 0.5 and \u03c6 = 1.3 is shown in Figure 14. We consider\nas well five values of the concentration, c = 0.1, 0.2, 0.3, 0.4, 0.5. Then, for each of\nthese values, we compute and show in Figure 15 (left) the values of \u03bby = \u03bby(\u03c6).\n\nAfterwards, we take up the plane slits density \u03c6 = \u03c6(m, a, b) to be constant\nand we choose the values of the parameters a and b such that the concentration\nc = c(m, a, b) \u2208 [0.1, 0.5]. We consider four values of \u03c6, \u03c6 = 0.4, 0.7, 1, 1.3, and\ncompute again \u03bby = \u03bby(c) for each case. The obtained results are presented in\nFigure 15 (right).\n\nFigure 14: The domain \u2126 with m = 276 elliptic CNTs for c = 0.5 and \u03c6 = 1.3.\n\nFigure 15: The effective thermal conductivity \u03bby for the domain \u2126 with m = 276\nelliptic CNTs. On the left, the values of \u03bby = \u03bby(\u03c6) for \u03c6 \u2208 [0.4, 1.3] and for several\nvalues of c. On the right, the values of \u03bby = \u03bby(c) for c \u2208 [0.1, 0.5] and for several\nvalues of \u03c6.\n\n\n\n20\n\n7 Conclusion\n\nA systematic estimation of the local fields and the effective conductivity properties\nof 2D composites reinforced by uniformly and randomly distributed CNTs is car-\nried out. It is assumed that the medium may contains voids as well. The CNTs\nare considered as perfectly conducting elliptic inclusions and the voids as circular\ninsulators. For definiteness, a composite strip is considered with the given constant\nexternal field passing through the strip. The local field is governed by the Laplace\nequation in the multiply connected domain formed by the strip without two types\nof holes, CNTs and voids. The Dirichlet boundary condition is imposed on the\nCNTs boundary and the Neumann boundary condition governs the void boundary.\nA numerical method is developed to solve the mixed problem for a large number\nof CNTs and voids. The method is based on using the boundary integral equation\nwith the generalized Neumann kernel [11, 12]. One key feature of this method is\nthat it can be employed for domains with complex geometry as it provides accurate\nresults even when the boundaries are close together. To solve the integral equation,\nthe Fast Multipole Method has been employed, which enables to treat the case of\nthousands of CNTs and voids. With the help of conformal mappings, the presented\nmethod can be extended to include the case when CNTs and voids are rectilinear\nslits as done in [16] for example.\n\nThe computational study has shown a dependence of the local fields and the\neffective conductivity \u03bby on the concentration of voids c given by (34) as well as\non the density \u03c6 of CNTs given by (35). Besides the opposite conductive proper-\nties, voids and CNTs have also different types of the geometric parameters c and\n\u03c6 that are not reduced to each other. Hence, the present study is concerned ad-\nditionally with the case of three-phase composites of high contrast conductivity.\nIt is demonstrated that our simulations are covered with the classical lower order\napproximations (Clausius-Mossotti, Maxwell) for dilute composites. The high or-\nder concentrations and densities led to different results from the classical ones. It\nis worth noting that the huge number of numerical experiments for uniformly dis-\ntributed inclusions yield the graphical dependencies of \u03bby on c and \u03c6, which can be\nused in practical applications.\n\nAcknowledgments\n\nReferences\n\n[1] Mostafizur Rahaman, Dipak Khastgir, and Ali Kanakhir Aldalbahi. Carbon-\ncontaining polymer composites. Springer, 2019.\n\n[2] Lichao Feng, Ning Xie, and Jing Zhong. Carbon nanofibers and their compos-\nites: a review of synthesizing, properties and applications. Materials, 7(5):3919\u2013\n3945, 2014.\n\n[3] Marcio Loos. Carbon nanotube reinforced composites: CNT Polymer Science\nand Technology. Elsevier, 2014.\n\n[4] Ronald L Poveda and Nikhil Gupta. Carbon nanofiber reinforced polymer com-\nposites. Springer, 2016.\n\n\n\n21\n\n[5] Pierre M Adler, Jean-Franc\u0327ois Thovert, and Valeri V Mourzenko. Fractured\nporous media. Oxford University Press, 2013.\n\n[6] S. Gluzman, V. Mityushev, and W. Nawalaniec. Computational analysis of\nstructured Media. Academic Press, London, 2017.\n\n[7] Mohamed Nasser, Ali HM Murid, and Samer AA Al-Hatemi. A boundary\nintegral equation with the generalized neumann kernel for a certain class of\nmixed boundary value problem. J. Appl. Math., 2012, 2012.\n\n[8] Mohamed MS Nasser and Matti Vuorinen. Numerical computation of the ca-\npacity of generalized condensers. J. Comput. Appl. Math., 377:112865, 2020.\n\n[9] S Malekie and F Ziaie. Study on a novel dosimeter based on polyethylene\u2013\ncarbon nanotube composite. Nuclear Instruments and Methods in Physics Re-\nsearch Section A: Accelerators, Spectrometers, Detectors and Associated Equip-\nment, 791:1\u20135, 2015.\n\n[10] Jianming Zhang, Masataka Tanaka, and Toshiro Matsumoto. A simplified ap-\nproach for heat conduction analysis of cnt-based nano-composites. Computer\nmethods in applied mechanics and engineering, 193(52):5597\u20135609, 2004.\n\n[11] R. Wegmann and M.M.S. Nasser. The Riemann-Hilbert problem and the gener-\nalized Neumann kernel on multiply connected regions. J. Comput. Appl. Math.,\n214:36\u201357, 2008.\n\n[12] M.M.S. Nasser. Fast solution of boundary integral equations with the general-\nized Neumann kernel. Electron. Trans. Numer. Anal., 44:189\u2013229, 2015.\n\n[13] M.M.S. Nasser. Numerical conformal mapping of multiply connected regions\nonto the second, third and fourth categories of Koebe canonical slit domains.\nJ. Math. Anal. Appl., 382:47\u201356, 2011.\n\n[14] K.E. Atkinson. The Numerical Solution of Integral Equations of the Second\nKind. Cambridge University Press, Cambridge, 1997.\n\n[15] L. Greengard and Z. Gimbutas. FMMLIB2D: A MATLAB toolbox for fast\nmultipole method in two dimensions, version 1.2. edition, 2012. http://www.\n\ncims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html. Accessed 1 Jan 2018.\n\n[16] M.M.S. Nasser and E. Kalmoun. Application of integral equations to simulat-\ning local fields in carbon nanotube reinforced composites. In R. Mcphedran,\nS. Gluzman, V. Mityushev, and N. Rylko, editors, 2D and Quasi-2D Compos-\nite and Nanocomposite Materials: Properties and Photonic Applications, pages\n233\u2013248. Elsevier, Amsterdam, 2020.\n\n[17] V Mityushev and N Rylko. Maxwell\u2019s approach to effective conductivity and\nits limitations. Quarterly Journal of Mechanics and Applied Mathematics,\n66(2):241\u2013251, 2013.\n\nhttp://www.cims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html\nhttp://www.cims.nyu.edu/cmcl/fmm2dlib/fmm2dlib.html\n\n\t1 Introduction\n\t2 Problem formulation\n\t3 The integral equation method\n\t4 Computing the temperature distribution and the heat flux\n\t5 Computing the effective thermal conductivity\n\t6 Numerical results\n\t6.1 The domain  with only circular voids\n\t6.2 The domain  with only CNTs\n\t6.3 The domain  with 2000 CNTs and/or circular voids\n\t6.4 The dependence of y on  and c\n\n\t7 Conclusion\n\n"}
{"Title": "Robust reliability-based topology optimization under random-field material model", "Authors": "Trung Pham, Christopher Hoyle", "Abstract": "  This paper proposes an algorithm to find robust reliability-based topology optimized designs under a random-field material model. The initial design domain is made of linear elastic material whose property, i.e., Young's modulus, is modeled by a random field. To facilitate computation, the Karhunen-Lo\u00e8ve expansion discretizes the modeling random field into a small number of random variables. Robustness is achieved by optimizing a weighted sum of mean and standard deviation of a quantity of interest, while reliability is employed through a probabilistic constraint. The Smolyak-type sparse grid and the stochastic response surface method are applied to reduce computational cost. Furthermore, an efficient inverse-reliability algorithm is utilized to decouple the double-loop structure of reliability analysis. The proposed algorithm is tested on two common benchmark problems in literature. Finally, Monte Carlo simulation is used to validate the claimed robustness and reliability of optimized designs.      ", "Subject": "Optimization and Control (math.OC)", "ID": "arXiv:2201.00004", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust reliability-based topology optimization\nunder random-field material model\n\nTrung Pham\u2217\nDepartment of Aerospace Engineering\n\nUniversity of Michigan\nAnn Arbor, Michigan 48109, USA\n\nEmail: trungp@umich.edu\n\nChristopher Hoyle\nSchool of Mechanical, Industrial & Manufacturing Engineering\n\nOregon State University\nCorvallis, Oregon 97331\u20136001, USA\nEmail: chris.hoyle@oregonstate.edu\n\nThis paper proposes an algorithm to find robust reliability-\nbased topology optimized designs under a random-field ma-\nterial model. The initial design domain is made of linear\nelastic material whose property, i.e., Young\u2019s modulus, is\nmodeled by a random field. To facilitate computation, the\nKarhunen\u2212\u2013Loe\u0300ve expansion discretizes the modeling ran-\ndom field into a small number of random variables. Robust-\nness is achieved by optimizing a weighted sum of mean and\nstandard deviation of a quantity of interest, while reliability\nis employed through a probabilistic constraint. The Smolyak-\ntype sparse grid and the stochastic response surface method\nare applied to reduce computational cost. Furthermore, an\nefficient inverse-reliability algorithm is utilized to decouple\nthe double-loop structure of reliability analysis. The pro-\nposed algorithm is tested on two common benchmark prob-\nlems in literature. Finally, Monte Carlo simulation is used to\nvalidate the claimed robustness and reliability of optimized\ndesigns.\n\n1 Introduction\nA mechanical structure is characterized by its boundary\n\nand loading conditions, its material properties, and its topol-\nogy. Finding an appropriate topology is often a major task\nin structural design, which has fueled the rise of topology\noptimization (TO) in the last two decades. Without consid-\nering a designer\u2019s experience, TO is a mathematical tool to\nidentify the optimal size, shape, and connectivity of a de-\nsign [1], resulting in improved performance while using the\nleast amount of material. However, research in TO often\nonly concerns with deterministic inputs, while uncertainty\nis inherent in nature, which manifests itself in the stochastic-\nity of random parameters of engineered systems. The anal-\n\n\u2217Address all correspondence related to this paper to this author.\n\nysis and design of engineered systems are affected heavily\nby uncertainty; for example, modern design codes, such as\nACI 318 [2] and AISC 360 [3], have comprehensive recom-\nmendations of safety factors for loading, material property,\nconstruction conditions, etc., which obviously are intended\nto take into account uncertainty. Among different sources\nof uncertainty, material property is intrinsically random in\nspace, which has been modeled by random field in the de-\nsign of composite structures [4, 5, 6]. Such a modeling tech-\nnique has been especially popular in the vast literature of the\nStochastic Finite Element Method [7, 8, 9], which certainly\nproves its validity and the need to be considered in TO. So\nfar, uncertainty in TO has been treated separately by robust\noptimization or reliability-based optimization, while both ro-\nbustness and reliability are desired properties of design under\nuncertainty. Therefore, this paper presents an algorithm to\nfind robust reliability-based topology optimized design un-\nder a random-field material model.\n\nThere are a number of steps in our proposed algo-\nrithm, which are addressed in depth in the subsequent\nsections. Here we provide a brief overview of them.\nFirst, from a known covariance function, the modeling ran-\ndom field is estimated by a random polynomial using the\nKarhunen\u2212\u2013Loe\u0300ve expansion. To make the design robust,\na weighted sum of mean and standard deviation of a quantity\nof interest, which are computed by a Smolyak-type sparse\ngrid, is considered as the objective function. Reliability of\nthe design is reflected in the probabilistic constraint, which\nis handled by the Sequential Optimization and Reliability\nAssessment (SORA) method [10]\u2212a single-loop inverse-\nreliability algorithm\u2212coupled with the performance measure\napproach [11] to reduce the computational cost of reliability\nanalysis. The stochastic response surface method approxi-\nmates the random output, which is required to solve the in-\n\n1 Copyright \u00a9 by ASME\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n4v\n1 \n\n [\nm\n\nat\nh.\n\nO\nC\n\n] \n 2\n\n9 \nD\n\nec\n 2\n\n02\n1\n\n\n\nverse reliability analysis problem.\nThe layout of this paper is as follows. Section 2 is\n\na literature review of uncertainty propagation, robust and\nreliability-based optimization, and reliability analysis, with\nfocus on TO under uncertainty. Section 3 derives the math-\nematical formulation of the deterministic TO problem and\nthe robust reliability-based topology optimization (RRBTO)\nproblem. This section also exposes the details of our pro-\nposed solution for the RRBTO problem. Two numerical ex-\namples show how our proposed algorithm works, and are\nverified by Monte Carlo simulation in section 4 followed by\ndiscussions of the results. Finally, the paper is summarized\nwith major findings, and then suggests future work.\n\n2 Background\nThe earliest idea of topology optimization (TO) can be\n\ntraced back to Michell\u2019s paper [12] in 1904. Since then TO\nhas been mature enough to have its own treatise [1]. As a\nmathematical optimization problem, TO requires specifica-\ntion of objective function(s) and constraint(s), which do not\ninvolve any probabilistic quantities when using deterministic\ninputs. Thus, changes are needed to deal with uncertainty\nin the forms of robust optimization (RO) and reliability-\nbased optimization (RBO). A number of papers, which are\nreviewed below, have tried to integrate uncertainty into a TO\nproblem using RO and RBO separately.\n\nRO primarily aims to minimize the variability of an\noutput of interest [13], due to uncertainty, around its mean\nvalue. Therefore, this goal can be formulated by minimizing\na weighted sum of mean and standard deviation of the output\nof interest. This approach was chosen in several papers cov-\nering various sources of uncertainty and solution methods:\nspatial variation of manufacturing error with Monte Carlo\nsimulations [14]; random-field truss material with a multi-\nobjective approach [15]; random loading field and random\nmaterial field with the level set method [16]; material and\ngeometric uncertainties with stochastic collocation methods\nand perturbation techniques [17, 18]; misplacement of ma-\nterial and imperfect geometry [19, 20]; Young\u2019s modulus of\ntruss members with a perturbation method [21]; random-field\nmaterial properties with a polynomial chaos expansion [22];\ngeometric and material property uncertainties with a stochas-\ntic perturbation method for frame structures [23]; material\nuncertainty with known second-order statistics [24]; random\nspatial distribution of Young\u2019s modulus and loading uncer-\ntainty in a stress-based problem [25,26]; and random loading\nfield with stochastic collocation methods [27]. The robust\ntopology optimization (RTO) problem is solved by a unified\nframework based on polynomial chaos expansion in [28],\nwhile [29] tackled the problem exploiting the linear elas-\nticity of structure. The seemingly arbitrary factors in the\nweighted sum are often cited as one major weakness of this\nRO methodology [30, 15]; however, they are well-defined in\ndecision-based design reflecting risk-taking attitude of de-\nsigners [31, 32, 33].\n\nInstead of modifying the objective function, RBO makes\nsome of the constraints probabilistic\u2212probability of failure\n\nevent is used in place of the event itself. This change requires\nspecialized methods to handle, because the probabilistic con-\nstraints are expressed by multiple integrals of the joint prob-\nability density function (PDF) of random variables, both of\nwhich are either practically impossible to obtain or very dif-\nficult to evaluate [34]. Many methods have been devised to\novercome such difficulties, which were surveyed thoroughly\nin [35]. Within the scope of this paper, we only briefly review\nthe first-order reliability methods (FORM), the second-order\nreliability methods (SORM), and the Sequential Optimiza-\ntion and Reliability Assessment (SORA) method. FORM\nappeared early [36] together with the concept of reliability\nindex [37] to solve RBO problems. SORM [38] followed\nto improve accuracy of the FORM in case of highly nonlin-\near limit state functions and/or slow decay of the joint PDF.\nThe main idea of FORM and SORM is to approximate the\nlimit state functions using first-order and second-order Tay-\nlor series, respectively, at appropriate values (i.e., means) of\nrandom variables. This results in a double-loop optimiza-\ntion problem to find the most probable point (MPP). In the\ncontext of reliability-based topology optimization (RBTO),\ndirectly solving the double-loop optimization problem has\nbeen shown in [39] for MEMS mechanisms with stochastic\nloading, boundary conditions as well as material properties;\nin [40] for shape uncertainty; in [41] for geometric imperfec-\ntions; in [42] for frame structures using system reliability un-\nder random-variable inputs; in [43] for electromagnetic sys-\ntems; in [44] for geometrically nonlinear structures; in [45]\nfor local failure constraints; and in [46] for continuum struc-\ntures subject to local stress constraints. In [47], FORM was\nreplaced by a mean-value, second-order saddlepoint approx-\nimation method, which was asserted to be more accurate.\nThe double-loop approach is prohibitively expensive and\nlacks robustness when a large number of random variables\npresents [48]. For this reason, single-loop approaches have\nbeen developed, in which, i.e., the Karush\u2212Kuhn\u2212Tucker\n(KKT) optimality conditions are utilized to avoid the inner\nloop. Both [49] and [50] used variants of the single-loop\nmethod in [51] for component and system reliability-based\nTO. In [52], it is somewhat unique when the authors used\ntheir own single-loop method [53]. Kogiso et al. [54] applied\nthe single-loop-single-vector method [55] for frame struc-\ntures under random-variable loads and nonstructural mass.\nAnother way to bypass the double-loop problem is the de-\ncoupling approaches [35], in which reliability analysis re-\nsults are used to facilitate the optimization loops. Among\nthem, the SORA method is known for its simple implemen-\ntation compared to the above single-loop methods, and its ef-\nficiency with FORM [10,56]. This method was employed for\nRBTO under random-variable inputs in [57] and [58]. Meta\nmodeling or surrogate modeling used together with simula-\ntion techniques to solve RBO problems has received consid-\nerable attention [59], but still remained relatively unexplored\nin TO literature. In [60], reliability was assessed using a\nprobabilistic neural network classifier for truss structures un-\nder random Young\u2019s modulus.\n\nBoth robustness and reliability are desired properties of\ndesign under uncertainty; however, to the best of our knowl-\n\n2 Copyright \u00a9 by ASME\n\n\n\nedge, this paper is the first one considering both criteria in\nTO. Therefore, a literature review of robust reliability-based\noptimization (RRBO) has to be drawn from other fields. The\nRRBO problem was investigated in [61] using an inverse re-\nliability strategy; in [62] using a performance moment inte-\ngration method to estimate the product quality loss; in [63]\nusing a preference aggregation method to produce a single-\nobjective RBO problem; and in [64] under epistemic un-\ncertainty. Both [65] and [66] used a genetic algorithm to\nsolve the problem. The dimension reduction method and its\nderivatives were introduced in [67, 68, 69] as an alternative\napproach to the RRBO problem.\n\nWith respect to RBTO, the approaches in [57], [30],\nand [70] are closest to ours. Still, random-field modeling was\nnot used for material property in [57] and [70]. Furthermore,\nseveral concerns can be identified from [70]. One of the most\nimportant stages in their method is the approximation of both\nfailure probability and its sensitivity, which were calculated\nby Monte Carlo sampling. Direct Monte Carlo sampling is\nwell-known to have variability [71], meaning two indepen-\ndent runs are very likely to get different values of failure\nprobability and its sensitivity which would obviously affect\nthe optimization results. Another concern is that the value\nof the parameter \u03b5 needed to replace the Heaviside func-\ntion with a smooth approximation [72] and was chosen by a\n\u201crecommendation\u201d backed by observation only. In [30], the\nmodeling random field was assumed with a known marginal\ndistribution, and in order to apply a perturbation technique,\nrandom variability of Young\u2019s modulus had to be small. Both\nof these assumptions clearly restrict the general applicability\nof their method. Lastly, robustness against uncertainty was\nnot studied in the three papers. As described in the following\nsections, our proposed method considers random field un-\ncertainty with the Karhunen\u2212\u2013Loe\u0300ve (KL) expansion used\nto reduce the dimension of the random field. The KL ex-\npansion covers a large class of random field without any re-\nstrictions on random variability. In this way, we are able to\nuse the FORM-based inverse reliability method within the\nSORA framework coupled with the stochastic response sur-\nface method to avoid the aforementioned weaknesses of di-\nrect Monte Carlo sampling.\n\n3 Topology Optimization under Uncertainty\n3.1 Deterministic Topology Optimization\n\nA standard notation is adopted throughout this\npaper\u2212bold upper and lower case letters denote matrices\nand vectors, respectively. The below formulation shows a\ndensity-based deterministic topology optimization (DTO):\n\nmin\n\u03c1\u03c1\u03c1\n\nC(\u03c1\u03c1\u03c1) = uT Ku\n\nsubject to K(\u03c1\u03c1\u03c1)u(\u03c1\u03c1\u03c1) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(1)\n\nwhere \u03c1\u03c1\u03c1 is the vector of design variables of the TO prob-\nlem, which also are the deterministic finite-element densi-\nties; V (\u03c1\u03c1\u03c1) and V0 are the total and the initial volume of the\nfinite-element mesh, respectively; \u03b3 is the predetermined vol-\nume fraction; K(\u03c1\u03c1\u03c1), u(\u03c1\u03c1\u03c1), and f are the stiffness matrix, the\ndisplacement vector, and the external load vector, respec-\ntively; and C(\u03c1\u03c1\u03c1) is the structural compliance. In the opti-\nmization problem (1), there are three constraints: the first ex-\npresses the equilibrium of the structure; the second requires\nthe optimized design to have a prescribed volume; and the\nthird is a component-wise inequality, in which each density\n(design variable) must be between 1 and a lower limit (i.e.,\n\u03c1min = 0.001).\n\nTo ensure manufacturability, the optimized design must\nhave a well-defined boundary, which is not guaranteed if\nsolving (1) directly because there is nothing to prevent\nintermediate values of densities from dominating the de-\nsign. Hence, the Solid Isotropic Material with Penalization\n(SIMP) method [1] is used to make intermediate densities\nunfavorable compared to \u03c1min or 1. According to SIMP,\neach finite element has a Young\u2019s modulus Ei specified by\nEi = \u03c1\n\np\ni E0\n\ni , where p is the penalization factor and E0\ni is the\n\ninitial value of the Young\u2019s modulus corresponding to unit\ndensity. The interpretation and possible values of p were\nelaborated in [73]. Any established gradient-based algo-\nrithms can solve the problem (1) after it is converted into\na nonlinear optimization problem using the SIMP method.\nThis paper follows common practice in the literature, select-\ning the Method of Moving Asymptotes (MMA) [74, 75] as\nthe optimizer of the DTO problem. The MMA has proved its\nreliability and competitive performance in various settings\nof TO. However, SIMP alone is plagued with checkerboard-\ning, mesh dependence, and local minima [76]. Many mesh-\nindependent filtering methods [77] have been designed to\npreclude checkerboarding and mesh dependence, while lo-\ncal minima remain an open question. This paper uses the\ndensity filtering [78, 79] as implemented in [80]. The next\nsections describe how uncertainty shapes our problem for-\nmulation and the solution algorithm.\n\n3.2 Robust Reliability-based Topology Optimization\n3.2.1 Problem Formulation\n\nConsidering input uncertainty modeled by a random\nfield y(\u03c9,x), a robust reliability-based topology optimization\n(RRBTO) problem is formulated as follows:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\nPi [gi(\u03c1\u03c1\u03c1,y)< 0]\u2264 P0\ni , i = 1,2 . . . ,m,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(2)\n\nwhere x \u2208 D \u2282 Rd is coordinates of a point in a d-\ndimensional physical domain D; \u03c9 \u2208 \u2126 is an element of the\n\n3 Copyright \u00a9 by ASME\n\n\n\nsample space \u2126; \u00b5 [C(\u03c1\u03c1\u03c1,y)] and \u03c3 [C(\u03c1\u03c1\u03c1,y)] are the mean and\nstandard deviation of the compliance C(\u03c1\u03c1\u03c1,y), respectively;\n\u03ba1 and \u03ba2 are the real non-negative weighting factors. The\nlimit state function gi(\u03c1\u03c1\u03c1,y) is defined so that gi(\u03c1\u03c1\u03c1,y) < 0\nmeans failure of the design, and Pi[gi(\u03c1\u03c1\u03c1,y) < 0] shows the\nprobability of the ith failure event. The target probability P0\n\ni\nis the upper bound of the failure probability Pi and often de-\nfined as P0\n\ni = \u03a6(\u2212\u03b2i), where \u03b2i is the reliability index and\n\u03a6(\u00b7) is the standard normal cumulative distribution function.\nIn this paper the random field y(\u03c9,x) is taken to be the mate-\nrial Young\u2019s modulus, which must be physically meaningful\n(i.e., taking only positive values) and is modeled as in [17]:\n\nE(x) = F\u22121 \u25e6\u03a6 [y(\u03c9,x)] , (3)\n\nwhere \u03a6[\u00b7] is the standard normal cumulative distribution\nfunction (CDF), and F\u22121 is the inverse of a prescribed CDF.\nThe uniform distribution is chosen for the two numerical ex-\namples resulting in\n\nE(x) = a+(b\u2212a)\u03a6 [y(\u03c9,x)] , (4)\n\nwhere a and b are the two bounds of the distribution. The\nlog-normal and the beta distribution are also capable of mod-\neling non-negative, bounded physical quantities, which can\nsupersede the uniform distribution in (3) with minimal effort.\n\nA number of challenges need to be cleared before we\nare able to solve (2). The modeling random field, which tries\nto capture spatial variability of material property, needs to\nbe cast into an explicit, computable form because a defined\nvalue of material property is required to perform finite el-\nement analysis. The Karhunen\u2212\u2013Loe\u0300ve (KL) expansion in\nSection 3.2.3 is able to turn a random field into a series of\nrandom variables. The mean and standard deviation of the\ncompliance, and the probabilistic constraints are often very\nhard or expensive to evaluate because of complex geome-\ntry of their domains. A Smolyak-type sparse grid in Sec-\ntion 3.2.2 is an efficient method to calculate the mean and\nstandard deviation, while Inverse Reliability Analysis (IRA)\nand SORA in Section 3.2.4, coupled with the Stochastic Re-\nsponse Surface Method (SRSM) in Section 3.2.5, handle the\nprobabilistic constraints effectively by avoiding the demand-\ning double-loop problem. Combining the above methods, a\ndetailed description of our proposed algorithm is laid out in\nSection 3.2.6.\n\n3.2.2 Smolyak-type Sparse Grid\nIn practice, it is very difficult or even impossible to\n\ncalculate the mean and standard deviation of the compli-\nance in (2) analytically through multidimensional integrals.\nSuch difficulties have motivated the development of various\nnumerical methods such as simulation-based methods (i.e.,\nMonte Carlo (MC), important sampling, adaptive sampling,\netc.), and the stochastic collocation methods (SCM) [81].\nSimulation-based methods are usually more straightforward\nto implement and embarrassingly parallel, and their cost does\n\nnot depend on the number of dimensions; however, even\nwith better sampling techniques, they still require a lot more\nsampling points than the SCM. Depending on the smooth-\nness of the target function, the convergence rate of the SCM\ncan be orders of magnitude faster than MC-based methods\n[82, 83]. The SCM approximates the quantity of interest by\na weighted sum, whose weighing factors and terms are com-\nputed at specific collocation points. Locating such points is\none of the central topics in SCM. The popular approach is\nto pick a known one-dimensional quadrature rule and then\nbuild up the multidimensional grid from the one-dimension\nrule. Interested readers can find in [84] a list of popular\nquadrature rules. The Gauss-Hermite quadrature, which is\nparticularly suitable for approximating the mean of a normal\ndistribution, is selected in this paper. The multidimensional\ngrid can be constructed using a tensor product; nevertheless,\ndue to the well-known curse of dimensionality, the cost of\nSCM on a full tensor-product grid is still excessively high\nfor a large number of dimensions. The Smolyak-type sparse\ngrid (SSG), which may be traced back to the Smolyak algo-\nrithm [85], can significantly reduce the cost by using only a\nsubset of the full tensor grid. In [86] numerical experiments\nwith random input, whose dimension was up to 50, showed\nthat the SCM on sparse grids was more efficient than MC.\n\nFor the sake of completeness the SSG is reviewed here.\nThe construction presented below follows [87]. Consider a\nd-dimensional function f (x), the difference \u2206\n\n(1)\nl f is defined\n\nas\n\n\u2206\n(1)\nl f =\n\n(\nQ(1)\n\nl \u2212Q(1)\nl\u22121\n\n)\nf , (5)\n\nwhere\n\nQ(1)\nl f =\n\nn(1)l\n\n\u2211\ni=1\n\nf\n(\n\nx(i)l\n\n)\nw(i)\n\nl ,\n\nQ(1)\n0 f = 0,\n\n(6)\n\nand n(1)l is the number of nodes for the l-level quadrature\n\nformula. The collocation points x(i)l and the corresponding\n\nweights w(i)\nl are calculated using the Gauss-Hermite quadra-\n\nture rule, which is a natural choice for the class of integrals\ninvolving an exponential function over an infinite interval\nsuch as mean and standard deviation [88]. The sparse in-\ntegration formula at level l is expressed as\n\nQ(d)\nl f = \u2211\n\n|`|\u2264l+d\u22121\n\n(\n\u2206\n(1)\nl1\n\u2297\u2206\n\n(1)\nl2\n\u2297\u00b7\u00b7 \u00b7\u2297\u2206\n\n(1)\nld\n\n)\nf , (7)\n\nwhere |`| = l1 + l2 + . . .+ ld . The mean and standard devia-\ntion of f (x) can be approximated using (7).\n\n3.2.3 Karhunen\u2212\u2013Loe\u0300ve Expansion\nIn a physical system, the quantity of interest can be mea-\n\nsured at spatial points over the system domain. If a random\n\n4 Copyright \u00a9 by ASME\n\n\n\nfield is considered an appropriate model for such a quan-\ntity, it is then required to construct the random field from\nmeasurements. Several methods, including the Expansion\nOptimal Linear Estimator [89] and polynomial chaos expan-\nsion [82, 8], have been adopted. Compared to others, the\nKarhunen\u2212\u2013Loe\u0300ve (KL) expansion [90] is \u201cthe most effi-\ncient in terms of the number of random variables required\nfor a given accuracy\u201d [7]. The KL expansion of a random\nfield y(\u03c9,x) is given as\n\ny(\u03c9,x) = E[x]+\n\u221e\n\n\u2211\ni=1\n\n\u221a\n\u03bbi\u03bei(\u03c9)ei(x) (8)\n\nwhere E[x] is the mean of the random field. The orthogo-\nnal eigenfunctions ei(x) and the corresponding eigenvalues\n\u03bbi are solutions of the following eigenvalue problem:\n\n\u222b\nD\n\nK(x1,x2)ei(x)dx = \u03bbiei(x) x,x1,x2 \u2208 D (9)\n\nwhere K(x1,x2) is the covariance function of the random\nfield\n\nK(x1,x2) = E [y(x1)y(x2)] x1,x2 \u2208 D (10)\n\nThe random variables \u03bei(\u03c9) are uncorrelated and satisfy:\n\nE[\u03bei] = 0,E[\u03bei\u03be j] = \u03b4i j,\n\n\u03bei(\u03c9) =\n1\u221a\n\u03bbi\n\n\u222b\nD\n(y(\u03c9,x)\u2212E[x])ei(x)dx,\n\n(11)\n\nwhere \u03b4i j is the Kronecker delta. The infinite series in (8) has\nto be truncated to use in practice. Because the influence of\nhigher order terms decays rapidly, satisfactory precision can\nbe achieved using only the first few terms of the expansion.\n\nThe KL expansion requires the solution of the eigen-\nvalue problem (9), which is pretty straightforward in the case\nof a random process (1-dimensional random field) [91]. For\nthe purpose of demonstration and without loss of generality,\nthis paper in Section 4 assumes the separability of the covari-\nance function of a 2-dimensional random field:\n\nK(s, t) = exp\n(\n\u2212|s1\u2212 t1|\n\nl1\n\u00d7 \u2212|s2\u2212 t2|\n\nl2\n\n)\n= exp\n\n(\n\u2212|s1\u2212 t1|\n\nl1\n\n)\nexp\n(\n\u2212|s2\u2212 t2|\n\nl2\n\n)\n,\n\ns, t \u2208 D\u2282R2,\n\n(12)\n\nwhere l1 and l2 are the correlation lengths in the two coordi-\nnate directions. The separability of the covariance function\nleads to separable eigenvalues and eigenfunctions, which are\nthe product of their univariate counterparts [92].\n\n3.2.4 Inverse Reliability Analysis and SORA\nThe probabilistic constraints formulated as in (2) are\n\ncalled the reliability index approach (RIA); however, as [11]\nreported, the performance measure approach (PMA) pro-\nvides better numerical stability and higher rate of conver-\ngence. Using the PMA, (2) is transformed as follows:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\ngi(\u03c1\u03c1\u03c1,y)\u2265 0, i = 1,2 . . . ,m,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1.\n\n(13)\n\nThe most notable change is that the probabilistic constraints\nare replaced by inequalities of the limit state functions. Solv-\ning the new problem requires a truncated KL expansion\ny(\u03c9,x)\u2248 y(\u03be\u03be\u03be(\u03c9),x), FORM, and inverse reliability analysis\n(IRA). In order to apply FORM, the random vector \u039e\u039e\u039e = {\u03bei}\nis first transformed into a vector of standard normal random\nvariables \u03a8\u03a8\u03a8 = {\u03c8i} using the Rosenblatt or the Nataf trans-\nformation \u03a8\u03a8\u03a8 = T (\u039e\u039e\u039e) or \u039e\u039e\u039e = T\u22121(\u03a8\u03a8\u03a8). Then, the most prob-\nable point (MPP) \u03be\u03be\u03be\n\n\u2217\ni in physical space or \u03c8\u03c8\u03c8\u2217i in transformed\n\nspace is obtained by solving the following IRA problem:\n\nmin\n\u03c8\u03c8\u03c8\n\ngi(\u03c8\u03c8\u03c8)\n\ns.t. \u2016 \u03c8\u03c8\u03c8 \u2016= \u03b2i,\n(14)\n\nwhere gi(\u03c8\u03c8\u03c8) is the ith limit state function in transformed\nspace. In this paper, the Matlab CODES toolbox [93] is\nchosen to solve (14). Furthermore, the SORA framework\nis adopted to decouple the double-loop structure of (13).\nIn SORA, instead of nesting the optimization problem (14)\nwithin (13), it serializes (13) into a chain of loops of DTO\nand IRA (Fig. 1). Each kth loop starts with DTO followed by\nIRA:\n\nmin\n\u03c1\u03c1\u03c1k\n\n\u03ba1\u00b5\n[\nC(\u03c1\u03c1\u03c1k,y)\n\n]\n+\u03ba2\u03c3\n\n[\nC(\u03c1\u03c1\u03c1k,y)\n\n]\n\ns.t. K(\u03c1\u03c1\u03c1k,y)u(\u03c1\u03c1\u03c1k,y) = f,\n\nV (\u03c1\u03c1\u03c1k)\n\nV0\n= \u03b3,\n\ngi\n\n(\n\u03c1\u03c1\u03c1\n\nk,y(\u03be\u03be\u03be\u2217(k\u22121)\ni ,x)\n\n)\n\u2265 0, i = 1,2 . . . ,m,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\nk \u2264 1.\n\n(15)\n\nwhere \u03be\u03be\u03be\n\u2217(k\u22121)\ni denotes the MPP in physical space of ith limit\n\nstate function in the (k\u22121)th loop. Solving (15) gives \u03c1\u03c1\u03c1\u2217(k),\nwhich is substituted into (14) to find the next MPP \u03be\u03be\u03be\n\n\u2217(k)\ni in\n\n5 Copyright \u00a9 by ASME\n\n\n\nthe form of \u03c8\u03c8\u03c8\n\u2217(k)\ni :\n\nmin\n\u03c8\u03c8\u03c8\n\ngi(\u03c1\u03c1\u03c1\n\u2217(k),\u03c8\u03c8\u03c8)\n\ns.t. \u2016 \u03c8\u03c8\u03c8 \u2016= \u03b2i.\n(16)\n\nStart\n\nInitialization:\n- Initial values\n- KL expansion\n- Collocation and sample points\n\nFinite Element Analysis\n\nSensitivity and filtering\n\nUpdate densities\n\nConvergeNo\n\nSIMP\nDTO\n\nFinite Element Analysis\n\nConstruct limit state \nfunction\n\nFind MPP\n\nConverge\n\nInverse \nReliability \nAnalysis\n\nSRSM\n\nYes\n\nNo\n\nEnd\n\nYes\n\nUpdate Young\u2019s \nmodulus using \n\nMPP\n\nCalculate robust objective and \nits derivarives using the SCM\n\nFig. 1. SORA-based RRBTO flowchart [57].\n\nThe SORA framework coupled with the PMA can save\ncomputational cost significantly by reducing the number of\nreliability analyses performed to reach convergence of both\nDTO and IRA. However, as a heuristic method, the optimiza-\ntion solution \u03c1\u03c1\u03c1\u2217 acquired by SORA may not be the one found\nin the double-loop problem, which is corrected in each loop\nby shifting the random design variables using information\nfrom the previous loop [94]. Such modification is not neces-\nsary in this paper because there are only deterministic design\nvariables (only the material property is random).\n\n3.2.5 Stochastic Response Surface Method\nAs uncertainty is propagated from random input to out-\n\nput through complex computations such as finite element\nanalysis, it is almost unlikely to derive the output directly\nas an explicit expression of input. However, such an expres-\nsion is needed to run the gradient-based algorithm in IRA.\nThe SRSM deals with this difficulty by approximating the\noutput by a polynomial chaos expansion [82]. The below\nformulations follows [95]. The multidimensional Hermite\npolynomials of degree p are used in the SRSM and defined\nas:\n\nHp(\u03b1i1 ,\u03b1i2 , . . . ,\u03b1ip)\n\n= (\u22121)pe\n1\n2 \u03b1\u03b1\u03b1T \u03b1\u03b1\u03b1 \u2202p\n\n\u2202\u03b1i1 ,\u2202\u03b1i2 , . . . ,\u2202\u03b1ip\n\ne\u2212\n1\n2 \u03b1\u03b1\u03b1T \u03b1\u03b1\u03b1\n\n(17)\n\nwhere \u03b1\u03b1\u03b1 = {\u03b1ik}\np\nk=1 is a vector of standard normal random\n\nvariables. The output of interest z is estimated as follows:\n\nz = a0 +\nn\n\n\u2211\ni1=1\n\nai1H1(\u03b1i1)+\nn\n\n\u2211\ni1=1\n\ni1\n\n\u2211\ni2=1\n\nai1i2H2(\u03b1i1 ,\u03b1i2)\n\n+\nn\n\n\u2211\ni1=1\n\ni1\n\n\u2211\ni2=1\n\ni2\n\n\u2211\ni3=1\n\nai1i2i3H3(\u03b1i1 ,\u03b1i2 ,\u03b1i3)+ . . .\n\n(18)\n\nwhere n is the number of standard normal random vari-\nables used in the expansion, and a0,ai1 ,ai1i2 ,ai1i2i3 , . . . are\nunknown coefficients. If n = 2 and p = 3, then the expan-\nsion (18) will become:\n\nz(\u03b1i1 ,\u03b1i2) = a0 +a1\u03b1i1 +a2\u03b1i2 +a3(\u03b1\n2\ni1 \u22121)+a4(\u03b1\n\n2\ni2 \u22121)\n\n+a5\u03b1i1\u03b1i2 +a6(\u03b1\n3\ni1 \u22123\u03b1i1)+a7(\u03b1\n\n3\ni2 \u22123\u03b1i2)\n\n+a8(\u03b1i1\u03b1\n2\ni2 \u2212\u03b1i1)+a9(\u03b1\n\n2\ni1\u03b1i2 \u2212\u03b1i2)\n\n= a0 +\n9\n\n\u2211\nk=1\n\nakhik\n\n(19)\nwhere 1,hi1 ,hi2 , . . . ,hi9 are Hermite polynomials. The ten\nunknown coefficients a0,a1, . . . ,a9 are found by solving a\nsystem of linear equations using at least ten different realiza-\ntions of (\u03b1i1 ,\u03b1i2). Such realizations can be chosen at colloca-\ntion points according to the SSG in Section 3.2.2, or a much\nsimpler heuristic rule in [96], which is selected in this paper.\nFor the approximation in (19) the rule generates 17 colloca-\ntion points to form a stochastic response surface, which was\nvery close to the target output [95].\n\n3.2.6 Solution Algorithm\nThe optimization algorithm (Fig. 1) to solve the RRBTO\n\nproblem (2) is expounded below:\n\n1. Initialize the problem: size of the finite element mesh;\ninitial values of design variables, SIMP and optimization\nparameters; KL expansion of random field; collocation\npoints and weights for the SSG, and the SRSM; etc.\n\n6 Copyright \u00a9 by ASME\n\n\n\n2. Until convergence do:\n\n\u2022 Solve Kiui = fi and compute\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\nfor i =\n\n1,2, . . . ,n(d)l .\n\u2022 Calculate mean, variance and their derivatives:\n\nE [C] =\n\nn(d)l\n\n\u2211\ni=1\n\nwiCi,\n\n\u03c3\n2 [C] =\n\nn(d)l\n\n\u2211\ni=1\n\nwiC2\ni \u2212E2 [C] ,\n\n\u2202E [C]\n\n\u2202\u03c1\u03c1\u03c1\n=\n\nn(d)l\n\n\u2211\ni=1\n\nwi\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\n,\n\n\u2202\u03c32 [C]\n\n\u2202\u03c1\u03c1\u03c1\n=\n\nn(d)l\n\n\u2211\ni=1\n\n2Ci(\u03c1\u03c1\u03c1)wi\n\u2202Ci(\u03c1\u03c1\u03c1)\n\n\u2202\u03c1\u03c1\u03c1\n\u22122E [C]\n\n\u2202E [C]\n\n\u2202\u03c1\u03c1\u03c1\n.\n\n(20)\n\n\u2022 Compute derivative of the robust objective:\n\n\u03ba1\n\u2202E [C]\n\n\u2202\u03c1\u03c1\u03c1\n+\u03ba2\n\n1\n\n2\n\u221a\n\n\u03c32[C]\n\n\u2202\u03c32 [C]\n\n\u2202\u03c1\u03c1\u03c1\n. (21)\n\n\u2022 Deterministic topology optimization (DTO): the most\nprobable point (MPP) \u03be\u03be\u03be\n\n\u2217(k\u22121)\ni found in the previous loop\n\n(or some initial values for the first loop) is used in place\nof random parameters \u03be\u03be\u03be(\u03c9), making (15) a regular TO\nproblem. The SIMP and the MMA method are em-\nployed to solve it.\n\n\u2022 Inverse reliability analysis (IRA): the optimum values\nof design variables from the DTO step and the colloca-\ntion points given in Section 3.2.5 are used to construct\nstochastic response surfaces, which in turn are utilized\nin (16) to find the next MPP. Based on convergence con-\nditions, the algorithm may stop, or a new loop is re-\nquested with updated Young\u2019s modulus using the new\nMPP.\n\n4 Results\nIn this section our proposed algorithm is run on two\n\ncommon benchmark problems (the cantilever and the L-\nshaped beam) with three target reliability levels, six weight-\ning factors, and one parameter tuple of the uniform distribu-\ntion in (4). The correctness and accuracy of our algorithm\nis then verified on the optimization results by Monte Carlo\nsimulations. All quantities given below are dimensionless\nfor simplicity.\n\nTo ensure the generality of our approach, we intention-\nally do not specify the limit state functions gi(\u03c1\u03c1\u03c1,y) in the\nprevious sections, which is essential for the two numerical\n\nexamples. The RRBTO problem now becomes:\n\nmin\n\u03c1\u03c1\u03c1\n\n\u03ba1\u00b5 [C(\u03c1\u03c1\u03c1,y)]+\u03ba2\u03c3 [C(\u03c1\u03c1\u03c1,y)]\n\ns.t. K(\u03c1\u03c1\u03c1,y)u(\u03c1\u03c1\u03c1,y) = f,\nV (\u03c1\u03c1\u03c1)\n\nV0\n= \u03b3,\n\nP [u(\u03c1\u03c1\u03c1,y)\u2212u0 < 0]\u2264 P0,\n\n0 < \u03c1min \u2264 \u03c1\u03c1\u03c1\u2264 1,\n\n(22)\n\nwhere u(\u03c1\u03c1\u03c1,y) and u0 are the actual displacement and the\nminimum allowable displacement at a selected point, respec-\ntively. The above formulation is inspired by design of com-\npliant mechanisms [97], in which both flexibility and stiff-\nness are required. Flexibility allows the mechanisms to reach\ndesigned deformation, implied by the limit state function\ng(\u03c1\u03c1\u03c1,y) = u(\u03c1\u03c1\u03c1,y)\u2212 u0, while maximizing stiffness, or min-\nimizing compliance, helps them withstand loads. Further-\nmore, the weighting factors \u03ba1 and \u03ba2 need substantial at-\ntention. Our preliminary numerical results showed that the\nmean and standard deviation of the compliance are differ-\nent by about two orders of magnitude, which may have crit-\nical impact on the solution. This was examined carefully\nin [98] and normalization transforming them into the same\nscale has been recommended. \u03ba1 and \u03ba2 are identified ac-\ncording to [21]:\n\n\u03ba1 =\n\u03b5\n\n\u00b5\u2217\n,\u03ba2 =\n\n1\u2212 \u03b5\n\n\u03c3\u2217\n, (23)\n\nwhere \u03b5 \u2208 [0,1], \u00b5\u2217 is the mean of the compliance when\n(\u03b5,1\u2212 \u03b5) = (0,1), and \u03c3\u2217 is the standard deviation of the\ncompliance when (\u03b5,1\u2212\u03b5)= (1,0). \u00b5\u2217 and \u03c3\u2217 have to be cal-\nculated on the same set of input parameters except \u03b5, under\nwhich they are the maximum values of the mean and stan-\ndard deviation of the compliance resulting in 0 <\n\n\u00b5\n\u00b5\u2217\n\n,\n\u03c3\n\n\u03c3\u2217\n\u2264 1\n\nin (22).\nCoding the algorithm demands concrete values of ev-\n\nery parameter, many of which are shared between the two\nexamples. The finite element mesh in both examples is as-\nsembled from square, linear, plane stress elements, whose\nside length and thickness are unit dimension. Those ele-\nments are made of an isotropic, linear elastic material with\nPoisson\u2019s ratio \u03bd = 0.3. The material Young\u2019s modulus\nis assumed to be a centered, mean-square Gaussian ran-\ndom field with known covariance function as in (12), ex-\npanded into a series of independent, standard normal ran-\ndom variables [99]. The correlation lengths are chosen as\nl1 = l2 = 0.6, and only the first two eigenvalues and eigen-\nfunctions are picked for the truncated KL expansion. A wide\nrange of optimization algorithms for reliability analysis is\navailable in the CODES toolbox [93], including the Hybrid\nMean Value method selected for the examples due to its ef-\nficiency [100]. Other parameters of the optimization prob-\nlem (22) are the target reliability levels \u03b2 = {1.0,2.0,3.0},\n\n7 Copyright \u00a9 by ASME\n\n\n\nweighting factors \u03b5 = {1,0.9,0.8,0.5,0.2,0}, and the ma-\nterial property limits (a,b) = (1,1.5). Due to iterative na-\nture of MMA and SORA, several convergence criteria are\nenforced. The MMA optimizer stops when the maximum\ndifference of design variables of two consecutive iterations\nis smaller than a prescribed value (dMMA\n\nmax \u2264 0.001), or the\nnumber of iterations is more than nMMA = 200. The sim-\nilar conditions are applied in the SORA loops, but for the\nMPPs (dMPP\n\nmax \u2264 0.001) and a different maximum allowable\nnumber of iterations (nSORA = 20). The level of sparse grid\napproximation is 4 using Gauss-Hermite quadrature as the\nbase one-dimensional rule. In SIMP, the minimum length\nscale rmin = 1.5 and penalization factor p = 3 are used. Each\nexample is then validated by 50000 Monte Carlo simulations\n(MCS), which compute failure probabilities of the limit state\nfunction, and the mean and standard deviation of the compli-\nance. The examples are implemented in Matlab using Latin\nhypercube sampling for MCS with seed 0. Those probabil-\nities are compared with values calculated from the three re-\nliability levels, while statistical moments of the compliance\nprove robustness of the optimization results against uncer-\ntainty.\n\n4.1 The Cantilever Beam\n\n/ \n\nA B A B\n\nFig. 2. The cantilever beam\n\nFig. 2 displays the cantilever beam, a two-dimensional\ndomain used in this example. The beam is fixed on its left\nside, meshed into 60 \u00d7 20 elements, and subject to two unit\nvertical loads, which are placed on its bottom edge at equal\ndistances (points A and B). The optimization problem is set\nup as in (22), in which the minimum allowable displacement\nat the load application point B is given as u0 = 220. Then our\nproposed algorithm is tested on the example with different\nvalues of target reliability, material parameters and weight-\ning factors. The 18 optimized designs are presented in Tables\n1 and 2. The MCS and SRSM utilize those designs to calcu-\nlate the mean and standard deviation of vertical displacement\nof point B (\u00b5B and \u03c3B in Table 3), as well as the probabili-\nties of failure event Pf = P [g(\u03c1\u03c1\u03c1,y)< 0] to show the reliabil-\nity levels achieved by the designs. Moreover, the mean and\nstandard deviation of the compliance are also obtained from\nthe MCS (\u00b5[C] and \u03c3[C] in Table 3) to examine how they\nvary with respect to the weighting factors \u03b5. All of theses\nvalues are gathered in Table 3, whose second column shows\n\nexpected failure probabilities Pf = \u03a6(\u2212\u03b2). Some conclu-\nsions from this example results can be found in Section 5.\n\n4.2 The L-shaped Beam\n\n/ \n\nA B A B\n\nFig. 3. The L-shaped beam\n\nThe second numerical example to illustrate our proposed\nalgorithm is the L-shaped beam as shown in Fig. 3. The\nbeam is fixed on its topmost edge and subject to two unit\nvertical loads on its bottom edge\u2212one at the right endpoint\nB and the other at point A located one quarter of the bot-\ntom edge length from point B. As in the previous example,\nthe weighted sum of the two statistical moments of the com-\npliance is minimized, while a probabilistic constraint is im-\nposed on the vertical displacement of one load application\npoint (point B in Fig. 3) to design for flexibility. The mini-\nmum allowable vertical displacement of point B is chosen as\nu0 = 130. The design domain is discretized using a 60\u00d760\nmesh of finite elements, and then one quarter of the mesh is\nremoved to make the domain L-shaped by forcing the ele-\nment densities in this region to be 0.001 before proceeding\nto the next operation. The larger mesh used in this exam-\nples results in much longer running time based on our ex-\nperiments on the same computer. The results also exhibit the\nsame trends as in the previous example. Therefore, instead of\nrunning the complete set of 18 combinations, only 12 cases,\nwhich are the combinations of \u03b2 = {1,3}, six weighting fac-\ntors, and (a,b) = (1,1.5), are considered. Table 6 shows the\nprobabilities of displacement constraint violation Pf at point\nB, the statistical moments of that point\u2019s vertical displace-\nment (\u00b5B and \u03c3B) calculated from both the MCS and SRSM,\nand the mean and standard deviation of the compliance (\u00b5[C]\nand \u03c3[C]). The L-shaped optimized designs are analyzed for\ninsights in the next section.\n\n5 Discussions\nIn this section we closely scrutinize the two numerical\n\nexamples for comparison, verification, and insights.\nVisual inspection and analysis of topology optimized de-\n\nsigns (i.e., identifying and comparing their differences) is\n\n8 Copyright \u00a9 by ASME\n\n\n\nTa\nbl\n\ne\n1.\n\nTh\ne\n\nca\nnt\n\nile\nve\n\nrb\nea\n\nm\n:\n\nR\nR\n\nB\nTO\n\nre\nsu\n\nlts\n\n(\u03b5\n,1\n\u2212\n\n\u03b5\n)\n\n(1\n,0\n)\n\n(0\n.9\n,0\n.1\n)\n\n(0\n.8\n,0\n.2\n)\n\n\u03b2\n=\n\n1\n\n\u03b2\n=\n\n2\n\n\u03b2\n=\n\n3\n\nTa\nbl\n\ne\n2.\n\nTh\ne\n\nca\nnt\n\nile\nve\n\nrb\nea\n\nm\n:\n\nR\nR\n\nB\nTO\n\nre\nsu\n\nlts\n\n(\u03b5\n,1\n\u2212\n\n\u03b5\n)\n\n(0\n.5\n,0\n.5\n)\n\n(0\n.2\n,0\n.8\n)\n\n(0\n,1\n)\n\n\u03b2\n=\n\n1\n\n\u03b2\n=\n\n2\n\n\u03b2\n=\n\n3\n\n9 Copyright \u00a9 by ASME\n\n\n\nTable 3. The cantilever beam: Numerical results\n\nMCS SRSM\n\n\u03b2 Expected Pf (\u03b5,1\u2212 \u03b5) \u00b5[C] \u03c3[C] \u00b5B \u03c3B Pf \u00b5B \u03c3B\n\n1 0.15865\n\n(1,0) 162.9505 0.9263 -220.6120 0.6071 0.15674 -220.6120 0.6071\n\n(0.9,0.1) 162.9992 0.9188 -220.6070 0.6017 0.15642 -220.6070 0.6017\n\n(0.8,0.2) 163.2204 0.8953 -220.5980 0.5853 0.15326 -220.5980 0.5853\n\n(0.5,0.5) 166.5160 0.9032 -225.0110 0.5906 0.00000 -225.0110 0.5906\n\n(0.2,0.8) 177.7632 0.8588 -240.6990 0.5572 0.00000 -240.6990 0.5572\n\n(0,1) 206.2317 0.8559 -278.9100 0.5527 0.00000 -278.9100 0.5527\n\n2 0.02275\n\n(1,0) 163.4230 0.9150 -221.1960 0.5995 0.02252 -221.1960 0.5995\n\n(0.9,0.1) 163.6040 0.9106 -221.1880 0.5961 0.02250 -221.1880 0.5961\n\n(0.8,0.2) 163.7847 0.9118 -221.1890 0.5967 0.02266 -221.1890 0.5967\n\n(0.5,0.5) 164.7008 0.8953 -222.9560 0.5866 0.00000 -222.9560 0.5866\n\n(0.2,0.8) 178.0176 0.8586 -241.0670 0.5570 0.00000 -241.0670 0.5570\n\n(0,1) 206.2320 0.8559 -278.9110 0.5527 0.00000 -278.9110 0.5527\n\n3 0.001349\n\n(1,0) 163.7490 0.9094 -221.7690 0.5962 0.001340 -221.7690 0.5962\n\n(0.9,0.1) 164.0019 0.9078 -221.7630 0.5944 0.001340 -221.7630 0.5944\n\n(0.8,0.2) 164.0458 0.9015 -221.7520 0.5907 0.001320 -221.7520 0.5907\n\n(0.5,0.5) 165.0556 0.8938 -223.2560 0.5855 0.000000 -223.2560 0.5855\n\n(0.2,0.8) 177.8977 0.8585 -240.8960 0.5570 0.000000 -240.8960 0.5570\n\n(0,1) 206.2320 0.8559 -278.9110 0.5527 0.000000 -278.9110 0.5527\n\nlargely an untouched topic in TO research, which, in our\nopinion, is curious because topology is all about geometry\nand \u201cappearance\u201d of structures. Without such tools, the best\neffort is to compare those results qualitatively. To make their\ndifferences more pronounced, readers may render them into\nshort animations, which would reveal much more than hu-\nman eyes can perceive using only static images. There would\nbe subtle material re-distributions (i.e., among results under\nthe same tuple (\u03b5,1\u2212\u03b5)), as well as thickening or thinning of\ncertain features, which could be almost undetectable by com-\nparing static images. The removal or addition of features is\neasier to spot among results. The most distinct results corre-\nspond to \u03b5 = 1 and \u03b5 = 0, which is understandable because\nthey are the extreme cases. The results between them are sort\nof transitions from one bounding value to the other.\n\nA number of trends can be observed from both the opti-\nmized designs and their corresponding numerical results:\n\n1. The MCS-based Pf is always smaller than the expected\nPf , which confirms that the designs have achieved the\ndesired reliability level.\n\n2. Decreasing \u03b5, or increasing the weight on standard de-\nviation in the robust objective, makes the MCS-based\nPf smaller until reaching 0. We hypothesize that there\nare two classes of solutions depending on the weight:\none on the constraint boundary and the other inside the\nfeasible region of the optimization problem. In the first\nclass, the MCS-based Pf is close to the expected Pf :\ndecreasing rate of the MCS-based Pf is very slow for\ncertain range of \u03b5 (i.e., \u03b5 = {1,0.9,0.8} in Table 3, and\n\u03b5 = {1,0.9} in Table 6). In the second class, the so-\n\n10 Copyright \u00a9 by ASME\n\n\n\nTable 4. The L-shaped beam: RRBTO results\n\n(\u03b5,1\u2212 \u03b5) (1,0) (0.9,0.1) (0.8,0.2)\n\n\u03b2 = 1\n\n\u03b2 = 3\n\nTable 5. The L-shaped beam: RRBTO results\n\n(\u03b5,1\u2212 \u03b5) (0.5,0.5) (0.2,0.8) (0,1)\n\n\u03b2 = 1\n\n\u03b2 = 3\n\n11 Copyright \u00a9 by ASME\n\n\n\nTable 6. The L-shaped beam: Numerical results\n\nMCS SRSM\n\n\u03b2 Expected Pf (\u03b5,1\u2212 \u03b5) \u00b5[C] \u03c3[C] \u00b5B \u03c3B Pf \u00b5B \u03c3B\n\n1 0.15865\n\n(1,0) 96.4893 0.5352 -130.3580 0.3577 0.15808 -130.3580 0.3577\n\n(0.9,0.1) 96.3536 0.5321 -130.3560 0.3553 0.15790 -130.3560 0.3553\n\n(0.8,0.2) 96.8678 0.5241 -131.0290 0.3498 0.00144 -131.0290 0.3498\n\n(0.5,0.5) 99.5821 0.5045 -135.7740 0.3396 0.00000 -135.7740 0.3396\n\n(0.2,0.8) 108.7352 0.4917 -149.3090 0.3332 0.00000 -149.3090 0.3332\n\n(0,1) 133.3052 0.4762 -183.8160 0.3238 0.00000 -183.8160 0.3238\n\n3 0.001349\n\n(1,0) 96.8866 0.5300 -131.0510 0.3544 0.00130 -131.0510 0.3544\n\n(0.9,0.1) 96.7519 0.5298 -131.0510 0.3545 0.00126 -131.0510 0.3545\n\n(0.8,0.2) 96.8852 0.5240 -131.0560 0.3497 0.00106 -131.0560 0.3497\n\n(0.5,0.5) 99.6087 0.5049 -135.9450 0.3399 0.00000 -135.9450 0.3399\n\n(0.2,0.8) 108.7883 0.4916 -149.3880 0.3331 0.00000 -149.3880 0.3331\n\n(0,1) 133.9731 0.4755 -184.5450 0.3229 0.00000 -184.5450 0.3229\n\nlutions are away from the constraint boundary but still\ninside the feasible region: the decreasing rate acceler-\nates and the MCS-based Pf eventually becomes 0 (i.e.,\n\u03b5\u2265 0.5 in Table 3, and \u03b5\u2265 0.8 in Table 6).\n\n3. From our understanding of robust optimization, increas-\ning the weight on standard deviation in a minimization\nproblem will decrease its value and have the opposite ef-\nfect on the mean, which is actually the case as observed\nin Tables 3 and 6. However, there are a couple of out-\nliers to this trend (i.e., (\u03b5,\u03b2) = (0.8,2) in Table 3, and\n\u03b5 = 0.9 in Table 6). An explanation can be made by in-\nvestigating where the solution converges in the design\nspace. When the solutions are away from the constraint\nboundary, the robust objective is more dominant in the\nsolution: a marked increase and decrease of the mean\nand standard deviation, respectively, is observed. In so-\nlutions at the constraint limit, the robust objective has\nless in the solution.\nThis trend explains the decreasing tendency of the MCS-\nbased Pf . Increasing the weight on standard deviation\nleads to decreased influence of the mean compliance,\nwhose major proportion is contributed by the displace-\nment of point B (Fig. 2 and 3) which is constrained prob-\nabilistically in (22) to be larger than the minimum al-\nlowable value u0. This results in increasing the mean of\npoint B displacement, whose changing rate is slow for\nsolutions close to constraint boundary and much more\n\nrapid in the remaining cases (i.e., the sixth column of\nTables 3 and 6). The bigger the displacement of point B\nbecomes, the smaller the MCS-based Pf is. It is ob-\nvious that under a specific set of inputs (i.e., loading\nand boundary conditions, material property) mechani-\ncal capabilities of a structure (i.e., stress, strain, dis-\nplacement), even if heavily optimized, are always finite.\nThus, the MCS-based Pf approaches 0 when the dis-\nplacement of point B continues to increase.\n\n4. The Smolyak-type sparse grid and the SRSM are both\nvery good methods for their respective approximating\ntargets. As shown in Tables 3 and 6, approximately\nsix significant digits are required to see the differences\nbetween the MCS-based and the SRSM results. The\ncumulative distribution functions of point B displace-\nment from the two methods are also almost identi-\ncal, so they are not included in the paper. This also\nmakes us confident in choosing only two terms in the\nKL expansion\u2212adding more terms would only increase\ncomputational cost without clear benefits. The same ob-\nservation is applied to the Smolyak-type sparse grid and\nMCS-based results of the mean and standard deviation\nof the compliance. Because of such agreement, we de-\ncide to use only one level of the sparse grid. Multiple\nlevels were tested in [17, 27].\n\n12 Copyright \u00a9 by ASME\n\n\n\n6 Conclusions\nIn this paper, we have presented an efficient robust\n\nreliability-based design approach for topology optimized de-\nsigns, considering random field uncertainty in material prop-\nerty. Our approach avoids a double-loop approach to reliabil-\nity evaluation, and utilizes a number of techniques to reduce\ncomputational cost without sacrificing solution accuracy.\nThe two case studies have demonstrated the methodology,\nand have shown the impact of using the robust reliability-\nbased design approach. As shown in the case studies, the\ntopology can converge to a (local) solution where either the\nreliability-based constraint or the robust objective has more\ninfluence upon the resulting topology. This difference in\nconverged solution is determined by the relative weight of\nthe mean versus the variance in the robust objective. This\nfinding is significant to designers because it shows that us-\ning either exclusively a robust design approach or reliability-\nbased design approach will not identify the optimal topology\nconsidering material property uncertainty. Only the robust\nreliability-based design approach is capable of identifying\nthe optimal topology considering the influence of material\nproperty uncertainty in both the objective and the constraint.\n\nExplicitly considering material property uncertainty will\nbe significant in design for additive manufacturing, where\nthe additive process can lead to significant material property\nuncertainty due to temperature gradients or other sources of\nvariation. In terms of future work, the following are rec-\nommended. Further case studies should be considered to\nbetter understand the interplay between the reliability con-\nstraint and the robust objective. Different objectives and con-\nstraints can be considered as well. Considering topology op-\ntimization as a tool for design for additive manufacturing,\nanother significant characteristic of the material property is\nnon-linearity. Polymeric materials used in additive manu-\nfacturing will be better modeled as hyper-elastic or visco-\nelastic, as opposed to linear elastic. Another need is visu-\nalization of the results. As noted in the text, it can be dif-\nficult to understand the differences in topology based upon\nvisual inspection. A more systematic comparison of differ-\nent converged results will help researchers better understand\nthe differences in designs resulting from different problem\nformulations, and will lead to a better understanding of the\ndesign principles leading to robust, reliable designs.\n\nAcknowledgements\nThe first author would like to thank the Vietnam Edu-\n\ncation Foundation (VEF) for their financial support through\nthe VEF fellowship, and Prof. Krister Svanberg for his assis-\ntance on the MMA code.\n\nReferences\n[1] Bends\u00f8e, M. P., and Sigmund, O., 2003. Topol-\n\nogy optimization: theory, methods, and applications.\nSpringer, Berlin ; New York.\n\n[2] American Concrete Institute. Building Code Require-\nments for Structural Concrete (ACI 318-14).\n\n[3] American Institute of Steel Construction. Specifica-\ntion for Structural Steel Buildings (ANSI/AISC 360-\n16).\n\n[4] Sriramula, S., and Chryssanthopoulos, M. K., 2013.\n\u201cAn experimental characterisation of spatial variabil-\nity in GFRP composite panels\u201d. Structural Safety, 42,\npp. 1\u201311.\n\n[5] Nader, J. W., Dagher, H. J., Lopez-Anido, R., El Chiti,\nF., Fayad, G. N., and Thomson, L., 2008. \u201cProba-\nbilistic Finite Element Analysis of Modified ASTM\nD3039 Tension Test for Marine Grade Polymer Ma-\ntrix Composites\u201d. Journal of Reinforced Plastics and\nComposites, 27(6), pp. 583\u2013597.\n\n[6] Sriramula, S., and Chryssanthopoulos, M. K., 2009.\n\u201cQuantification of uncertainty modelling in stochastic\nanalysis of FRP composites\u201d. Composites Part A: Ap-\nplied Science and Manufacturing, 40(11), pp. 1673\u2013\n1684.\n\n[7] Sudret, B., and Kiureghian, A. D., 2000. Stochastic\nFinite Element Methods and Reliability: A State-of-\nthe-Art Report (Report No. UCB/SEMM-2000/08).\nDepartment of Civil and Environmental Engineering,\nUniversity of California, Berkeley.\n\n[8] Ghanem, R., and Spanos, P., 2003. Stochastic Finite\nElements: A Spectral Approach. Civil, Mechanical\nand Other Engineering Series. Dover Publications.\n\n[9] Charmpis, D., Schue\u0308ller, G., and Pellissetti, M., 2007.\n\u201cThe need for linking micromechanics of materials\nwith stochastic finite elements: A challenge for ma-\nterials science\u201d. Computational Materials Science,\n41(1), pp. 27\u201337.\n\n[10] Du, X., and Chen, W., 2004. \u201cSequential Optimiza-\ntion and Reliability Assessment Method for Efficient\nProbabilistic Design\u201d. Journal of Mechanical Design,\n126(2), p. 225.\n\n[11] Tu, J., Choi, K. K., and Park, Y. H., 1999. \u201cA\nNew Study on Reliability-Based Design Optimiza-\ntion\u201d. Journal of Mechanical Design, 121(4), p. 557.\n\n[12] Michell, A., 1904. \u201cThe limits of economy of ma-\nterial in frame-structures\u201d. The London, Edinburgh,\nand Dublin Philosophical Magazine and Journal of\nScience, 8(47), pp. 589\u2013597.\n\n[13] Taguchi, G., 1986. Introduction to quality engineer-\ning: designing quality into products and processes.\nDistributed by the American Supplier Institute, Inc.,\nDearborn, MI.\n\n[14] Schevenels, M., Lazarov, B., and Sigmund, O., 2011.\n\u201cRobust topology optimization accounting for spa-\ntially varying manufacturing errors\u201d. Computer Meth-\nods in Applied Mechanics and Engineering, 200(49-\n52), Dec., pp. 3613\u20133627.\n\n[15] Richardson, J. N., Filomeno Coelho, R., and Adri-\naenssens, S., 2015. \u201cRobust topology optimization\nof truss structures with random loading and material\nproperties: A multiobjective perspective\u201d. Computers\n& Structures, 154, July, pp. 41\u201347.\n\n[16] Chen, S., Chen, W., and Lee, S., 2010. \u201cLevel set\nbased robust shape and topology optimization under\n\n13 Copyright \u00a9 by ASME\n\n\n\nrandom field uncertainties\u201d. Structural and Multidis-\nciplinary Optimization, 41(4), Apr., pp. 507\u2013524.\n\n[17] Lazarov, B. S., Schevenels, M., and Sigmund, O.,\n2012. \u201cTopology optimization considering material\nand geometric uncertainties using stochastic colloca-\ntion methods\u201d. Structural and Multidisciplinary Opti-\nmization, 46(4), Oct., pp. 597\u2013612.\n\n[18] Lazarov, B. S., Schevenels, M., and Sigmund, O.,\n2012. \u201cTopology optimization with geometric un-\ncertainties by perturbation techniques\u201d. Interna-\ntional Journal for Numerical Methods in Engineering,\n90(11), June, pp. 1321\u20131336.\n\n[19] Jansen, M., Lombaert, G., Diehl, M., Lazarov, B. S.,\nSigmund, O., and Schevenels, M., 2013. \u201cRobust\ntopology optimization accounting for misplacement\nof material\u201d. Structural and Multidisciplinary Opti-\nmization, 47(3), Mar., pp. 317\u2013333.\n\n[20] Jansen, M., Lombaert, G., and Schevenels, M., 2015.\n\u201cRobust topology optimization of structures with im-\nperfect geometry based on geometric nonlinear anal-\nysis\u201d. Computer Methods in Applied Mechanics and\nEngineering, 285, Mar., pp. 452\u2013467.\n\n[21] Asadpoure, A., Tootkaboni, M., and Guest, J. K.,\n2011. \u201cRobust topology optimization of structures\nwith uncertainties in stiffness \u2212 Application to truss\nstructures\u201d. Computers & Structures, 89(11-12),\nJune, pp. 1131\u20131141.\n\n[22] Tootkaboni, M., Asadpoure, A., and Guest, J. K.,\n2012. \u201cTopology optimization of continuum struc-\ntures under uncertainty \u2212 A Polynomial Chaos ap-\nproach\u201d. Computer Methods in Applied Mechanics\nand Engineering, 201-204, Jan., pp. 263\u2013275.\n\n[23] Changizi, N., and Jalalpour, M., 2017. \u201cRobust topol-\nogy optimization of frame structures under geometric\nor material properties uncertainties\u201d. Structural and\nMultidisciplinary Optimization, 56(4), Oct., pp. 791\u2013\n807.\n\n[24] da Silva, G. A., and Cardoso, E. L., 2016. \u201cTopology\noptimization of continuum structures subjected to un-\ncertainties in material properties\u201d. International Jour-\nnal for Numerical Methods in Engineering, 106(3),\nApr., pp. 192\u2013212.\n\n[25] da Silva, G., and Cardoso, E., 2017. \u201cStress-based\ntopology optimization of continuum structures under\nuncertainties\u201d. Computer Methods in Applied Me-\nchanics and Engineering, 313, Jan., pp. 647\u2013672.\n\n[26] da Silva, G. A., Beck, A. T., and Cardoso, E. L., 2018.\n\u201cTopology optimization of continuum structures with\nstress constraints and uncertainties in loading\u201d. Inter-\nnational Journal for Numerical Methods in Engineer-\ning, 113(1), Jan., pp. 153\u2013178.\n\n[27] Zhao, Q., Chen, X., Ma, Z.-D., and Lin, Y., 2015.\n\u201cRobust Topology Optimization Based on Stochastic\nCollocation Methods under Loading Uncertainties\u201d.\nMathematical Problems in Engineering, 2015, pp. 1\u2013\n14.\n\n[28] Richardson, J., Coelho, R. F., and Adriaenssens, S.,\n2016. \u201cA unified stochastic framework for robust\n\ntopology optimization of continuum and truss-like\nstructures\u201d. Engineering Optimization, 48(2), Feb.,\npp. 334\u2013350.\n\n[29] Zhao, J., and Wang, C., 2014. \u201cRobust topology op-\ntimization under loading uncertainty based on linear\nelastic theory and orthogonal diagonalization of sym-\nmetric matrices\u201d. Computer Methods in Applied Me-\nchanics and Engineering, 273, May, pp. 204\u2013218.\n\n[30] Jalalpour, M., and Tootkaboni, M., 2016. \u201cAn effi-\ncient approach to reliability-based topology optimiza-\ntion for continua under material uncertainty\u201d. Struc-\ntural and Multidisciplinary Optimization, 53(4), Apr.,\npp. 759\u2013772.\n\n[31] McIntire, M. G., Vasylkivska, V., Hoyle, C., and Gib-\nson, N., 2014. \u201cApplying robust design optimiza-\ntion to large systems\u201d. In ASME 2014 International\nDesign Engineering Technical Conferences and Com-\nputers and Information in Engineering Conference,\npp. V02BT03A054\u2013V02BT03A054.\n\n[32] Lewis, K., Chen, W., and Schmidt, L., 2006. Decision\nMaking in Engineering Design. ASME Press, New\nYork.\n\n[33] Beck, A. T., Gomes, W. J. S., Lopez, R. H., and\nMiguel, L. F. F., 2015. \u201cA comparison between ro-\nbust and risk-based optimization under uncertainty\u201d.\nStructural and Multidisciplinary Optimization, 52(3),\nSept., pp. 479\u2013492.\n\n[34] Haldar, A., and Mahadevan, S., 2000. Probability,\nreliability, and statistical methods in engineering de-\nsign. John Wiley.\n\n[35] Valdebenito, M. A., and Schue\u0308ller, G. I., 2010. \u201cA sur-\nvey on approaches for reliability-based optimization\u201d.\nStructural and Multidisciplinary Optimization, 42(5),\nNov., pp. 645\u2013663.\n\n[36] Cornell, C., 1969. \u201cA probability-based structural\ncode\u201d. ACI Journal Proceedings, 66(12).\n\n[37] Hasofer, A. M., and Lind, N. C., 1974. \u201cExact\nand invariant second moment code format\u201d. Journal\nof Engineering Mechanics Division, 100(EM1), 01,\npp. 111\u2013121.\n\n[38] Fiessler, B., Neumann, H., and Rackwitz, R., 1979.\n\u201cQuadratic limit states in structural reliability\u201d. Jour-\nnal of Engineering Mechanics Division, 105(4), 08,\npp. 661\u2013676.\n\n[39] Maute, K., and Frangopol, D. M., 2003. \u201cReliability-\nbased design of MEMS mechanisms by topology op-\ntimization\u201d. Computers & Structures, 81(8-11), May,\npp. 813\u2013824.\n\n[40] Sato, Y., Izui, K., Yamada, T., Nishiwaki, S., Ito, M.,\nand Kogiso, N., 2018. \u201cReliability-based topology\noptimization under shape uncertainty modeled in Eu-\nlerian description\u201d. Structural and Multidisciplinary\nOptimization, Sept.\n\n[41] Kang, Z., and Liu, P., 2018. \u201cReliability-based topol-\nogy optimization against geometric imperfections\nwith random threshold model\u201d. International Journal\nfor Numerical Methods in Engineering, 115(1), July,\npp. 99\u2013116.\n\n14 Copyright \u00a9 by ASME\n\n\n\n[42] Mogami, K., Nishiwaki, S., Izui, K., Yoshimura,\nM., and Kogiso, N., 2006. \u201cReliability-based struc-\ntural optimization of frame structures for multiple fail-\nure criteria using topology optimization techniques\u201d.\nStructural and Multidisciplinary Optimization, 32(4),\nOct., pp. 299\u2013311.\n\n[43] Kang, J., Kim, C., and Wang, S., 2004. \u201cReliability-\nbased topology optimization for electromagnetic sys-\ntems\u201d. COMPEL - The international journal for com-\nputation and mathematics in electrical and electronic\nengineering, 23(3), Sept., pp. 715\u2013723.\n\n[44] Jung, H.-S., and Cho, S., 2004. \u201cReliability-\nbased topology optimization of geometrically nonlin-\near structures with loading and material uncertain-\nties\u201d. Finite Elements in Analysis and Design, 41(3),\nDec., pp. 311\u2013331.\n\n[45] Luo, Y., Zhou, M., Wang, M. Y., and Deng, Z., 2014.\n\u201cReliability based topology optimization for contin-\nuum structures with local failure constraints\u201d. Com-\nputers & Structures, 143, Sept., pp. 73\u201384.\n\n[46] da Silva, G. A., and Beck, A. T., 2018. \u201cReliability-\nbased topology optimization of continuum structures\nsubject to local stress constraints\u201d. Structural and\nMultidisciplinary Optimization, 57(6), Jun, pp. 2339\u2013\n2355.\n\n[47] Papadimitriou, D. I., and Mourelatos, Z. P., 2018.\n\u201cReliability-Based Topology Optimization Using\nMean-Value Second-Order Saddlepoint Approxima-\ntion\u201d. Journal of Mechanical Design, 140(3), Jan.,\np. 031403.\n\n[48] Schue\u0308ller, G., Pradlwarter, H., and Koutsourelakis, P.,\n2004. \u201cA critical appraisal of reliability estimation\nprocedures for high dimensions\u201d. Probabilistic En-\ngineering Mechanics, 19(4), Oct., pp. 463\u2013474.\n\n[49] Nguyen, T. H., Song, J., and Paulino, G. H., 2011.\n\u201cSingle-loop system reliability-based topology opti-\nmization considering statistical dependence between\nlimit-states\u201d. Structural and Multidisciplinary Opti-\nmization, 44(5), Nov., pp. 593\u2013611.\n\n[50] Silva, M., Tortorelli, D. A., Norato, J. A., Ha, C.,\nand Bae, H.-R., 2010. \u201cComponent and system\nreliability-based topology optimization using a single-\nloop method\u201d. Structural and Multidisciplinary Opti-\nmization, 41(1), Feb., pp. 87\u2013106.\n\n[51] Liang, J., Mourelatos, Z. P., and Tu, J., 2004. \u201cA\nSingle-Loop Method for Reliability-Based Design\nOptimization\u201d. In Volume 1: 30th Design Automa-\ntion Conference, Vol. 2004, ASME, pp. 419\u2013430.\n\n[52] Kharmanda, G., Olhoff, N., Mohamed, A., and\nLemaire, M., 2004. \u201cReliability-based topology op-\ntimization\u201d. Structural and Multidisciplinary Opti-\nmization, 26(5), Mar., pp. 295\u2013307.\n\n[53] Kharmanda, G., Mohamed, A., and Lemaire, M.,\n2002. \u201cEfficient reliability-based design optimization\nusing a hybrid space with application to finite element\nanalysis\u201d. Structural and Multidisciplinary Optimiza-\ntion, 24(3), Sept., pp. 233\u2013245.\n\n[54] Kogiso, N., Hirano, Y., Nishiwaki, S., Izui, K.,\n\nYoshimura, M., and Min, S., 2010. \u201cReliability-Based\nTopology Optimization of Frame Structures for Multi-\nple Criteria Using SLSV Method\u201d. Journal of Compu-\ntational Science and Technology, 4(3), pp. 172\u2013184.\n\n[55] Chen, X., Hasselman, T., Neill, D., Chen, X., Hassel-\nman, T., and Neill, D., 1997. \u201cReliability based struc-\ntural design optimization for practical applications\u201d.\nIn 38th Structures, Structural Dynamics, and Materi-\nals Conference, American Institute of Aeronautics and\nAstronautics.\n\n[56] Lopez, R. H., and Beck, A. T., 2012. \u201cReliability-\nbased design optimization strategies based on FORM:\na review\u201d. Journal of the Brazilian Society of Mechan-\nical Sciences and Engineering, 34(4), Dec., pp. 506\u2013\n514.\n\n[57] Zhao, Q., Chen, X., Ma, Z.-D., and Lin, Y.,\n2015. \u201cReliability-Based Topology Optimization Us-\ning Stochastic Response Surface Method with Sparse\nGrid Design\u201d. Mathematical Problems in Engineer-\ning, 2015, pp. 1\u201313.\n\n[58] Zhao, Q., Chen, X., Ma, Z., and Lin, Y., 2016.\n\u201cA Comparison of Deterministic, Reliability-Based\nTopology Optimization under Uncertainties\u201d. Acta\nMechanica Solida Sinica, 29(1), Feb., pp. 31\u201345.\n\n[59] Wang, G. G., and Shan, S., 2007. \u201cReview of Meta-\nmodeling Techniques in Support of Engineering De-\nsign Optimization\u201d. Journal of Mechanical Design,\n129(4), p. 370.\n\n[60] Patel, J., and Choi, S.-K., 2012. \u201cClassification ap-\nproach for reliability-based topology optimization us-\ning probabilistic neural networks\u201d. Structural and\nMultidisciplinary Optimization, 45(4), Apr., pp. 529\u2013\n543.\n\n[61] Du, X., Sudjianto, A., and Chen, W., 2004. \u201cAn In-\ntegrated Framework for Optimization Under Uncer-\ntainty Using Inverse Reliability Strategy\u201d. Journal of\nMechanical Design, 126(4), p. 562.\n\n[62] Youn, B. D., Choi, K. K., and Yi, K., 2005. \u201cPerfor-\nmance Moment Integration (PMI) Method for Quality\nAssessment in Reliability-Based Robust Design Opti-\nmization\u201d. Mechanics Based Design of Structures and\nMachines, 33(2), Apr., pp. 185\u2013213.\n\n[63] Mourelatos, Z. P., and Liang, J., 2006. \u201cA Method-\nology for Trading-Off Performance and Robustness\nUnder Uncertainty\u201d. Journal of Mechanical Design,\n128(4), p. 856.\n\n[64] Tang, Y., Chen, J., and Wei, J., 2012. \u201cA Sequential\nAlgorithm for Reliability-Based Robust Design Opti-\nmization Under Epistemic Uncertainty\u201d. Journal of\nMechanical Design, 134(1), p. 014502.\n\n[65] Forouzandeh Shahraki, A., and Noorossana, R., 2014.\n\u201cReliability-based robust design optimization: A gen-\neral methodology using genetic algorithm\u201d. Comput-\ners & Industrial Engineering, 74, Aug., pp. 199\u2013207.\n\n[66] Rathod, V., Yadav, O. P., Rathore, A., and Jain,\nR., 2013. \u201cOptimizing reliability-based robust de-\nsign model using multi-objective genetic algorithm\u201d.\nComputers & Industrial Engineering, 66(2), Oct.,\n\n15 Copyright \u00a9 by ASME\n\n\n\npp. 301\u2013310.\n[67] Lee, I., Choi, K., Du, L., and Gorsich, D., 2008.\n\n\u201cDimension reduction method for reliability-based ro-\nbust design optimization\u201d. Computers & Structures,\n86(13-14), July, pp. 1550\u20131562.\n\n[68] Youn, B. D., Xi, Z., Wells, L. J., and Lamb,\nD. A., 2006. \u201cStochastic Response Surface Using the\nEnhanced Dimension-Reduction (eDR) Method for\nReliability-Based Robust Design Optimization\u201d. In III\nEuropean Conference on Computational Mechanics,\nC. A. Motasoares, J. A. C. Martins, H. C. Rodrigues,\nJ. A. C. Ambro\u0301sio, C. A. B. Pina, C. M. Motasoares,\nE. B. R. Pereira, and J. Folgado, eds. Springer Nether-\nlands, Dordrecht, pp. 388\u2013388.\n\n[69] Youn, B. D., and Xi, Z., 2009. \u201cReliability-based ro-\nbust design optimization using the eigenvector dimen-\nsion reduction (EDR) method\u201d. Structural and Multi-\ndisciplinary Optimization, 37(5), Feb., pp. 475\u2013492.\n\n[70] Keshavarzzadeh, V., Fernandez, F., and Tortorelli,\nD. A., 2017. \u201cTopology optimization under uncer-\ntainty via non-intrusive polynomial chaos expansion\u201d.\nComputer Methods in Applied Mechanics and Engi-\nneering, 318, May, pp. 120\u2013147.\n\n[71] Taflanidis, A. A., and Beck, J. L., 2008. \u201cAn effi-\ncient framework for optimal robust stochastic system\ndesign using stochastic simulation\u201d. Computer Meth-\nods in Applied Mechanics and Engineering, 198(1),\nNov., pp. 88\u2013101.\n\n[72] Keshavarzzadeh, V., Meidani, H., and Tortorelli,\nD. A., 2016. \u201cGradient based design optimization\nunder uncertainty via stochastic expansion methods\u201d.\nComputer Methods in Applied Mechanics and Engi-\nneering, 306, July, pp. 47\u201376.\n\n[73] Bends\u00f8e, M. P., and Sigmund, O., 1999. \u201cMate-\nrial interpolation schemes in topology optimization\u201d.\nArchive of Applied Mechanics (Ingenieur Archiv),\n69(9-10), Nov., pp. 635\u2013654.\n\n[74] Svanberg, K., 1987. \u201cThe method of moving asymp-\ntotes\u2014a new method for structural optimization\u201d. In-\nternational Journal for Numerical Methods in Engi-\nneering, 24(2), Feb., pp. 359\u2013373.\n\n[75] Svanberg, K., 2002. \u201cA Class of Globally Convergent\nOptimization Methods Based on Conservative Convex\nSeparable Approximations\u201d. SIAM Journal on Opti-\nmization, 12(2), Jan., pp. 555\u2013573.\n\n[76] Sigmund, O., and Petersson, J., 1998. \u201cNumer-\nical instabilities in topology optimization: A sur-\nvey on procedures dealing with checkerboards, mesh-\ndependencies and local minima\u201d. Structural Opti-\nmization, 16(1), Aug., pp. 68\u201375.\n\n[77] Sigmund, O., 2007. \u201cMorphology-based black and\nwhite filters for topology optimization\u201d. Structural\nand Multidisciplinary Optimization, 33(4-5), Feb.,\npp. 401\u2013424.\n\n[78] Bruns, T. E., and Tortorelli, D. A., 2001. \u201cTopol-\nogy optimization of non-linear elastic structures and\ncompliant mechanisms\u201d. Computer Methods in Ap-\nplied Mechanics and Engineering, 190(26-27), Mar.,\n\npp. 3443\u20133459.\n[79] Bourdin, B., 2001. \u201cFilters in topology optimization\u201d.\n\nInternational Journal for Numerical Methods in En-\ngineering, 50(9), Mar., pp. 2143\u20132158.\n\n[80] Andreassen, E., Clausen, A., Schevenels, M.,\nLazarov, B. S., and Sigmund, O., 2011. \u201cEfficient\ntopology optimization in MATLAB using 88 lines of\ncode\u201d. Structural and Multidisciplinary Optimization,\n43(1), Jan., pp. 1\u201316.\n\n[81] Lee, S. H., and Chen, W., 2009. \u201cA comparative\nstudy of uncertainty propagation methods for black-\nbox-type problems\u201d. Structural and Multidisciplinary\nOptimization, 37(3), Jan., pp. 239\u2013253.\n\n[82] Xiu, D., 2010. Numerical Methods for Stochastic\nComputations: A Spectral Method Approach. Prince-\nton University Press.\n\n[83] Xiong, F., Greene, S., Chen, W., Xiong, Y., and Yang,\nS., 2010. \u201cA new sparse grid based method for uncer-\ntainty propagation\u201d. Structural and Multidisciplinary\nOptimization, 41(3), Apr., pp. 335\u2013349.\n\n[84] Gerstner, T., and Griebel, M., 1998. \u201cNumerical in-\ntegration using sparse grids\u201d. Numerical Algorithms,\n18, Jan., pp. 209\u2013232.\n\n[85] Smolyak, S. A., 1963. \u201cQuadrature and interpolation\nformulas for tensor products of certain classes of func-\ntions\u201d. Dokl. Akad. Nauk SSSR, 148(5), pp. 1042\u2013\n1045.\n\n[86] Xiu, D., and Hesthaven, J. S., 2005. \u201cHigh-Order Col-\nlocation Methods for Differential Equations with Ran-\ndom Inputs\u201d. SIAM Journal on Scientific Computing,\n27(3), Jan., pp. 1118\u20131139.\n\n[87] Maitre, O., and Knio, O., 2010. Spectral Methods\nfor Uncertainty Quantification: With Applications to\nComputational Fluid Dynamics. Scientific Computa-\ntion. Springer Netherlands.\n\n[88] Davis, P., and Rabinowitz, P., 2007. Methods of Nu-\nmerical Integration. Dover Books on Mathematics Se-\nries. Dover Publications.\n\n[89] Li, C., and Der Kiureghian, A., 1993. \u201cOptimal Dis-\ncretization of Random Fields\u201d. Journal of Engineer-\ning Mechanics, 119(6), June, pp. 1136\u20131154.\n\n[90] Loe\u0300ve, M., 2017. Probability Theory: Third Edition.\nDover Books on Mathematics. Dover Publications.\n\n[91] Ray, S. S., and Sahu, P. K., 2013. \u201cNumerical Meth-\nods for Solving Fredholm Integral Equations of Sec-\nond Kind\u201d. Abstract and Applied Analysis, 2013,\npp. 1\u201317.\n\n[92] Wang, L., 2008. \u201cKarhunen\u2212\u2013Loe\u0300ve Expansions and\ntheir Applications\u201d. PhD thesis, London School of\nEconomics and Political Science.\n\n[93] Missoum, S., Lacaze, S., Boroson, E., and Jiang, P.,\n2015. CODES Toolbox. Computational Optimal De-\nsign of Engineering Systems Laboratory. University\nof Arizona.\n\n[94] Yin, X., and Chen, W., 2006. \u201cEnhanced sequen-\ntial optimization and reliability assessment method for\nprobabilistic optimization with varying design vari-\nance\u201d. Structure and Infrastructure Engineering, 2(3-\n\n16 Copyright \u00a9 by ASME\n\n\n\n4), Sept., pp. 261\u2013275.\n[95] Huang, S., and Kou, X., 2007. \u201cAn extended stochas-\n\ntic response surface method for random field prob-\nlems\u201d. Acta Mechanica Sinica, 23(4), Aug., pp. 445\u2013\n450.\n\n[96] Isukapalli, S., Balakrishnan, S., and Georgopoulos, P.,\n2004. \u201cComputationally efficient uncertainty propa-\ngation and reduction using the stochastic response sur-\nface method\u201d. IEEE, pp. 2237\u20132243 Vol.2.\n\n[97] Frecker, M. I., Ananthasuresh, G. K., Nishiwaki,\nS., Kikuchi, N., and Kota, S., 1997. \u201cTopologi-\ncal Synthesis of Compliant Mechanisms Using Multi-\nCriteria Optimization\u201d. Journal of Mechanical De-\nsign, 119(2), p. 238.\n\n[98] Marler, R. T., and Arora, J. S., 2010. \u201cThe weighted\nsum method for multi-objective optimization: new in-\nsights\u201d. Structural and Multidisciplinary Optimiza-\ntion, 41(6), June, pp. 853\u2013862.\n\n[99] Alexanderian, A., 2015. A brief note on the\nKarhunen-Loe\u0300ve expansion.\n\n[100] Youn, B. D., Choi, K. K., and Park, Y. H., 2003.\n\u201cHybrid Analysis Method for Reliability-Based De-\nsign Optimization\u201d. Journal of Mechanical Design,\n125(2), p. 221.\n\n17 Copyright \u00a9 by ASME\n\n\n\t1 Introduction\n\t2 Background\n\t3 Topology Optimization under Uncertainty\n\t3.1 Deterministic Topology Optimization\n\t3.2 Robust Reliability-based Topology Optimization\n\t3.2.1 Problem Formulation\n\t3.2.2 Smolyak-type Sparse Grid\n\t3.2.3 Karhunen-\u2013Lo\u00e8ve Expansion\n\t3.2.4 Inverse Reliability Analysis and SORA\n\t3.2.5 Stochastic Response Surface Method\n\t3.2.6 Solution Algorithm\n\n\n\t4 Results\n\t4.1 The Cantilever Beam\n\t4.2 The L-shaped Beam\n\n\t5 Discussions\n\t6 Conclusions\n\n"}
{"Title": "A Literature Review on Length of Stay Prediction for Stroke Patients using Machine Learning and Statistical Approaches", "Authors": "Ola Alkhatib, Ayman Alahmar", "Abstract": "  Hospital length of stay (LOS) is one of the most essential healthcare metrics that reflects the hospital quality of service and helps improve hospital scheduling and management. LOS prediction helps in cost management because patients who remain in hospitals usually do so in hospital units where resources are severely limited. In this study, we reviewed papers on LOS prediction using machine learning and statistical approaches. Our literature review considers research studies that focus on LOS prediction for stroke patients. Some of the surveyed studies revealed that authors reached contradicting conclusions. For example, the age of the patient was considered an important predictor of LOS for stroke patients in some studies, while other studies concluded that age was not a significant factor. Therefore, additional research is required in this domain to further understand the predictors of LOS for stroke patients.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00005", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaper Title (use style: paper title)\n\n\nA Literature Review on Length of Stay Prediction for Stroke \n\nPatients using Machine Learning and Statistical Approaches \n\nOla Alkhatib1 and Ayman Alahmar2 \n\n1Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada \n2Department of Software Engineering, Lakehead University, Thunder Bay, Ontario, Canada \n\nAbstract Hospital length of stay (LOS) is one of the most essential healthcare metrics that \n\nreflects the hospital quality of service and helps improve hospital scheduling and management. \n\nLOS prediction helps in cost management because patients who remain in hospitals usually do \n\nso in hospital units where resources are severely limited. In this study, we reviewed papers on \n\nLOS prediction using machine learning and statistical approaches. Our literature review \n\nconsiders research studies that focus on LOS prediction for stroke patients. Some of the \n\nsurveyed studies revealed that authors reached contradicting conclusions. For example, the age \n\nof the patient was considered an important predictor of LOS for stroke patients in some studies, \n\nwhile other studies concluded that age was not a significant factor. Therefore, additional \n\nresearch is required in this domain to further understand the predictors of LOS for stroke \n\npatients. \n\nKeywords: Length of Stay, Stroke, Machine Learning, Data Mining, Statistical Analysis. \n\n1. INTRODUCTION\n\nEALTHCARE sectors show increasing costs in most regions around the world. Healthcare\n\nexpenditure constitutes a significant share of the gross domestic product for many \n\ncountries. There are many challenges associated with growth in the healthcare sector, including \n\nincreased pressure on the limited resources of hospitals. This issue has motivated researchers \n\nto conduct further research related to hospital resource optimization. Since hospitalization \n\nconstitutes a significant cost of patient care, many researchers have been investigating the \n\nproblem of patient Length of Stay (LOS) prediction. LOS is defined as the duration of a patient \n\nhospitalization, and it is determined as the difference between the timestamp of a patient \n\nhospital discharge and the timestamp of their hospital admission [1], [2]. LOS prediction is an \n\nimportant topic for many reasons, such as: \n\n\u2022 Knowledge of LOS allows hospitals to manage their bed and room capacities so that\n\nthey can know how long a patient is expected to occupy hospital space.\n\n\u2022 Information about LOS allows hospitals to determine the number of staff that must be\n\nscheduled over the day/night shifts to properly accommodate the patients.\n\n\u2022 Patients and their families can estimate the cost of a stay in paid hospitalizations.\n\nBy investigating the existing literature, we found that LOS prediction papers used machine \n\nlearning/statistical approaches and can be divided into the type of disease under consideration. \n\nSome authors studied LOS prediction in general (i.e. without specifying a specific disease), \n\nwhile other researchers focused on LOS prediction pertinent to a specific disease (e.g., stroke, \n\nH \n\n1 \n\n\n\n2 \n\ndiabetes). Fig. 1 depicts this categorization and includes example references to research articles. \n\nFig. 1. Classification of LOS prediction research articles. \n\nIn this survey, we review papers that predict the patients\u2019 LOS in general and then we focus \n\non LOS prediction for stroke patients. We focused on stroke patients because they face many \n\nchallenges with definite need for hospitalization, and also because strokes have an enormous \n\ncost on healthcare systems around the world. Using popular research search engines (e.g., IEEE \n\nXplore, Springer, Science Direct, etc.), we searched phrases such as \u201clength of stay\u201d, \u201chospital \n\nlength of stay\u201d, \u201cprediction\u201d, \u201cmachine learning\u201d, \u201cstroke\u201d, \u201cischemic stroke\u201d, \u201cdata mining\u201d, \n\nand \u201cstatistical analysis\u201d in order to find existing work on this topic (up to mid 2020). \n\nStroke is a disease that affects the arteries leading to and within the brain. It can be a \n\nsignificant financial and health burden for patients, medical staff, and healthcare systems. \n\nStroke is associated with prolonged LOS in hospitals and rehabilitation facilities [1] and is a \n\nleading cause of death and disability worldwide. According to Statistics Canada, in 2018, stroke \n\nwas the third largest cause of death in Canada after cancer and heart disease \n\n(https://www.statcan.gc.ca). Stroke, also known as cerebrovascular accident (or CVA), is a \n\nsudden and devastating illness that is characterized by the rapid loss of the functions of the brain \n\ndue to a disruption of blood flow to the brain (see Fig. 2). This disruption is caused by: lack of \n\nblood flow (ischemic strokes), which account for more than 80% of all strokes; blockage of \n\nblood flow; or hemorrhage [3]. \n\nFig. 2. Illustration of stroke (Source: Mayo Clinic (mayoclinic.org)). \n\nThe remainder of the paper is organized as follows. Below we present our literature review on \n\n\n\n \n\n \n\n \n\n \n\n \n\n3 \n\n \n\nLOS prediction for general patients. Next we consider stroke patients. Finally, the paper ends \n\nwith a discussion and conclusions section. \n\n2. LOS PREDICTION FOR GENERAL PATIENTS \n\nKabir et al. [4] proposed a non-linear feature selection method using artificial neural networks \n\n(ANNs) to determine the most essential features for LOS prediction. The study evaluates the \n\nperformance of (ANNs), support vector machines (SVM), and logistic regression (LR) on \n\nselected subsets of features to predict the LOS class and identify the best subset of features. The \n\nstudy used a dataset from the National Surgical Quality Improvement Program database. The \n\ndataset, based on data from 2015, included 273 features of more than 880,000 surgical patients \n\nadmitted to hospital for various surgical procedures to address different diseases and medical \n\nconditions. The authors reduced the features from 273 to 40 based on consultation with domain \n\nexperts (anesthesiologists). After preprocessing the dataset, 715,143 patient records were \n\nselected for further analysis. The patients were categorized using their medical group into the \n\nfollowing nine surgical categories: (1) general surgery, (2) vascular, (3) urology, (4) plastics, \n\n(5) otolaryngology, (6) orthopedics, (7) gynecology, (8) neurosurgery, and (9) other surgical \n\nconditions (including thoracic, cardiac surgery, and interventional radiology patients). An \n\nadditional category that includes all patients was added as group (10) for comparison purposes. \n\nThe authors presented the normalized importance score of features for each patient category. In \n\ngeneral, features 16, 20, and 21 showed the most significant contribution to the prediction of \n\nLOS. Feature 16 indicates the period from admission to surgery, feature 20 denotes whether the \n\npatient is an outpatient or inpatient, and feature 21 represents the estimated probability of \n\nmorbidity computed by the hospital using LR. These features had a strong correlation with LOS \n\nwhich validates the performance of the non-linear approach of this study in obtaining \n\nconsiderable features. Another important factor presented in this research is the specific \n\ncorrelation of features with their categories. For example, feature 38, which represents the \n\nsituation of a patient\u2019s wound, was important in predicting the LOS for otolaryngology patients, \n\nwhile it had less importance in LOS predicting for other patient categories. By comparing the \n\nimportance of features computed for all patients (group 10) with other categories, the authors \n\nshowed that grouping patients based on their disease can improve the accuracy of LOS \n\npredictive models. The final results revealed that ANNs, as non-linear classifiers, beat SVMs \n\nand LR in the achieved accuracy for LOS prediction. This proves that the relationship between \n\nLOS and its predictors is highly non-linear. The ANNs model improves accuracy and eliminates \n\nthe number of required features. \n\nAzari et al. [5] used a multi-tiered data mining approach for predicting hospital LOS to \n\ndecrease the uncertainty related with the LOS for inpatients. Their prediction approach was \n\nbased on clustering (i.e., k-means clustering) to create the training sets that train various \n\nclassification algorithms. The number of clusters was determined based on the disease \n\nconditions or by using the Charlson index which provides the general categories of the diseases. \n\nFig. 3 describes the approach used in this study. Several classifiers were used to predict the \n\nLOS such as: K-nearest neighbors, LR, naive Bayes, SVMs, Bayesian networks (Bnets), J48 \n\ndecision tree, classification rules (JRip), bagging, random forest, and boosting. The paper \n\nconsidered various performance metrics such as accuracy, Kappa statistic, precision, recall, and \n\narea under the curve (AUC). In order to rank the classifiers, researchers used the Friedman test \n\nto determine the classifier with the best outcome for a certain level of clustering. The dataset \n\n\n\n \n\n \n\n \n\n \n\n \n\n4 \n\n \n\nused the Heritage Health prize data. The dataset contains 1,048,576 records of hospital claims \n\nwithin a 3-year period. The results showed that using clustering as a precursor to form the \n\ntraining set provides better results compared to non-clustering based training sets. The results \n\nalso showed that Bnets, SVMs, JRip, Bagging, and J48 had better overall performance than the \n\nother classifiers. The outcomes of the paper were validated by a domain expert from Emergency \n\nMedicine. \n\n \n\n \n \n\nFig. 3. LOS prediction approach of Azari et al. [5]. \n\n \n\nNouaouri et al. [6] proposed the application of data mining techniques to predict the LOS for \n\npatients without considering a specific disease. They introduced the Evidential LOS prediction \n\nAlgorithm (ELOSA) that allows the prediction of the LOS of a new patient. Their approach \n\nhandles the imprecision, uncertainty, and missing data within the dataset of patients. The \n\nELOSA algorithm is based on the precise support and association rule confidence measures [6]. \n\nThe LOS experiments were conducted on a real hospital dataset that contains the data for 270 \n\npatients. To predict the inpatient LOS, the authors considered age, sex, physiological conditions \n\n(emergency degree), and operation length. The emergency degree column in the dataset was a \n\ncategorical attribute that contained values from the following set {A, R, D}. A indicates an \n\nabsolute emergency, R is for relative emergency, and D represents delayed emergency. The \n\nlength of stay was classified as Short (S), approximately 3 days, Medium (M), approximately \n\n10 days, and Long (L), approximately 20 days, with a small overlap between the ranges as \n\nshown in Fig. 4. They compared their results with other algorithms in similar studies and \n\nconcluded that their approach showed better results. \n\nRathor et al. [7] used a clustering algorithm (i.e., Density Based Spatial Clustering of \n\nApplications with Noise (DB- SCAN)) and K-Apriori, which is a combination of Apriori and \n\nK-means algorithms. The algorithms were applied to a dataset of 9,052 patients (the source of \n\nthe dataset was not disclosed). The execution time of the algorithms were compared, showing \n\nDBSCAN to be faster than the K-Apriori; although, DBSCAN took exponentially longer as the \n\nnumber of inputs increased. The prediction was based on the current symptoms and medical \n\nhistory of the patients, which was provided by the patient at the time of admission. For \n\nprediction of LOS, the medical data underwent a pre-processing phase, which had three steps:  \n\n \n\n \n\n\n\n \n\n \n\n \n\n \n\n \n\n5 \n\n \n\n \n \n\nFig. 4. LOS classes in terms of days [6]. \n\n \n\n \n\ndata cleaning, data integration and transformation, and data reduction. Then, using the \n\nprocessed data, symptoms for a particular disease were grouped together and used for LOS \n\nprediction. The study determined the times of execution of K-apriori and DBSCAN \n\nindependently and subsequently compared them. Both algorithms were treated with the same \n\nnumber of inputs and with the same values. The authors concluded that the execution time of \n\nDBSCAN was comparatively much shorter than K-Apriori, but as the number of inputs increase \n\nto high values, the execution time of DBSCAN increased exponentially whereas there was no \n\nchange in K-Apriori. \n\n \n\n3. LOS PREDICTION FOR STROKE PATIENTS \n\nIn stroke, the brain is prevented from getting oxygen and nutrients from the blood. Without \n\noxygen and nutrients, brain cells begin to die within minutes. Sudden bleeding in the brain can \n\nalso cause a stroke if it damages brain cells. A stroke is a medical emergency that can cause \n\nlasting brain damage, long-term disability, or even death. Signs of a stroke can range from mild \n\nweakness to paralysis or numbness on one side of the face or body. Other signs include a sudden \n\nand severe headache, sudden weakness, trouble seeing, and trouble speaking or understanding \n\nspeech (https://www.nhlbi.nih.gov/health-topics/stroke). \n\nAl Taleb et al. [3] introduced a machine learning method for early prediction of LOS of stroke \n\npatients. They tested their approach at the Stroke Unit of King Fahad Bin Abdul- Aziz Hospital \n\nin Saudi Arabia. The study was based on 866 stroke patients, whose data was retrieved from \n\nthe Neurology Department database. For data cleaning, each set of patient data was manually \n\nexamined for invalid or erroneous inputs. Records with missing values in more than 50% of the \n\nattributes were deleted. For the records with missing values in less than 50% of attributes, \n\nmissing values were replaced with the average value of the respective attributes for numeric \n\nattributes, and with the mode value for the categorical attributes. The approach involved a \n\nfeature selection step based on Information Gain (IG) followed by a prediction model \n\ndevelopment step using different machine learning algorithms as explained below. \n\n \n\nThe original dataset contained 105 attributes, out of which 54 attributes were manually \n\neliminated due to being irrelevant or redundant, such as time of arrival, date of MRI, and cause \n\nof death. The remaining 51 attributes were ranked based on their IG with respect to LOS, and \n\nthen an iterative process of elimination was applied where the researchers began processing all \n\n\n\n \n\n \n\n \n\n \n\n \n\n6 \n\n \n\nof the features. Then features were eliminated one at a time, starting with the least ranked one, \n\nand the IG was recalculated. The repetitive process stopped when there was no further \n\nimprovement in IG. Finally, 16 remaining attributes (including LOS) were selected for the \n\nprediction steps. The selected attributes and their IG values are listed in Fig. 5. \n\n \n\n \n\n \n \n\nFig. 5. Selected attributes and their IG values with respect to the class attribute (LOS) [3].  \n\n \n\nPrediction results were compared to identify the algorithm with the best performance. Several \n\nexperiments were performed in various settings. The authors found that the most accurate model \n\nin their study was the Bnet model with accuracy of 81.28%. \n\nIn another study, Neto et al. [8] proposed a neural network LOS prediction method based on \n\nthe information available on the stroke neurological events, the patient\u2019s health status, and \n\nsurgery details. The neural network was trained to test with three attribute subsets of different \n\nsizes. The first subset contained 33 attributes, the second 14, and the third subset consisted of \n\nonly 7 attributes. By testing the three subsets, it was possible to define an optimal neural \n\nnetwork configuration where the lowest error values were registered as Root Mean Squared \n\nError, 5.9451, and Mean Absolute Error, 4.6354. They concluded that the third use case (the \n\none with fewer variables) obtained better results than the other attribute sets. \n\nZhang et al. [1] aimed to develop a risk prediction model of prolonged LOS in stroke patients \n\nfor 50 inpatient rehabilitation centers in 20 provinces across mainland China, based on the \n\nInternational Classification of Functioning, Disability, and Health Generic Set case mix on \n\nadmission. The study was conducted on 383 stroke patients. The independent predictors of \n\nprolonged LOS were identified using Multivariate Logistic Regression (MLR) analysis. A \n\nprediction model was established and then evaluated by receiver operating characteristic curve \n\nanalysis, and the Hosmer-Lemeshow test. The results showed that the type of medical insurance \n\nand the performance of daily activities were associated with prolonged LOS. Age and mobility \n\nlevel demonstrated no significant predictive value. The prediction model revealed acceptable \n\ndiscrimination shown by an AUC of 0.699. The researchers concluded that the scores for the \n\ntype of medical insurance and the performance of daily activities on admission were \n\n\n\n \n\n \n\n \n\n \n\n \n\n7 \n\n \n\nindependent predictors of prolonged LOS for stroke patients. Their study proved that prediction \n\nmodels allow stakeholders to quantitatively estimate the risk of prolonged LOS upon admission, \n\nand to facilitate financial planning. They can also determine any required treatment regimens \n\nduring hospitalization, the need for referral after discharge, and reimbursement of costs. \n\nMinaeian et al. [9] sought to determine whether a longer emergency LOS was associated with \n\na poor 90-day outcome following an ischemic stroke. Their method was based on a \n\nretrospective analysis of a single-center cohort of consecutive ischemic stroke patients. There \n\nwere 325 patients in the study. They constructed multivariable linear and LR models to \n\ndetermine factors independently associated with emergency LOS as well as a poor 90-day \n\noutcome. The results revealed that the median LOS in the cohort was 5.8 hours of time spent in \n\nemergency. For patients admitted to the inpatient stroke ward (160 patients) versus \n\nneurointensive care unit (NICU) (165 patients), the median LOS was 8.2 hours versus 3.7 hours, \n\nrespectively. On multivariable linear regression, NICU admission, endovascular stroke therapy, \n\nand thrombolysis were inversely associated with the LOS. Evening shift presentation was \n\nassociated with a longer LOS. On MLR, a greater admission stroke severity, worse pre-\n\nadmission modified Rankin scale, hemorrhagic conversion, and a shorter LOS were associated \n\nwith a poor 90-day outcome. Early initiation of statin therapy, endovascular stroke therapy, \n\nNICU admission, and evening shift presentation were associated with a good 90-day outcome. \n\nThe authors stressed in their conclusion that in contrast to prior studies, a shorter emergency \n\nLOS was associated with a worse 90-day functional outcome, possibly reflecting prioritized \n\nadmission of more severely affected stroke patients who were at high risk for a poor functional \n\noutcome. \n\nChang et al. [10] aimed to determine the clinical and demographic predictors of LOS of acute \n\ncare hospital stay for patients with first-ever ischemic stroke. In the study, a group of 330 \n\npatients who had their first-ever ischemic stroke and were admitted to a medical center in \n\nsouthern Taiwan were followed prospectively. The researchers evaluated only the factors that \n\ncould be known at the time of admission. Univariate analysis and multiple regression analysis \n\nwere used to identify the LOS main predictors. \n\nIn the reported results, the median LOS was 7 days, average LOS was 11 days, and the LOS \n\nrange was 1 to 122 days. Among the prespecified demographic and clinical characteristics, the \n\nNational Institutes of Health Stroke Scale (NIHSS) score at admission, the quadratic term of \n\nthe initial NIHSS score, the modified Barthel Index score at admission, small-vessel occlusion \n\nstroke, smoking, and sex were the main predictors for LOS. In particular, for each 1-point \n\nincrease in the score of NIHSS, LOS increased by approximately 1 day for patients with mild \n\nor moderate neurological impairments (score 0 to 15 points), while LOS decreased \n\napproximately 1 day for patients with severe neurological impairments (score 15 points). The \n\nauthors concluded that the severity of acute stroke, as scored by the total score on NIHSS, was \n\nan important factor influencing LOS after acute stroke hospitalization.  \n\nAppelros et al. [11] examined the factors that influence acute and total LOS for stroke \n\npatients. The basis of their investigation was a population-based cohort of first-ever stroke \n\npatients (388 patients). Patient data included age, sex, risk factors, social factors, dementia, \n\nstroke type, and stroke severity, measured using the NIHSS. The results showed a mean acute \n\nLOS of 12 days and mean total LOS of 29 days. Independent predictors of acute LOS were \n\nstroke severity, lacunar stroke, pre-stroke dementia, and smoking. Independent predictors of \n\ntotal LOS were stroke severity and pre-stroke activities of daily living dependency. The NIHSS \n\n\n\n \n\n \n\n \n\n \n\n \n\n8 \n\n \n\nelements that best correlated with LOS included paresis, unilateral neglect, and level of \n\nconsciousness. The conclusion was that stroke severity is a strong and reliable predictor of LOS. \n\nThe results can be used as a baseline for evaluating cost-effectiveness of stroke care changes, \n\nsuch as assessment of new drugs and organizational modifications. \n\nThe study conducted by Okere et al. [12] was designed to evaluate predictors of hospital LOS \n\nand re-admissions among non-surgical ischemic stroke patients. The patients in this study were \n\nadult patients (\u2265 18 years) with a diagnosis of non-surgical ischemic stroke, who were \n\nhospitalized between November 2007 and March 2013. The results of the statistical analyses \n\n(multivariate and bivariate analyses), revealed that insurance type was a significant predictor of \n\nLOS, with Medicare patients having a longer LOS compared to patients with private insurance. \n\nSeverity of illness was also a predictor of LOS, whereby patients prescribed statins and patients \n\naged less than 80 years old had a lower 30-day hospital re-admission rate compared to patients \n\nwho were not prescribed statins and who were older than 80 years of age, respectively. \n\nChoi et al. [13] considered LOS prediction for acute stroke patients and extracted their dataset \n\nfrom 2013 and 2014 discharge injured patient data. The data was classified as 60% for training \n\nand 40% for evaluation. In their model, they used the multiple regression analysis method \n\ncombined with machine learning techniques (such as decision tree and neural network) to create \n\nan ensemble technique that integrates all methods. They evaluated their model using root \n\nabsolute error index. Considering the used methods, the error index was 23.7 for multiple \n\nregression, 23.7 for decision tree, 22.7 for neural network, and 22.7 for the ensemble technique. \n\nThey concluded that the neural network technique was found to be superior (even reaching the \n\nlevel of ensemble methods). \n\nIn the study carried out by Svendsen et al. [14], the author\u2019s objective was to determine \n\nwhether healthcare quality was associated with LOS among stroke patients. They performed a \n\npopulation-based study that included 2,636 stroke patients between 2003 and 2005 from a \n\nstroke unit in Denmark. In this study, quality of care was measured as fulfillment of twelve (12) \n\ncriteria: \u201cearly admission to a stroke unit, early antiplatelet therapy, early anticoagulant therapy, \n\nearly computed tomography/magnetic resonance imaging scan, early water swallowing test, \n\nearly mobilization, early intermittent catheterization, early deep venous thromboembolism \n\nprophylaxis, early assessment by a Physiotherapist and an Occupational Therapist, and early \n\nassessment of nutritional and constipation risk\u201d [14]. The authors\u2019 analyzed the patients\u2019 data \n\nusing linear regression clustered at the stroke units by multilevel modeling. The results showed \n\nthat the median length of stay was 13 days. Fulfilling each quality of care criterion was \n\nassociated with shorter LOS. The authors found that \u201cthe association between meeting more \n\nquality of care criteria and LOS followed a dose-response effect, that is, patients who fulfilled \n\nbetween 75% and 100% of the quality of care criteria were hospitalized only one-half as long \n\nas patients who fulfilled between 0% and 24% of the criteria\u201d. The study concluded that the \n\ncare in the early phase of stroke is very important as a high initial quality of care was associated \n\nwith shorter length of stay among stroke patients. \n\nGarza-Ulloa [15] used neural network algorithms to predict rehabilitation LOS for stroke \n\npatients along with other stroke metrics (i.e., the need for surgery and rehabilitation need). The \n\nstudy objective was to find an optimal neural network configuration using three different \n\navailable software: one manual (with no automatic stepwise functions and limited diagnostic \n\ncapability), another semi-automatic (allows step- wise function with good diagnostics), and \n\nneuro-intelligence (uses genetic algorithm to find the best neural network (NN) configuration). \n\n\n\n \n\n \n\n \n\n \n\n \n\n9 \n\n \n\nBased on the 14 stroke input variables and the 3 output target stroke values, the paper suggested \n\nthat the forecasting of: surgery, rehab and days of rehabilitation were possible using neural \n\nnetwork tools. Fig. 6 (from [15]) outlines the 14-group variables for the proposed neural \n\nnetwork . \n\n \n\n \nFig. 6. 14-Group variables for the proposed NN [15]. \n\n \n\nThe study of Ng et al. [16] aimed to investigate LOS characteristics and identify the predictors \n\nof post-stroke acute, rehabilitation and total LOS. The study divided the stroke patients (1,277 \n\npatients) into two subgroups of short LOS and long LOS, and compared the two subgroups \n\nregarding complication rates and functional outcomes. The authors considered stroke patients \n\nwithin a 5-year period from 2004 to 2009 in a dedicated rehabilitation unit within a tertiary \n\nacademic acute hospital in Singapore. The primary outcome measure considered in the \n\nrehabilitation phase was the functional independence measure (FIM). Short acute LOS patients \n\nwere defined as patients who stayed less than 7 days. Most patients in the study were ischemic \n\nstroke patients (1,019 patients (80%)), while the remaining patients were haemorrhagic stroke \n\npatients (20%). The results of the study showed that the average acute and rehabilitation LOS \n\nwere 9-7 days and 18-10 days, respectively. \u201cHaemorrhagic strokes and anterior circulation \n\ninfarcts had significantly longer acute, rehabilitation and total LOS compared to posterior \n\ncirculation and lacunar infarcts\u201d [16]. Patients that were admitted after 2007 had significantly \n\nshorter acute, rehabilitation and total LOS. The authors found poor correlation between the \n\nacute and rehabilitation LOS (r = 0.12). In multivariate analysis, considering rehabilitation \n\nLOS, admission FIM scores were significantly associated with LOS, while, in acute LOS, \n\nstroke type was strongly associated with LOS. \u201cPatients in the short acute LOS group had fewer \n\nmedical complications and similar FIM efficacies compared to the longer acute LOS group.\u201d \n\n[16]. The authors concluded that it is very important to transfer appropriate patients as early as \n\npossible to rehabilitation units as this ensures that the development of clinical complications is \n\nminimized, while rehabilitation efficacy is maintained. \n\nBindawas et al. [17] aimed to investigate the association between LOS and functional \n\noutcomes among patients with stroke discharged from a rehabilitation facility in Saudi Arabia. \n\nThere were 409 adult patients in the study (age 18) admitted between 2008 and 2014, with no \n\ndeaths during the study period. Patients were divided into 4 different groups based on the days \n\n\n\n \n\n \n\n \n\n \n\n \n\n10 \n\n \n\nof rehabilitation: \u2264 30 days (n=114), 31\u201360 days (n=199), 61\u201390 days (n=72), and > 90 days \n\n(n=24). Multivariate regression analyses were used to evaluate functional outcomes using the \n\nFIM. The results of the study showed that higher FIM scores were significantly associated with \n\na LOS \u2264 30 days and 31\u201360 days, compared to > 90 days. The authors concluded that \u201ca short \n\nor intermediate LOS is not necessarily associated with worse outcomes, assuming adequate care \n\nis provided.\u201d [17]. \n\nArboix et al. [18] considered the identification of clinical predictors of prolonged hospital \n\nstay after acute stroke. They considered a long study period of 17 years for patients in Spain \n\nwho have had their first-ever ischemic stroke and primary intracerebral hemorrhage. Prolonged \n\nLOS stay was defined as LOS longer than 12 days after admission. The attributes considered \n\nincluded demographic data, cardiovascular risk factors, neuroimaging findings, clinical factors, \n\nand outcome. LR analysis was used to evaluate the independent influence of statistically \n\nsignificant variables in the duration of hospitalization. The results of 3,112 acute stroke patients \n\nshowed that prolonged hospital stay was recorded in 1,536 (49.4%) cases. Furthermore, males, \n\nlimb weakness, vascular complications, urinary complications, and infectious complications \n\nwere independently associated with longer LOS, whereas being symptom free at hospital \n\ndischarge and lacunar infarction were inversely associated with prolonged LOS. The authors \n\nconcluded that \u201cin-hospital medical complications (vascular, urinary, and infectious) are \n\nrelevant factors influencing duration of hospitalization after acute stroke. Therefore, prevention \n\nof potentially modifiable risk factors for medical complications is an important aspect of the \n\nearly management of patients who experienced stroke\u201d [18]. \n\nThe objective of the study conducted by Koton et al. [19] was to derive a simple score for the \n\nassessment of the risk of prolonged length of stay for acute stroke patients. Prolonged LOS was \n\ndefined as LOS \u2265 7 days. The results showed that the severity of stroke was the strongest \n\nmultivariable predictor of prolonged LOS. The study concluded that a simple prolonged LOS \n\nscore, based on available baseline information (stroke severity), may be useful for developing \n\npolicies aimed at better use of resources and optimal discharge planning of acute stroke patients \n\n[19]. \n\nHung et al. [20] aimed to consider the factors that influence LOS for stroke patients in \n\nTaiwan. The researchers explored how intravenous thrombolysis (IVT) affects LOS in an acute \n\ncare hospital setting. The study considered adult patients with ischemic stroke who presented \n\nwithin 48 hours of stroke onset. The relationship between IVT and prolonged length of stay \n\n(LOS \u2265 7 days) was studied by both classification and regression tree, as well as MLR analyses. \n\nFig. 7 illustrates the risk stratification for prolonged LOS by means of the classification and \n\nregression tree analysis. Among the study population of 3,054 patients, 1,110 presented within \n\n4.5 hours. The median LOS was 7 days (ranging from 4 to 11 days), and 1,619 patients had \n\nprolonged LOS. MLR revealed that IVT was an independent factor that reduced the risk of \n\nprolonged LOS, whereas age, NIHSS score, diabetes mellitus, and leukocytosis at admission \n\npredicted prolonged LOS. Decision tree analysis identified four variables (NIHSS score, IVT, \n\nleukocytosis at admission, and age) as important factors and they were used to partition the \n\npatients into six subgroups (see Fig. 7). The patient subgroup that had an NIHSS score of 5 to \n\n7 and received IVT had the lowest probability (19%) of prolonged LOS [20]. The authors \n\nconcluded that IVT minimized the risk of prolonged length of stay in patients with acute \n\nischemic stroke. They recommended that measures to increase the rate of IVT be encouraged. \n\n \n\n\n\n \n\n \n\n \n\n \n\n \n\n11 \n\n \n\n \nFig. 7. Risk stratification for prolonged LOS by means of the classification \n\nand regression tree analysis [20]. \n\n 4. DISCUSSION AND CONCLUSIONS \n\nThe topic of hospital LOS is an important topic for hospital resource utilization and \n\noptimization [21][22]. Although many researchers have conducted research on LOS prediction, \n\nmore research is needed to further enrich this domain of study. We noticed from our literature \n\nreview that researchers occasionally reached contradicting conclusions about LOS for stroke \n\npatients. For example, some researchers (e.g., [1]) found that the age of the patient was not a \n\nsignificant predictor of prolonged LOS, whereas, others (e.g., [20]) concluded that a patient\u2019s \n\nage was an important predictor for LOS for stroke patients. This shows how LOS prediction is \n\na complex phenomenon that requires more studies and careful investigation. On the other hand, \n\nmost researchers (implicitly or explicitly) agreed that stroke severity (e.g., NIHSS) is a major \n\npredictor of LOS in stroke patients. \n\nAnother observation from our literature review is that not all researchers teamed up with \n\ndomain experts while conducting machine learning studies on LOS prediction. We view this as \n\na limitation in such studies because LOS prediction is a topic that is highly related to the medical \n\nfield as well as to patients\u2019 medical data and characteristics. This implies that in future research, \n\ndomain experts should be consulted before finalizing and publishing such LOS prediction \n\nstudies. Domain experts enrich the studies and make them more realistic. \n\nAnother point is that some researchers did not specifically mention the attributes that were \n\neffective in LOS prediction at the end of their studies. However, this particular information is \n\nhighly important for the readers of such research articles so that new research can build on \n\nprevious studies. We also recommend more future cooperation between machine learning \n\nresearchers in this field because of its importance in hospital resource utilization, decreasing \n\nhealthcare costs, and achieving healthier people and an overall healthier society.  \n\n\n\n \n\n \n\n \n\n \n\n \n\n12 \n\n \n\n \n\nREFERENCES \n\n[1] X. Zhang, H. Qiu, S. Liu, J. Li, and M. Zhou, \u201cPrediction of prolonged length of stay for stroke \n\npatients on admission for inpatient rehabilitation based on the international classification of \n\nfunctioning, disability, and health (ICF) generic set: A study from 50 centers in china,\u201d Medical \n\nScience Monitor: International Medical Journal of Experimental and Clinical Research, vol. 26, \n\npp. e918 811\u20131, 2020. \n\n[2] I. E. Livieris, I. F. Dimopoulos, T. Kotsilieris, and P. Pintelas, \u201cPredicting length of stay in \n\nhospitalized patients using ssl algorithms,\u201d in Proceed- ings of the 8th International Conference on \n\nSoftware Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion, \n\n2018, pp. 16\u201322. \n\n[3] A. R. Al Taleb, M. Hoque, A. Hasanat, and M. B. Khan, \u201cApplication of data mining techniques \n\nto predict length of stay of stroke patients,\u201d in 2017 International Conference on Informatics, \n\nHealth & Technology (ICIHT). IEEE, 2017, pp. 1\u20135. \n\n[4] S. Kabir and L. Farrokhvar, \u201cNon-linear feature selection for prediction of hospital length of stay,\u201d \n\nin 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA). \n\nIEEE, 2019, pp. 945\u2013950. \n\n[5] A. Azari, V. P. Janeja, and A. Mohseni, \u201cPredicting hospital length of stay (PHLOS): A multi-\n\ntiered data mining approach,\u201d in 2012 IEEE 12th International Conference on Data Mining \n\nWorkshops. IEEE, 2012, pp. 17\u201324. \n\n[6] I. Nouaouri, A. Samet, and H. Allaoui, \u201cEvidential data mining for length of stay (LOS) prediction \n\nproblem,\u201d in 2015 IEEE International Conference on Automation Science and Engineering \n\n(CASE). IEEE, 2015, pp. 1415\u20131420. \n\n[7]    R. Rathor and P. Agarkar, \u201cLosh prediction using data mining,\u201d Inter- national Journal of \n\nComputer Applications, vol. 119, no. 2, 2015. \n\n[8]    C. Neto, M. Brito, H. Peixoto, V. Lopes, A. Abelha, and J. Machado, \u201cPrediction of length of \n\nstay for stroke patients using artificial neural networks,\u201d in World Conference on Information \n\nSystems and Technolo- gies. Springer, 2020, pp. 212\u2013221. \n\n[9]    A. Minaeian, A. Patel, B. Essa, R. P. Goddeau Jr, M. Moonis, and N. Henninger, \u201cEmergency \n\ndepartment length of stay and outcome after ischemic stroke,\u201d Journal of Stroke and \n\nCerebrovascular Diseases, vol. 26, no. 10, pp. 2167\u20132173, 2017. \n\n[10] K.-C. Chang, M.-C. Tseng, H.-H. Weng, Y.-H. Lin, C.-W. Liou, and T.-Y. Tan, \u201cPrediction of \n\nlength of stay of first-ever ischemic stroke,\u201d Stroke, vol. 33, no. 11, pp. 2670\u20132674, 2002. \n\n\n\n \n\n \n\n \n\n \n\n \n\n13 \n\n \n\n[11] P. Appelros, \u201cPrediction of length of stay for stroke patients,\u201d Acta Neurologica Scandinavica, vol. \n\n116, no. 1, pp. 15\u201319, 2007. \n\n[12] A. N. Okere, C. M. Renier, and A. Frye, \u201cPredictors of hospital length of stay and readmissions \n\nin ischemic stroke patients and the impact of inpatient medication management,\u201d Journal of Stroke \n\nand Cerebrovascular Diseases, vol. 25, no. 8, pp. 1939\u20131951, 2016. \n\n[13] B. K. Choi, S. W. Ham, C. H. Kim, J. S. Seo, M. H. Park, and S. H. Kang, \u201cDevelopment of \n\npredictive model for length of stay (los) in acute stroke patients using artificial intelligence,\u201d \n\nJournal of Digital Convergence, vol. 16, no. 1, pp. 231\u2013242, 2018. \n\n[14] M. L. Svendsen, L. H. Ehlers, G. Andersen, and S. P. Johnsen, \u201cQuality of care and length of \n\nhospital stay among patients with stroke,\u201d Medical care, pp. 575\u2013582, 2009. \n\n[15] J. Garza-Ulloa, \u201cArtificial intelligence analysis using neural network to predict three stroke \n\nparameters: Surgery needed, treatment, and length of stay for rehabilitation.\u201d Unpublished. \n\n[16] Y. S. Ng, K. H. Tan, C. Chen, G. C. Senolos, E. Chew, and G. C. Koh, \u201cPredictors of acute, \n\nrehabilitation and total length of stay in acute stroke: a prospective cohort study,\u201d Ann Acad Med \n\nSingapore, vol. 45, no. 9, pp. 394\u2013403, 2016. \n\n[17] S. M. Bindawas, V. Vennu, H. Mawajdeh, H. M. Alhaidary, and E. Mof- tah, \u201cLength of stay and \n\nfunctional outcomes among patients with stroke discharged from an inpatient rehabilitation facility \n\nin saudi arabia,\u201d Medical science monitor: international medical journal of experimental and \n\nclinical research, vol. 24, p. 207, 2018. \n\n[18] A. Arboix, J. Massons, L. Garc\u00b4\u0131a-Eroles, C. Targa, M. Oliveres, and E. Comes, \u201cClinical predictors \n\nof prolonged hospital stay after acute stroke: relevance of medical complications,\u201d 2012. \n\n[19] S. Koton, N. Bornstein, R. Tsabari, D. Tanne et al., \u201cDerivation and validation of the prolonged \n\nlength of stay score in acute stroke patients,\u201d Neurology, vol. 74, no. 19, pp. 1511\u20131516, 2010. \n\n[20] L.-C. Hung, Y.-H. Hu, and S.-F. Sung, \u201cExploring the impact of intravenous thrombolysis on length \n\nof stay for acute ischemic stroke: a retrospective cohort study,\u201d BMC health services research, vol. \n\n15, no. 1, p. 404, 2015. \n\n[21] A. Alahmar, E. Mohammed, and R. Benlamri. \"Application of data mining techniques to predict \n\nthe length of stay of hospitalized patients with diabetes.\" In 2018 4th International Conference on \n\nBig Data Innovations and Applications (Innovate-Data), pp. 38-43. IEEE, 2018. \n\n[22] A. Alahmar and R. Benlamri, Optimizing Hospital Resources using Big Data Analytics with \n\nStandardized e-Clinical Pathways. In 2020 IEEE Intl Conf on Cloud and Big Data Computing, \n\n(CBDCom), pp. 650-657. IEEE, August 2020. \n\n \n\n \n\n\n"}
{"Title": "Knowledge intensive state design for traffic signal control", "Authors": "Liang Zhang, Qiang Wu, Jianming Deng", "Abstract": "  There is a general trend of applying reinforcement learning (RL) techniques for traffic signal control (TSC). Recently, most studies pay attention to the neural network design and rarely concentrate on the state representation. Does the design of state representation has a good impact on TSC? In this paper, we (1) propose an effective state representation as queue length of vehicles with intensive knowledge; (2) present a TSC method called MaxQueue based on our state representation approach; (3) develop a general RL-based TSC template called QL-XLight with queue length as state and reward and generate QL-FRAP, QL-CoLight, and QL-DQN by our QL-XLight template based on traditional and latest RL models.Through comprehensive experiments on multiple real-world datasets, we demonstrate that: (1) our MaxQueue method outperforms the latest RL based methods; (2) QL-FRAP and QL-CoLight achieves a new state-of-the-art (SOTA). In general, state representation with intensive knowledge is also essential for TSC methods. Our code is released on Github.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00006", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge intensive state design for traffic signal control\n\nLiang Zhang1, Qiang Wu2, Jianming Deng1*\n\n1 School of Life Sciences, Lanzhou University, Lanzhou 730000, China\n2 Institute of Fundamental and Frontier Sciences, University of Electronic Science and Technology of China, Chengdu\n\n611731, China\n\nAbstract\n\nThere is a general trend of applying reinforcement learning\n(RL) techniques for traffic signal control (TSC). Recently,\nmost studies pay attention to the neural network design and\nrarely concentrate on the state representation. Does the design\nof state representation has a good impact on TSC? In this pa-\nper, we (1) propose an effective state representation as queue\nlength of vehicles with intensive knowledge; (2) present a\nTSC method called MaxQueue based on our state representa-\ntion approach; (3) develop a general RL-based TSC template\ncalled QL-XLight with queue length as state and reward and\ngenerate QL-FRAP, QL-CoLight, and QL-DQN by our QL-\nXLight template based on traditional and latest RL models.\nThrough comprehensive experiments on multiple real-world\ndatasets, we demonstrate that: (1) our MaxQueue method out-\nperforms the latest RL based methods; (2) QL-FRAP and QL-\nCoLight achieves a new state-of-the-art (SOTA). In general,\nstate representation with intensive knowledge is also essential\nfor TSC methods. Our code is released on Github1.\nKeywords: intensive knowledge, traffic signal control, rein-\nforcement learning, state design, effective state\n\n1 Introduction\nWith population and economic growth, automobiles increase\nrapidly, and traffic congestion has become an emergent prob-\nlem. Traffic congestion causes fuel waste, environmental\npollution, economic losses, and waste of time. Mitigating\ntraffic congestion and improving transportation efficiency is\nof great urgency.\n\nIn many modern cities, FixedTime[5], GreenWave[12],\nSCOOT[4], and SCATS[7] are the most common traffic\nsignal control systems, which relys on pre-designed traffic\nsignal plans. These methods can\u2019t adapt to dynamic traf-\nfic flows. In addition, some traditional traffic signal control\n(TSC) methods such as MaxPressure[14] and SOTL[2] have\ngood performance but takes much efforts to deploy.\n\nRecently, reinforcement learning (RL) has drawn increas-\ning attention, and people have begun to use RL to solve TSC\nproblems. RL models can directly learn from the environ-\nment through trial-and-error without requiring assumptions\nlike traditional TSC methods. Furthermore, RL models can\n\n*Jianming Deng is the corresponding author. Email:\ndengjm@lzu.edu.cn\n\n1https:github.com/LiangZhang1996/QL XLight\n\nhandle complex and dynamic environments with a deep neu-\nral network[8]. RL-based TSC methods[16, 1, 16] become\na promising solution for realizing intelligent transportation\nsystems. PressLight[16] can realize large-scale traffic sig-\nnal control. Furthermore, MPLight[1] and CoLight[17] have\ndemonstrate the ability to handle city-level TSC. In addi-\ntion, MPLight uses a decentralized RL paradigm and is eas-\nier for large-scale deployment. PressLight[16] and MPLight\nall demonstrate the essential role of the state and reward de-\nsign.\n\nIn RL-based approach, the state representations vary in\nterms of queue length[9, 18], number of vehicles[18, 23, 20,\n16, 22, 20, 17, 19], traffic image[13, 18]; the reward rep-\nresentations vary in terms of queue length[22, 16, 17, 19] ,\npressure[1], total wait time[18, 9, 13, 19], and delay[18, 13,\n19]. Some methods can perform better with simple state and\nreward. However, some methods with complex state and re-\nward designs get limited results. However, most studies con-\ncentrate on developing novel network structures to improve\nTSC performance. Few of the studies have deeply explored\nwhy some methods have great performance with simple state\nand reward design. More attention should be paid to the state\ndesign for TSC.\n\nIn summary, the main contribution of this article as fol-\nlows:\n1. Propose an effective state representation as queue length\n\nwith intensive-knowledge;\n2. Propose one transportation method, namely MaxQueue,\n\nwhich has superior performance than previous state-of-\nthe-art RL methods;\n\n3. With effective state design, we develop an RL-based TSC\ntemplate: QL-XLight with queue length as state and re-\nward;\n\n4. Based on QL-XLight, we generate three RL-based meth-\nods: QL-DQN, QL-FRAP, QL-MPLight, which all have\nsuperior performance than the latest methods;\n\n5. Demonstrate that state design with intensive knowledge\nis as essential as network structure design.\n\nThe remainder of this paper is organized as follows:\nSection 2 introduces the related works, including typi-\ncal transprotation and RL-based approaches for TSC; Sec-\ntion 3 depicts the definitions of TSC; Section 4 system-\natically analyzes the typical used state representation with\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n6v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\nhttps:github.com/LiangZhang1996/QL_XLight\n\n\nintensive-knowledge, and develop the MaxQueue algorithm\nand QL-XLight template. Section 5 conducts experiments\nand demonstrates the results. Section 6 concludes the paper\nand discusses future work.\n\n2 Related work\n2.1 Conventional transportation methods\nConventional transportation methods can be mainly catego-\nrized into the four categories: fixed-time control[5, 12], actu-\nated control[3, 2], adaptive control [4, 7], and optimization-\nbased control[14, 6, 10]. All the methods mentioned above\nhighly rely on expert knowledge. Fixed-time and adaptive\ncontrol rely on predefined signal plans (i.e., cycle length,\nphase split, and offset). Actuated control relies on the prede-\nfined threshold, which highly influences the control perfor-\nmance; optimization-based control also relies on the prede-\nfined signal plan (i.e., cycle length), turn ratios, and satura-\ntion flow rates. Therefore, these conventional transportation\nmethods have limited capacity to adapt to dynamic traffic.\n\n2.2 RL based methods\nRL models can learn their policy directly from environments\nthrough trial-and-error, and deep neural networks make\nthem adapt to various conditions. The RL-based method is a\npromising solution for traffic signal control. PressLight[16]\ncan achieve multi-intersection traffic signal control. MP-\nLight and CoLight can realize city-level TSC. HiLight also\nachieves superior performance than MPLight and CoLight\nwith hierarchical RL models. The state, reward, and neu-\nral network design play an essential role in RL models. We\nsummarize some typical RL-based methods and category\nthem into the following classes:\n\n\u2022 The methods that introduce the novel neural network\nstructure. GCN[9] adopt graph convolution neural net-\nwork for TSC control; IntelliLight[18] develops a com-\nplex neural network with phase selector; FRAP[22] uses\na modified network structure to capture the phase com-\npetition relation between different traffic movements;\nCoLight[17] uses graph attention networks to learn inter-\nsection cooperation; HiLight[19] adopts hierarchical RL\napproach for TSC.\n\n\u2022 The methods that introduce effective state and reward de-\nsign. PressLight[16] incorporates pressure into state and\nreward design; MPLight[1] uses traffic movement pres-\nsure as state, intersection pressure as reward.\n\nWe can know that most people try to develop an effective\nnetwork structure from the above. The concentration on state\ndesign is rare.\n\n2.3 State design\nIn other RL fields, the state representation is clear, and peo-\nple can directly use images as a state. However, in the TSC\nfield, the state is dynamic and complex, and the state rep-\nresentation should be dealt carefully. The state design for\nTSC has not been deeply studied. LIT[23] finds that: as a\nreward representation, queue length is better than delay; as a\n\nstate representation, number of vehicles is better than wait-\ning time and traffic image. PressLight finds pressure is better\nthan queue length as a reward representation. MPLight intro-\nduces pressure into state design and finds the improvement\nin the model. However, none of them systematically explain\nwhy some state and reward is better. The state representation\nfor TSC needs to be further discussed.\n\n3 Preliminary\nIn this section, we summarize the definition for recent TSC\nmethods[1, 17].\n\nFigure 1: The illustration of an intersection with four phases.\nIn this case, phase #2 is activated.\n\nDefinition 1 (Traffic network). Each traffic network is de-\nscribed as a directed graph, in which each node represents\nthe intersection, and each edge represents the road. Each\nroad consists of several lanes. An incoming lane for an inter-\nsection is where the vehicles enter the intersection. An out-\ngoing lane for an intersection is where the vehicles leave the\nintersection. We denote the set of incoming lanes and outgo-\ning lanes of intersection i as Lin\n\ni and Lout\ni respectively. We\n\nuse l,m, k to denote the lanes.\nDefinition 2 (Traffic movement). A traffic movement is\n\ndefined as the traffic traveling across an intersection towards\na certain direction, i.e., left turn, go straight, and right turn.\nFollowing the traffic rules in most cities, right turn traffic can\npass regardless of the signal, but it needs to yield on a red\nlight. In Figure 1 (a), there are 12 traffic movements.\n\nDefinition 3(Signal phase). Each signal phase is a set of\npermissible traffic movements, denoted by d, andDi denotes\nthe set of all the phases at intersection i. As shown in Figure\n1, the intersection has 4 phases with phase #2 activated.\n\nDefinition 4 (Phase queue length). The queue length of\neach phase is the sum queue length of the incoming lanes of\nthe phase, denoted by\n\nq(d) =\n\u2211\n\nq(l), l \u2208 d (1)\n\nin which q(l) is the queue length of lane l.\nDefinition 5 (Intersection queue length). The queue\n\nlength of each intersection is defined as the total queue\n\n\n\nlength of the incoming lanes of the intersection, denoted by\n\nQi =\n\u2211\n\nq(l), l \u2208 Lin\ni (2)\n\nin which q(l) represents the queue length of lane l.\nDefinition 6 (Phase duration). The minimum duration for\n\neach phase is denoted by tduration. It can also represent the\naction interval of RL-based models.\n\nProblem (Multi-intersection traffic signal control). Each\nintersection is controlled by a RL agent. At time step t,\nagent i views the environment as its observation oti. Every\ntduration, the action ati is taken to control the signal of inter-\nsection i. The goal of the agent is to take an optimal action\nati (i.e. which phase to set) to maximize the throughput of\nthe systems and minimize the average travel time.\n\nTable 1: Summary of notation.\n\nNotation Meaning\n\nLin\ni set of incoming lanes of intersection i\nLout\ni set of outgoing lanes of intersection i\n\nl,m, k lanes\nq(l) queue length of lane l\nd signal phase which is set of traffic movements\nDi set of all phases at intersection i\nQi total queue length of intersection i\n\ntduration minimal phase duration or said action interval\n\n4 Method\nIn this section, we first propose an effective state representa-\ntion as queue length with intensive knowledge. Next, we dis-\ncuss why queue length is more effective than some typical\nused state representation. Then, we propose a transportation\nmethod MaxQueue based on intensive knowledge inspired\nby MaxPressure. Finally, we develop an RL-based TSC tem-\nplate: QL-XLight and generate QL-DQN, QL-FRAP, and\nQL-COLight.\n\n4.1 Queue length as the state\nFor TSC, each vehicle in the traffic network has two states:\nrunning and queueing. Queueing vehicles can directly re-\nsult in congestion while running vehicles potentially result\nin congestion. Almost all the queueing vehicles stop near\nthe intersection and have the demand for a green signal.\nMP[14] maximizes the throughput of the traffic by balanc-\ning the queue length in the network. The queueing vehicles\nplay an essential role in the traffic condition representation.\nFrom empirical knowledge, the queue length is considered\nadequate.\n\nIn the traffic network, the phase signal can only directly\nchange the state of the queuing vehicles. Any consequent\nchanges such as the number of vehicles, vehicle position,\nspeed score are full of uncertainty. Therefore, we choose to\nuse queue length as the traffic state representation.\n\nDiscussion According to the existing studies, various state\nrepresentations are used in TSC, while some state represen-\ntation is more effective than others. We will summarize the\ntypically used state representations and give a systematical\nanalysis to answer which state is a effective traffic state rep-\nresentation.\n\nThe RL agents learn from the environment through trial-\nand-error and learn the state-action value through explo-\nration. Suppose the state representation does not include crit-\nical contents of traffic movement. In that case, the agent will\nbe confused about the state and can\u2019t learn an appropriate\npolicy.\n\nIf one phase is activated, the queue length of the phase\nchanges to zero, while the queue length for other phases may\ngrow gradually, depending on the arrival from upstream.\nThere is a deterministic change when each phase is acti-\nvated, and is considered effective.\n\nThen, we analyze the following traffic state representation\nand explain why they are as effective as queue length.\n\n\u2022 Number of vehicles: it is described as the total vehicle\nnumber of the incoming lanes. If one phase is activated,\nthe vehicles near the intersection pass through gradually,\nbut vehicles also arrive gradually from upstream. The to-\ntal number of the corresponding lanes probably:(1) be-\ncomes larger if the number of entering is larger than exit-\ning;(2) do not change if the number of entering is equal to\nexit; (3) become smaller if a number of entering smaller\nthan exiting. In addition, if there is no vehicle near the in-\ntersection, the traffic state can\u2019t change even if the phase\nchanges. Therefore, the change of state is vague and can\u2019t\nbe explicitly captured, which makes the agent \u201dconfus-\ning.\u201d\n\n\u2022 Vehicle position. The position of vehicles is usually in-\ntegrated as an image representation, which is defined as\na matrix, with \u201d1\u201d indicating the presence of vehicles on\na location, and \u201d0\u201d the absence of vehicles on that loca-\ntion. Each lane is usually divided into small segments,\nand some use the total vehicle number to replace \u201d1\u201d and\n\u201d0\u201d. This is similar to a number of vehicles that do not\nhave explicit changes after one phase be activated.\n\n\u2022 Speed score. The speed score is calculated by the aver-\nage speed divided by the speed limit. If one phase is acti-\nvated, the speed score change degree relies on the accel-\neration. In addition, if there are only queueing vehicles,\nthe speed score grows proportional to the acceleration; if\nthere are lots of running vehicles and few queueing vehi-\ncles, the speed score may change, not obvious. It is also\nconfusing for the RL agents.\n\n\u2022 Traffic movement pressure calculated by a number of ve-\nhicles. It is calculated by a number of vehicles and has\nsimilar properties to it.\n\n4.2 MaxQueue control\nBased on MaxPressure[14] and the property of queue length,\nwe propose a TSC method called MaxQueue. Like MaxPres-\nsure, MaxQueue control selects the phase with maximum\nqueue length in a greedy manner. At intersection i, the phase\n\n\n\nqueue length is calculated (by equation(1)), then activate the\nphase with maximum pressure every tduration, denoted by\n\nd\u0302 = argmax (q(d))|d \u2208 Di) (3)\nThe MaxQueue method is formally summarized in Algo-\nrithm 1.\n\nAlgorithm 1: MaxQueue Control\nParameter: Current phase time t, minimum phase duration\ntduration\n\nfor (time step) do\nt = t+ 1;\nif t = tduration then\n\nFor each intersection, get q(d) by equation (1);\nActivate the phase according to equation (3);\nt = 0\n\nend if\nend for\n\nComparison of MaxQueue and MaxPressure MaxPres-\nsure control selects the phase with maximum pressure,\nwhich is the difference of queue length between upstream\nand downstream, indicating the balance of the queue length.\nOnly consider the control logic, MaxQueue(MQ) and Max-\nPressure(MP) are highly similar, and both use a greedy man-\nner to select the phase. For the case of single intersection\ncontrol, MP and MQ are the same. There are no queueing\nvehicles on the outgoing lanes of the single intersection be-\ncause it is assumed that the outgoing is infinite. Thus, the\ncalculated pressure is exactly the queue length.\n\nMP considers the neighbor influence, stabilizes the queue\nlength, and maximizes the throughput by selecting the phase\nwith maximum pressure. The key idea of MP is that ensure\nthe vehicles can\u2019t be stopped by the queue vehicle of the up-\nstream. Therefore, if a phase has a large pressure, the queue\nlength can only be larger. The MP method is really effective\nwhen the traffic road length is small because the neighbor\nvehicles can fast influence the current intersection.\n\nHowever, when the traffic road length is longer, the influ-\nence may come after several tduration, and the pressure is\nnot effective. For example, set tduration = 15s and vehi-\ncles\u2019 maximum velocity is 10m/s; if the road is 100m, then\nit takes 10s to the neighbor, and the neighbor condition in-\nfluences the policy; if the road is 300m, then it takes at least\n30s to the neighbor, and the policy can\u2019t be influenced by the\nneighbor condition.\n\nIn summary, if the traffic road is relatively long, the MQ\nwill perform better; if the traffic road is relatively short, the\nMP will perform better.\n\n4.3 QL-XLight\nWe develop an RL-based TSC methods template with queue\nlength as the traffic state and reward, QL-XLight. Based on\nQL-XLight, DQN, FRAP, and CoLight are introduced as\nthe based model, and we get QL-DQN, QL-FRAP, and QL-\nCoLight.\n\u2022 State The current phase and queue length are used as the\n\nstate representation(agent observations).\n\n\u2022 Action At time t, each agent choose a phase d\u0302 according\nto the state, and the traffic signal will be changed to d\u0302.\n\n\u2022 Reward Negative intersection queue length is used as the\nreward. The reward for the agent controlling intersection\ni is denoted by\n\nri = \u2212Qi = \u2212|\n\u2211\n\nq(l)|, l \u2208 Lin\ni (4)\n\nin which q(l) is the queue length at lane l. By maximizing\nthe reward, the agent is trying to maximize the through-\nput in the system.\n\nDeep Q-learning The DQN agents are updated by the\nBellman Equation:\n\nQ(st, at) = R(st, at) + \u03b3maxQ(st+1, at+1) (5)\n\nin which st and st+1 are the state, at and at+1 are the action.\n\nBase model The following base models are introduced to\nget QL-DQN, QL-FRAP, QL-CoLight:\n\u2022 DQN based model. A simple DQN[8] with only two\n\nfully connected layers. The neural network structure is\nstraightforward and basic. Besides, we also adopt the de-\ncentralized approach from MPLight to train the model.\nWe refer to a simple DQN based approach as QL-DQN.\n\n\u2022 FRAP-based model. FRAP[22] is adopted as one of the\nbase models. FRAP can learn the phase competition\nin TSC with a specially designed architecture. It has a\nfast training process compared with other TSC methods.\nFRAP has been used as the base model by MPLight. We\nrefer to FRAP based approach as QL-FRAP.\n\n\u2022 CoLight based model. CoLight[17] is graph attention\nnetwork[15] based method, and learns intersection com-\nmunication and cooperation for TSC. CoLight is capable\nof large-scale TSC. We will adopt CoLight as one of the\nbase models. We refer to CoLight based model in this\narticle as QL-CoLight.\n\nTheoretically, we could build QL-LIT and QL-HiLight.\nHowever, because the code of HiLight is not available,\nwe implement QL-FRAP, QL-CoLight, and QL-DQN first,\nwithout the loss of validity of our conclusion.\n\nParameter Sharing Parameters of the network are shared\namong all the agents. It is essential to improve model\nperformance[1]. Besides, the replay memory is also shared\nso that all the intersections can benefit from the experiences\nof others. Note that the CoLight based model does not need\nparameter sharing. Some baseline models are also trained\nunder parameter sharing for fair model comparison.\n\nDiscussion We are not the first that introduce queue\nlength into both state and reward, but we are the first to\npropose queue length as an effective state representation.\nIntelliLight[18] uses complex state and reward representa-\ntion apart from queue length. GCN[9] uses queue length and\naverage velocity as state, total wait time as a reward. Tan et\nal.[11] uses queue length as state, queue length and a num-\nber of running vehicles as a reward. Although these studies\nhave used queue length as state representation, they do not\nemphasize queue length property.\n\n\n\nThe results of FRAP[22] and CoLight[17] demonstrates\nthe poor performance of IntelliLight and GCN. In addition,\nthe reward in [11] indicates the smaller queue length and\nrunning number, the better results, which is unreasonable\nbecause for the number of running vehicles, the larger, the\nbetter. Therefore, the reward is also essential for RL-based\nTSC, and only queue length is more reliable than that used\nin IntelliLight, GCN, and [11].\n\n5 Experiment\n5.1 Settings\nSimulator We conduct the experiments on an open-source\nsimulator called CityFlow2[21], which supports large-scale\ntraffic signal control and has faster speed than SUMO.\nThe simulator provides the environment observations to the\nagent and receives the command from the agent. In the ex-\nperiments, each green signal is followed by three-second\nyellow time and two-second all red time to prepare the tran-\nsition.\n\nTable 3: Average arrival rate of the two datasets\n\nDataset Arrival rate(vehicles/s)\nDJiNan1\n\n1.75\nDJiNan2\n\n1.21\nDJiNan3\n\n1.53\nDHangZhou1 0.83\nDHangZhou2 1.94\n\nDatasets We use five real-world datasets3 in the exper-\niment, three from Jinan and two from Hangzhou. These\ndatasets have been wildly used by various methods such as\nMPLight, CoLight, and HiLight.\n\nEach traffic dataset consists of two parts: (1) traffic road-\nnet dataset; (2) traffic flow dataset. The traffic road-net\ndataset describes the traffic network, including lanes, roads,\nand intersections. The traffic flow dataset contains vehicles\ntravel information, which is described as (t, u), where t is\nthe time that each vehicle starts entering the traffic network,\nu is the pre-planned route from its original location to desti-\nnation.\n\n\u2022 Jinan datasets: The road network has 12 intersections\n(3 \u00d7 4). Each intersection is four-way, with two 400-\nmeter road segments (East-West) and two 800-meter\nroad segments (South-North). There are three traffic flow\ndatasets, and they have different average arrival rates (Ta-\nble 3).\n\n\u2022 Hangzhou datasets. The road network has 16 intersec-\ntions (4 \u00d7 4). Each intersection is four-way, with two\n800-meter road segments (East-West) and two 600-meter\nroad segments (South-North). There are two traffic flow\ndatasets, and they also have different average arrival rates\n(Table 3).\n2https://cityflow-project.github.io\n3https://traffic-signal-control.github.io\n\nEvaluation metric Based on existing studies in traffic sig-\nnal control[17], we choose average travel time as the eval-\nuation metric, which is the mostly used metric to evaluate\ncontrol performance in the TSC. The travel time of each ve-\nhicle is the time speed between entering and leaving the traf-\nfic network. We use all the vehicles\u2019 average travel time to\nevaluate the model performance.\n\nCompared methods We compare our methods with the\nfollowing baseline methods, including both transportation\nand RL methods. For a fair comparison, the phase num-\nber is set as four, and the action interval (phase duration) is\nset as 15 seconds. All the RL methods are learned with the\nsame hyper-parameters. Each episode is a 60-minutes sim-\nulation, and we adopt one result as the average of the last\nten episodes of testing. Each reported result is the average\nof three independent results.\n\nTransportation Methods:\n\u2022 Fixed-Time[5]: a policy uses fixed cycle length with pre-\n\ndefined phase split among all the phases.\n\u2022 Max-Pressure[14]: the max-pressure control selects the\n\nphase with maximum pressure.\nRL Methods:\n\n\u2022 PressLight[16]: incorporates pressure in the state and\nreward design for the RL model and has shown supe-\nrior performance in multi-intersection control problems.\nPressLight is trained with parameter sharing for fairly\ncomparison.\n\n\u2022 FRAP[22]: uses a novel network structure to cap-\nture phase competition relation between different traffic\nmovements. FRAP is trained with parameter sharing like\nMPLight for fair comparison.\n\n\u2022 MPLight[1]: a FRAP[22] based decentralized model, in-\ncorporates pressure in the state and reward design and has\nshown superior performance in city-level TSC. It is one\nstate-of-the-art RL-based TSC method.\n\n\u2022 CoLight[17]: another state-of-the-art method uses a\ngraph attention network to realize intersection coopera-\ntion and has shown superior performance in large-scale\nTSC.\n\nOur Proposed Methods:\n\u2022 MaxQueue: the MaxQueue control selects the phase\n\nwith maximum queue length.\n\u2022 QL-DQN: adopts a two-layer network as the base model,\n\nuses queue length and current phase as state, intersection\nqueue length as a reward.\n\n\u2022 QL-FRAP: a FRAP-based model, uses queue length and\ncurrent phase as state, intersection queue length as a re-\nward.\n\n\u2022 QL-CoLight: a CoLight based model, uses queue length\nand current phase as state, intersection queue length as a\nreward.\n\n5.2 Overall Performance\nTable 2 reports our experimental results under JiNan and\nHangZhou real-world datasets with respect to the average\ntravel time. We have the following findings:\n\n\n\nTable 2: Overall performance. For average travel time, the smaller the better.\n\nMethod JiNan HangZhou\n1 2 3 1 2\n\nFixedTime 428.11(+56.29%) 368.77(+50.29%) 383.01(+55.82%) 495.57(+71.75%) 406.65(+16.53%)\nMaxPressure 273.96 245.38 245.81 288.54 348.98\nPressLight 314.63(+14.85%) 264.62(+7.84%) 258.12(+5.01%) 385.71(+33.68%) 458.12(+31.27%)\nFRAP 296.46(+8.21%) 266.93(+8.78%) 269.64(+9.69%) 309.60(+7.30%) 356.47(+2.15%)\nMPLight 297.46(+8.58%) 270.05(+10.05%) 276.15(+12.34%) 314.60(+9.03%) 357.61(+2.47%)\nCoLight 272.06(\u22120.69%) 252.44(+2.88%) 249.56(+1.53%) 297.02(+2.94%) 347.27(\u22120.49%)\nMaxQueue 268.21(\u22122.10%) 238.91(\u22122.64%) 237.8(\u22123.26%) 283.12(\u22121.88%) 324.38(\u22127.05%)\nQL-DQN 260.74(\u22124.83%) 245.32(0.02%) 239.33(\u22122.64%) 284.74(\u22121.32%) 333.44(\u22124.45%)\nQL-FRAP 255.53(\u22126.73%) 238.74(\u22122.71%) 236.04(\u22123.97%) 282.28(\u22122.17%) 315.03(\u22129.73%)\nQL-CoLight 254.94(\u22126.94%) 239.05(\u22122.58%) 236.25(\u22123.89%) 282.17(\u22122.21%) 322.75(\u22127.52%)\n\n(1) Our proposed MaxQueue consistently outperforms all\nother previous methods. MaxQueue has a significant im-\nprovement as a conventional transportation method com-\npared to MaxPressure. In addition, MaxQueue has superior\nperformance than MPLight and CoLight. The conventional\ntransportation methods are still powerful.\n\n(2) Our proposed QL-DQN, QL-FRAP, and QL-CoLight\noutperform all other previous methods. With only changing\nthe state and reward compared to MPLight and CoLight, the\nimprovement of QL-FRAP and QL-CoLight is significant,\nproving the importance of state representation for RL-based\nTSC.\n\n(3) QL-FRAP and QL-CoLight are state-of-the-art among\ntraditional and RL-based TSC methods. CoLight and MP-\nLight are the previous state-of-the-art methods, and QL-\nFRAP and QL-CoLight have a better performance. Besides,\nQL-XLight only uses queue length information of a particu-\nlar intersection, which has the advantage of deployment than\nCoLight and MPLight.\n\n(4) Parameter sharing is essential for RL-based models.\nMPLight[1] has shown better performance than FRAP and\naddresses the importance of parameter sharing. However,\nwhen FRAP is trained with parameter sharing same to MP-\nLight, it has slightly better performance than MPLight.\n\n5.3 State representation is also essential\n\nBoth the neural network structure and the state representa-\ntion play an important role in the performance improvement.\nHowever, most studies pay attention to the network design.\nWe will demonstrate that the state representation is also es-\nsential.\n\nQL-DQN uses a simple neural network structure, but\neffective state representation. FRAP and CoLight use ad-\nvanced neural network structure, but the state representation\nis not effective. In addition, FRAP, CoLight, and QL-DQN\nuse the same reward. Compare the performance of QL-DQN\nwith FRAP and CoLight, QL-DQN is consistently better\nover all the datasets.\n\nTherefore, we can conclude that state representation is\nalso essential as neural network structure for TSC. The state\nrepresentation should be paid more attention in TSC.\n\nFigure 2: Model performance under different phase duration.\n\n5.4 Performance under different phase duration\nExperiments are also conducted under different phase du-\nration for further model comparison. Figure 2 reports the\nmodel performance under different phase duration. QL-\nDQN, QL-FRAP, and QL-CoLight consistently perform bet-\nter than CoLight and MPLight over all the datasets and\nphase duration. MaxQueue performs better than MPLight\nand CoLight in most cases, except at JiNan1 and JiNan3\n\nwhen tduration = 10s. MaxQueue also perform better than\nQL-DQN in most cases. The performance of MaxQueue ad-\ndresses that the transportation method is still powerful and\nessential.\n\n5.5 Reward comparison\nPressLight and MPLight have demonstrated that RL ap-\nproaches perform better under pressure than queue length.\nWe will re-test the impact of reward settings with queue\nlength as the state representation. The FRAP and CoLight\nare used as the base model; experiments are conducted un-\nder the following configurations:\n\n\u2022 Config1: queue length and current phase are used as the\nstate, intersection queue length as the reward. This is ex-\nactly QL-XLight.\n\n\u2022 Config2: queue length and current phase are used as the\nstate, intersection pressure as the reward.\n\nExperiments are conducted over all the datasets, and Fig-\nure 3 reports the model performance with a different reward.\n\n\n\nFigure 3: Model performance under different reward w.r.t\naverage travel time, the smaller the better.\n\nQL-FRAP performs better under queue length than pressure.\nThe performance difference is not promising. QL-CoLight\nhas significantly better performance under queue length than\npressure. The CoLight based model has poor performance\nunder pressure, maybe the property of GAT that already con-\nsiders the neighbor influence and optimizes the global queue\nlength in the network.\n\nConsidering the calculation of state and reward, the queue\nlength is easier to get because pressure requires complex\ncalculation and neighbor information. Queue length can di-\nrectly get from the traffic environment. In summary, using\nthe queue length as state and reward is a better choice.\n\n6 Conclusion\nIn this paper, we propose an effective state representation\nas queue length. Based on queue length, we developed a\ntransportation method: MaxQueue and an RL template: QL-\nXLight. Our proposed methods have demonstrated supe-\nrior performance than the previous state-of-the-art method,\nand QL-CoLight achieves state-of-the-art performance. The\nimportance of transportation methods is also addressed by\nMaxQueue. The comparison of QL-DQN with FRAP and\nCoLight demonstrates that state representation is as essen-\ntial as a neural network structure. In a word, we should pay\nmore attention to the state design apart from the neural net-\nwork design.\n\nHowever, only queue length as the state representation is\nnot enough for the complex traffic conditions, and more in-\nformation about the traffic conditions should be added to\nthe state representation. In future research, we will try to\nadd more information about the traffic conditions to the RL\nagent observations. In addition, a more complex reward and\nnovel network structure are also taken into consideration to\nimprove the performance of TSC.\n\n7 Acknowledgments\nReferences\n\n[1] Chen, C.; Wei, H.; Xu, N.; Zheng, G.; Yang, M.;\nXiong, Y.; Xu, K.; and Li, Z. 2020. Toward a thousand\nlights: Decentralized deep reinforcement learning for\nlarge-scale traffic signal control. In Proceedings of the\n\nAAAI Conference on Artificial Intelligence, volume 34,\n3414\u20133421.\n\n[2] Cools, S.-B.; Gershenson, C.; and D\u2019Hooghe, B. 2013.\nSelf-organizing traffic lights: A realistic simulation. In\nAdvances in applied self-organizing systems, 45\u201355.\nSpringer.\n\n[3] Gershenson, C. 2004. Self-organizing traffic lights.\narXiv preprint nlin/0411066.\n\n[4] Hunt, P.; Robertson, D.; Bretherton, R.; and Royle,\nM. C. 1982. The SCOOT on-line traffic signal op-\ntimisation technique. Traffic Engineering & Control,\n23(4).\n\n[5] Koonce, P.; and Rodegerdts, L. 2008. Traffic signal\ntiming manual. Technical report, United States. Fed-\neral Highway Administration.\n\n[6] Le, T.; Kova\u0301cs, P.; Walton, N.; Vu, H. L.; Andrew,\nL. L.; and Hoogendoorn, S. S. 2015. Decentralized\nsignal control for urban road networks. Transportation\nResearch Part C: Emerging Technologies, 58: 431\u2013\n450.\n\n[7] Lowrie, P. 1992. SCATS: A traffic responsive method\nof controlling urban traffic control. Roads and Traffic\nAuthority.\n\n[8] Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.;\nVeness, J.; Bellemare, M. G.; Graves, A.; Ried-\nmiller, M.; Fidjeland, A. K.; Ostrovski, G.; et al.\n2015. Human-level control through deep reinforce-\nment learning. nature, 518(7540): 529\u2013533.\n\n[9] Nishi, T.; Otaki, K.; Hayakawa, K.; and Yoshimura,\nT. 2018. Traffic signal control based on reinforce-\nment learning with graph convolutional neural nets.\nIn 2018 21st International conference on intelligent\ntransportation systems (ITSC), 877\u2013883. IEEE.\n\n[10] Sun, X.; and Yin, Y. 2018. A simulation study on max\npressure control of signalized intersections. Trans-\nportation research record, 2672(18): 117\u2013127.\n\n[11] Tan, T.; Bao, F.; Deng, Y.; Jin, A.; Dai, Q.; and Wang,\nJ. 2019. Cooperative deep reinforcement learning for\nlarge-scale traffic grid signal control. IEEE transac-\ntions on cybernetics, 50(6): 2687\u20132700.\n\n[12] To\u0308ro\u0308k, J.; and Kerte\u0301sz, J. 1996. The green wave\nmodel of two-dimensional traffic: Transitions in the\nflow properties and in the geometry of the traffic jam.\nPhysica A: Statistical Mechanics and its Applications,\n231(4): 515\u2013533.\n\n[13] Van der Pol, E.; and Oliehoek, F. A. 2016. Coordi-\nnated deep reinforcement learners for traffic light con-\ntrol. Proceedings of Learning, Inference and Control\nof Multi-Agent Systems (at NIPS 2016).\n\n[14] Varaiya, P. 2013. Max pressure control of a network of\nsignalized intersections. Transportation Research Part\nC: Emerging Technologies, 36: 177\u2013195.\n\n[15] Velic\u030ckovic\u0301, P.; Cucurull, G.; Casanova, A.; Romero,\nA.; Lio, P.; and Bengio, Y. 2017. Graph attention net-\nworks. arXiv preprint arXiv:1710.10903.\n\n\n\n[16] Wei, H.; Chen, C.; Zheng, G.; Wu, K.; Gayah, V.; Xu,\nK.; and Li, Z. 2019. Presslight: Learning max pres-\nsure control to coordinate traffic signals in arterial net-\nwork. In Proceedings of the 25th ACM SIGKDD Inter-\nnational Conference on Knowledge Discovery & Data\nMining, 1290\u20131298.\n\n[17] Wei, H.; Xu, N.; Zhang, H.; Zheng, G.; Zang, X.; Chen,\nC.; Zhang, W.; Zhu, Y.; Xu, K.; and Li, Z. 2019. Co-\nlight: Learning network-level cooperation for traffic\nsignal control. In Proceedings of the 28th ACM In-\nternational Conference on Information and Knowledge\nManagement, 1913\u20131922.\n\n[18] Wei, H.; Zheng, G.; Yao, H.; and Li, Z. 2018. In-\ntellilight: A reinforcement learning approach for intel-\nligent traffic light control. In Proceedings of the 24th\nACM SIGKDD International Conference on Knowl-\nedge Discovery & Data Mining, 2496\u20132505.\n\n[19] Xu, B.; Wang, Y.; Wang, Z.; Jia, H.; and Lu, Z. 2021.\nHierarchically and Cooperatively Learning Traffic Sig-\nnal Control. In Proceedings of the AAAI Conference on\nArtificial Intelligence, volume 35, 669\u2013677.\n\n[20] Zang, X.; Yao, H.; Zheng, G.; Xu, N.; Xu, K.; and Li,\nZ. 2020. Metalight: Value-based meta-reinforcement\nlearning for traffic signal control. In Proceedings of the\nAAAI Conference on Artificial Intelligence, volume 34,\n1153\u20131160.\n\n[21] Zhang, H.; Feng, S.; Liu, C.; Ding, Y.; Zhu, Y.; Zhou,\nZ.; Zhang, W.; Yu, Y.; Jin, H.; and Li, Z. 2019.\nCityflow: A multi-agent reinforcement learning envi-\nronment for large scale city traffic scenario. In The\nWorld Wide Web Conference, 3620\u20133624.\n\n[22] Zheng, G.; Xiong, Y.; Zang, X.; Feng, J.; Wei, H.;\nZhang, H.; Li, Y.; Xu, K.; and Li, Z. 2019. Learning\nphase competition for traffic signal control. In Pro-\nceedings of the 28th ACM International Conference on\nInformation and Knowledge Management, 1963\u20131972.\n\n[23] Zheng, G.; Zang, X.; Xu, N.; Wei, H.; Yu, Z.; Gayah,\nV.; Xu, K.; and Li, Z. 2019. Diagnosing reinforce-\nment learning for traffic signal control. arXiv preprint\narXiv:1905.04716.\n\n\n\t1 Introduction\n\t2 Related work\n\t2.1 Conventional transportation methods\n\t2.2 RL based methods\n\t2.3 State design\n\n\t3 Preliminary\n\t4 Method\n\t4.1 Queue length as the state\n\t4.2 MaxQueue control\n\t4.3 QL-XLight\n\n\t5 Experiment\n\t5.1 Settings\n\t5.2  Overall Performance \n\t5.3 State representation is also essential\n\t5.4 Performance under different phase duration\n\t5.5 Reward comparison\n\n\t6 Conclusion\n\t7 Acknowledgments\n\n"}
{"Title": "Confidence-Aware Multi-Teacher Knowledge Distillation", "Authors": "Hailin Zhang, Defang Chen, Can Wang", "Abstract": "  Knowledge distillation is initially introduced to utilize additional supervision from a single teacher model for the student model training. To boost the student performance, some recent variants attempt to exploit diverse knowledge sources from multiple teachers. However, existing studies mainly integrate knowledge from diverse sources by averaging over multiple teacher predictions or combining them using other various label-free strategies, which may mislead student in the presence of low-quality teacher predictions. To tackle this problem, we propose Confidence-Aware Multi-teacher Knowledge Distillation (CA-MKD), which adaptively assigns sample-wise reliability for each teacher prediction with the help of ground-truth labels, with those teacher predictions close to one-hot labels assigned large weights. Besides, CA-MKD incorporates intermediate layers to further improve student performance. Extensive experiments show that our CA-MKD consistently outperforms all compared state-of-the-art methods across various teacher-student architectures.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00007", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCONFIDENCE-AWARE MULTI-TEACHER KNOWLEDGE DISTILLATION\n\nHailin Zhang Defang Chen Can Wang?\n\nZhejiang University, China.\n{zzzhl, defchern, wcan}@zju.edu.cn\n\nABSTRACT\n\nKnowledge distillation is initially introduced to utilize addi-\ntional supervision from a single teacher model for the student\nmodel training. To boost the student performance, some re-\ncent variants attempt to exploit diverse knowledge sources\nfrom multiple teachers. However, existing studies mainly in-\ntegrate knowledge from diverse sources by averaging over\nmultiple teacher predictions or combining them using other\nvarious label-free strategies, which may mislead student in\nthe presence of low-quality teacher predictions. To tackle\nthis problem, we propose Confidence-Aware Multi-teacher\nKnowledge Distillation (CA-MKD), which adaptively assigns\nsample-wise reliability for each teacher prediction with the\nhelp of ground-truth labels, with those teacher predictions\nclose to one-hot labels assigned large weights. Besides, CA-\nMKD incorporates intermediate layers to further improve\nstudent performance. Extensive experiments show that our\nCA-MKD consistently outperforms all compared state-of-the-\nart methods across various teacher-student architectures.\n\nIndex Terms\u2014 knowledge distillation, multiple teachers,\nconfidence-aware weighting\n\n1. INTRODUCTION\n\nNowadays, deep neural networks have achieved unprece-\ndented success in various applications [1, 2, 3]. However,\nthese complex models requiring huge memory footprint and\ncomputational resources are difficult to be applied on embed-\nded devices. Knowledge distillation (KD) is thus proposed as\na model compression technique to resolve this issue, which\nimproves the accuracy of a lightweight student model by dis-\ntilling the knowledge from a pre-trained cumbersome teacher\nmodel [4]. The transferred knowledge was originally formal-\nized as softmax outputs (soft targets) of the teacher model\n[4] and latter extended to the intermediate teacher layers for\nachieving more promising performance [5, 6, 7].\n\nAs the wisdom of the masses exceeds that of the wisest in-\ndividual, some multi-teacher knowledge distillation (MKD)\n\n?Corresponding author\nThis work is supported by National Key R&D Program of China (Grant\n\nNo: 2019YFB1600700) and National Natural Science Foundation of China\n(Grant No: U1866602).\n\nFig. 1. Comparison of the previous average direction (green\nline) and our proposed confidence-aware direction (red line).\n\nmethods are proposed and have been proven to be benefi-\ncial [8, 9, 10, 11, 12]. Basically, they combine predictions\nfrom multiple teachers with the fixed weight assignment [8,\n9, 10] or other various label-free schemes, such as calculat-\ning weights based on a optimization problem or entropy crite-\nrion [11, 12], etc. However, fixed weights fail to differentiate\nhigh-quality teachers from low-quality ones [8, 9, 10], and\nthe other schemes may mislead the student in the presence of\nlow-quality teacher predictions [11, 12]. Figure 1 provides an\nintuitive illustration on this issue, where the student trained\nwith the average weighting strategy might deviate from the\ncorrect direction once most teacher predictions are biased.\n\nFortunately, we actually have ground-truth labels in hand\nto quantify our confidence about teacher predictions and then\nfilter out low-quality predictions for better student training.\nTo this end, we propose Confidence-Aware Multi-teacher\nKnowledge Distillation (CA-MKD) to learn sample-wise\nweights by taking the prediction confidence of teachers into\nconsideration for adaptive knowledge integration. The con-\nfidence is obtained based on the cross entropy loss between\nprediction distributions and ground-truth labels. Compared\nwith previous label-free weighting strategies, our technique\nenables the student to learn from a relatively correct direction.\n\nNote that our confidence-aware mechanism not only is\nable to adaptively weight different teacher predictions based\non their sample-wise confidence, but also can be extended to\nthe student-teacher feature pairs in intermediate layers. With\nthe help of our generated flexible and effective weights, we\ncould avoid those poor teacher predictions dominating the\nknowledge transfer process and considerably improve the stu-\ndent performance on eight teacher-student architecture com-\nbinations (as shown in Table 1 and 3).\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n7v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\n\n\n2. RELATED WORK\n\nKnowledge Distillation. Vanilla KD aims to transfer knowl-\nedge from a complex network (teacher) to a simple network\n(student) with the KL divergence minimization between their\nsoftened outputs [13, 4]. Mimicking the teacher representa-\ntions from intermediate layers was latter proposed to explore\nmore knowledge forms [5, 6, 14, 15, 7]. Compared to these\nmethods that require pre-training a teacher, some works si-\nmultaneously train multiple students and encourage them to\nlearn from each other instead [16, 17]. Our technique dif-\nfers from these online KD methods since we attempt to distill\nknowledge from multiple pre-trained teachers.\nMulti-teacher Knowledge Distillation. Rather than employ-\ning a single teacher, MKD boosts the effectiveness of distil-\nlation by integrating predictions from multiple teachers. A\nbunch of methods are proposed, such as simply assigning av-\nerage or other fixed weights for different teachers [8, 9, 10],\nand calculating the weights based on entropy [12], latent fac-\ntor [18] or multi-objective optimization in the gradient space\n[11]. However, these label-free strategies may mislead the\nstudent training in the presence of low-quality predictions.\nFor instance, entropy-based strategy will prefer models with\nblind faith since it favors predictions with low variance [12];\noptimization-based strategy favors majority opinion and will\nbe easily misled by noisy data [11]. In contrast, our CA-MKD\nquantifies the teacher predictions based on ground-truth labels\nand further improves the student performance.\n\n3. METHODOLOGY\n\nWe denote D = {xi,yi}Ni as a labeled training set, N is\nthe number of samples, K is the number of teachers. F \u2208\nRh\u00d7w\u00d7c is the output of the last network block. We denote\nz = [z1, ..., zC ] as the logits output, where C is the category\nnumber. The final model prediction is obtained by a softmax\nfunction \u03c3 (zc) = exp(zc/\u03c4)\u2211\n\nj exp(zj/\u03c4) with temperature \u03c4 . In the\nfollowing sections, we will introduce our CA-MKD in detail.\n\n3.1. The Loss of Teacher Predictions\n\nTo effectively aggregate the prediction distributions of multi-\nple teachers, we assign different weights which reflects their\nsample-wise confidence by calculating the cross entropy loss\nbetween teacher predictions and ground-truth labels\n\nLkCEKD\n= \u2212\n\nC\u2211\nc=1\n\nyc log\n(\n\u03c3\n(\nzcTk\n\n))\n, (1)\n\nwkKD =\n1\n\nK \u2212 1\n\n\uf8eb\uf8ed1\u2212\nexp\n\n(\nLkCEKD\n\n)\u2211\nj exp\n\n(\nLjCEKD\n\n)\n\uf8f6\uf8f8 , (2)\n\nwhere Tk denotes the kth teacher. The less LkCEKD\ncorre-\n\nsponds to the larger wkKD. The overall teacher predictions are\n\nFig. 2. An overview of our CA-MKD. The weight calculation\nof teacher predictions and intermediate teacher features are\ndepicted as the red lines and green lines, respectively.\n\nthen aggregated with calculated weights\n\nLKD = \u2212\nK\u2211\nk=1\n\nwkKD\n\nC\u2211\nc=1\n\nzcTk\nlog (\u03c3 (zcS)) . (3)\n\nAccording to the above formulas, the teacher whose pre-\ndiction is closer to ground-truth labels will be assigned larger\nweight wkKD, since it has enough confidence to make accu-\nrate judgement for correct guidance. In contrast, if we simply\nacquire the weights by calculating the entropy of teacher pre-\ndictions [12], the weight will become large when the output\ndistribution is sharp regardless of whether the highest prob-\nability category is correct. In this case, those biased targets\nmay misguide the student training and further hurt its distilla-\ntion performance.\n\n3.2. The Loss of Intermediate Teacher Features\n\nIn addition to KD Loss, inspired by FitNets [5], we believe\nthat the intermediate layers are also beneficial for learning\nstructural knowledge, and thus extend our method to interme-\ndiate layers for mining more information. The calculation of\nintermediate feature matching is presented as follows\n\nzS\u2192Tk\n=WTk\n\nhS , (4)\n\nLkCEinter\n= \u2212\n\nC\u2211\nc=1\n\nyc log\n(\n\u03c3\n(\nzcS\u2192Tk\n\n))\n, (5)\n\nwkinter =\n1\n\nK \u2212 1\n\n\uf8eb\uf8ed1\u2212\nexp\n\n(\nLkCEinter\n\n)\u2211\nj exp\n\n(\nLjCEinter\n\n)\n\uf8f6\uf8f8 . (6)\n\nwhere WTk\nis the final classifier of the kth teacher. hS \u2208 Rc\n\nis the last student feature vector, i.e, hS = AvgPooling(FS).\nLkCEinter\n\nis obtained by passing hS through each teacher clas-\nsifier. The calculation of wkinter is similar to that of wkKD.\n\n\n\nTable 1. Top-1 test accuracy of MKD methods by distilling the knowledge on multiple teachers with the same architectures.\n\nTeacher WRN40-2 ResNet56 VGG13 VGG13 ResNet32x4 ResNet32x4 ResNet32x4\n76.62\u00b10.26 73.28\u00b10.30 75.17\u00b10.18 75.17\u00b10.18 79.31\u00b10.14 79.31\u00b10.14 79.31\u00b10.14\n\nEnsemble 79.62 76.00 77.07 77.07 81.16 81.16 81.16\n\nStudent ShuffleNetV1 MobileNetV2 VGG8 MobileNetV2 ResNet8x4 ShuffleNetV2 VGG8\n71.70\u00b10.43 65.64\u00b10.19 70.74\u00b10.40 65.64\u00b10.19 72.79\u00b10.14 72.94\u00b10.24 70.74\u00b10.40\n\nAVER [8] 76.30\u00b10.25 70.21\u00b10.10 74.07\u00b10.23 68.91\u00b10.35 74.99\u00b10.24 75.87\u00b10.19 73.26\u00b10.39\nFitNet-MKD [5] 76.59\u00b10.17 70.69\u00b10.56 73.97\u00b10.22 68.48\u00b10.07 74.86\u00b10.21 76.09\u00b10.13 73.27\u00b10.19\n\nEBKD [12] 76.61\u00b10.14 70.91\u00b10.22 74.10\u00b10.27 68.24\u00b10.82 75.59\u00b10.15 76.41\u00b10.12 73.60\u00b10.22\nAEKD [11] 76.34\u00b10.24 70.47\u00b10.15 73.78\u00b10.03 68.39\u00b10.50 74.75\u00b10.28 75.95\u00b10.20 73.11\u00b10.27\nCA-MKD 77.94\u00b10.31 71.38\u00b10.02 74.30\u00b10.16 69.41\u00b10.20 75.90\u00b10.13 77.41\u00b10.14 75.26\u00b10.32\n\nTable 2. Top-1 test accuracy of CA-MKD compared to\nsingle-teacher knowledge distillation methods.\n\nTeacher WRN40-2 ResNet32x4 ResNet56\n76.62\u00b10.26 79.31\u00b10.14 73.28\u00b10.30\n\nStudent ShuffleNetV1 VGG8 MobileNetV2\n71.70\u00b10.19 70.74\u00b10.40 65.64\u00b10.43\n\nKD [4] 75.77\u00b10.14 72.90\u00b10.34 69.96\u00b10.14\nFitNet [5] 76.22\u00b10.21 72.55\u00b10.66 69.02\u00b10.28\n\nAT [6] 76.44\u00b10.38 72.16\u00b10.12 69.79\u00b10.26\nVID [14] 76.32\u00b10.08 73.09\u00b10.29 69.45\u00b10.17\nCRD [15] 76.58\u00b10.23 73.57\u00b10.25 71.15\u00b10.44\n\nCA-MKD 77.94\u00b10.31 75.26\u00b10.13 71.38\u00b10.02\n\nWe utilize wkinter instead of wkKD for the knowledge ag-\ngregation in intermediate layers, which achieves better results\nas shown in our ablation study. Perhaps this is due to the ex-\nistence of the last classifier will affect the whole knowledge\ntransfer process and should be taken into account.\n\nLinter =\nK\u2211\nk=1\n\nwkinter||FTk\n\u2212 r (FS) ||22, (7)\n\nwhere r(\u00b7) is a function for aligning the student and teacher\nfeature dimensions. The `2 loss function is used as distance\nmeasure of intermediate features. Finally, the overall training\nloss between feature pairs will be aggregated by wkinter.\n\nIn our work, only the output features of the last block are\nadopted to avoid incurring too much computational cost.\n\n3.3. The Overall Loss Function\n\nIn addition to the aforementioned two losses, a regular cross\nentropy with the ground-truth labels is calculated\n\nLCE = \u2212\nC\u2211\nc=1\n\nyc log (\u03c3(zcS)) . (8)\n\nThe overall loss function of our CA-MKD is summarize as\n\nL = LCE + \u03b1LKD + \u03b2Linter, (9)\n\nwhere \u03b1 and \u03b2 are hyper-parameters to balance the effect of\nknowledge distillation and standard cross entropy losses.\n\n4. EXPERIMENT\n\nIn this section, we conduct extensive experiments on CIFAR-\n100 dataset [19] to verify the effectiveness of our proposed\nCA-MKD. We adopt eight different teacher-student combi-\nnations based on popular neural network architectures. All\ncompared multi-teacher knowledge distillation (MKD) meth-\nods use three teachers except for special declarations.\n\nCompared Methods. Besides the na\u0131\u0308ve AVER [8], we\nreimplement a single-teacher based method FitNet [5] on\nmultiple teachers and denote it as FitNet-MKD. FitNet-MKD\nwill leverage extra information coming from averaged inter-\nmediate teacher features. We also reimplement an entropy-\nbased MKD method [12], which has achieved remarkable\nresults in acoustic experiments, on our image classification\ntask and we denote it as EBKD. As for AEKD, we adopt its\nlogits-based version with the author provided code [11].\n\nHyper-parameters. All neural networks are optimized\nby stochastic gradient descent with momentum 0.9, weight\ndecay 0.0001. The batch size is set to 64. As the previous\nworks do [15, 7], the initial learning rate is set to 0.1, ex-\ncept MobileNetV2, ShuffleNetV1 and ShuffleNetV2 are set\nto 0.05. The learning rate is multiplied by 0.1 at 150, 180 and\n210 of the total 240 training epochs. For the sake of fairness,\nthe temperature \u03c4 is set to 4 and the \u03b1 is set to 1 in all methods.\nFurthermore, we set the \u03b2 of our CA-MKD to 50 throughout\nthe experiments. All results are reported in means and stan-\ndard deviations over 3 runs with different random seeds.\n\n4.1. Results on the Same Teacher Architectures\n\nTable 1 shows the top-1 accuracy comparison on CIFAR-100.\nWe also include the results of teacher ensemble with the ma-\njority voting strategy. We can find that CA-MKD surpasses\nall competitors cross various architectures. Specifically, com-\npared to the second best method (EBKD), CA-MKD out-\n\n\n\nTable 3. Top-1 test accuracy of MKD approaches by distilling the knowledge on multiple teachers with different architectures.\nVGG8 AVER FitNet-MKD EBKD AEKD CA-MKD ResNet8x4 ResNet20x4 ResNet32x4\n\n70.74\u00b10.40 74.55\u00b10.24 74.47\u00b10.21 74.07\u00b10.17 74.69\u00b10.29 75.96\u00b10.05 72.79 78.39 79.31\n\nFig. 3. The visualization results of learned weights by CA-\nMKD on each training sample.\n\nperforms it with 0.81% average improvement1, and achieves\n1.66% absolute accuracy improvement in the best case.\n\nTo verify the benefits of diverse information brought by\nmultiple teachers, we compare CA-MKD with some excellent\nsingle-teacher based methods. The results in Table 2 show the\nstudent indeed has the potential to learn knowledge from mul-\ntiple teachers, and its accuracy is further improved compared\nwith the single-teacher methods to a certain extent.\n\n4.2. Results on the Different Teacher Architectures\n\nTable 3 shows the results of training a student (VGG8)\nwith three different teacher architectures, i.e., ResNet8x4,\nResNet20x4 and ResNet32x4. We find the student accu-\nracy becomes even higher than that of training with three\nResNet32x4 teachers, which may be attributed to that the\nknowledge diversity is enlarged in different architectures.\n\nSince the performance of ResNet20x4/ResNet32x4 is bet-\nter than that of ResNet8x4, we could reasonably believe that\nfor most training samples, the student will put larger weights\non predictions from the former two rather than the latter one,\nwhich is verified in Figure 3. Moreover, our CA-MKD can\ncapture those samples on which the predictions are more con-\nfident by ResNet8x4, and assign them dynamic weights to\nhelp the student model achieve better performance.\n\n4.3. Impact of the Teacher Number\n\nAs shown in Figure 4, the student model trained with CA-\nMKD generally achieves satisfactory results. For example,\non the \u201cResNet56 & MobileNetV2\u201d setting, the accuracy of\n\n1Average Improvement= 1\nn\n\n\u2211n\ni\n\n(\nAcciCA\u2212MKD \u2212AcciEBKD\n\n)\n, where\n\nthe accuracies of CA-MKD, EBKD in the i-th teacher-student combination\nare denoted as AcciCA\u2212MKD, AcciEBKD, respectively.\n\nFig. 4. The effect of different teacher numbers.\n\nTable 4. Ablation study with VGG13 & MobileNetV2.\n\navg weight w/o Linter w/o wkinter CA-MKD\n\n67.74\u00b10.87 68.11\u00b10.02 68.82\u00b10.63 69.41\u00b10.20\n\nCA-MKD increases continually as the number of teachers in-\ncreases and it surpasses the competitors with three teachers\neven those competitors are trained with more teachers.\n\n4.4. Ablation Study\n\nWe summarize the observations from Table 4 as follows:\n(1) avg weight. Simply averaging multiple teachers will\n\ncause 1.67% accuracy drop, which confirms the necessity of\ntreating different teachers based on their specific quality.\n\n(2) w/o Linter. The accuracy will appear considerably\nreduction as we remove the Equation (7), demonstrating the\nintermediate layer contains useful information for distillation.\n\n(3) w/o wkinter. we directly use the wkKD obtained from\nthe last layer to integrate intermediate features. The lower\nresult indicates the benefits of designing a separate way of\ncalculating weights for the intermediate layer.\n\n5. CONCLUSION\n\nIn this paper, we introduce confidence-aware mechanism on\nboth predictions and intermediate features for multi-teacher\nknowledge distillation. The confidence of teachers is calcu-\nlated based on the closeness between their predictions or fea-\ntures and the ground-truth labels for the reliability identifica-\ntion on each training sample. With the guidance of labels,\nour technique effectively integrates diverse knowledge from\nmultiple teachers for the student training. Extensive empiri-\ncal results show that our method outperforms all competitors\nin various teacher-student architectures.\n\n\n\n6. REFERENCES\n\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun, \u201cDeep residual learning for image recognition,\u201d in\nProceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770\u2013778.\n\n[2] David Silver, Julian Schrittwieser, Karen Simonyan,\nIoannis Antonoglou, Aja Huang, Arthur Guez, Thomas\nHubert, Lucas Baker, Matthew Lai, Adrian Bolton,\net al., \u201cMastering the game of go without human knowl-\nedge,\u201d Nature, vol. 550, no. 7676, pp. 354\u2013359, 2017.\n\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova, \u201cBERT: pre-training of deep bidi-\nrectional transformers for language understanding,\u201d in\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies,\n2019, pp. 4171\u20134186.\n\n[4] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean, \u201cDistill-\ning the knowledge in a neural network,\u201d arXiv preprint\narXiv:1503.02531, 2015.\n\n[5] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Ka-\nhou, Antoine Chassang, Carlo Gatta, and Yoshua Ben-\ngio, \u201cFitnets: Hints for thin deep nets,\u201d in International\nConference on Learning Representations, 2015.\n\n[6] Sergey Zagoruyko and Nikos Komodakis, \u201cPaying more\nattention to attention: improving the performance of\nconvolutional neural networks via attention transfer,\u201d in\nInternational Conference on Learning Representations,\n2017.\n\n[7] Defang Chen, Jian-Ping Mei, Yuan Zhang, Can Wang,\nZhe Wang, Yan Feng, and Chun Chen, \u201cCross-layer\ndistillation with semantic calibration,\u201d in Proceedings\nof the AAAI Conference on Artificial Intelligence, 2021,\nvol. 35, pp. 7028\u20137036.\n\n[8] Shan You, Chang Xu, Chao Xu, and Dacheng Tao,\n\u201cLearning from multiple teacher networks,\u201d in Proceed-\nings of the 23rd ACM SIGKDD International Confer-\nence on Knowledge Discovery and Data Mining, 2017,\npp. 1285\u20131294.\n\n[9] Takashi Fukuda, Masayuki Suzuki, Gakuto Kurata,\nSamuel Thomas, Jia Cui, and Bhuvana Ramabhadran,\n\u201cEfficient knowledge distillation from an ensemble of\nteachers.,\u201d in Interspeech, 2017, pp. 3697\u20133701.\n\n[10] Meng-Chieh Wu, Ching-Te Chiu, and Kun-Hsuan Wu,\n\u201cMulti-teacher knowledge distillation for compressed\nvideo action recognition on deep neural networks,\u201d in\nICASSP 2019-2019 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2019, pp. 2202\u20132206.\n\n[11] Shangchen Du, Shan You, Xiaojie Li, Jianlong Wu, Fei\nWang, Chen Qian, and Changshui Zhang, \u201cAgree to\ndisagree: Adaptive ensemble knowledge distillation in\ngradient space,\u201d Advances in Neural Information Pro-\ncessing Systems, vol. 33, 2020.\n\n[12] Kisoo Kwon, Hwidong Na, Hoshik Lee, and Nam Soo\nKim, \u201cAdaptive knowledge distillation based on en-\ntropy,\u201d in ICASSP 2020-2020 IEEE International Con-\nference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, 2020, pp. 7409\u20137413.\n\n[13] Jimmy Ba and Rich Caruana, \u201cDo deep nets really need\nto be deep?,\u201d in Advances in Neural Information Pro-\ncessing Systems, 2014, pp. 2654\u20132662.\n\n[14] Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D\nLawrence, and Zhenwen Dai, \u201cVariational information\ndistillation for knowledge transfer,\u201d in Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition, 2019, pp. 9163\u20139171.\n\n[15] Yonglong Tian, Dilip Krishnan, and Phillip Isola, \u201cCon-\ntrastive representation distillation,\u201d in International\nConference on Learning Representations, 2020.\n\n[16] Xu Lan, Xiatian Zhu, and Shaogang Gong, \u201cKnowl-\nedge distillation by on-the-fly native ensemble,\u201d arXiv\npreprint arXiv:1806.04606, 2018.\n\n[17] Defang Chen, Jian-Ping Mei, Can Wang, Yan Feng, and\nChun Chen, \u201cOnline knowledge distillation with diverse\npeers.,\u201d in Proceedings of the AAAI Conference on Arti-\nficial Intelligence, 2020, pp. 3430\u20133437.\n\n[18] Yuang Liu, Wei Zhang, and Jun Wang, \u201cAdaptive multi-\nteacher multi-level knowledge distillation,\u201d Neurocom-\nputing, vol. 415, pp. 106\u2013113, 2020.\n\n[19] Alex Krizhevsky and Geoffrey Hinton, \u201cLearning mul-\ntiple layers of features from tiny images,\u201d Technical Re-\nport, 2009.\n\n\n\t1  Introduction\n\t2  RELATED WORK\n\t3  METHODOLOGY\n\t3.1  The Loss of Teacher Predictions\n\t3.2  The Loss of Intermediate Teacher Features\n\t3.3  The Overall Loss Function\n\n\t4  EXPERIMENT\n\t4.1  Results on the Same Teacher Architectures\n\t4.2  Results on the Different Teacher Architectures\n\t4.3  Impact of the Teacher Number\n\t4.4  Ablation Study\n\n\t5  CONCLUSION\n\t6  References\n\n"}
{"Title": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting", "Authors": "Guanyao Li, Shuhan Zhong, Letian Xiang, S.-H. Gary Chan, Ruiyuan Li, Chih-Chieh Hung, Wen-Chih Peng", "Abstract": "  We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency between regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t-1, we predict the traffic at time t at any region. Prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner or are rather computationally intensive in training with a large number of hyper-parameters to tune. We propose ST-TIS, a novel, lightweight, and accurate Spatial-Temporal Transformer with information fusion and region sampling for traffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion module captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency and prediction accuracy, cutting the computation complexity for dependency learning from $O(n^2)$ to $O(n\\sqrt{n})$, where n is the number of regions. With far fewer parameters than state-of-the-art models, the offline training of our model is significantly faster in terms of tuning and computation (with a reduction of up to $90\\%$ on training time and network parameters). Notwithstanding such training efficiency, extensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an average improvement of up to $9.5\\%$ on RMSE, and $12.4\\%$ on MAPE).      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00008", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\nA Lightweight and Accurate Spatial-Temporal\nTransformer for Traffic Forecasting\n\nGuanyao Li, Shuhan Zhong, Letian Xiang, S.-H. Gary Chan\nRuiyuan Li, Chih-Chieh Hung, Wen-Chih Peng\n\nAbstract\u2014We study the forecasting problem for traffic with dynamic, possibly periodical, and joint spatial-temporal dependency\nbetween regions. Given the aggregated inflow and outflow traffic of regions in a city from time slots 0 to t\u2212 1, we predict the traffic at\ntime t at any region. Prior arts in the area often consider the spatial and temporal dependencies in a decoupled manner, or are rather\ncomputationally intensive in training with a large number of hyper-parameters to tune.\nWe propose ST-TIS, a novel, lightweight and accurate Spatial-Temporal Transformer with information fusion and region sampling for\ntraffic forecasting. ST-TIS extends the canonical Transformer with information fusion and region sampling. The information fusion\nmodule captures the complex spatial-temporal dependency between regions. The region sampling module is to improve the efficiency\nand prediction accuracy, cutting the computation complexity for dependency learning from O(n2) to O(n\n\n\u221a\nn), where n is the number of\n\nregions. With far fewer parameters than state-of-the-art models, ST-TIS\u2019s offline training is significantly faster in terms of tuning and\ncomputation (with a reduction of up to 90% on training time and network parameters). Notwithstanding such training efficiency,\nextensive experiments show that ST-TIS is substantially more accurate in online prediction than state-of-the-art approaches (with an\naverage improvement of 9.5% on RMSE, and 12.4% on MAPE compared to STDN and DSAN).\n\nIndex Terms\u2014spatial-temporal forecasting; spatial-temporal data mining; efficient Transformer; joint spatial-temporal dependency;\nregion sampling.\n\nF\n\n1 INTRODUCTION\n\nTraffic forecasting is to predict the inflow (i.e., the number\nof arriving objects per unit time) and outflow (i.e., the\nnumber of departing objects per unit time) of any region\nin a city at the next time slot. The objects can be people,\nvehicles, goods/items, etc. Traffic forecasting has important\napplications in transportation, retails, public safety, city\nplanning, etc [1], [2]. For example, with traffic forecasting, a\ntaxi company may dispatch taxis in a timely manner to meet\nthe supply and demand in different regions of a city. Yet\nanother example is bike sharing, where the company may\nwant to balance bike supply and demand at dock stations\n(regions) based on such forecasting.\n\nAlthough there has been much effort on deep learning to\nimprove the prediction accuracy of the state-of-the-art fore-\ncasting models, progressive improvements on benchmarks\nhave been correlated with an increase in the number of\nparameters and the amount of training resources required\nto train the model, making it costly to train and deploy\nlarge deep learning models [3]. Therefore, a lightweight\n\n\u2022 Guanyao Li, Shuhan Zhong, Letian Xiang, andd S.-H. Gary Chan are\nwith the Department of Computer Science and Engineering, The Hong\nKong University of Science and Technology.\nE-mail: {gliaw, szhongaj, lxiangab, gchan}@cse.ust.hk\n\n\u2022 Ruiyuan Li is with College of Computer Science, Chongqing University.\nE-mail: liruiyuan@cqu.edu.cn\n\n\u2022 Chih-Chieh Hung is with Department of Computer Science and Engineer-\ning, National Chung Hsing University.\nE-mail: smalloshin@email.nchu.edu.tw\n\n\u2022 Wen-Chih Peng is with Department of Computer Science, National Yang\nMing Chiao Tung University.\nE-mail: wcpeng@g2.nctu.edu.tw\n\nand training-efficient model is essential for fast delivery and\ndeployment.\n\nIn this work, we study the following spatial-temporal\ntraffic forecasting problem: Given the historical (aggregated)\ninflow and outflow data of different regions from time slots\n0 to t \u2212 1 (with slot size of, say, 30 minutes), what is the\ndesign of a training-efficient model to accurately predict the\ninflow and outflow of any region at time t? (Note that even\nthough we consider predicting for the next time slot, our\nwork can be straightforwardly extended to any future time\nslot by successive application of the algorithm.) We seek\na \u201csmall\u201d training model with substantially fewer parame-\nters, which naturally leads to efficiency in tuning, memory,\nand computation time. Despite its training efficiency, our\nlightweight model lightweight, it should also achieve higher\naccuracy than the state-of-the-art approaches in its online\npredictions.\n\nIntuitively, region traffic is spatially and temporally cor-\nrelated. As an example, the traffic of a region could be\ncorrelated with that of another with some temporal lag\ndue to the travel time between them. Moreover, such de-\npendency may be dynamic over different time slots, and it\nmay have temporal periodic patterns. This is the case for the\ntraffic of office regions, which exhibit high correlation with\nthe residence regions in workday morning but much less\nthan at night or weekend. To accurately predict the region\ntraffic, it is hence significantly crucial to account for the\ndynamic, possibly periodical, and joint spatial-temporal (ST)\ndependency between regions, no matter how far the regions\nis apart.\n\nMuch effort has been devoted to capturing the de-\npendency between regions for traffic forecasting. While\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n8v\n2 \n\n [\ncs\n\n.L\nG\n\n] \n 4\n\n J\nan\n\n 2\n02\n\n2\n\n\n\n2\n\nFig. 1. Visualization of attention scores between a target region (6,4)\nand other regions. The color of a cell (xi, yi) indicates the dependency\nof (6, 4) on (xi, yi), where a darker color indicates stronger dependency.\n\ncommendable, most works consider spatial and temporal\ndependency separately with independent processing mod-\nules [4]\u2013[9], which can hardly capture their joint nature\nin our current setting. Some recent works apply canonical\nTransformer [10] to capture region dependency [11]\u2013[14].\nWhile impressive, canonical Transformer limits the train-\ning efficiency because it learns a region\u2019s embedding as\nthe weighted aggregation of all the other regions based\non their computed attention scores. This results in O(n2)\ncomputation complexity per layer, where n is the number of\nregions. Moreover, it has been observed that the attention\nscores from the canonical Transformer have a long tail\ndistribution [15]. We illustrate this in Figure 1 using a taxi\ndataset collected in New York City. We split New York City\ninto 10\u00d720 regions and visualize the attention scores (after a\nSoftMax operation) between a target region (i.e., the region\n(6, 4)) and other regions. Clearly, most regions have very\nsmall attention scores (i.e., the long-tail phenomenon), with\nthe attention scores of more than 60% of regions being less\nthan 0.004. Such a long-tail effect may introduce noise for\nthe region embedding learning and degrade the prediction\nperformance.\n\nWe propose ST-TIS, a novel, small, efficient and accurate\nSpatial-Temporal Transformer with information fusion and\nregion sampling for traffic forecasting. Given the histor-\nical (aggregated) inflow and outflow of regions from 0\nto t \u2212 1, ST-TIS predicts the inflow and outflow of any\nregion at t, without relying on the transistion data between\nregions. With a small set of parameters, ST-TIS is efficient\nto train (offline phase). It extends the canonical Transformer\nwith novel information fusion and region sampling strate-\ngies to learn the dynamic and possibly periodical spatial-\ntemporal dependency between regions in a joint manner,\nhence achieving high prediction accuracy (online phase).\n\nST-TIS makes the following contributions:\n\n\u2022 A data-driven Transformer scheme for dynamic, possibly\nperiodical, and joint spatial-temporal dependency learn-\ning. ST-TIS jointly considers the spatial-temporal de-\npendencies between regions, rather than considering\nthe two dependencies sequentially in a decoupled\nmanner. In particular, ST-TIS considers the dynamic\nspatial-temporal dependency for any individual time\nslot with an information fusion module, and also the\npossibly periodical characteristic of spatial-temporal\n\ndependency from multiple time slots using an atten-\ntion mechanism. Moreover, the dependency learning\nis data-driven, without any assumption on spatial\nlocality. Due to its design, ST-TIS is small (in parame-\nter footprint), fast (in training time), and accurate (in\nprediction).\n\n\u2022 A novel region sampling strategy for computationally effi-\ncient dependency learning. ST-TIS leverages the Trans-\nformer framework [10] to learn region dependency.\nTo address the quadratic computation issue and\nmitigate the long-tail effect, it employs a novel re-\ngion sampling strategy to generate a connected re-\ngion graph and learns the dependency based on\nthe graph. The dependencies between any pair of\nregions (both close and distant dependencies) are\nguaranteed to be considered in ST-TIS via informa-\ntion propagation, and the computational complexity\nis reduced from O(n2) to O(n\n\n\u221a\nn), where n is the\n\nnumber of regions.\n\u2022 Extensive experimental validation: We evaluate ST-TIS\n\non two large-scale real datasets of taxi and bike\nsharing. Our results shows that ST-TIS is substan-\ntially more accurate than the state-of-the-art ap-\nproaches, with a significant improvement in RMSE\nand MAPE (an average improvement of 9.5% on\nRMSE, and 12.4% on MAPE compared to STDN and\nDSAN). Furthermore, it is much more lightweight\nthan most state-of-the-art models, and is ultra fast for\ntraining (with a reduction of 46% \u223c 95% on training\ntime and 23% \u223c 98% on network parameters).\n\nThe remainder of this paper is organized as follows. We\nfirst discuss related works in Section 2. After preliminaries\nin Section 3, we detail ST-TIS in Section 4. We present the\nexperimental settings and results in Section 5, and conclude\nin Section 6.\n\n2 RELATED WORKS\n\nTraffic forecasting has raised much attention in both\nacademia and industry due to its social and commercial\nvalues. Some early traffic forecasting works propose using\nregression models, such as auto-regressive integrated mov-\ning average (ARIMA) models [16]\u2013[19] and non-parametric\nregion models [20], [21]. All of these works consider tem-\nporal dependency, but they have not considered the spatial\ndependency between regions. Some other works extract fea-\ntures from heterogeneous data sources (e.g., POI, weather,\netc.), and use machine learning models such as Support\nVector Machine [22], Gradient Boosting Regression Tree [23],\nand linear regression model [24]. Despite of the encouraging\nresults, they rely on manually defined features and have not\nconsidered the joint spatial-temporal dependency.\n\nIn recent years, deep learning techniques have been\nemployed to study spatial and temporal correlations for\ntraffic forecasting. Most existing works consider the spa-\ntial and temporal dependency in a decouple manner [4]\u2013\n[9], which can hardly capture their joint effect. For spatial\ndependency, Convolution Neural Network (CNN), Graph\nNeural Network (GNN), and Transformer have been widely\napplied. Regarding temporal dependency, Recurrent Neural\nNetwork (RNN) and its variants such as Long Short Term\n\n\n\n3\n\nMemory (LSTM) and Gated Recurrent Unit (GRU) have\nbeen extensively studied. Compared with these works, ST-\nTIS considers the spatial and temporal dependency in a joint\nmanner.\n\nCNN has been applied in many works to capture depen-\ndencies between close regions [4]\u2013[7], [25]. In these works,\na city is divided into some connected but non-overlapping\ngrids, and the traffic in each grid is then predicted. However,\nthese works cannot be used for fine-grained flow forecasting\nat an individual location [26], such as predicting flow for a\ndocked bike-sharing station or a subway station. Moreover,\nCNN can hardly capture distant traffic dependency due to\nits relatively small receptive field [27], [28].\n\nSome other works use GCN to capture spatial depen-\ndency [8], [9], [29]\u2013[35]. In these works, a city is represented\nas a graph structure, and convolution operations are ap-\nplied to aggregate spatially distributed information in the\ngraph. In each aggregation layer, a region would aggregate\nthe embedding of its neighbouring regions in the graph.\nHowever, these works highly rely on the graph structure for\ndependency learning. Prior works usually construct graphs\nbased on the distance between regions or road network,\nbased on the locality assumption (i.e., close regions have\nhigher dependency). They have to stack more layers to\nlearn dependency if the distance between two regions in the\ngraph is long, and it ends up with an inefficient and over-\nsmoothing model [31]. In recent years, Transformer [10] has\nbeen applied for traffic forecasting [11]\u2013[14]. The canonical\nTransformer can be seen as a special graph neural network\nwith a complete graph, in which any pair of regions are\nconnected. Consequently, the dependencies between both\nclose and distant regions could be considered. Moreover,\nthe self-attention mechanism and the network structure of\nTransformer have been demonstrated to be powerful in\nmany prior works. However, the computational complexity\nof each aggregation round isO(n2) for Transformer where n\nis the number of regions, while that for GNN is O(E) where\nE is the number of edges in the graph (E \u2264 n2). Further-\nmore, as a region may only have a strong dependency on a\nsmall portion of regions, aggregating the embedding of all\nregions would introduce noise and degrade its performance.\nIn ST-TIS, we propose a region connected graph (i.e., there\nexists a path between any pair of regions in the graph), in\nwhich the degree of any node (i.e., region) is O(\n\n\u221a\nn) and\n\nthe distance between any two regions in the graph is no\nmore than 2. We extend the canonical Transformer with the\nproposed region connected graph, so that it can inherit the\nadvantage of efficiency and effectiveness from both GNN\nand Transformer.\n\nRNN and its variants such as LSTM and GRU [36], [37]\nhave been used to capture temporal dependency [6], [34],\n[35], [38]. However, the performance of RNN-based models\ndeteriorates rapidly as the length of the input sequence\nincreases [39]. Some works incorporate the attention mecha-\nnism [40] to improve their capability of modeling long-term\ntemporal correlations [7], [9], [29], [41]. Nevertheless, RNN-\nbased networks are widely known to be difficult to train and\nare computationally intensive [8]. As recurrent networks\ngenerate the current hidden states as a function of the\nprevious hidden state and the input for the position, they are\nin general more difficult to be trained in parallel. To address\n\nthe issue, the self-attention mechanism is proposed as the\nreplacement of RNN to model sequential data [10]. It has\nenjoyed success in capturing temporal correlations for traf-\nfic forecasting [11]\u2013[13], [42]. Compared with RNN-based\nmodels, self-attention models can directly model long-term\ntemporal interactions, but the computational complexity of\nusing self-attention for temporal dependency learning in\nexisting works is O(q2), where q is the number of historical\ntime slots. Compared with them, ST-TIS is conditional on\nthe spatial-temporal dependency at any individual slot to\ngenerate weights for different time slots, so its computa-\ntional complexity is O(q) in our work. In addition, the\ntemporal dependency is jointly considered with the spatial\ndependency in ST-TIS, instead of in a decouple manner.\n\nSome variants of Transformer have been proposed to\naddress the efficiency issues of the canonical Transformer,\nsuch as LogSparse [43], Reformer [44], Informer [15], etc.\nWhile impressive, these approaches cannot be used in the\nscenario of capturing spatial-temporal dependency between\nregions for traffic forecasting we are considering in this\nwork.\n\n3 PRELIMINARIES\n\n3.1 Problem formulation\n\nDefinition 1. (Region) The area (e.g., a city or subway route)\nis partitioned into n non-overlapping regions. We use R =\n{r1, r2, . . . , rn} to denote the partitioned regions, in which ri\ndenotes the i-th region.\n\nThe way to partition an area is flexible for ST-TIS, e.g.,\ngrid map, road network, clustering, or train/bus/bike sta-\ntions, etc.\n\nDefinition 2. (Traffic data) We use I and O to denote the inflow\nand outflow data of all regions over time, respectively. Specifically,\nIt \u2208 R1\u00d7n and Ot \u2208 R1\u00d7n is the inflow and outflow of the\nn regions at time t. Moreover, Iti and Ot\n\ni is the inflow and\noutflow of region ri at time t (i.e., the number of objects arriving\nat/departing from the region ri at time slot t). Furthermore, we use\nIt\u2032:ti = [It\u2032i , It\n\n\u2032+1\ni , . . . , Iti ] to denote the inflow of ri from t\u2032 to\n\nt. Similarly, Ot\u2032:t\ni = [Ot\u2032\n\ni ,Ot\u2032+1\ni , . . . ,Ot\n\ni ] indicates the outflow\nof ri from t\u2032 to t.\n\nThe formal formulation of the traffic forecasting problem\nis as follows:\n\nDefinition 3. (Traffic Forecasting) Given the traffic data of\nregions from 0 to t \u2212 1, namely I0:t\u22121 and O0:t\u22121, the traffic\nforecasting problem is to predict the inflow and outflow of any\nregion at t, namely It and Ot.\n\n3.2 ST-TIS Overview\n\nWe overview the proposed ST-TIS in Figure 2. Given the\ntraffic data of all regions from time slots 0 to t \u2212 1, ST-\nTIS is an end-to-end model to capture the spatial-temporal\ndependency and predict the inflow and outflow for any\nregion at t. There are five modules in ST-TIS. We explain\nthe design goals and the relationship among modules as\nfollows:\n\n\n\n4\n\nFig. 2. ST-TIS overview.\n\n\u2022 Information Fusion Module: A key to accurately pre-\ndicting the traffic for regions is capturing the dy-\nnamic spatial-temporal (ST) dependency between re-\ngions in a joint manner. To this end, ST-TIS employs\na information fusion module to learn the spatial-\ntemporal-flow (STF) embedding by encoding its spa-\ntial, temporal, and flow information for any individ-\nual region at a time slot.\n\n\u2022 Region Sampling Module: To address the issues of\nquadratic computational complexity and long tail\ndistribution of attention scores for the canonical\nTransformer, ST-TIS uses a novel region sampling\nstrategy to generate a region connected graph. The\ndependency learning would be based on the gener-\nated graph.\n\n\u2022 Dependency Learning for Individual Time Slot (DLI):\nGiven the STF embedding at a time slot and the\nregion connected graph, ST-TIS extends the canonical\nTransformer to jointly capture the dynamic spatial-\ntemporal dependency between regions at the time\nslot. As the spatial and temporal information has\nbeen both encoded in the STF embedding, the joint\neffect of spatial-temporal dependencies between re-\ngions could be captured. Moreover, with the region\nconnected graph, only the attention scores between\nneighbouring nodes (i.e., regions) are computed,\nand only the embedding of one\u2019s neighbouring re-\ngions are aggregated. Dependency between non-\nneighbouring nodes is considered via information\npropagation between multiple layers in the network.\nConsequently, it cuts the computational complexity\nof a layer from O(n2) to O(n \u00d7\n\n\u221a\nn) where n is the\n\nnumber of regions, and addresses the issue of the\nlong-tail effect for dependency learning.\n\n\u2022 Dependency Learning over Multiple Time Slots (DLM):\nGiven the region embedding from DLI at multi-\nple time slots, DLM captures the periodic patterns\n\nof spatial-temporal dependency using the attention\nmechanism. The influence of spatial-temporal de-\npendency at historical time slots on the predicted\ntime slot is hence considered in ST-TIS. The learning\nprocess is data-driven, without any prior assumption\nof traffic periods.\n\n\u2022 Prediction Network (PN): Given the results from DLM,\nST-TIS uses a fully connected neural network to\npredict the inflow and outflow of regions (It and\nOt) simultaneously.\n\n4 ST-TIS DETAILS\n\nWe present the details of ST-TIS in this section. We first elab-\norate the information fusion module in Section 4.1, followed\nby the region sampling module in Section 4.2. After that,\nwe introduce the dependency learning for individual time\nslot (DLI) in Section 4.3, and the dependency learning over\nmultiple time slots (DLM) in Section 4.4. Finally, we present\nthe prediction network (PN) in Section 4.5.\n\n4.1 Information Fusion Module\nTo capture the dynamic joint spatial-temporal dependency\nfor traffic forecasting, it is essential to fuse the spatial-\ntemporal information for each region at any individual time\nslot. To this end, ST-TIS employs the information fusion\nmodule to learn one\u2019s spatial-temporal-flow (STF) embed-\nding by fusing its position, time slot, and flow information.\n\nGiven n regions, we first use a one-hot vector Si \u2208 R1\u00d7n\n\nto represent a region ri, in which only the i-th element in\nSi is 1 and otherwise 0. After that, we encode the position\ninformation for a region ri as follows,\n\nS\u0302i = Si \u00b7WS + bS . (1)\n\nwhere S\u0302i \u2208 R1\u00d7d is the spatial embedding of ri, WS \u2208\nRn\u00d7d and bS \u2208 R1\u00d7d are learnable parameters, and d is a\nhyperparameter.\n\nIn terms of temporal information, we first split a day\ninto o time slots and represent the i-th time slot using a\none-hot vector Ti \u2208 R1\u00d7o. After that, we learn the temporal\nembedding by\n\nT\u0302i = Ti \u00b7WT + bT , (2)\n\nwhere T\u0302i \u2208 R1\u00d7d is the temporal embedding of the i-th time\nslot in a day, WT \u2208 Ro\u00d7d and bT \u2208 R1\u00d7d are learnable\nparameters.\n\nRecall that the traffic of one region at ti may depend on\nthat of another region at previous time slots due to the travel\ntime between two regions. Thus, we use one\u2019s surrounding\nobservations instead of solely using a snapshot to learn the\ndependency [43]. We define the surrounding observations\nof a region at a time slot tj as follows:\n\nDefinition 4. (Surrounding observations) For a region\nri at a time slot tj , its surrounding observations are\ndefined as the flow in the w previous time slots:\n{Itj\u2212wi , \u00b7 \u00b7 \u00b7 , Itj\u22122i , Itj\u22121i ,Otj\u2212w\n\ni , \u00b7 \u00b7 \u00b7 ,Otj\u22122\ni ,Otj\u22121\n\ni }.\n\nNote that by employing the surrounding observations,\nthe temporal lag of the dependency between regions could\nbe considered. Given the surrounding observations of ri at\ntj , we first apply the 1-D convolution of kernel size 1 \u00d7\n\n\n\n5\n\nFig. 3. Information propagation in a graph.\n\nFig. 4. The process of connected graph generation.\n\np (p < w) with stride 1 and f output channels on its inflow\nand outflow surrounding observations to extract different\npatterns. The flow embedding F tj\n\ni \u2208 R1\u00d7d of ri at tj is\ncomputed as\n\nF tj\ni = (ConvI(Itj\u2212w:tj\u22121\n\ni )||ConvO(Otj\u2212w:tj\u22121\ni ))\u00b7WF +bF ,\n\n(3)\nwhere || is the concatenation operation, ConvI(\u00b7) and\nConvO(\u00b7) are the convolutional operation for inflow and\noutflow data respectively, WF \u2208 Rl\u00d7d, bF \u2208 R1\u00d7d are\nlearnable parameters, and l = 2\u00d7 f \u00d7 (w \u2212 k + 1).\n\nFinally, we fuse the position, time slot and flow informa-\ntion to learn the STF embedding of a region ri at time tj . We\ndefine that tj is the M(tj)-th time slot in a day, where M(\u00b7)\nis an matching function. The fusion process is defined as\n\nLtj\ni = (S\u0302i + T\u0302M(tj) + F tj\n\ni ) \u00b7WL + bLi , (4)\n\nwhere Lj\ni \u2208 R1\u00d7d is the STF embedding, WL \u2208 Rd\u00d7d and\n\nbLi \u2208 R1\u00d7d are learnable parameters.\n\n4.2 Region Sampling\n\nTo capture a region\u2019s dependency on others (both nearby\nand distant), a canonical Transformer computes the atten-\ntion scores between the target region and all other regions,\nand aggregats the embedding of all other regions based\non the computed attention scores. However, this results in\n\nthe issues of quadratic computation and long-tail effect for\ndependency learning.\n\nFortunately, prior works have showed that information\ncould be propogated between nodes in a graph via a multi-\nlayer network structure [45]. Hence, with a proper graph\nstructure and network structure, a region can aggregate\nthe embedding of another even without directly evaluating\ntheir attention score. We present a toy example in Figure\n3, in which regions are represented as nodes in the graph\nand connected with egdes. In the first aggregation layer,\nr1 would capture the information from r2, while r2 would\ncapture the information from r3. Since the information of r3\nhas been aggregated in r2, r1 could also capture it in the\nsecond aggregation layer without computing the attention\nscore between r1 and r3. From this example, we conclude\nthat a node\u2019s information can reach another with a \u03b2-layer\naggregation operation if their distance is not more than \u03b2 in\nthe graph.\n\nTo address the limitations of the canonical Transformer,\nwe propose to generate a connected graph (i.e., there exists\nat least a path between any two nodes in the graph), in\nwhich the degree of any node (i.e., region) is not more\nthan c \u00d7\n\n\u221a\nn and the distance between any pair of nodes\n\nare not more than 2. In this way, for a target region, we\nonly have to aggregate the embedding of O(\n\n\u221a\nn) regions\n\nin an aggregation layer, and the influence from other re-\ngions can be captured in a two-layer aggregation process\nby information propagation. With such design, we do not\nhave to compute the attention scores between any pairs of\nregions and aggregate the embedding of all n regions for a\ntarget region, so that the computation complexity is reduced\nto O(n\n\n\u221a\nn) for each layer, and the long-tail issue is also\n\naddressed.\nIn this work, we present a heuristic approach for region\n\nconnected graph generation. We first calculate the traffic\nsimilarity between any pair of regions. The calculation of\nthe traffic similarity is flexible and it could be any similarity\nmetric. As an example, we use DTW in this work to measure\nthe similarity in terms of the average traffic over time slots\nof a day. We use M \u2208 Rn\u00d7n to represent the similarity\nmatrix, in which Mi,j is the similarity between ri and rj .\nBased onM, the process of the connected graph generation\nis illustrated in Figure 4.\n\nWe first select top b\n\u221a\nnc regions without replacement,\n\nwhich have the largest sum of similarity with other regions,\nrepresented as {r1,1, r1,2, \u00b7 \u00b7 \u00b7 , r1,b\u221anc}. For any region r1,i,\nwe then select b\n\n\u221a\nnc \u2212 1 regions without replacement,\n\nwhich have the largest similarity between them and r1,i,\nrepresented as {r2,i,1, r2,i,2, \u00b7 \u00b7 \u00b7 , r2,i,b\u221anc\u22121}, and we con-\nnect r1,i to r2,i,j (j = 1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc \u2212 1). After that, we\n\nconnect a region r2,i,j to regions r2,i,k and r2,u,j , where k \u2208\n{{1, 2, ..., b\n\n\u221a\nnc \u2212 1}\\{j}} and u \u2208 {{1, 2, ..., b\n\n\u221a\nnc}\\{i}}.\n\nFinally, if\n\u221a\nn /\u2208 Z, the remaining regions woule be con-\n\nnected to r1,i where i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}, represented\n\nas {r3,1, r3,2, \u00b7 \u00b7 \u00b7 , r3,n\u2212b\u221anc2}. If\n\u221a\nn \u2208 Z, we randomly\n\nselect a region from r1,i, and connect it to r1,j , where\nj \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc}\\{i}, represented as r\u2217.\n\nTheorem 1. The degree of any node in the region connected graph\nis O(\n\n\u221a\nn), and the distance between any two nodes in the graph\n\nis less than 2.\n\n\n\n6\n\nProof. The generation of the region connected graph ensures\nthat a node is connected to at most max(2\u00d7 b\n\n\u221a\nnc \u2212 2, n\u2212\n\nb\n\u221a\nnc2 + b\n\n\u221a\nnc \u2212 1) other nodes, and hence the degree is\n\nO(\n\u221a\nn).\n\nThe distance of (r3,i, r1,j) (or (r\u2217, r1,j)) and (r1,j , r2,j,k)\nis both 1, where i \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , n \u2212 b\n\n\u221a\nnc2}, j \u2208\n\n{1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}, and k \u2208 {1, 2, ..., b\n\n\u221a\nnc \u2212 1}. Thus, the\n\ndistance between r3,i (or r\u2217) and any other region is no more\nthan 2 in the graph.\n\nFor region r1,j , since the distance of (r1,j , r2,j,k) and\n(r2,j,k, r2,m,k) is both 1 where k \u2208 {1, 2, ..., b\n\n\u221a\nnc \u2212 1} and\n\nm \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc}\\{j}, the distance of (r1,j , r2,m,k) is\n\nhence 2. Thus, the distance between r1,j and any other\nregion is also no more than 2.\n\nIn terms of r2,j,k, as the distance of (r2,j,k, r2,m,k) and\n(r2,j,k, r2,j,v) is 1, where m \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , b\n\n\u221a\nnc}\\{j} and v \u2208\n\n{1, 2, \u00b7 \u00b7 \u00b7 , b\n\u221a\nnc \u2212 1}\\{k}, the distance between r2,j,k and\n\nany other regions is hence no more than 2. Therefore, the\ndistance between any two regions in the graph is less than\n2.\n\nBecause the distance between any two regions in the\nproposed graph is less than 2, the dependencies between\nany two regions could be considered if the layer number of\nthe aggregation network is larger than 2.\n\n4.3 Dependency Learning for Individual Time Slot (DLI)\nGiven the STF embedding of regions for time tj and the gen-\nerated region connected graph, ST-TIS captures the spatial-\ntemporal dependencies between regions based on an ex-\ntended Transformer encoder. Following the canonical Trans-\nformer, ST-TIS employs an multi-head attention mechanism,\nso that it could account for different dependencies between\nregions. For the m-th head, the attention score between ri\nand rv at tj is defined as\n\nAm(ri, rv, tj) =\n(Ltj\n\ni \u00b7WQm) \u00b7 (Ltj\nv \u00b7WKm)T\u221a\n\nd\n, (5)\n\nwhere Ltj\ni \u2208 R1\u00d7d and Ltj\n\nv \u2208 R1\u00d7d are the STF embedding\nof regions ri and rv at tj (Equation 4), WQm\n\n\u2208 Rd\u00d7d\n\nand WKm\n\u2208 Rd\u00d7d are learnable parameters, and d is a\n\nhyperparameter for the embedding size.\nUnlike the canonical Transformer, we do not evaluate the\n\nattention scores between one region and all other regions.\nInstead, we only compute one\u2019s attention scores with its\nneighbouring regions in the region connected graph, and\naggregate their embedding in terms of their attention score\nto update the region\u2019s embedding. For the m-th head, the\nembedding of a region ri at time tj is then updated as\n\nL\u0302tj\ni,m =\n\n\u2211\nrv\u2208Neigh(ri)\n\nsoftmax(Am(ri, rv, tj)) \u00b7 Ltj\nv\n\n=\n\u2211\n\nrv\u2208Neigh(ri)\n\nexp(Am(ri, rv, tj))\u2211\nru\u2208Neigh(ri)\n\nexp(Am(ri, ru, tj))\n\u00b7 Ltj\n\nv ,\n\n(6)\n\nwhere L\u0302tj\ni,m \u2208 R1\u00d7d is the output of the m-th head,\n\nNeigh(ri) is the neighbouring regions of ri in the graph,\nAm(ri, rv, tj) is the attention score defined in Equation 5.\nAs the degree of any node is O(\n\n\u221a\nn), the computation\n\nFig. 5. Processing of dependency learning for individual time slot.\n\ncomplexity of attention score evaluation and embedding\naggregation is hence O(n\n\n\u221a\nn) for all regions in a layer.\n\nFinally, we concatenate the results of multi-heads and\nthe embedding of ri is computed as\n\nL\u0302tj\ni = Concat(L\u0302tj\n\ni,1, \u00b7 \u00b7 \u00b7 , L\u0302\ntj\ni,M ) \u00b7WO, (7)\n\nwhere Concat(\u00b7) is the concatenation operation, L\u0302t\ni \u2208 R1\u00d7d\n\nis the embedding of ri, WO \u2208 R(d\u00d7M)\u00d71 are learnable\nparameters and M is the number of heads.\n\nFollowing the structure of Transformer [10], the output\nof the multi-head region attention layers L\u0302tj\n\ni is then passed\nto a fully connected neural network (Figure 5). We also em-\nploy a residual connection between each of the two layers.\nAs we discussed in Section 4.2, the information propagation\nis achieved with a multi-layer network structure. Thus, we\nstack the layers \u03b1 times (the effect of \u03b1 will be discussed\nin Section 5.7). We denote the final output of the DLI as\nRtj = {Rtj\n\n1 ,R\ntj\n2 , \u00b7 \u00b7 \u00b7 ,R\n\ntj\nn }, where Rtj\n\ni is the embedding of\nregion ri at tj .\n\nCompared with the canonical Transformer, we only need\nto compute the attention scores and aggregate the embed-\nding between adjacent nodes in the region connected graph.\nThe computation complexity is hence reduced from O(n2)\nto O(n\n\n\u221a\nn) for each layer.\n\n4.4 Dependency Learning over Multiple Time\nSlots (DLM)\nConsidering the spatial-temporal dependency may have pe-\nriorical characteristic, DLM learns the periodic dependency\nby evaluating the correlation between Rt\n\nn and the depen-\ndency at other historical time slots Rt\u0302\n\ni (where t\u0302 < t). After\nthat, it generates a new embedding for ri by aggregating\nthe embedding at different time slots according to their\ncorrelations.\n\nSpecifically, we consider the short-term and long-term\nperiod for traffic data in this work. The spatial-temporal\ndependency at the following historical time slots are used\nas the model input to predict the inflow and outflow of\n\n\n\n7\n\nregions at t: spatial-temporal dependency in the recent h\ntime slots (i.e., short-term period); the same time interval in\nthe recent l days (i.e.,long-term period).\n\nWe employ a point-wise aggregation with self-attention\nto evaluate their correlations and aggregate the embedding\naccordingly. To capture the multiple periodic dependency,\nwe use an multi-head attention network in DLM.\n\nGiven a set of historical time slot Q, the z-th dependency\non a historical time slot t\u0302 \u2208 Q is calculated as follows:\n\nez(t, t\u0302) =\n(Rt\n\ni \u00b7W TQz\n) \u00b7 (Rt\u0302\n\ni \u00b7W TKz\n)T\n\n\u221a\nd\n\n, (8)\n\nwhere W TQz\n\u2208 Rd\u00d7d and W TKz\n\n\u2208 Rd\u00d7d are learnable param-\neters.\n\nWe use a softmax function to normalize the dependency\nand aggregate the context of each time slot by weight:\n\n\u03b2z(t, t\u0302) = softmax(ez(t, t\u0302)) =\nexp(ez(t, t\u0302))\u2211\n\ntp\u2208Q exp(ez(t, tp))\n. (9)\n\nThe aggregation of the z-th head is hence\n\nR\u0302t\ni,z = (\n\n\u2211\nt\u0302\u2208Q\n\n(\u03b2z(t, t\u0302) \u00b7 Rt\u0302\ni) \u00b7W TV , (10)\n\nwhere Q is the set of historical time slots, R\u0302t\ni,z is the\n\naggregation result of the z-th head, and W TV \u2208 Rd\u00d7d are\nlearnable parameters. Finally, we concatenate the results of\ndifferent heads with\n\nR\u0302t\ni = Concat(R\u0302t\n\ni,1, R\u0302t\ni,2, \u00b7 \u00b7 \u00b7 , R\u0302t\n\ni,Z) \u00b7WT , (11)\n\nwhere Concat(\u00b7) is the concatenation operation, and WT \u2208\nR(Z\u00d7d)\u00d7d are learnable parameters. We then pass R\u0302t\n\ni to\na fully connected neural network to obtain the spatial-\ntemporal embedding of ri at t. Note that we also employ a\nresidual connection between each of the two layers to avoid\ngradient exploding or vanishing. The output of the DLM is\ndenoted as \u2126t\n\ni for region ri at t.\nDifferent from prior works, the periodic dependency\n\nlearning is conditional on the spatial-temporal dependency\nat each individual time slot. Consequently, the spatial and\ntemproal dependencies are jointly considered during the\nperiodic dependency learning. The computation complexity\nis O(|Q|), where |Q| is the number of historical time slots\nused for learning.\n\n4.5 Prediction Network (PN)\nGiven the spatial-temporal embedding T t\n\nri of a region, the\nprediction network predicts the inflow and outflow using\nthe fully connected network. The forecasting function is\ndefined as\n\n[I\u0302ti , O\u0302t\ni ] = \u03c3(\u2126t\n\ni \u00b7WP + bP ), (12)\n\nwhere I\u0302ti and O\u0302t\ni is the forecasting inflow and outflow\n\nrespectively, \u03c3(\u00b7) is the ReLU activation function and WP \u2208\nRd\u00d72, and bP \u2208 R1\u00d72 are learnable parameters.\n\nWe simultaneously forecast the inflow and outflow in\nour work, and define the loss function as follows:\n\nLOSS =\n\n\u221a\u2211n\ni=1(Iti \u2212 I\u0302ti )2 +\n\n\u2211n\ni=1(Ot\n\ni \u2212 O\u0302t\ni)\n\n2\n\n2n\n, (13)\n\nwhere n is the number of regions.\n\n5 ILLUSTRATIVE EXPERIMENTAL RESULTS\n\nIn this section, we first introduce the datasets and the data\nprocessing approaches in Section 5.1, and the evaluation\nmetrics and baseline approaches in Section 5.2. Then, we\ncompare the accuracy and training efficiency of ST-TIS with\nthe state-of-the-art methods in Sections 5.3 and 5.4, respec-\ntively. After that, we evaluate the performance of variants\nof ST-TIS and the effect of surrounding observations in\nSections 5.6 and 5.5, respectively, followed by the discussion\non the hyperparameters of layer number in Section 5.7 and\nhead number in Section 5.8.\n\n5.1 Datasets\nWe conduct extensive traffic study and model evaluations\nbased on two real-world traffic flow datasets collected in\nNew York City (NYC), the NYC-Taxi dataset and the NYC-\nBike dataset. Each dataset contains trip records, each of\nwhich consists of origin, destination, departure time, and\narrival time. The NYC-Taxi dataset contains 22, 349, 490\ntaxi trip records of NYC in 2015, from 01/01/2015 to\n03/01/2015. The NYC-Bike dataset was collected from the\nNYC Citi Bike system from 07/01/2016 to 08/29/2016, and\ncontains 2, 605, 648 trip records.\n\nThe city is split into 10 \u00d7 20 regions with a size of\n1km\u00d71km. The time interval is set as 30 minutes for both\ndatasets. The two datasets were pre-processed and released\nonline1 by the prior work [7].\n\nIn both of the taxi dataset and bike dataset, we use\ndata from the previous 40 days as the training data, and\nthe remaining 20 days as the testing data. In the training\ndata, we select 80% of the training data to train our model\nand the remaining 20% for validation. We use the Min-Max\nnormalization to rescale the range of volume value in [0, 1],\nand recover the result for evaluation after forecasting. In\nour experiments, we exclude the results of those regions the\ninflow or outflow of which is less than 10 when evaluating\nthe model. It is a common practice used in industry and\nmany prior works [6], [7], [42].\n\n5.2 Performance Metrics and Baseline Methods\nWe use Root Mean Squared Errors (RMSE) and Mean Av-\nerage Percentage Error (MAPE) as the evaluation metrics,\nwhich are defined as follows:\n\nRMSE =\n\n\u221a\u2211N\ni=1(yi \u2212 y\u0302i)2\n\nN\n, (14)\n\nMAPE =\n1\n\nN\n\nN\u2211\ni=1\n\n|yi \u2212 y\u0302i|\nyi\n\n, (15)\n\nwhere yi and y\u0302i are the ground-truth and forecasting result\nof the i-th sample, and N is the total number of samples.\n\nWe compare our model with the following state-of-the-\nart approaches:\n\n\u2022 Historical average (HA): It uses the average of traffic at\nthe same time slots in historical data for prediction.\n\n\u2022 ARIMA: It is a conventional approach for time series\ndata forecasting.\n\n1. https://github.com/tangxianfeng/STDN/blob/master/data.zip\n\n\n\n8\n\nTABLE 1\nComparison with the state-of-the-art methods.\n\nDataset Method Inflow Outflow\nRMSE MAPE RMSE MAPE\n\nNYC-Taxi\n\nHA 33.83 21.14% 43.82 23.18%\nARIMA 27.25 20.91% 36.53 22.21%\nRidge 24.38 20.07% 28.51 19.94%\n\nXGBoost 21.72 18.70% 26.07 19.35%\nMLP 22.08\u00b10.50 18.31\u00b10.83% 26.67\u00b10.56 18.43\u00b10.62%\n\nConvLSTM 23.67\u00b10.20 20.70\u00b10.20% 28.13\u00b10.25 20.50\u00b10.10%\nST-ResNet 21.63\u00b10.25 21.09\u00b10.51% 26.23\u00b10.33 21.13\u00b10.63%\n\nSTDN 19.05\u00b10.31 16.25\u00b10.26% 24.10\u00b10.25 16.30\u00b10.23%\nASTGCN 22.05\u00b10.37 20.25\u00b10.26% 26.10\u00b10.25 20.30\u00b10.31%\nSTGODE 21.46\u00b10.42 19.22\u00b10.36% 27.24\u00b10.46 19.30\u00b10.34%\nSTSAN 23.07\u00b10.64 22.24\u00b11.91% 27.83\u00b10.30 25.90\u00b11.67%\nDSAN 18.32\u00b10.39 16.07\u00b10.31% 24.27\u00b10.30 17.70\u00b10.35%\nST-TIS 17.73\u00b10.23 14.65\u00b10.32% 21.96\u00b10.13 14.83\u00b10.76%\n\nNYC-Bike\n\nHA 11.93 27.06% 12.49 27.82%\nARIMA 11.25 25.79% 11.53 26.35%\nRidge 10.33 24.58% 10.92 25.29%\n\nXGBoost 8.94 22.54% 9.57 23.52%\nMLP 9.12\u00b10.24 22.40\u00b10.40% 9.83\u00b10.19 23.12\u00b10.24%\n\nConvLSTM 9.22\u00b10.19 23.20\u00b10.47% 10.40\u00b10.17 25.10\u00b10.45%\nST-ResNet 8.85\u00b10.13 22.98\u00b10.53% 9.80\u00b10.12 25.06\u00b10.36%\n\nSTDN 8.15\u00b10.15 20.87\u00b10.39% 8.85\u00b10.11 21.84\u00b10.36%\nASTGCN 9.05\u00b10.31 22.25\u00b10.36% 9.34\u00b10.24 23.13\u00b10.30%\nSTGODE 8.58\u00b10.38 23.33\u00b10.26% 9.23\u00b10.31 23.99\u00b10.23%\nSTSAN 8.20\u00b10.45 20.42\u00b11.33% 9.87\u00b10.23 23.87\u00b10.71%\nDSAN 7.97\u00b10.25 20.23\u00b10.18% 10.07\u00b10.58 23.92\u00b10.39%\nST-TIS 7.57\u00b10.04 18.64\u00b10.23% 7.73\u00b10.10 18.58\u00b10.19%\n\n\u2022 Ridge Regression: A regression approach for time se-\nries data forecasting.\n\n\u2022 XGBoost [46]: A powerful approach for building su-\npervised regression models.\n\n\u2022 Multi-Layer Perceptron (MLP): A three-layer fully-\nconnected neural network.\n\n\u2022 Convolutional LSTM (ConvLSTM) [47]: It is a special\nrecurrent neural network with a convolution struc-\nture for spatial-temporal prediction.\n\n\u2022 ST-ResNet [5]: It uses multiple convolutional net-\nworks with residual structures to capture spatial cor-\nrelations from different temporal periods for traffic\nforecasting. It also considers external data such as\nweather, holiday events, and metadata.\n\n\u2022 STDN [7]: It considers the dynamic spatial correla-\ntion and temporal shifted problem using the com-\nbination of CNN and LSTM. External data such as\nweather and event are considered in the work.\n\n\u2022 ASTGCN [48]: It is an attention-based spatial-\ntemporal graph convolutional network (ASTGCN)\nmodel to solve traffic flow forecasting problem.\n\n\u2022 STGODE [31]: It uses a spatial-temporal graph ordi-\nnary differential equation network to predict traffic\nflow based on two predefine graph, namely a spatial\ngraph in terms of distance, and a semantic graph in\nterms of flow similarity.\n\n\u2022 STSAN [12]: It uses CNN to capture spatial infor-\nmation and the canonical Transformer to consider\nthe temporal dependencies over time. In particular,\ntransition data between regions are used to indicate\nthe correlation between regions.\n\n\u2022 DSAN [13]: It uses the canonical Transformer to\ncapture the spatial-temporal correlations for spatial-\ntemporal prediction, in which transition data be-\n\ntween regions are used for correlation modeling.\n\nWe use the identical datasets and data process approach\nas the work STDN [7], and use the results of the work [7] as\nthe benchmark for discussion. The experiment results of (1)\n\u223c (8) in Table 1 are reported in the work [7]. The evaluation\nof ASTGCN, STGODE, STSAN, and DSAN is based on the\ncode from their authors\u2019 GitHubs.\n\nWe implement our model using PyTorch. Data and code\ncan be found in https://github.com/GuanyaoLI/ST-TIS.\nWe use the following data as the model input since they\nachieve the best performance on the validation datasets:\ndata in the recent past 3 hours (i.e., h = 6 as the slot duration\nis 30 minutes); the same time slot in the recent past 10\ndays (i.e., l = 10). The other default hyperparameter settings\nare as follows. The default length w of the surrounding\nobservations is 6 (i.e. 3 hours), the number of convolution\nkernels F is 4, and the dimension d is set as 8. The number\nof k for DLI in Figure 5 is set as 3, and the number of heads\nis set as 6 for the two modules. Furthermore, the dropout\nrate is set as 0.1, the learning rate is set as 0.001, and the\nbatch size is set to be 32. Adam optimizer is used for model\ntraining. We trained our model on a machine with a NVIDIA\nRTX2080 Ti GPU.\n\n5.3 Prediction Accuracy\nWe compared the accuracy of ST-TIS with the state-of-the-\nart methods using the metrics RMSE and MAPE. The results\nfor the two datasets are presented in Table 1. Each approach\nwas run 10 times, and the mean and standard deviation are\nreported. As shown in the table, ST-TIS significantly outper-\nforms all other approaches on both metrics and datasets.\n\nSpecifically, the performance of the conventional time\nseries forecasting approaches (HA and ARIMA) is poor for\n\n\n\n9\n\nTABLE 2\nComparison of training time.\n\nDataset Method Average time\nper epoch (s) Total time (s)\n\nNYC-Taxi\n\nST-ResNet 7.31 3077.51\nSTDN 445.47 34746.66\n\nASTGCN 25.31 6272.88\nSTGODE 18.53 3423.48\nSTSAN 426.75 33769.32\nDSAN 386.17 29390.75\nST-TIS 10.21 1231.5\n\nNYC-Bike\n\nST-ResNet 7.25 2921.75\nSTDN 480.21 23066.43\n\nASTGCN 25.68 5084.64\nSTGODE 18.76 3752.89\nSTSAN 426.28 31216.28\nDSAN 434.03 26476.20\nST-TIS 10.37 1556.8\n\nboth datasets because these approaches do not consider\nthe spatial dependency. Conventional machine learning\napproaches (Ridge, XGBoost, and MLP), which consider\nspatial dependency as features, have better performance\nthan HA and ARIMA. However, they fail to consider the\njoint spatial-temporal dependencies between regions. Most\ndeep learning-based models have further improvements\nthan conventional works, illustrating the ability of deep\nneural networks to capture the complicated spatial and\ntemporal dependency. ST-TIS is substantially more accurate\nthan state-of-the-art approaches (i.e., ConvLSTM, STResNet,\nSTDN, ASTGCN and STGODE). For example, it has an\naverage improvement of 9.5% on RMSE and 12.4% on\nMAPE compared to STDN and DSAN. The reasons for\nthe improvements are that it can capture the correlations\nbetween both nearby and distant regions, and it considers\nthe spatial and temporal dependency in a joint manner.\nWe find that the improvement is more significant on the\nNYC-Taxi dataset than on the NYC-Bike dataset. The reason\ncould be that people prefer using taxis instead of bikes for\nlong-distance travel, and so the correlations with distant\nregions are more important for the prediction task on the\ntaxi dataset. The significant improvement demonstrates that\nST-TIS has a better ability to capture the correlations for\ndistant regions than the other approaches which have the\nspatial locality assumption. ST-TIS also outperforms other\nTransformer-based approaches (such as STSAN and DSAN).\nThe reason is that with the information fusion and region\nsampling strategies in ST-TIS, the long-tail issue of the\ncanonical Transformer is addressed and the joint spatial-\ntemporal correlations are considered. The significant im-\nprovements demonstrate the effectiveness of our proposed\nmodel.\n\n5.4 Training Efficiency\n\nTraining and deploying large deep learning models is costly.\nFor example, the cost of trying combinations of different\nhyper-parameters for a large model is computationally ex-\npensive and it highly relies on training resources [3]. Thus,\nwe compare the training efficiency of ST-TIS with some\nstate-of-the-art deep learning based approaches (i.e., ST-\nResNet, STDN, ASTGCN, STGODE, STSAN, and DSAN) in\nterms of training time and number of learnable parameters.\n\nTABLE 3\nComparison of the number of parameters.\n\nMethod Number of parameters\nST-ResNet 4,917,041\n\nSTDN 9,446,274\nASTGCN 450,031\nSTGODE 433,073\n\nDSAN 1,621,634\nSTSAN 34,327,298\nST-TIS 139,506\n\n 16\n\n 18\n\n 20\n\n 22\n\n 24\n\n 26\n\nInflow Outflow\n\nR\nM\n\nS\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n18%\n\n19%\n\nInflow Outflow\n\nM\nA\n\nP\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(b) MAPE.\n\nFig. 6. Performance of variants on the NYC-Taxi dataset.\n\nThe results of the average training time per epoch and\nthe total training time are presented in Table 2. ST-ResNet\nachieves the least training time among all comparison ap-\nproaches because it solely employs simple CNN and does\nnot rely on RNN for temporal dependency learning. The\naverage time per epoch of ST-TIS is close to ST-ResNet. In\naddition, ST-TIS is trained significantly faster than other\napproaches (with a reduction of 46% \u223c 95%). STDN uses\nLSTM to capture temporal correlation, which is in general\nmore difficult to be trained in parallel. STSAN and DSAN\nalso employ Transformer with self-attention for spatial and\ntemporal correlation learning, but our proposed approach is\nsignificantly efficient than them, illustrating the efficiency of\nthe proposed region graph for model training.\n\nFurthermore, we also compare the number of learnable\nparameters of each model in Table 3. More parameters may\nlead to difficulties in model training, and it requires more\nmemory and training resources. Compared with other state-\nof-the-art approaches, ST-TIS is much more lightweight\nwith fewer parameters for training (with a reduction of\n23% \u223c 98%). The comparison results in Tables 1, 2 and 3\ndemonstrate that our proposed ST-TIS is faster and more\nlightweight than other deep learning based baseline ap-\nproaches, while achieving even better prediction accuracy.\n\n5.5 Design Variations of ST-TIS\nWe compare ST-TIS with its variants to evaluate the effec-\ntiveness of the proposed modules. The following variants\nare discussed:\n\n\u2022 NoIFM: We remove the information fusion module\nfrom ST-TIS. Only the surrounding observation of a\ntime slot is used as the input of the model instead of\nthe fusion result.\n\n\u2022 NoRSM: We remove the region sampling module\nfrom ST-TIS. The canonical Transformer is used to\ncapture the dependencies between regions without\nregion sampling.\n\n\n\n10\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 9.5\n\nInflow Outflow\n\nR\nM\n\nS\nE\n\n NoIMF\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(a) RMSE.\n\n17%\n\n18%\n\n19%\n\n20%\n\n21%\n\n22%\n\n23%\n\n24%\n\n25%\n\nInflow Outflow\n\nM\nA\n\nP\nE\n\n NoIFM\n\n NoDLM\n\n NoRSM\n\n ST\u2212TIS\n\n(b) MAPE.\n\nFig. 7. Performance of variants on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 25\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nw\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nw\n\n inflow\n\n outflow\n\n(b) MAPE.\n\nFig. 8. Impact of surrounding observations on the NYC-Taxi dataset.\n\n\u2022 NoDLM: We remove the module of dependency\nlearning over multiple time slots, and only use Rt\n\ni\n\nas the input of the prediction network for prediction.\n\nThe RMSE and MAPE on the NYC-Taxi dataset are\npresented in Figures 6(a) and 6(b), respectively. After tak-\ning the information fusion module away, the performance\ndegrades significantly. The reason is that the information\nfusion module plays a fundermental role in jointly con-\nsidering the spatial-temporal dependency. Without such\nmodule, our approach would degenerate to consider the\nspatial and temporal dependency in a decouple manner.\nThe experimental results demonstrate the importance of\nconsidering spatial-temporal dependency jointly and the\neffective of the proposed information fusion module. More-\nover, without the region sampling module, our approach\nstill achieve a good prediction performance because the\ncanonical Transformer is good at capturing dependencies\nbetween regions. The performance is further improved with\nthe region sampling since it could address the long-tail issue\nof the canonical Transformer for embedding aggregation.\nFurthermore, the RMSE and MAPE increase when the peri-\nodical characteristic of spatial-temporal dependency is not\nconsidered (i.e., NoDLM), which indicates the necessity of\nconsidering the period of spatial-temporal dependency and\ndemonstrates the effectiveness and rationality of our model\ndesign. Similar and consistent findings can be observed on\nthe NYC-Bike dataset in Figures 7(a) and 7(b).\n\n5.6 Surrounding Observations\nRecall that the dependency between two regions may have\ntemporal lagging due to the travel time between them. To\ncapture such lagging dependency, ST-TIS uses the surround-\ning observations to learn the region correlations for each\ntime slot, which contains the inflow and outflow in the\nprevious w time slots. We thus evaluate the impact of w\non the performance of our model.\n\n 7\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nw\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n19%\n\n20%\n\n20%\n\n20%\n\n21%\n\n22%\n\n22%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nw\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 9. Impact of surrounding observations on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 1  2  3  4  5  6\n\nR\nM\n\nS\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n 1  2  3  4  5  6\n\nM\nA\n\nP\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 10. Impact of layer number on the NYC-Taxi dataset.\n\nFigures 8(a) and 8(b) show the RMSE and MAPE versus\ndifferent lengths on the NYC-Taxi dataset. A larger length\nw indicates that more information is encoded from the sur-\nrounding observations. When w = 1, only the observation\nat a time slot is used for dependency learning, and the\nmodel fails to capture the lagging characteristic of depen-\ndency. As the length increases, the RMSE and MAPE of\nboth inflow and outflow forecasting decrease (w \u2264 5). The\nperformance improvement demonstrates the importance of\nusing the surrounding observations to learn the dependen-\ncies between regions. RMSE and MAPE increase slightly\nbut remain stable when the length is large (w \u2265 5). The\npotential reason is that, when w is larger than the travel time\nbetween regions, increasing w would not introduce more\ninformation for dependency learning. On the other hand, a\nlarger w may introduce some noise and more parameters for\nthe model, leading to difficulties in model training [13]. The\nRMSE and MAPE versus different lengths of surrounding\nobservations on the NYC-Bike dataset are shown in Figures\n9(a) and 9(b), which are consistent with the results for the\nNYC-Taxi dataset. When the length is small (w \u2264 4), RMSE\nand MAPE decrease as the length becomes larger, but they\nslightly increase when the length is large (w \u2265 4).\n\n5.7 Layer Number\n\nIn ST-TIS, DLI is stacked \u03b1 times to ensure the informa-\ntion propagtion between regions and improve the model\nrobustness. We evaluate the effect of \u03b1 on the prediction\nperformance using RMSE and MAPE. The results for the taxi\ndataset are presented in Figure 10. When \u03b1 = 1, only the\ndependencies on one\u2019s neighbouring regions in the graph\nare considering, resulting in the worst prediction accuracy.\nWhen \u03b1 \u2265 2, the dependencies on all other regions could be\ncaptured. We find that with the layer number \u03b1 increases,\nthe RMSE and the MAPE declines for both inflow and out-\nflow, indicating the performance improvement. However,\n\n\n\n11\n\n 7\n\n 7.5\n\n 8\n\n 8.5\n\n 1  2  3  4  5  6\n\nR\nM\n\nS\nE\n\n\u03b1\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n18%\n\n19%\n\n20%\n\n21%\n\n 1  2  3  4  5  6\n\nM\nA\n\nP\nE\n\n\u03b1\n\n inflow\n\n outflow\n\n(b) MAPE.\n\nFig. 11. Impact of layer number on the NYC-Bike dataset.\n\n 17\n\n 19\n\n 21\n\n 23\n\n 25\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nM\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n14%\n\n15%\n\n16%\n\n17%\n\n18%\n\n19%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nM\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 12. Impact of head number on the NYC-Taxi dataset.\n\nwe find that when the layer number is too large (\u03b1 > 5\nin our experiments), the performance on RMSE and MAPE\ndegrades, because too many layers may result in difficulties\nof model training. Similar results are observed on the bike\ndataset (Figure 11).\n\n5.8 Head Number\n\nWe use the multi-head attention mechanism in ST-TIS for\ndependency learning, so that different heads could capture\ndifferent patterns from the historical data. In our experi-\nments, we evaluate the impact of the head number M on\nthe prediction performance. The results of RMSE and MAPE\nversus the head number M on the taxi and bike datasets are\npresented in Figures 12 and 13, respectively. As shown in\nFigures 12(a) and 13(a), with the head number increases,\nthe RMSE on the two datasets declines, demonstrating\nthe multi-head mechanism could benefit the dependency\nlearning and improve the prediction accuracy. We also ob-\nserve that when the head number become larger (M > 4\non the taxi dataset while M > 6 on the bike dataset),\nthe improvements are not significant. The reason could\nbe that some heads may focus on the same pattern when\nthere are many heads. In terms of MAPE, similar findings\ncould be observed in Figures 12(b) and 13(b). Moreover, the\nMAPE increases slightly when the head number becomes\nlarge (M > 6). It is because increasing the head number\nleads to more learnable parameters, which would result in\ndifficulties for model training.\n\n6 CONCLUSION\n\nWe propose ST-TIS, a novel, small (in parameters), com-\nputationally efficient and highly accurate model for traffic\nforecasting. ST-TIS employs a spatial-temporal Transformer\nwith information fusion and region sampling to jointly\nconsider the dynamic spatial and temporal dependencies\n\n 7.5\n\n 8\n\n 8.5\n\n 9\n\n 1  2  3  4  5  6  7  8\n\nR\nM\n\nS\nE\n\nM\n\n outflow\n\n inflow\n\n(a) RMSE.\n\n18%\n\n19%\n\n20%\n\n21%\n\n22%\n\n 1  2  3  4  5  6  7  8\n\nM\nA\n\nP\nE\n\nM\n\n outflow\n\n inflow\n\n(b) MAPE.\n\nFig. 13. Impact of head number on the NYC-Bike dataset.\n\nbetween regions at any individual time slots, and also the\npossibly periodic spatial-temporal dependency from multi-\nple time slots. In particular, ST-TIS boosts the efficiency and\naddresses the long-tail issue of the canonical Transformer\nusing a novel region sampling strategy, which reduces the\ncomplexity from O(n2) to O(n\n\n\u221a\nn), where n is the number\n\nof regions. We have conducted extensive experiments to\nevaluate ST-TIS, using a taxi and a bike sharing datasets.\nOur experimental results show that ST-TIS significantly out-\nperforms the state-of-the-art approaches in terms of training\nefficiency (with a reduction of 46% \u223c 95% on training time\nand 23% \u223c 98% on network parameters), and hence is\nefficient in tuning, training and memory. Despite its small\nsize and fast training, it achieves higher accuracy in its\nonline predictions than other state-of-the-art works (with\nimprovement of up to 9.5% on RMSE, and 12.4% on MAPE).\n\nREFERENCES\n\n[1] Y. Zheng, L. Capra, O. Wolfson, and H. Yang, \u201cUrban computing:\nconcepts, methodologies, and applications,\u201d ACM Transactions on\nIntelligent Systems and Technology (TIST), vol. 5, no. 3, pp. 1\u201355,\n2014.\n\n[2] W. Jiang and J. Luo, \u201cGraph neural network for traffic forecasting:\nA survey,\u201d arXiv preprint arXiv:2101.11174, 2021.\n\n[3] G. Menghani, \u201cEfficient deep learning: A survey on making\ndeep learning models smaller, faster, and better,\u201d arXiv preprint\narXiv:2106.08962, 2021.\n\n[4] J. Zhang, Y. Zheng, D. Qi, R. Li, and X. Yi, \u201cDnn-based prediction\nmodel for spatio-temporal data,\u201d in Proceedings of the 24th ACM\nSIGSPATIAL International Conference on Advances in Geographic\nInformation Systems. California, USA: ACM, 2016, pp. 1\u20134.\n\n[5] J. Zhang, Y. Zheng, and D. Qi, \u201cDeep spatio-temporal residual\nnetworks for citywide crowd flows prediction,\u201d in Thirty-First\nAAAI Conference on Artificial Intelligence. California USA: AAAI,\n2017, pp. 1655 \u2013 1661.\n\n[6] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye,\nand Z. Li, \u201cDeep multi-view spatial-temporal network for taxi\ndemand prediction,\u201d in Thirty-Second AAAI Conference on Artificial\nIntelligence. Louisiana, USA: AAAI, 2018, pp. 2588 \u2013 2595.\n\n[7] H. Yao, X. Tang, H. Wei, G. Zheng, and Z. Li, \u201cRevisiting spatial-\ntemporal similarity: A deep learning framework for traffic predic-\ntion,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence,\nvol. 33. New York, USA: AAAI, 2019, pp. 5668\u20135675.\n\n[8] B. Yu, H. Yin, and Z. Zhu, \u201cSpatio-temporal graph convolutional\nnetworks: a deep learning framework for traffic forecasting,\u201d in\nProceedings of the 27th International Joint Conference on Artificial\nIntelligence. Stockholm, Sweden: IJCAI, 2018, pp. 3634\u20133640.\n\n[9] X. Geng, Y. Li, L. Wang, L. Zhang, Q. Yang, J. Ye, and Y. Liu,\n\u201cSpatiotemporal multi-graph convolution network for ride-hailing\ndemand forecasting,\u201d in Proceedings of the AAAI Conference on\nArtificial Intelligence, vol. 33. Hawaii, USA: AAAI, 2019, pp. 3656\u2013\n3663.\n\n[10] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d\nin Advances in neural information processing systems. Long Beach,\nCA, USA: ACM, 2017, pp. 5998\u20136008.\n\n\n\n12\n\n[11] Y. Zhou, J. Li, H. Chen, Y. Wu, J. Wu, and L. Chen, \u201cA spatiotem-\nporal attention mechanism-based model for multi-step citywide\npassenger demand prediction,\u201d Information Sciences, vol. 513, pp.\n372\u2013385, 2020.\n\n[12] H. Lin, W. Jia, Y. You, and Y. Sun, \u201cInterpretable crowd flow\nprediction with spatial-temporal self-attention,\u201d arXiv preprint\narXiv:2002.09693, vol. [cs.LG], 2020.\n\n[13] H. Lin, R. Bai, W. Jia, X. Yang, and Y. You, \u201cPreserving dynamic\nattention for long-term spatial-temporal prediction,\u201d in Proceedings\nof the 26th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining. Virtual Conference: ACM, 2020, pp.\n36\u201346.\n\n[14] M. Xu, W. Dai, C. Liu, X. Gao, W. Lin, G.-J. Qi, and H. Xiong,\n\u201cSpatial-temporal transformer networks for traffic flow forecast-\ning,\u201d arXiv preprint arXiv:2001.02908, 2020.\n\n[15] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and\nW. Zhang, \u201cInformer: Beyond efficient transformer for long se-\nquence time-series forecasting,\u201d in Proceedings of AAAI, 2021.\n\n[16] S. Shekhar and B. M. Williams, \u201cAdaptive seasonal time series\nmodels for forecasting short-term traffic flow,\u201d Transportation Re-\nsearch Record, vol. 2024, no. 1, pp. 116\u2013125, 2007.\n\n[17] B. Pan, U. Demiryurek, and C. Shahabi, \u201cUtilizing real-world\ntransportation data for accurate traffic prediction,\u201d in 2012 IEEE\n12th International Conference on Data Mining. Brussels, Belgium:\nIEEE, 2012, pp. 595\u2013604.\n\n[18] L. Moreira-Matias, J. Gama, M. Ferreira, J. Mendes-Moreira, and\nL. Damas, \u201cPredicting taxi\u2013passenger demand using stream-\ning data,\u201d IEEE Transactions on Intelligent Transportation Systems,\nvol. 14, no. 3, pp. 1393\u20131402, 2013.\n\n[19] A. Abadi, T. Rajabioun, and P. A. Ioannou, \u201cTraffic flow prediction\nfor road transportation networks with limited traffic data,\u201d IEEE\ntransactions on intelligent transportation systems, vol. 16, no. 2, pp.\n653\u2013662, 2014.\n\n[20] B. L. Smith, B. M. Williams, and R. K. Oswald, \u201cComparison of\nparametric and nonparametric models for traffic flow forecasting,\u201d\nTransportation Research Part C: Emerging Technologies, vol. 10, no. 4,\npp. 303\u2013321, 2002.\n\n[21] R. Silva, S. M. Kang, and E. M. Airoldi, \u201cPredicting traffic volumes\nand estimating the effects of shocks in massive transportation\nsystems,\u201d Proceedings of the National Academy of Sciences, vol. 112,\nno. 18, pp. 5643\u20135648, 2015.\n\n[22] Y. Zhang and Y. Xie, \u201cForecasting of short-term freeway volume\nwith v-support vector machines,\u201d Transportation Research Record,\nvol. 2024, no. 1, pp. 92\u201399, 2007.\n\n[23] Y. Li, Y. Zheng, H. Zhang, and L. Chen, \u201cTraffic prediction in a\nbike-sharing system,\u201d in Proceedings of the 23rd SIGSPATIAL Inter-\nnational Conference on Advances in Geographic Information Systems.\nSeattle, Washington: ACM, 2015, pp. 1\u201310.\n\n[24] Y. Tong, Y. Chen, Z. Zhou, L. Chen, J. Wang, Q. Yang, J. Ye, and\nW. Lv, \u201cThe simpler the better: a unified approach to predicting\noriginal taxi demands based on large-scale online platforms,\u201d in\nProceedings of the 23rd ACM SIGKDD international conference on\nknowledge discovery and data mining. Halifax, NS, Canada: ACM,\n2017, pp. 1653\u20131662.\n\n[25] T. Li, J. Zhang, K. Bao, Y. Liang, Y. Li, and Y. Zheng, \u201cAutost: Ef-\nficient neural architecture search for spatio-temporal prediction,\u201d\nin Proceedings of the 26th ACM SIGKDD International Conference on\nKnowledge Discovery & Data Mining. Virtual Conference: ACM,\n2020, pp. 794\u2013802.\n\n[26] S. He and K. G. Shin, \u201cTowards fine-grained flow forecasting: A\ngraph attention approach for bike sharing systems,\u201d in Proceedings\nof The Web Conference 2020. Taiwan: ACM, 2020, pp. 88\u201398.\n\n[27] H. Yao, C. Zhang, Y. Wei, M. Jiang, S. Wang, J. Huang, N. V.\nChawla, and Z. Li, \u201cGraph few-shot learning via knowledge\ntransfer,\u201d in Thirty-Forth AAAI Conference on Artificial Intelligence.\nNew York, USA: AAAI, 2020, pp. 6656 \u2013 6663.\n\n[28] G. Li, M. Muller, A. Thabet, and B. Ghanem, \u201cDeepgcns: Can\ngcns go as deep as cnns?\u201d in Proceedings of the IEEE International\nConference on Computer Vision. Seoul, Korea: IEEE, 2019, pp. 9267\u2013\n9276.\n\n[29] Z. Pan, Y. Liang, W. Wang, Y. Yu, Y. Zheng, and J. Zhang, \u201cUrban\ntraffic prediction from spatio-temporal data using deep meta\nlearning,\u201d in Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining. Anchorage,\nAK, USA: ACM, 2019, pp. 1720\u20131730.\n\n[30] X. Wang, Y. Ma, Y. Wang, W. Jin, X. Wang, J. Tang, C. Jia, and\nJ. Yu, \u201cTraffic flow prediction via spatial temporal graph neural\n\nnetwork,\u201d in Proceedings of The Web Conference 2020. Taiwan:\nACM, 2020, pp. 1082\u20131092.\n\n[31] Z. Fang, Q. Long, G. Song, and K. Xie, \u201cSpatial-temporal graph\node networks for traffic flow forecasting,\u201d in Proceedings of the\n27th ACM International Conference on knowledge Discovery and Data\nMining. Singapore: ACM, 2021.\n\n[32] M. Li and Z. Zhu, \u201cSpatial-temporal fusion graph neural net-\nworks for traffic flow forecasting,\u201d in Proceedings of the 27th ACM\nInternational Conference on knowledge Discovery and Data Mining.\nSingapore: ACM, 2021.\n\n[33] C. Song, Y. Lin, S. Guo, and H. Wan, \u201cSpatial-temporal syn-\nchronous graph convolutional networks: A new framework for\nspatial-temporal network data forecasting,\u201d in Proceedings of the\nAAAI Conference on Artificial Intelligence, vol. 34, no. 01, 2020, pp.\n914\u2013921.\n\n[34] H. Shi, Q. Yao, Q. Guo, Y. Li, L. Zhang, J. Ye, Y. Li, and Y. Liu,\n\u201cPredicting origin-destination flow via multi-perspective graph\nconvolutional network,\u201d in 2020 IEEE 36th International Conference\non Data Engineering (ICDE). IEEE, 2020, pp. 1818\u20131821.\n\n[35] H. Yuan, G. Li, Z. Bao, and L. Feng, \u201cAn effective joint prediction\nmodel for travel demands and traffic flows,\u201d in 2021 IEEE 37th\nInternational Conference on Data Engineering (ICDE). IEEE, 2021,\npp. 348\u2013359.\n\n[36] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d\nNeural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n\n[37] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, \u201cEmpirical evalua-\ntion of gated recurrent neural networks on sequence modeling,\u201d\narXiv preprint arXiv:1412.3555, 2014.\n\n[38] Y. Li, R. Yu, C. Shahabi, and Y. Liu, \u201cDiffusion convolutional\nrecurrent neural network: Data-driven traffic forecasting,\u201d in In-\nternational Conference on Learning Representations. Vancouver, BC,\nCanada: ICLR, 2018, pp. 1 \u2013 16.\n\n[39] K. Cho, B. van Merrie\u0308nboer, D. Bahdanau, and Y. Bengio, \u201cOn\nthe properties of neural machine translation: Encoder\u2013decoder\napproaches,\u201d in Proceedings of SSST-8, Eighth Workshop on Syntax,\nSemantics and Structure in Statistical Translation. Doha, Qatar:\nAssociation for Computational Linguistics, Oct. 2014, pp. 103\u2013111.\n[Online]. Available: https://www.aclweb.org/anthology/W14-\n4012\n\n[40] D. Bahdanau, K. Cho, and Y. Bengio, \u201cNeural machine translation\nby jointly learning to align and translate,\u201d in 3rd International\nConference on Learning Representations. San Diego, CA, USA: ICLR,\n2015, pp. 7 \u2013 9.\n\n[41] Y. Liang, S. Ke, J. Zhang, X. Yi, and Y. Zheng, \u201cGeoman: Multi-\nlevel attention networks for geo-sensory time series prediction.\u201d\nin Proceedings of the 27th International Joint Conference on Artificial\nIntelligence. Stockholm, Sweden: IJCAI, 2018, pp. 3428\u20133434.\n\n[42] Y. Li and J. M. Moura, \u201cForecaster: A graph transformer for fore-\ncasting spatial and time-dependent data,\u201d in European Conference\non Artificial Intelligence (ECAI). Pitesti, Arges, Romania: EurAI,\n2020, p. 274.\n\n[43] S. Li, X. Jin, Y. Xuan, X. Zhou, W. Chen, Y.-X. Wang, and X. Yan,\n\u201cEnhancing the locality and breaking the memory bottleneck of\ntransformer on time series forecasting,\u201d Advances in Neural Infor-\nmation Processing Systems, vol. 32, pp. 5243\u20135253, 2019.\n\n[44] N. Kitaev, L. Kaiser, and A. Levskaya, \u201cReformer: The efficient\ntransformer,\u201d in International Conference on Learning Representations,\n2019.\n\n[45] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, \u201cA\ncomprehensive survey on graph neural networks,\u201d IEEE transac-\ntions on neural networks and learning systems, vol. 32, no. 1, pp. 4\u201324,\n2020.\n\n[46] T. Chen and C. Guestrin, \u201cXgboost: A scalable tree boosting\nsystem,\u201d in Proceedings of the 22nd acm sigkdd international conference\non knowledge discovery and data mining. San Francisco: ACM, 2016,\npp. 785\u2013794.\n\n[47] S. Xingjian, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c.\nWoo, \u201cConvolutional lstm network: A machine learning approach\nfor precipitation nowcasting,\u201d in Advances in neural information\nprocessing systems. Montreal, Quebec, Canada: ACM, 2015, pp.\n802\u2013810.\n\n[48] S. Guo, Y. Lin, N. Feng, C. Song, and H. Wan, \u201cAttention based\nspatial-temporal graph convolutional networks for traffic flow\nforecasting,\u201d in Proceedings of the AAAI Conference on Artificial\nIntelligence, vol. 33, no. 01, 2019, pp. 922\u2013929.\n\n\n"}
{"Title": "Improving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI", "Authors": "Erico Tjoa, Hong Jing Khok, Tushar Chouhan, Guan Cuntai", "Abstract": "  This paper quantifies the quality of heatmap-based eXplainable AI methods w.r.t image classification problem. Here, a heatmap is considered desirable if it improves the probability of predicting the correct classes. Different XAI heatmap-based methods are empirically shown to improve classification confidence to different extents depending on the datasets, e.g. Saliency works best on ImageNet and Deconvolution on ChestX-Ray Pneumonia dataset. The novelty includes a new gap distribution that shows a stark difference between correct and wrong predictions. Finally, the generative augmentative explanation is introduced, a method to generate heatmaps maps capable of improving predictive confidence to a high level.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00009", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Deep Neural Network Classification Confidence using\nHeatmap-based eXplainable AI\n\nErico Tjoa 1 2 Hong Jing Khok 1 Tushar Chouhan 1 Guan Cuntai 1\n\nAbstract\nThis paper quantifies the quality of heatmap-based\neXplainable AI methods w.r.t image classification\nproblem. Here, a heatmap is considered desir-\nable if it improves the probability of predicting\nthe correct classes. Different XAI heatmap-based\nmethods are empirically shown to improve classi-\nfication confidence to different extents depending\non the datasets, e.g. Saliency works best on Ima-\ngeNet and Deconvolution on Chest X-Ray Pneu-\nmonia dataset. The novelty includes a new gap\ndistribution that shows a stark difference between\ncorrect and wrong predictions. Finally, the gen-\nerative augmentative explanation is introduced,\na method to generate heatmaps maps capable of\nimproving predictive confidence to a high level.\n\n1. Introduction\nArtificial intelligence (AI) and machine learning (ML) mod-\nels have been developed with various levels of transparency\nand interpretability. Recent issues related to the responsible\nusage of AI have been highlighted by large companies like\nGoogle (Lakshmanan, 2021) and Meta (Pesenti, 2021); this\nmay reflect the increasing demand for transparency and in-\nterpretability, hence the demand for eXplainable Artificial\nIntelligence (XAI). In particular, the blackbox nature of a\ndeep neural network (DNN) is a well-known problem in\nXAI. Many attempts to tackle the problem can be found in\nsurveys like (Adadi & Berrada, 2018; Dos\u030cilovic\u0301 et al., 2018;\nGilpin et al., 2018; Tjoa & Guan, 2020a).\n\nPopular XAI methods include post-hoc methods such as\nLocal Interpretable Model-agnostic Explanations (LIME)\n(Ribeiro et al., 2016) and SHapley Additive exPlanations\n(SHAP) that uses a game-theoretical concept (Lundberg &\n\n*Equal contribution 1Nanyang Technological University, Sin-\ngapore 2Alibaba Inc. Correspondence to: Erico Tjoa <eri-\ncotjoa@gmail.com>.\n\nPaper is under review. This format is borrowed from Proceedings\nof the 39 th International Conference on Machine Learning, Balti-\nmore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the\nauthor(s).\n\nLee, 2017). Many heatmap-generating XAI methods have\nalso been developed for DNN, in particular Class Activation\nMappings (CAM) (Zhou et al., 2016; Selvaraju et al., 2016),\nLayerwise Relevance Propagation (LRP) (Bach et al., 2015)\nand many other well-known methods, as listed in afore-\nmentioned surveys papers. These methods are appealing\nbecause heatmap-like attributions are intuitive and easy to\nunderstand. Although there are other remarkable ways to\ninvestigate interpretability and explainability e.g. methods\nthat directly attempt to visualize the inner working of a DNN\n(Zeiler & Fergus, 2014; Olah et al., 2017; 2020), we do not\ncover them here. This paper focuses on heatmap-based\nmethods.\n\nQuantifying the quality of heatmap-based XAI meth-\nods. Several existing efforts have also been dedicated to\nquantitatively measure the quality of heatmaps and other ex-\nplanations. For example, heatmaps have been measured by\ntheir potentials to improve object localization performance\n(Zhou et al., 2016; Selvaraju et al., 2016). The pointing\ngame (Fong & Vedaldi, 2017; Rebuffi et al., 2020) is an-\nother example where localization concept is used to quan-\ntify XAI\u2019s performance. The \u201cmost relevant first\u201d (MORF)\nframework has also been introduced to quantify the explain-\nability of heatmaps by ordered removal of pixels based on\ntheir importance (Samek et al., 2017); the MORF paper\nalso emphasizes that there is a difference between compu-\ntational relevance and human relevance i.e. objects which\nalgorithms find salient may not be necessarily salient for a\nhuman observer. Others can be found e.g. in (Tjoa & Guan,\n2020b). This paper quantifies the quality of a heatmap\nbased on how much the heatmap improves classification\nconfidence.\n\nUsing heatmaps to improve the classification confidence\nof DNN. Heatmaps have been said to not \u201c[tell] us anything\nexcept where the network is looking at\u201d (Rudin, 2019). In\nthis work, we would like to refute such claims and show\nthat heatmaps can be computationally useful. To test the\nusefulness of heatmaps in a direct way, we perform the Aug-\nmentative eXplanation (AX) process: combine an image x\nwith its heatmap h to obtain higher probability of predict-\ning the correct class, e.g. if f(x) gives a 60% probability\nof making a correct prediction, we consider using h such\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n00\n\n9v\n2 \n\n [\ncs\n\n.L\nG\n\n] \n 8\n\n J\nan\n\n 2\n02\n\n2\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nthat f(x+ h) yields 65%. We empirically show that such\nimprovement is possible for existing XAI methods but it\ndoes not happen in general since heatmaps are usually not\ndesigned to explicitly improve prediction computationally.\nThis improvement is quantified through a metric we call the\nConfidence Optimization (CO) score. Briefly speaking, CO\nscore is a weighted difference between raw output values\nbefore and after heatmaps/attributions modify the images\nx+ h. The metric assigns a positive/negative score if x+ h\nincreases/decreases the probability of making the correct\nprediction.\n\nThis paper is arranged as the following. In the next sec-\ntion, AX and Generative AX (GAX) are demonstrated\nthrough a two-dimensional toy example. Explicit form\nof heatmaps/attribution values can be obtained in the toy\nexample, useful for lower level analysis and direct ob-\nservation. The following section describes dataset pre-\nprocessing, computation of CO scores for AX process\non existing XAI methods, formal definition GAX process\nand the results. We then present our results, starting with\nthe novel finding: distribution gap as correctness indica-\ntors, CO scores distribution for common XAI methods,\nfollowed by high scores attained by GAX heatmaps and\nfinally qualitative aspects of the methods. All codes are\navailable in https://github.com/ericotjo001/\nexplainable_ai/tree/master/gax.\n\n2. Formulation in Low Dimensional Space\n\nFigure 1. Solid red (blue) lines are x1(x2) components of sample\ndata x. Dotted red (blue) lines are h1(h2) components of heatmaps\nh with k\u03b7 = 1.2. Heatmap values or attribute importances are\nassigned large values when either (1) the true components a1, a2\ndiffer significantly (2) the W transforms the data heterogenously\ni.e. not \u03b8 \u2248 (2k + 1)\u03c0\n\n4\n. See interpretations in the main text for\n\nmore details.\n\nThe application presented in this paper is based on the fol-\nlowing concept. We illustrate the idea using binary clas-\nsification of data sample x \u2208 R2, a 2D toy example. Let\ny = W\u22121x where y \u2208 R2 and W \u2208 R2\u00d72 is invertible. Let\nthe true label/category of sample x be c = argmaxiyi so\nthat it is compatible with one-hot encoding usually used in\na DNN classification task. Conventions:\n\n1. Output space Y . Let the output variable be y =\na1\n(\n1\n0\n\n)\n+ a2\n\n(\n0\n1\n\n)\n, clearly an element of a vector space.\n\nThe shape of this vector is the same as the output\nshape of the last fully connected layer for the stan-\ndard binary classification. Class prediction can be per-\nformed in the winner-takes-all manner, for example, if\na1 = 1, a2 = 0, then the label is c = argmaxiyi = 1.\nIf a1 = 0.1, a2 = 0.5, then c = 2. Basis of Y is\nBY =\n\n{\ny(1) =\n\n(\n1\n0\n\n)\n, y(2) =\n\n(\n0\n1\n\n)}\n.\n\n2. Sample space X is a vector space with the correspond-\ning basis BX = {Wy : y \u2208 BY } = {x(1) =\nWy(1), x(2) = Wy(2)} so x = a1x\n\n(1) + a2x\n(2) \u2208 X .\n\n3. Pixelwise sample space is the same sample space, but\nwe specifically distinguish it as the sample space with\nthe canonical basis. We will need this later, because\npixelwise space has \u201chuman relevance\u201d, since human ob-\nservers perceive the components (pixels) directly, rather\nthan automatically knowing the underlying structure (i.e.\nwe cannot see a1, a2 directly). We denote a sample in\nthis basis with x = x1\n\n(\n1\n0\n\n)\n+ x2( 0\n\n1 ).\n\n4. A heatmap or attribute vector h in this paper has the\nsame shape as x and can be operated directly with x\nvia component-wise addition. Thus, they also belong to\nsample space or the pixelwise sample space. Writing\na heatmap in the sample space h = Ax(1) + Bx(2) is\nuseful for obtaining a closed form expression later.\n\nThe perfect classifier, f . Define f(x,\u0398) = \u03c3(\u0398x) as\na trainable classifier with parameters \u0398 \u2208 R2\u00d72. Let\n\u0398 = W\u22121 and the activation \u03c3 be any strictly monotonic\nfunction, like the sigmoid function. Then, the classifier\nf(x) = \u03c3(W\u22121x) \u2208 R2 is perfect, in the sense that,\nif a1 > a2, then c = argmaxifi(x) = 1; likewise if\na1 < a2, then c = 2 and, for a1 = a2 either decision\nis equally probable. This is easily seen as the following:\nf(x) = \u03c3(W\u22121(a1x\n\n(1)+a2x\n(2))) = \u03c3(a1\n\n(\n1\n0\n\n)\n+a2\n\n(\n0\n1\n\n)\n) =(\n\n\u03c3(a1)\n\u03c3(a2)\n\n)\n.\n\nConfidence optimization score (CO score), sco. In this\nsection, we show a simple explicit form of CO score for\nbetter illustration; in the experimental method section, for-\nmal definition will be given. The score increases if x + h\nleads to an improvement in the probability of correctly pre-\ndicting label c, hence the score\u2019s definition depends on the\ngroundtruth label. Throughout this section, for illustration,\nwe use x = a1x\n\n(1) + a2x\n(2) with groundtruth label c = 1,\n\ni.e. a1 > a2. Define the CO score as\n\nsco(x, h) =\n(\n\n1\n\u22121\n\n)\n\u00b7\n[\nf(x+ h)\u2212 f(x)\n\n]\n(1)\n\nFor the perfect classifier, see that f1(x + h) > f1(x) and\nf2(x + h) < f2(x) contribute to a larger sco. In other\n\nhttps://github.com/ericotjo001/explainable_ai/tree/master/gax\nhttps://github.com/ericotjo001/explainable_ai/tree/master/gax\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nwords, increasing the probability of predicting the correct\nlabel c = 1 increases the score. For c = 2, replace\n\n(\n1\n\u22121\n\n)\nwith\n\n(\u22121\n1\n\n)\n.\n\nAugmentative explanation. AX is defined here as any\nmodification on x by h that is intended to yield positive\nthe CO score, i.e to increase the probability of making a\ncorrect classification. This paper mainly considers the sim-\nplest implementation, namely x+ h. Let us consider a few\npossibilities. Suppose \u03c3 = LeakyReLU and h = x. We\nget sco =\n\n(\n1\n\u22121\n\n)\n\u00b7\n(\n\u03c3(2a1)\u2212\u03c3(a1)\n\u03c3(2a2)\u2212\u03c3(a2)\n\n)\n= a1 \u2212 a2 > 0. In other\n\nwords, choosing the image as the heatmap itself improves\nthe score. However, as a heatmap or attribute vector, h is\nuseless, since it does not provide us with any information\nabout the relative importance of the components of x in\ncanonical basis, which is the part of data directly visible to\nthe observer. Even so, h = x has computational relevance\nto the model, since a1, a2 are modified in the correct direc-\ntion. Our aim is to find computationally relevant h that does\nnot score zero in \u201chuman relevance\u201d, figuratively speak-\ning. We therefore rule out obviously uninformative heatmap\nin the upcoming sections. Further, consider similar situa-\ntion but set \u03c3 to sigmoid function. Simply setting h = x\nwill no longer increase the score significantly all the time.\nSince sigmoid is asymptotic, when a1, a2 are sufficiently\nfar away from zero, the increase will be so negligible, the\nheatmap will be uninformative even though the magnitude\nof |a1 \u2212 a2| may be large. Hence, we use the raw DNN\noutput in our main experiment, without sigmoid, softmax\netc.\n\nGenerative Augmentative EXplanation (GAX) is an AX\nprocess where the heatmap h = w \u2217 x is generated by\ntuning the trainable parameter w so that sCO is optimized;\n\u2217 denotes component/pixel-wise multiplication. Here we\nwill define \u2206 = s1 as the term that we maximize by hand,\nfor clarity and illustration. By comparison, in the main\nexperiment, we directly perform gradient descent on \u2212s1\n(plus regularization terms) to generate GAX heatmaps, i.e.\nwe minimize a total loss. To start with GAX, recall our\nchoice of heatmap written in sample space basis,\n\nh = w \u2217 x = Ax(1) +Bx(2) (2)\n\nThis form is desirable as it can be manipulated more easily\nthan the pixelwise sample space form h = (w1x1\n\nw2x2\n), as the\n\nfollowing. From RHS of eq. (2), get AWy(1) +BWy(2) =\nW\n(\nA\nB\n\n)\n. We thus have ( AB ) = W\u22121(w \u2217 x). To increase\n\nCO score, the aim is to find parameter w that maximizes\nA\u2212B, i.e. find w\u2217 = argmaxw(A\u2212B). Expanding the\nterms in w \u2217x of eq. (2), we obtain (w1\n\nw2\n) \u2217\n(\na1W11+a2W12\n\na2W21+a2W22\n\n)\n.\n\nTaking the difference between the components gives us\n\n\u2206 \u2261A\u2212B\n=w1(W\u22121\n\n11 \u2212W\n\u22121\n21 )(a1W11 + a2W12)\n\n\u2212 w2(W\u22121\n22 \u2212W\n\n\u22121\n12 )(a1W21 + a2W22)\n\n(3)\n\nMaximizing \u2206 to a large \u2206 > 0 will clearly optimize\nsco(x, h) = \u03c3(a1)\u2212 \u03c3(a2) + \u03c3(A)\u2212 \u03c3(B), assuming \u03c3 is\nstrictly monotonously increasing.\n\nHeatmap obtained through optimization using gradient\nascent. Recall that gradient ascent is done by \u2206 \u2192\n\u2206 + dw \u00b7 \u2207w\u2206 with the choice dw = \u03b7\u2207w\u2206, hence\n\u2206 + \u03b7||\u2207w\u2206||2 \u2265 \u2206. Hence, the heatmap after k steps\nof optimization is given by\n\nh =(w + kdw) \u2217 x\n\n=\n[\nw + k\u03b7\n\n(\n(W\u22121\n\n11 \u2212W\u22121\n21 )(a1W11+a2W12)\n\n\u2212(W\u22121\n22 \u2212W\u22121\n\n12 )(a1W21+a2W22)\n\n)]\n\u2217 x\n\n(4)\n\nTo visualize the heatmap, here we use the example where\nW is the rotation matrix W =\n\n(\ncos\u03b8 \u2212sin\u03b8\nsin\u03b8 cos\u03b8\n\n)\n. Examples\n\nof heatmaps plotted along with the input x are shown in\nfig. 1, to be discussed in the next subsection. If \u03b8 = 0, x\nare identical to y, so binary classification is straightforward\nand requires no explanation. Otherwise, consider \u03b8 being\na small deviation from 0. Such slightly rotated system is a\ngood toy-example for the demonstration of component-wise\n\u201cimportance attribution\u201d. This is because if x belongs to\ncategory c = 1 with high a1 component, then it still has a\nmore significant first component x1 after the small rotation.\nThus, a heatmap that correspondingly gives a higher score to\nthe first component is \u201ccorrect\u201d in the sense that it matches\nthe intuition of attribute importance: high h1 emphasizes\nthe fact that high x1 literally causes high y1. Furthermore,\nif the system rotates by \u03c0/4, we see that the classification\nbecomes harder. This is because the components x1 and\nx2 start to look more similar because cos\u03c04 = sin\u03c04 , and\nconsequently, the attribution values will be less prominent\nas well.\n\n2.1. Interpretability\n\nDISCLAIMER: for the benefit of readers who are used to\nregard heatmaps as the explanation or a method to perform\nlocalization, we must emphasize that this paper does not\nappeal to that ideal. To reiterate, in this paper, heatmaps are\nthe maps of pixel intensity that computationally optimize\nthe classification confidence.\n\nHomogenous and Heterogenous transformations. For the\nlack of better words, we refer to transformations like \u03b8 \u2248\n\u03c0/4 or more generally (2k+ 1)\u03c04 for k = ...,\u22121, 0, 1, ... as\nhomogenous transformations, since the components become\nmore indistinguishable (recall: cos\u03c04 = sin\u03c04 ). Otherwise,\nthe transformation is called heterogenous. These defini-\ntions are given here with the intention of drawing parallels\nbetween (1) the toy data that have been homogenously trans-\nformed (hence hard to distinguish) and (2) samples in real\ndatasets that look similar to each other, but are categorized\ndifferently due to a small, not obvious difference.\n\nInterpretation of attribute values for distinct non-negative\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\ncomponents. In the pixelwise sample space, we will be more\ninterested in non-negative data sample x1, x2 \u2265 0 since we\nonly pass [0, 1]-normalized images for GAX. Fig. 1 left\nshows a data sample with distinct components, indicated\nby high a1 = 0.95 component and low a2. Non-negative\ndata samples are found around \u03b8 \u2208 [0, \u03c0/2]. High x1 value\nis given high h1 attribution score while low x2 is given a\nsuppressed value of h2 near \u03b8 = 0, matching our intuition as\ndesired. As rotation proceeds to \u03c0/4, there is a convergence\nbetween x1 and x2, making the components more indistin-\nguishable. At \u03b8 = \u03c0/4 exactly, we still see high h1 that\npicks up high signal due to high a1, also as desired. Between\n\u03c0/4 and \u03c0/2, rotation starts to flip the components; in fact,\nat \u03c0/2, x = [0, 1] is categorized as c = 1 and x = [1, 0] as\nc = 2. The attribution value h2 becomes more prominent,\nhighlighting x2, also as desired for our prediction of class\nc = 1. In fig. 1 middle, decreased/increased a1, a2 are\nassigned less prominent h1, h2 respectively than fig. 1 left,\nsince the model becomes less confident in its prediction,\nalso consistent with our intuition.\n\nThe other extreme. Fig. 1 right shows a1 and a2 that do\nnot differ significantly. At homogeneous transformation\n\u03b8 \u2248 \u00b1\u03c04 , heatmaps are almost equal to the input x. As\nexpected, it will be difficult to pick up signals that are very\nsimilar, although very close inspection might reveal small\ndifferences that could probably yield some information (not\nin the scope of this paper). Other interpretations can be\nfound in appendix More interpretations in low dimensional\nexample.\n\n3. Experimental Method and Datasets\nIn the previous section, we described how heatmap h can be\nused to improve classification probability. More precisely,\nx+h yields higher confidence in making a correct prediction\ncompared to x alone when used as the input to the model f .\nWe apply the same method to real dataset ImageNet (Deng\net al., 2009) and Chest X-Ray Images (Pneumonia) from\nKaggle (Mooney, 2018). The Pneumonia dataset needs\nreshuffling, since Kaggle\u2019s validation dataset consists of\nonly of 16 images for healthy and pneumonia cases com-\nbined. We combined the training and validation datasets and\nthen randomly draw 266/1083 healthy and 790/3093 pneu-\nmonia images for validation/training. There are 234/390\nhealthy/pneumonia images in the test dataset. Images are\nall resized to 256 \u00d7 256. The X-Ray images are black\nand white, so we stack them to 3 channels. Images from\nImageNet are normalized according to suggestion in the py-\ntorch website, with mean = [0.485, 0.456, 0.406], std =\n[0.229, 0.224, 0.225].\n\nFor both datasets, we use pre-trained models Resnet34 (He\net al., 2016) and AlexNet (Krizhevsky, 2014) available in\nPytorch. The models are used on ImageNet without fine-\n\nTable 1. Fine-tuning results for pre-trained models on Chest X-\nRay Pneumonia test dataset. The architectures marked with sub\nare deliberately trained to achieve lower validation accuracy for\ncomparison.\n\nResnet34 1 Resnet34 sub Alexnet sub\n\naccuracy 0.800 0.636 0.745\nprecision 0.757 0.632 0.726\n\nrecall 1.000 1.000 0.951\nval. acc. 0.99 0.8 0.8\n\ntuning. Resnet34 is fine-tuned for Pneumonia binary classi-\nfications, where the first 8 modules of the pre-trained model\n(according to pytorch\u2019s arrangement) are used, plus a new\nfully-connected (FC) layer with two output channels at the\nend. Similarly, for Alexnet, the first 6 modules are used\nwith a two-channel FC at the end. For Resnet34, we will\nuse Resnet34 1 and Resnet34 sub respectively trained to\nachieve 99% and 80% validation accuracies for comparison.\nThe same targets were specified for Alexnet, but only 80%\nvalidation accuracy was achieved, thus only Alexnet sub\nwill be used. Adam optimizer is used with learning rate\n0.001, \u03b2 = (0.5, 0.999). The usual weight regularization\nis not used during optimization i.e. in pytorch\u2019s Adam op-\ntimizer, weight decay is set to zero because we allow zero\nattribution values in large patches of the images. No number\nof epochs are specified. Instead, training is stopped after the\nmax number of iterations (240000) or the specified valida-\ntion accuracy is achieved after 2400 iterations have passed.\nAt each iteration, samples are drawn uniform-randomly with\nbatch size 32.\n\nCO scores on existing XAI methods via AX process. De-\nnote the deep neural network as DNN, define the CO score\nas the weighted difference between the predictive scores\naltered by AX process and the original predictive scores,\n\nsco(x, h) = \u03ba \u00b7\n[\nDNN(x+ h)\u2212DNN(x)\n\n]\n(5)\n\nwhere \u03ba \u2208 RC is defined as the score constants, C the\nnumber of classes, \u03baj = 1 if the groundtruth belongs to\nlabel/category j and \u03bai = \u22121/(C \u2212 1) for all i 6= j.\nThis equation is the general form of eq. (1). In our im-\nplementation, each DNN\u2019s output is raw, i.e. last layer\nis FC with C channels without softmax layer etc. A\nheatmap h that yields sco = 0 is uninformative (see ap-\npendix). We compute CO scores for heatmaps gener-\nated by six different existing heatmap-based XAI meth-\nods (all available in Pytorch Captum), namely, Saliency\n(Simonyan et al., 2014), Input*Gradient (Shrikumar et al.,\n2016), Layer GradCAM (Selvaraju et al., 2016), Decon-\nvolution (Zeiler & Fergus, 2014), Guided Backpropaga-\ntion (Springenberg et al., 2015) and DeepLift (Shrikumar\net al., 2017). Each heatmap is generated w.r.t predicted\ntarget, not groundtruth e.g. if y pred=DNN(x) predicts\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 2. Distribution of CO scores obtained through AX process on existing XAI methods. Classification probability is improved if the\nscore is positive. All distributions show gaps between CO scores of data whose classes are correctly and wrongly predicted (e.g. red\narrows); correct prediction tends to yield higher CO scores. The result is obtained using Resnet34 1 on Pneumonia dataset. [sum] denotes\nAX process with x+ h.\n\nclass n, then h=DeepLIFT(net).attribute(input, target=n)\nin Pytorch Captum notation. Then normalization is applied\nh\u2192 h/max(|h|) before we perform the AX process. Note:\nFor ImageNet, C = 1000, chest X-Ray, C = 2. We also\nconsider f(x \u2217 h), where \u2217 denotes component-wise multi-\nplication. The idea is generally to interact h with x so that,\nfor any interaction g, higher probability of correct predic-\ntion is achieved by f(g(x, h)); see appendix for their results.\nGradCAM of \u2018conv1\u2019 layer is used in this paper. Other meth-\nods and different arbitrary settings are to be tested in future\nworks.\n\nAchieving high sco with GAX. Here, GAX is the x+h AX\nprocess where heatmaps h = tanh(w \u2217 x) are generated by\ntraining parameters w to maximize sco. Maximizing sco in-\ndefinitely is impractical, and thus we have chosen sco = 48\nfor ImageNet dataset, a score higher than most sco attained\nby existing XAI methods we tested in this experiment. Tanh\nactivation is used both to ensure non-linearity and to en-\nsure that the heatmap is normalized to [\u22121, 1] range, so\nthat we can make a fair comparison with existing heatmap-\nbased XAI methods. For ImageNet, 10000 data samples are\nrandomly drawn from the validation dataset for evaluating\nGAX. For pneumonia, all data samples are used. Optimiza-\ntion is done with Adam optimizer with learning rate 0.1,\n\u03b2 = (0.9, 0.999). This typically takes less than 50 steps of\noptimization, a few seconds per data sample using a small\nGPU like NVIDIA GeForce GTX 1050.\n\nSimilarity loss and GAX bias. In our implementation,\nwe minimize \u2212sco. However, this is prone to producing\nheatmaps that are visually imperceptible from the image.\nSince w is initialized as an array of 1s with exactly the same\nshape (c, h, w) = (3, 256, 256) as x, the initial heatmap is\n\nsimply h = w \u2217 x = x. Possibly, small changes in w over\nthe entire pixel space is enough to cause large changes in\nthe prediction, reminiscent of adversarial attack (Szegedy\net al., 2014; Akhtar & Mian, 2018). We solve this prob-\nlem by adding the similarity loss, penalizing h = x. The\noptimization is now done by minimizing the modified loss,\nwhich is negative CO score plus similarity loss\n\nloss = \u2212sco + ls\n\n\u2329 (h\u2212 x+ \u03b5)2\n\nx+ \u03b5\n\n\u232a\u22121\n\n(6)\n\nwhere ls = 100 is the similarity loss factor. \u3008X\u3009 computes\nthe average over all pixels. Division / and square 2 are\nperformed component/pixel-wise. Pixel-wise division by x\nnormalizes the pixel magnitude, so that small pixel values\ncan contribute more significantly to the average value. The\nsmall term \u03b5 = 10\u22124 is to prevent division by zero and pos-\nsibly helps optimization by ensuring that zero terms do not\nmake the gradients vanish. Furthermore, for X-Ray images,\nwith many zeros (black region), the similarity factor seems\ninsufficient, resulting in heatmaps that mirror the input im-\nages. GAX bias isa dded for the optimization to work, so\nthat h = w \u2217 x+ b, where b is 0.01 array of the same shape\n(c, h, w) as well. Note: the similarity loss is positive, since x\nused here is [0, 1] normalized (by comparison, the standard\nResnet34 normalization can result in negative pixels).\n\n4. Results and Discussions\nRecall that we use pre-trained models for ImageNet. For\npneumonia dataset, the predictive results of fine-tuning mod-\nels are shown in table 1. AX and GAX processes will be\napplied on top of these models.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 3. Similar to fig. 2, but results are obtained from (A) Resnet34 architecture on Pneumonia dataset, but with less fine-tuning\n(Resnet34 sub). (B) Resnet34 on ImageNet.\n\n4.1. Gaps in CO Scores Distribution\n\nHere, we present the main novel finding: the gap in CO\ndistribution. AX process neither specifies any formulas nor\noptimizes any losses to distinguish correct predictions from\nthe wrong ones, but fig. 2 shows distinct gaps between\nthem (shown by the red arrows). Possible reason: heatmaps\nused in AX process are generated for the class predicted\nby the DNN. If the prediction is correct, there is a match\nbetween cpred in e.g. h=DeepLIFT(net).attribute(input,\ntarget=cpred) (recall: we use Pytorch Captum notation) and\nthe groundtruth label c that that affects CO score through \u03ba.\nThe different distributions found in fig. 2 and 3 indicate that\nsome existing XAI methods possess more information to\ndistinguish between correct and wrong predictions than the\nothers. With this, we might be able to debunk some claims\nthat heatmaps are not useful (Rudin, 2019): regardless of the\nsubjective assessment of heatmap shapes, heatmaps might\nbe relatively informative after some post-processing. In the\nabsence of such information, we expect to see uniformly\nrandom distribution of scores. Since we have observed dis-\ntinct distributional gaps on top of general difference in the\nstatistics, we have shown that some heatmap-based XAI\nmethods combined with CO score might be a new indicator\nto help support classification decision made by the particular\nDNN architecture.\n\nFurthermore, the extent of CO score distribution gap is\nclearly dependent on the dataset and DNN architecture. As\nit is, the discriminative capability of different XAI methods\nis thus comparable only within the same system of archi-\ntecture and dataset. ImageNet dataset shows a smaller gap\ncompared to pneumonia dataset and the largest gap in Im-\nageNet is produced by the Saliency method, as seen in fig.\n3(B). By comparison, the largest gap in pneumonia dataset is\nproduced by Deconvolution. Comparing fig. 2 and fig. 3(A),\nthe gaps appear to be wider when DNN is better trained.\nFurther investigation is necessary to explain the above obser-\nvations, but, to leverage this property, users are encouraged\nto test AX process on different XAI methods to find the\nparticular method that shows the largest gap. Once the XAI\nmethod is determined, it can be used as a supporting tool\nand indicator for the correctness of prediction.\n\nFigure 4. CO score optimization through GAX x+ tanh(w \u2217 x)\non ImageNet data using pre-trained Resnet34 (blue) and Alexnet\n(red), where each curve corresponds to a single image. The target\nsco is set to 48, exceeding most CO scores of other methods.\n\n4.2. Improvement in Predictive Probability with GAX\n\nThe higher the CO scores are, the better is the improvement\nin predictive probability. Is it possible to achieve even higher\nimprovement, i.e. higher CO score? Fig. 2 and 3 show the\nboxplots of CO scores for AX process applied on all six XAI\nmethods we tested in this experiment; histograms applied on\nselect XAI methods are also shown. Different XAI methods\nachieve different CO scores. For pneumonia dataset, very\nhigh CO scores (over 80) are attained by Deconvolution\nmethods. For ImageNet, highest CO scores attained are\naround 10. To attain even higher scores, Generative AX\n(GAX) will be used.\n\nUsing GAX on ImageNet, sco \u2265 48 can be attained as\nshown in fig. 4, where the time evolution of CO score for\neach image is represented by a curve. For Resnet34, most\nof the images attains sco \u2265 48 within 50 iterations. Alexnet\nGAX optimization generally takes more iterations to achieve\nthe target. High sco implies high confidence in making the\ncorrect prediction. We have thus obtained heatmaps and\nattribution values with computational relevance i.e. they can\nbe used to improve the model\u2019s performance. Note: (1) all\nimages tested do attain the target sco (not shown), although\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 5. (A) GAX dynamic heatmaps displayed with a slider for users to observe the evolution of heatmaps through time steps. (B-E)\nGAX heatmaps generated on Resnet34 for (B) healthy chest X-Ray and (C) chest X-Ray of a patient with bacterial pneumonia; and for\nImageNet images (D) a sheep dog image and (E) a planetarium image. (F) An instance of bacterial pneumonia chest X-Ray showing\nan irregular posture with heavy noise (top right). The empty space might have been used as a false distinct feature for pneumonia\nclassification. Three heatmaps for each image correspond to the attribution values assigned to R, G and B color channels respectively.\n\u201cAbs max\u201d specifies the maximum absolute value attained by the heatmap throughout all three channels (max is 1, due to Tanh activation).\nPositive/negative heatmap or attribution values (red/blue) indicate pixels to be increased/reduced in intensity to attain higher prediction\nconfidence. At higher CO scores, negative values emerge.\n\nsome of the images took a few hundreds iterations (2) we\nexclude images where predictions are made incorrectly by\nthe pre-trained or fine-tuned model. By comparison, in\ngeneral, using heatmaps derived from existing methods for\nAX process does not yield positive CO scores i.e. does\nnot improve predictive probability for the correct class (see\nespecially fig. 3(B)). Furthermore, for ImageNet, typically,\nsco \u2264 10. Other boxplots are shown in appendix fig. 7.\n\n4.3. Qualitative Assessment of GAX Heatmaps\n\nHeatmaps in GAX are obtained through a process optimiza-\ntion through a finite number of time steps. We provide\nmatplotlib-based graphic user interface (GUI) for users to\nobserve the evolution of heatmap pixels through GAX; see\nfig. 5(A). This provides users some information about the\nway the DNN architecture perceives input images. But, how\nexactly can user interpret this? Recall that the main premise\nof this paper is the computational relevance: GAX is de-\nsigned to generate heatmaps that improve the confidence in\npredicting the correct label numerically. Hence, the visual\n\ncues generated by the GAX heatmaps show which pixels\ncan be increased or decreased in intensity to give higher\nprobability of making the correct prediction.\n\nDNN optimizes through extreme intensities. Heatmaps in\nfig. 5(B-E) show that predictive confidence is improved\ngenerally through optimizing regions of extreme intensity.\nFor example, to improve CO scores through GAX, the pix-\nels corresponding to white hair of the dog in fig. 5(D)\nare assigned positive values (red regions in the heatmaps).\nDark region of healthy chest X-Ray in (B) are subjected to\nstronger optimization (intense red or blue) to achieve better\npredictive confidence. The DNN architecture seems to be\nmore sensitive to changes in extreme values in the image.\nIn a positive note, this property might be exploited during\ntraining: this is probably why normalization to [\u22121, 1] range\nin the standard practice of deep learning optimization works\ncompared to [0, 1]. On the other hand, this might be a prob-\nlem to address in the future as well: heatmaps that boost\nalgorithmic confidence are not intuitive to human viewers.\nWe can ask the question: is it possible to train DNN such\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nthat its internal structure is inherently explainable (e.g. if\nlocalization is accepted as an explanation, does there exist\nan architecture whose predictive confidence is tied directly\nto localization?). For comparison, existing XAI methods\ntypically specify extra settings to obtain these explanations.\nUnfortunately, the settings can be arbitrary, e.g. GradCAM\npaper (Selvaraju et al., 2016) sets an arbitrary 15% threshold\nof max intensity for binarization. To obtain explanation with\nbetter integrity, the settings might need to be specified in\ncontext beforehand. In this paper, we do NOT address such\narbitrary settings taylored to attain subjectively acceptable\nexplanation or to maximize high IoU for bounding boxes.\n\nDiscriminatory but unrefined patterns. Pneumonia dataset\nconsists of chest X-Ray of healthy patients and patients with\nseveral types of pneumonia with different recognizable pat-\nterns. Bacterial pneumonia has a focal lobar consolidation,\nwhile viral pneumonia has diffuse interstitial patterns; nor-\nmal chest X-Ray has neither. This turns out to affect the\nshape of GAX heatmaps. Fig. 5(B) shows a typical normal\nChest X-Ray pattern. By comparison, fig. 5(C) shows a\nheatmap generated on bacterial pneumonia. In the latter, we\nsee the drastic change in the heatmap features, especially\nhigh-intensity stripes around the lobar consolidation. There\nis a possibility that novel class-discriminatory patterns lie\nhidden within heatmaps generated by GAX. The heatmaps\nappear unrefined, but this might be related to the internal\nstructures of the DNN architecture itself, as described in the\nfollowing section.\n\nLimitations and Future works. We have offered some\nplausible explanations on heatmaps generated through our\nmethod GAX that are consistent with success of standard\ndeep learning training pipeline. Now, we discuss possible\nways to address the issues we briefly presented in the pre-\nvious sections and how they can be addressed in the future.\n(1) Optimized regions prefer extreme intensities (very bright\nor very dark regions). The heatmaps in fig. 5(B-E) indicate\nthat we are able to optimize predictive probability through\nrelative intensity manipulation of pixel patterns that are not\nhumanly intuitive. To truly capture variations in patterns\nand not rely heavily on large difference in intensity, a layer\nor module specifically designed to output very smooth repre-\nsentation might be helpful. Training might take longer, but\nwe hypothesize that skewed optimization through extreme\nintensity can be prevented. (2) Some optimized features\nare rife with artifact-looking patterns. An immediate hy-\npothesis that we can offer is the following. The internal\nstructure of the DNN (the set of weights) is noisy, thus, even\nif features are properly captured, they are amplified through\nnoisy channels, yielding artifacts. This is indicative of the\ninstability of high dimensional neuron activations in a DNN,\na sign of fragility against adversarial attack we previously\nmentioned. How should we address this? We need DNN\nthat are robust against adversarial attack; fortunately, many\n\nresearchers have indeed worked on this problem recently.\n(3) The regularity of data distribution is probably an impor-\ntant deciding factor in model training. In cases where the\nX-Ray images are not taken in a regular posture, the empty\nspace can become a false \u201cdistinct feature\u201d, as shown in fig.\n5(F). While this may indicate a worrying trend in the flawed\ntraining of DNN or data preparation (hence a misguided ap-\nplication) we believe GAX can be used to detect such issue\nbefore deployments. Related future studies may be aimed at\nquantifying the effect of skewed distribution on the appear-\nance of such \u201cfalse prediction\u201d cases. (4) Finally, depending\non the explanation context, ground-truth explanations might\nbe the most desirable features in XAI: we specify exactly\nwhat we want as the correct explanation. The ideal heatmaps\nmay for example resemble object-localization-mask or high-\nlight only relevant parts. Also see appendix for more, e.g.\nimplementation-specific limitations etc.\n\n5. Conclusion\nWe have investigated a method to use heatmap-based XAI\nmethods to improve DNN\u2019s classification performance. The\nmethod itself is called the AX process, and the improve-\nment is measured using a metric called the CO score. Some\nheatmaps can be directly used to improve model\u2019s predic-\ntion better than the others as seen by the boxplots of score\ndistribution. The distribution of scores shows a novel gap\ndistribution, an interesting feature that develops without any\nspecific optimization. GAX is also introduced to explicitly\nattain high improvement in predictive performance or help\ndetect issues. This work also debunks claims that heatmaps\nare not useful through the improvement of predictive confi-\ndence. We also give explanations on DNN behaviour con-\nsistent with the standard practice of deep learning training.\nFrom the results, we support the notion that computationally\nrelevant features are not necessarily relevant to human.\n\nSummary of novelties and contributions: (1) CO scores pro-\nvide empirical evidence for informative content of heatmaps\n(2) the distribution gap in CO scores may be a new indi-\ncator in predictive modelling (3) distinct (albeit unrefined)\nclass-dependent patterns that emerge on GAX-generated\nheatmaps could be used as discriminative signals. Overall,\nwe also provide insights into the DNN\u2019s behaviour.\n\nSoftware and Data\nAll codes are available; see main paper and also see ap-\npendix.\n\nAcknowledgements\nThis research was supported by Alibaba Group Holding Lim-\nited, DAMO Academy, Health-AI division under Alibaba-\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nNTU Talent Program. The program is the collaboration\nbetween Alibaba and Nanyang Technological University,\nSingapore.\n\nReferences\nAdadi, A. and Berrada, M. Peeking inside the black-box: A\n\nsurvey on explainable artificial intelligence (xai). IEEE\nAccess, 6:52138\u201352160, 2018. doi: 10.1109/ACCESS.\n2018.2870052.\n\nAkhtar, N. and Mian, A. Threat of adversarial attacks on\ndeep learning in computer vision: A survey. IEEE Ac-\ncess, 6:14410\u201314430, 2018. doi: 10.1109/ACCESS.2018.\n2807385.\n\nBach, S., Binder, A., Montavon, G., Klauschen, F., Mu\u0308ller,\nK.-R., and Samek, W. On pixel-wise explanations for\nnon-linear classifier decisions by layer-wise relevance\npropagation. PLOS ONE, 10(7):1\u201346, 07 2015. doi:\n10.1371/journal.pone.0130140. URL https://doi.\norg/10.1371/journal.pone.0130140.\n\nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and\nFei-Fei, L. Imagenet: A large-scale hierarchical\nimage database. In 2009 IEEE conference on com-\nputer vision and pattern recognition, pp. 248\u2013255.\nIeee, 2009. URL https://www.kaggle.com/c/\nimagenet-object-localization-challenge.\n\nDos\u030cilovic\u0301, F. K., Brc\u030cic\u0301, M., and Hlupic\u0301, N. Explainable arti-\nficial intelligence: A survey. In 2018 41st International\nConvention on Information and Communication Tech-\nnology, Electronics and Microelectronics (MIPRO), pp.\n0210\u20130215, 2018. doi: 10.23919/MIPRO.2018.8400040.\n\nFong, R. C. and Vedaldi, A. Interpretable explanations of\nblack boxes by meaningful perturbation. In 2017 IEEE\nInternational Conference on Computer Vision (ICCV), pp.\n3449\u20133457, 2017. doi: 10.1109/ICCV.2017.371.\n\nGilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M.,\nand Kagal, L. Explaining explanations: An overview of\ninterpretability of machine learning. In 2018 IEEE 5th\nInternational Conference on Data Science and Advanced\nAnalytics (DSAA), pp. 80\u201389, 2018. doi: 10.1109/DSAA.\n2018.00018.\n\nHe, K., Zhang, X., Ren, S., and Sun, J. Deep residual\nlearning for image recognition. 2016 IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), pp.\n770\u2013778, 2016.\n\nKrizhevsky, A. One weird trick for parallelizing convolu-\ntional neural networks. ArXiv, abs/1404.5997, 2014.\n\nLakshmanan, L. Why you need to explain\nmachine learning models, Jun 2021. URL\nhttps://cloud.google.com/blog/\nproducts/ai-machine-learning/\nwhy-you-need-to-explain-machine-learning-models.\n\nLundberg, S. M. and Lee, S.-I. A unified approach\nto interpreting model predictions. In Guyon, I.,\nLuxburg, U. V., Bengio, S., Wallach, H., Fer-\ngus, R., Vishwanathan, S., and Garnett, R. (eds.),\nAdvances in Neural Information Processing Sys-\ntems 30, pp. 4765\u20134774. Curran Associates, Inc.,\n2017. URL http://papers.nips.cc/paper/\n7062-a-unified-approach-to-interpreting-model-predictions.\npdf.\n\nMooney, P. Chest x-ray images (pneumo-\nnia), Mar 2018. URL https://www.\nkaggle.com/paultimothymooney/\nchest-xray-pneumonia.\n\nOlah, C., Mordvintsev, A., and Schubert, L. Feature\nvisualization. Distill, 2(11), November 2017. doi:\n10.23915/distill.00007. URL https://doi.org/10.\n23915%2Fdistill.00007.\n\nOlah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert,\nL., Ye, K., and Mordvintsev, A. The building blocks of\ninterpretability, Jan 2020. URL https://distill.\npub/2018/building-blocks.\n\nPesenti, J. Facebook\u2019s five pillars of responsible ai, Jun\n2021. URL https://ai.facebook.com/blog/\nfacebooks-five-pillars-of-responsible-ai/.\n\nRebuffi, S. A., Fong, R., Ji, X., and Vedaldi, A. There and\nback again: Revisiting backpropagation saliency methods.\nIn 2020 IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pp. 8836\u20138845, 2020. doi:\n10.1109/CVPR42600.2020.00886.\n\nRibeiro, M. T., Singh, S., and Guestrin, C. \u201cwhy\nshould i trust you?\u201d: Explaining the predictions of\nany classifier. In Proceedings of the 22nd ACM\nSIGKDD International Conference on Knowledge Dis-\ncovery and Data Mining, KDD \u201916, pp. 1135\u20131144,\nNew York, NY, USA, 2016. Association for Comput-\ning Machinery. ISBN 9781450342322. doi: 10.1145/\n2939672.2939778. URL https://doi.org/10.\n1145/2939672.2939778.\n\nRudin, C. Stop explaining black box machine learning\nmodels for high stakes decisions and use interpretable\nmodels instead. Nature Machine Intelligence, 1(5):206\u2013\n215, May 2019. ISSN 2522-5839. doi: 10.1038/\ns42256-019-0048-x. URL https://doi.org/10.\n1038/s42256-019-0048-x.\n\nhttps://doi.org/10.1371/journal.pone.0130140\nhttps://doi.org/10.1371/journal.pone.0130140\nhttps://www.kaggle.com/c/imagenet-object-localization-challenge\nhttps://www.kaggle.com/c/imagenet-object-localization-challenge\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttps://cloud.google.com/blog/products/ai-machine-learning/why-you-need-to-explain-machine-learning-models\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttp://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\nhttps://doi.org/10.23915%2Fdistill.00007\nhttps://doi.org/10.23915%2Fdistill.00007\nhttps://distill.pub/2018/building-blocks\nhttps://distill.pub/2018/building-blocks\nhttps://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/\nhttps://ai.facebook.com/blog/facebooks-five-pillars-of-responsible-ai/\nhttps://doi.org/10.1145/2939672.2939778\nhttps://doi.org/10.1145/2939672.2939778\nhttps://doi.org/10.1038/s42256-019-0048-x\nhttps://doi.org/10.1038/s42256-019-0048-x\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nSamek, W., Binder, A., Montavon, G., Lapuschkin, S., and\nMu\u0308ller, K. Evaluating the visualization of what a deep\nneural network has learned. IEEE Transactions on Neu-\nral Networks and Learning Systems, 28(11):2660\u20132673,\n2017.\n\nSelvaraju, R. R., Das, A., Vedantam, R., Cogswell,\nM., Parikh, D., and Batra, D. Grad-cam: Why\ndid you say that? visual explanations from deep\nnetworks via gradient-based localization. CoRR,\nabs/1610.02391, 2016. URL http://arxiv.org/\nabs/1610.02391.\n\nShrikumar, A., Greenside, P., Shcherbina, A., and Kun-\ndaje, A. Not just a black box: Learning important fea-\ntures through propagating activation differences. ArXiv,\nabs/1605.01713, 2016.\n\nShrikumar, A., Greenside, P., and Kundaje, A. Learn-\ning important features through propagating activa-\ntion differences. volume 70 of Proceedings of Ma-\nchine Learning Research, pp. 3145\u20133153, International\nConvention Centre, Sydney, Australia, 06\u201311 Aug\n2017. PMLR. URL http://proceedings.mlr.\npress/v70/shrikumar17a.html.\n\nSimonyan, K., Vedaldi, A., and Zisserman, A. Deep inside\nconvolutional networks: Visualising image classification\nmodels and saliency maps. In Workshop at International\nConference on Learning Representations, 2014.\n\nSpringenberg, J. T., Dosovitskiy, A., Brox, T., and Ried-\nmiller, M. A. Striving for simplicity: The all convolu-\ntional net. CoRR, abs/1412.6806, 2015.\n\nSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,\nD., Goodfellow, I., and Fergus, R. Intriguing properties\nof neural networks. CoRR, abs/1312.6199, 2014.\n\nTjoa, E. and Guan, C. A survey on explainable artificial in-\ntelligence (xai): Toward medical xai. IEEE Transactions\non Neural Networks and Learning Systems, pp. 1\u201321,\n2020a. doi: 10.1109/TNNLS.2020.3027314.\n\nTjoa, E. and Guan, C. Quantifying explainability of saliency\nmethods in deep neural networks. ArXiv, abs/2009.02899,\n2020b.\n\nZeiler, M. D. and Fergus, R. Visualizing and understanding\nconvolutional networks. In Fleet, D., Pajdla, T., Schiele,\nB., and Tuytelaars, T. (eds.), Computer Vision \u2013 ECCV\n2014, pp. 818\u2013833, Cham, 2014. Springer International\nPublishing. ISBN 978-3-319-10590-1.\n\nZhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba,\nA. Learning deep features for discriminative localization.\nIn 2016 IEEE Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pp. 2921\u20132929, June 2016. doi:\n10.1109/CVPR.2016.319.\n\nhttp://arxiv.org/abs/1610.02391\nhttp://arxiv.org/abs/1610.02391\nhttp://proceedings.mlr.press/v70/shrikumar17a.html\nhttp://proceedings.mlr.press/v70/shrikumar17a.html\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nA. Appendix\nAll codes are available in the supplementary materials. All instructions to reproduce the results can be found in README.md,\ngiven as command line input, such as:\n\n1. python main pneu.py \u2013mode xai collect \u2013model resnet34 \u2013PROJECT ID pneu256n 1 \u2013method Saliency \u2013split train\n\u2013realtime print 1 \u2013n debug 0\n\n2. python main pneu.py \u2013mode gax \u2013PROJECT ID pneu256n 1 \u2013model resnet34 \u2013label NORMAL \u2013split test \u2013\nfirst n correct 100 \u2013target co 48 \u2013gax learning rate 0.1\n\nThe whole experiment can be run on small GPU like NVIDIA GeForce GTX 1050 with 4 GB dedicated memory.\n\nThe codes are run on Python 3.8.5. The only specialized library used is Pytorch (specifically torch==1.8.1+cu102,\ntorchvision==0.9.1+cu102) and Pytorch Captum (captum==0.3.1). Other libraries are common python libraries.\n\nRegarding Captum. We replace Pytorch Captum \u201cinplace relu\u201d so that some attribution methods will work properly (see\nadjust for captum problem in model.py where applicable).\n\nWe also manually edit non-full backward hooks in the source codes to prevent the gradient propagation is-\nsues. For example, from Windows, see Lib \\site-packages \\captum \\attr \\ core \\guided backprop deconvnet.py,\nfunction def register hooks(self, module: Module). There is a need to change from hook = module. regis-\nter backward hook(self. backward hook) to hook = module. register full backward hook(self. backward hook).\n\nA.1. More interpretations in low dimensional example\n\nInterpretation of attribute values for non-negative less distinct components. Now, we consider data sample with lower\na1 = 0.7 (i.e. less distinct) but components are still non-negative. Fig. 1 middle shows that components are still non-\nnegative around \u03b8 \u2208 [\u03c0/8, 3\u03c0/8]. Similar attribution of h1 and suppression of h2 are observed similarly although with\nlower magnitude around \u03b8 \u2248 0. At \u03b8 \u2248 \u03c0/4, similar difficulty in distinguishing homogenous transformation is present,\nnaturally. Further rotation to 3\u03c0/8 will give higher h2 as well. Fig. 6 right shows similar behavior even for a1 \u2248 a2,\nthough non-negative values are observed for rotations around [\u2212\u03c0/4, \u03c0/4]. The sample is barely categorized as c = 1 since\na1 > a2. However, the resulting attribution values still highlights the positive contribution x1, primarily through higher h1\nattribution value, even though the magnitudes are lower compared to previous examples.\n\nInterpretation of attribute values for negative components. Beyond the rotation range that yields non-negative components,\nwe do see negative components xi < 0 assigned highly negative hi values. For example, fig. 6 left at \u03b8 \u2248 \u03c0 shows a rotation\nof the components to the negatives. In this formulation, negative attribution values are assigned to negative components\nnaturally, because w \u2217 x starts with wi = 1 and xi < 0, as wi is optimized, our example shows an instance where, indeed,\nwe need higher wi, very negative h1. Recall the main interpretation. In the end, this high negative attribution is aimed at\nimproving CO score. The large negative h1 component increases the likelihood of predicting c = 1; conversely, the relatively\nlow h2 magnitude increases the same likelihood. Therefore, we do not immediately conclude that negative attribution values\ncontribute \u201cnegatively\u201d to prediction, which is a term sometimes ambiguously used in XAI community. In practice, case by\ncase review may be necessary.\n\nA.2. Zero CO scores and other scores\n\nZero CO score might occur when when h yields uniform change to the output, i.e. DNN(x+ h) = DNN(x) + c for some\nconstant c. This is obtained by simply plugging into the CO score formula. Special case may occur when h is constant\nover all pixels, especially when N(g(x+ h)) = N(g(x)) for some intermediate normalization layer N and intermediate\npre-normalized composition of layers g = gk \u25e6 gk\u22121 \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 g1.\n\nPositive CO score indicates that the component [sco]i, where i corresponds to the groundtruth label, is increased by h at\na greater magnitude than the average of all other components, which in turn means that the component DNN(x + h)i\nis similarly increased at greater magnitude compared to the average of other components. Hence, the prediction favours\ncomponent i relatively more, i.e. the probability of predicting the correct class is increased. Negative CO score is simply the\nreverse: probability of predicting the correct class has been reduced relatively.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 6. Solid red (blue) lines are x1(x2) components of sample data x. Dotted red (blue) lines are h1(h2) components of heatmaps\nh with k\u03b7 = 1.2. Heatmap values or attribute importances are assigned large values when either (1) the true components a1, a2 differ\nsignificantly (2) the W transforms the data heterogenously i.e. not \u03b8 \u2248 (2k + 1)\u03c0\n\n4\n.\n\nA.3. More Boxplots of CO Scores.\n\nFig. 7 shows more variations of CO scores in our experiments, similar to the ones shown in the main text. Some scores\nclearly demonstrate distinct gaps in CO scores between the correct and wrong predictions.\n\nFrom fig. 8, AX process is applied to the heatmaps generated in different layers of ResNet34. We expect higher improvement\nof CO scores for AX process using heatmaps from deeper layers that are known to detect more features. We do observe a\ndifference in x \u2217 h AX process, but not in x+ h for Layer Grad CAM.\n\nA.4. More Considerations, Limitations and Future Works\n\nDifferent GAX and empirical choices in implementation. Parts of the implementations, such as the initialization of w to 1.0,\nare nearly arbitrary, though it is the first choice made from the 2D example that happens to work. Different implementations\ncome with various trade-offs. Most notably, the choice of learning rate 0.1 is manually chosen for its reliable and fast\nconvergence, although convergence is attainable for smaller learning rate like 0.001 after longer iterations. However, we\nneed to include more practical considerations. For example, saving heatmaps iteration by iteration will generally consume\naround 5-12 MB of memory for current choices. Longer optimization iterations may quickly cause a blow-up, and there is\nno known fixed number of iterations needed to achieve convergence to the target CO score. Saving heatmaps at certain\nCO scores milestones can be considered, though we might miss out on important heatmap changes in between. Parameter\nselection process is thus not straightforward. For practical purposes, learning rates can be tested in order of ten, 10n, and\nother parameters can be tested until a choice is found where each optimization process converges at a rate fast enough for\nnearly instantaneous, quick diagnosis. Other choices of optimizers with different parameters combination can be explored as\nwell, though we have yet to see dramatic changes.\n\nGAX, different DNN architectures and different datasets. Comparisons are tricky, since different architectures might behave\ndifferently at their FC end. For example, for Saliency method on ImageNet, Alexnet\u2019s boxplot of CO scores in appendix\nfig. 7(A) right (AX process x + w \u2217 x) shows a wider range of CO scores than that of Resnet34 in fig. ??. Comparison\nof CO scores on Chest X-Ray dataset shows even larger variability. Furthermore, recall that we illustrated using the 2D\nexample the reason we avoid sigmoid function: suppressed change in the CO score due to its asymptotic part. We have\navoided Softmax for similar reason, and a further study can be conducted to characterize the scores with Softmax or other\nmodifications. From here, the ideal vision is to develop a model that scales with CO score in not only a computationally\nrelevant way, but also in a human relevant way: we want a model that increases predictive probability when the heatmap\nhighlights exactly the correct localization of the objects or highly relevant features related to the objects. This is a tall effort,\nparticularly because explanations are highly context dependent. Transparent and trustworthy applications of DNN may\nbenefit from the combined improvements in humanly understandable context and computationally relevance attributions\nbuilt around that context.\n\n\n\nImproving Deep Neural Network Classification Confidence using Heatmap-based eXplainable AI\n\nFigure 7. Boxplots of CO scores for existing XAI methods, including another GAX implementation x \u2217 h = x \u2217 (w \u2217 x)\n.\n\nFigure 8. Boxplots of CO scores for heatmaps from Layer GradCAM for ResNet34 and ImageNet dataset. CO scores of heatmaps\ngenerated from different layers (and resized accordingly) are shown.\n\n.\n\n\n"}
{"Title": "Locally finite free space as limiting case of PT-symmetric medium", "Authors": "Mohammad Hasan, Mohammad Umar, Bhabani Prasad Mandal", "Abstract": "  We explicitly prove that the transfer matrix of a finite layered $PT$-symmetric system of fix length $L$ consisting of $N$ units of the potential system `$+iV$' and `$-iV$' of equal thickness becomes a unit matrix in the limit $N \\rightarrow \\infty$. This result is true for waves of arbitrary wave vector $k$. This shows that in this limit, the transmission coefficient is always unity while the reflection amplitude is zero for all waves traversing this length $L$. Therefore, a free space of finite length $L$ can be represented as a $PT$-symmetric medium.      ", "Subject": "Quantum Physics (quant-ph)", "ID": "arXiv:2201.00010", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocally finite free space as limiting case of\nPT -symmetric medium\n\nMohammad Hasan 1,3, Mohammad Umar 2 Bhabani Prasad Mandal 3\n\n1Indian Space Research Organisation, Bangalore-560094, INDIA\n2 Indian Institute of Technology, Delhi-110016, INDIA.\n\n3Department of Physics, Banaras Hindu University, Varanasi-221005, INDIA.\n\nAbstract\n\nWe explicitly prove that the transfer matrix of a finite layered PT -symmetric system of fix\nlength L consisting of N units of the potential system \u2018+iV \u2019 and \u2018\u2212iV \u2019 of equal thickness\nbecomes a unit matrix in the limit N \u2192 \u221e. This result is true for waves of arbitrary\nwave vector k. This shows that in this limit, the transmission coefficient is always unity\nwhile the reflection amplitude is zero for all waves traversing this length L. Therefore, a\nfree space of finite length L can be represented as a PT -symmetric medium.\n\n1e-mail address: mhasan@isro.gov.in, mohammadhasan786@gmail.com\n2e-mail address: pha212475@iitd.ac.in\n3e-mail address: bhabani.mandal@gmail.com, bhabani@bhu.ac.in\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n0v\n1 \n\n [\nqu\n\nan\nt-\n\nph\n] \n\n 3\n0 \n\nD\nec\n\n 2\n02\n\n1\n\n\n\n1 Introduction\n\nAround two decades ago, it was discovered that certain class of non-Hermitian Hamil-\ntonian can support real energy eigen values provided the Hamiltonian is invariant under\na combine parity (P) and time-reversal (T) operation [1]. It was also noted that that a\nfully consistent quantum theory can be developed for non-Hermitian system in a modi-\nfied Hilbert space through the modification of inner product which restore the equivalent\nHermiticity and the unitary time evolution of the system[2, 3]. Since then a new dimen-\nsion in quantum mechanics has emerged known as PT -symmetric quantum mechanics [4].\nThe non-Hermitian Hamiltonian display several new features which are originally absent\nin Hermitian Hamiltonians. The important features are exceptional points (EPs) [5, 6],\nspectral singularity (SS) [7]-[10], coherent perfect absorption (CPA) [10]-[15], critical cou-\npling (CC) [16]-[19] and CPA-laser [20]. Others notable features are invisibility [21, 22, 23]\nand reciprocity [24]. CPA and SS have also been studied in the context of non-Hermitian\nspace fractional quantum mechanics [25]. Phenomena of SS have also been studied in the\ndomain of quaternionic quantum mechanics [26].\n\nA quantum vacuum has fluctuations due to particle and anti-particle creations and\nannihilations in such a way that creations and annihilations balances each other to keep\nthe net charge neutrality of the vacuum. In a sufficiently small time interval, a snap\nshot of the vacuum will contain equal number of particle/anti-particles pairs or waves of\ncomplex frequencies having positive and negatives components of imaginary part. If the\ncreation and annihilation of the particles are respectively \u2018gain\u2019 and \u2018loss\u2019 component for\nthe vacuum system (and vice-versa for anti-particles), then the snap shot of the vacuum\nwill be a PT -symmetric system. In other words quantum vacuum is stable under PT -\nsymmetry.\n\nOur motivation for the present work arises due to the arguments presented in the\nabove paragraph. In order to check that whether vacuum can be represented as PT -\nsymmetric system, we consider a finite layered PT -symmetric system of fix length L\nconsisting of N units of the potential systems \u2018+iV \u2019 and \u2018\u2212iV \u2019 of equal thickness \u2018b\u2019\nwithout any intervening gap between the individual potential systems. It is shown that\nin the limit N \u2192\u221e such that 2Nb = L, the entire PT -symmetric system of finite length\nL is equivalent to an empty space of length L in all aspect. We prove this by showing\nthat the transfer matrix of our PT -symmetric system of length L is a unit matrix in the\nabove limiting case for particles of any wave vector k incident on this system.\n\nWe organize the paper as follows: In section 2 we briefly discuss the transfer matrix for\none dimensional scattering. In section 3 we calculate the transfer matrix for our layered\nPT -symmetric system and evaluate the limiting case N \u2192 \u221e of the finite length PT -\nsymmetric medium in section 4. We present results and associated discussion in section\n5.\n\n2\n\n\n\n2 Transfer matrix\n\nThe Hamiltonian operator in one dimension for a non-relativistic particle is (in the unit\n~ = 1 and 2m = 1)\n\nH = \u2212 d2\n\ndx2\n+ V (x), (1)\n\nwhere V (x) \u2208 C . V (x) \u2192 0 as x \u2192 \u00b1\u221e. If\n\u222b\nU(x)dx, where U(x) = (1 + |x|)V (x) is\n\nfinite over all x, then the Hamiltonian given above admits a scattering solution with the\nfollowing asymptotic values\n\n\u03c8(k, x\u2192 +\u221e) = A+(k)eikx +B+(k)e\u2212ikx, (2)\n\n\u03c8(k, x\u2192 \u2212\u221e) = A\u2212(k)eikx +B\u2212(k)e\u2212ikx. (3)\n\nThe coefficients A\u00b1, B\u00b1 are connected through a 2\u00d72 matrix M , called as transfer matrix\nas given below, (\n\nA+(k)\nB+(k)\n\n)\n= M(k)\n\n(\nA\u2212(k)\nB\u2212(k)\n\n)\n. (4)\n\nWhere,\n\nM(k) =\n\n(\nM11(k) M12(k)\nM21(k) M22(k)\n\n)\n. (5)\n\nWith the knowledge of the transfer matrix M(k), the transmission and reflection coeffi-\ncient are obtained as,\n\ntl(k) =\n1\n\nM22(k)\n= tr(k), rl(k) = \u2212 M12\n\nM22(k)\n, rr(k) =\n\nM21\n\nM22(k)\n. (6)\n\nThe transfer matrix shows composition property. If the transfer matrix for two non-\noverlapping finite scattering regions V1 and V2 , where V1 is to the left of V2, are M1 and\nM2 respectively, then the net transfer matrix Mnet of the whole system (V1 and V2) is\n\nMnet = M2.M1 . (7)\n\nThe composition result can be generalized for arbitrary numbers of non-overlapping fi-\nnite scattering regions. Knowing the transfer matrix, one easily compute the scattering\ncoefficients by using Eq. 6. From Eq. 6, it is also seen that if the diagonal elements\nare unity and off-diagonal elements are zero, then we always have tl(k) = 1 = tr(k) and\nrl(k) = 0 = rr(k). This case of transfer matrix represent empty space.\n\n3 Transfer matrix of layered PT -symmetric system\n\nFig 2 shows the layered PT -symmetric system which is made by periodic repetitions of\n\u2018unit cell\u2019 PT -symmetric system shown in Fig 1. It can be shown that the transfer matrix\n\n3\n\n\n\nFigure 1: A PT -symmetric \u2018unit cell\u2019 consisting of a pair of complex conjugate barrier.\ny-axis represent the imaginary height of the potential.\n\nFigure 2: A periodic PT -symmetric potential made by the periodic repetition of the \u2018unit\ncell\u2019 potential shown in Fig 1. y-axis represent the imaginary height of the potential.\n\n4\n\n\n\nof the \u2018unit cell\u2019 system is\n\nM(k) =\n\n(\n(\u03be + i\u03c7)e\u22122ikb i(\u03b7 \u2212 \u03c4)e\u22122ikb\n\ni(\u03b7 + \u03c4)e2ikb (\u03be \u2212 i\u03c7)e2ikb\n\n)\n. (8)\n\n\u03be =\n1\n\n2\n(cos 2\u03b1 + cosh 2\u03b2)\u2212 cos 2\u03c6(cosh2 \u03b2 sin2 \u03b1 + cos2 \u03b1 sinh2 \u03b2), (9)\n\n\u03c7 =\n1\n\n2\n(U+ cos\u03c6 sin 2\u03b1 + U\u2212 sin\u03c6 sinh 2\u03b2). (10)\n\n\u03b7 =\n1\n\n2\n(cosh 2\u03b2 \u2212 cos 2\u03b1) sin 2\u03c6. (11)\n\n\u03c4 =\n1\n\n2\n(U+ sin\u03c6 sinh 2\u03b2 + U\u2212 cos\u03c6 sin 2\u03b1). (12)\n\nIn the above equations, U\u00b1 = k\n\u03c1\n\u00b1 \u03c1\n\nk\n, \u03b1 = b\u03c1 cos\u03c6, \u03b2 = b\u03c1 sin\u03c6. \u03c1 and \u03c6 are the\n\nmodulus and phase of k2 =\n\u221a\nk2 + iV = \u03c1ei\u03c6 respectively such that \u03c1 = (k4 + V 2)\n\n1\n4 and\n\n\u03c6 = 1\n2\n\ntan\u22121\n(\nV\nk2\n\n)\n. It can be noted that k1 = \u03c1e\u2212i\u03c6. From the knowledge of transfer matrix\n\nof a \u2018unit cell\u2019 potential, one can find the transfer matrix for the corresponding locally\nperiodic potential consisting N such cells [28]. Using the approach outlined in [28, 29], we\nobtain the following transfer matrix for the layered PT -symmetric system,\n\n\u2126(k) =\n\n(\n[TN(\u03be) + i\u03c7UN\u22121(\u03be)]e\n\n\u2212ikL i(\u03b7 \u2212 \u03c4)UN\u22121(\u03be)e\n\u2212ikL\n\ni(\u03b7 + \u03c4)UN\u22121(\u03be)e\nikL [TN(\u03be)\u2212 i\u03c7UN\u22121(\u03be)]eikL\n\n)\n. (13)\n\nTN(\u03be) and UN(\u03be) are the Chebyshev polynomials of first and second kind respectively.\nL = 2Nb is the net spatial extent of the layered PT -symmetric system.\n\n4 Special case of layered PT -symmetric medium\n\nIn this section we show that a finite length L of our layered PT -symmetric system con-\nsisting infinitely many cells is analogous to an empty one dimensional space of length L.\nTo show this we take limiting case N \u2192 \u221e of each elements of transfer matrix 24 such\nthat b = L\n\n2N\nwhere L is fixed (and is finite). Various steps of the calculations are discussed\n\nbelow.\n\nThe limiting of case of \u03be and \u03c7 in the leading order of L can be shown to be,\n\nlim\nN\u2192\u221e\n\n\u03be = 1\u2212 (kL)2\n\n2N2\n, lim\n\nN\u2192\u221e\n\u03c7 =\n\nkL\n\nN\n(14)\n\nIn arriving at the above limit, we have used b = L\n2N\n\n. We also observe limN\u2192\u221e \u03be < 1.\nWith the above limiting value of \u03be, we also evaluate\n\nlim\nN\u2192\u221e\n\ncos\u22121 \u03be =\nkL\n\nN\n. (15)\n\n5\n\n\n\nIt is further known that for |\u03b5| < 1, one can express TN(\u03b5) = cos (N cos\u22121 \u03b5). Therefore,\n\nlim\nN\u2192\u221e\n\nTN(\u03be) = cos (N cos\u22121 \u03be).\n\nUsing Eq. 15 in the above, we find\n\nlim\nN\u2192\u221e\n\nTN(\u03be) = cos kL. (16)\n\nNext we evaluate the limiting value of Chebyshev polynomial of second kind for the\npresent problem. We use the following identity,\n\nUN\u22121(\u03be) =\nsin (N cos\u22121 \u03be)\n\nsin (cos\u22121 \u03be)\n.\n\nUsing Eq. 15 in the above, the limiting value is given by,\n\nlim\nN\u2192\u221e\n\nUN\u22121(\u03be) =\nsin kL\n\nsin kL\nN\n\n. (17)\n\nFrom the above result, we arrive at\n\nlim\nN\u2192\u221e\n\n\u03c7UN\u22121(\u03be) = sin kL. (18)\n\nIn the above we have used limN\u2192\u221e sin kL\nN\n\n= kL\nN\n\nCombining the limiting values of Eq. 16\nand Eq. 18 we have the following results,\n\nlim\nN\u2192\u221e\n\nTN(\u03be)\u00b1 i\u03c7UN\u22121(\u03be) = e\u00b1ikL. (19)\n\nUsing Eq. 19 in the diagonal values of transfer matrix (Eq. 24) we obtain\n\nlim\nN\u2192\u221e\n\n\u212611 = 1 = lim\nN\u2192\u221e\n\n\u212622, (20)\n\ni.e. the diagonal elements are unity in the limit N \u2192\u221e provided the support L is finite.\nNow we evaluate the limiting values of off-diagonal terms of the transfer matrix. The\nlimiting value of \u03b7 \u00b1 \u03c4 in the leading order of b is,\n\nlim\nN\u2192\u221e\n\n(\u03b7 \u00b1 \u03c4) = V b2. (21)\n\nUsing Eq.17 it can be easily shown that,\n\nlim\nN\u2192\u221e\n\n(\u03b7 \u00b1 \u03c4)UN\u22121(\u03be) =\nV b\n\n2k\nsin kL = 0. (22)\n\nTherefore, the off-diagonal terms of the transfer matrix (Eq. 24) are zero, i.e.,\n\nlim\nN\u2192\u221e\n\n\u212612 = 0 = lim\nN\u2192\u221e\n\n\u212621, (23)\n\n6\n\n\n\nFigure 3: Plot of transmission amplitude T (N, k) as a function of N and k for V = 40\nand L = 1. It is observed that the transmission is unity for large N . For a better clarity,\nthe plot range of T is chosen in the range from 0.9995 to 1.0005.\n\nfor finite support L. Thus it is proved that for all k,\n\nlim\nN\u2192\u221e\n\n(\n[TN(\u03be) + i\u03c7UN\u22121(\u03be)]e\n\n\u2212ikL i(\u03b7 \u2212 \u03c4)UN\u22121(\u03be)e\n\u2212ikL\n\ni(\u03b7 + \u03c4)UN\u22121(\u03be)e\nikL [TN(\u03be)\u2212 i\u03c7UN\u22121(\u03be)]eikL\n\n)\n=\n\n(\n1 0\n0 1\n\n)\n, (24)\n\nand therefore transmission coefficient is always unity and reflection coefficient is always\nzero for all wave number k in the limit N \u2192\u221e. Fig 3 shows the plot of transmission\namplitude T (N, k) as a function of N and k for V = 40 and L = 1. It is seen from the\nfigure that transmission amplitude is unity for large N as proven theoretically. The range\nof N in the figure is taken from 500 to 2000.\n\nThis is to be noted that when PT -symmetry is not respected, the vacuum configuration\nis not obtained. If one take the general case where the potential +iV is replaced by V1+iV2\nand potential \u2212iV with V1 \u2212 i\u03b5V2, {V1, V2} \u2208 R, the net configuration of length L in the\nlimit N \u2192 \u221e corresponds to a barrier potential of height V1 + i(1 \u2212 \u03b5)V2 and length L.\nWhen PT -symmetry is respected (\u03b5 = 1), the limiting case N \u2192\u221e correspond to a real\nbarrier of height V1 and length L. The case presented in this letter is the special case\nV1 = 0, \u03b5 = 1. The calculations for the more general case is much lengthy and is planned\nto be reported elsewhere.\n\n7\n\n\n\n5 Results and Discussions\n\nWe have shown that a finite layered PT -symmetric system of fix length L consisting of\nN units of adjacently arranged \u2018unit cell\u2019 PT -symmetric system represent a free space\nof length L in the limit N \u2192 \u221e at all wave number k. The \u2018unit cell\u2019 PT -symmetric\nsystem is made by potential \u2018+iV \u2019 and \u2018\u2212iV \u2019 ( V \u2208 R+ ), of same thickness and arranged\nadjacently without an intervening gap. This is proven by showing that the transfer matrix\nof such a layered PT -symmetric system over fix length L is a unity matrix at all wave\nnumber k for large number of unit cells. Therefore for such a system in this limit, the\ntransmission coefficient is always unity while the reflection coefficient is always zero. Thus\na free space of finite length L can be represented as PT -symmetric medium. The result\nis also shown numerically for transmission coefficient.\n\nIt is to be noted that in the present case of the layered PT -symmetric system, the\neffect of gain (+iV ) and loss part (\u2212iV ) cancel each other in the limit b \u2192 0 (or N \u2192\n\u221e for the present problem) as the wave traverses through it. This case is different\nthan considering vanishing strength of balanced gain and loss component of the non-\nHermitian potential. The present results shows that vacuum can be represented as the\nspecial case of PT -symmetric medium. More investigations are needed to understand the\nsignificant of this result. This finite PT -symmetric system for large L is also invisible for\nleft and right incidence. If particle production is represented as +iV (the gain part) and\nparticle annihilation is represented as \u2212iV (the lossy part), then the present limiting case\nof layered PT -symmetric medium represent the static snap shot of vacuum fluctuation.\nHowever it will be worth investigating the nature of transfer matrix when the height\nof each \u2018unit cell\u2019 is oscillatory in nature where frequency of oscillation is different for\ndifferent cells. This may represent a more realistic picture of vacuum fluctuation when\nrepresented in non-Hermitian quantum mechanics.\n\nAcknowledgements:\nMH acknowledges supports from Director-SPO and Scientific Secretary, ISRO for the\nencouragement of research activities. BPM acknowledges the Research Grant for Faculty\nunder IoE Scheme (number 6031).\n\nReferences\n\n[1] C. M. Bender and S. Boettcher, Phys. Rev. Lett. 80, 5243 (1998).\n\n[2] A. Mostafazadeh, Int. J. Geom. Meth. Mod. Phys. 7, 1191(2010) and references\ntherein.\n\n[3] C.M. Bender, Rep. Progr. Phys. 70 947 (2007) and references therein.\n\n[4] PT Symmetry in Quantum and Classical Physics, C. M. Bender, World Scientific\n(2019) and references therein.\n\n8\n\n\n\n[5] M. V. Berry, Czech. J. Phys. 54, 1039 (2004).\n\n[6] W. D. Heiss, Phys. Rep. 242, 443 (1994).\n\n[7] A. Mostafazadeh, Phys. Rev. Lett. 102, 220402 (2009).\n\n[8] A. Mostafazadeh, M. Sarisaman, Phys. Lett. A 375, 3387 (2011).\n\n[9] A. Ghatak, R. D. Ray Mandal, B. P. Mandal, Ann. of Phys. 336, 540 (2013).\n\n[10] M. Hasan, A. Ghatak, B. P. Mandal Ann. of Phys. 344, (2014)\n\n[11] C. F. Gmachl, Nature 467, 37 (2010).\n\n[12] W. Wan, Y. Chong, L. Ge, H. Noh, A. D. Stone, H. Cao, Science 331, 889 (2011).\n\n[13] N. Liu, M. Mesch, T. Weiss, M. Hentschel, and H. Giessen, Nano Lett. 10, 2342\n(2010).\n\n[14] H. Noh, Y. Chong, A. Douglas Stone, and Hui Cao, Phys. Rev. Lett. 108, 6805\n(2011).\n\n[15] A. Mostafazadeh and M. Sarisaman, Proc. R. Soc. A 468, 3224 (2012).\n\n[16] M. Cai, O. Painter, and K. J. Vahala, Phys. Rev. Lett. 85, 74 (2000).\n\n[17] J. R. Tischler, M. S. Bradley, and V. Bulovic, Opt. Lett. 31, 2045 (2006)\n\n[18] S. Dutta Gupta, Opt. Lett. 32, 1483 (2007).\n\n[19] S. Balci, C. Kocabas, and A. Aydinli, Opt. Lett. 36, 2770 (2011).\n\n[20] A. Mostafazadeh, Ann of Physics 375, 265 (2016).\n\n[21] S. Longhi, J. Phys. A: Math. Theor. 44, 485302 (2011).\n\n[22] A. Mostafazadeh, Phys. Rev. A 87, 012103 (2013).\n\n[23] F. Loran, Opt. Lett. 42, 5250 (2017).\n\n[24] L. Deak, T. Fulop, Ann. of Phys. 327, 1050 (2012).\n\n[25] M. Hasan, B. P. Mandal, Ann. of Phys. , 396, 371 (2018).\n\n[26] M. Hasan, B. P. Mandal, J. Math. Phys. ,61, 032104 (2020).\n\n[27] Elements of Quantum Mechanics, B. Dutta Roy, New Age Science Ltd. (2009).\n\n[28] D. J. Griffiths and C. A. Steinkea, Am. J. Phys. 69 (2), 137,(2001).\n\n[29] M. Hasan, V.N. Singh, B. P. Mandal, Eur. Phys. J. Plus , 135, 640 (2020).\n\n[30] M. Hasan and B.P. Mandal, Ann. of Phys., 391, 240 (2018).\n\n9\n\n\n\t1 Introduction\n\t2 Transfer matrix\n\t3 Transfer matrix of layered PT-symmetric system \n\t4 Special case of layered PT-symmetric medium\n\t5 Results and Discussions\n\n"}
{"Title": "An Efficient Federated Distillation Learning System for Multi-task Time Series Classification", "Authors": "Huanlai Xing, Zhiwen Xiao, Rong Qu, Zonghai Zhu, Bowen Zhao", "Abstract": "  This paper proposes an efficient federated distillation learning system (EFDLS) for multi-task time series classification (TSC). EFDLS consists of a central server and multiple mobile users, where different users may run different TSC tasks. EFDLS has two novel components, namely a feature-based student-teacher (FBST) framework and a distance-based weights matching (DBWM) scheme. Within each user, the FBST framework transfers knowledge from its teacher's hidden layers to its student's hidden layers via knowledge distillation, with the teacher and student having identical network structure. For each connected user, its student model's hidden layers' weights are uploaded to the EFDLS server periodically. The DBWM scheme is deployed on the server, with the least square distance used to measure the similarity between the weights of two given models. This scheme finds a partner for each connected user such that the user's and its partner's weights are the closest among all the weights uploaded. The server exchanges and sends back the user's and its partner's weights to these two users which then load the received weights to their teachers' hidden layers. Experimental results show that the proposed EFDLS achieves excellent performance on a set of selected UCR2018 datasets regarding top-1 accuracy.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00011", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1\n\nAn Efficient Federated Distillation Learning\nSystem for Multi-task Time Series Classification\n\nHuanlai Xing, Member, IEEE , Zhiwen Xiao, Rong Qu, Senior Member, IEEE , Zonghai Zhu,\nand Bowen Zhao\n\nAbstract\u2014This paper proposes an efficient federated distillation learning system (EFDLS) for multi-task time series classification\n(TSC). EFDLS consists of a central server and multiple mobile users, where different users may run different TSC tasks. EFDLS has\ntwo novel components, namely a feature-based student-teacher (FBST) framework and a distance-based weights matching (DBWM)\nscheme. Within each user, the FBST framework transfers knowledge from its teacher\u2019s hidden layers to its student\u2019s hidden layers via\nknowledge distillation, with the teacher and student having identical network structure. For each connected user, its student model\u2019s\nhidden layers\u2019 weights are uploaded to the EFDLS server periodically. The DBWM scheme is deployed on the server, with the least\nsquare distance used to measure the similarity between the weights of two given models. This scheme finds a partner for each\nconnected user such that the user\u2019s and its partner\u2019s weights are the closest among all the weights uploaded. The server exchanges\nand sends back the user\u2019s and its partner\u2019s weights to these two users which then load the received weights to their teachers\u2019 hidden\nlayers. Experimental results show that the proposed EFDLS achieves excellent performance on a set of selected UCR2018 datasets\nregarding top-1 accuracy.\n\nIndex Terms\u2014Deep Learning, Data Mining, Federated Learning, Knowledge Distillation, Time Series Classification.\n\nF\n\n1 INTRODUCTION\n\nT IME series data is a series of time-ordered data points\nassociated with one or more time-dependent variables\n\nand has been successfully applied to areas such as anomaly\ndetection [1], [2], traffic flow forecasting [3], service match-\ning [4], stock prediction [5], electroencephalogram (ECG)\ndetection [6] and parking behavior prediction [7]. A signif-\nicant amount of research attention has been dedicated to\ntime series classification (TSC) [8]. For example, Wang et al.\n[9] introduced a fully convolutional network (FCN) for local\nfeature extraction. Zhang et al. [10] devised an attentional\nprototype network (TapNet) to capture rich representations\nfrom the input. Karim et al. [11] proposed a long short-\nterm memory (LSTM) fully convolutional network (FCN-\nLSTM) for multivariate TSC. A robust temporal feature\nnetwork (RTFN) hybridizing temporal feature network and\nLSTM-based attention network was applied to extracting\nboth the local and global patterns of data [12]. Li et al.\n[13] put forward a shapelet-neural network approach to\nmine highly-diversified representative shapelets from the\ninput. Lee et al. [14] designed a learnable dynamic temporal\npooling method to reduce the temporal pooling size of the\nhidden representations obtained.\n\nTSC algorithms are usually data-driven, where data\n\n\u2022 H. Xing, Z. Zhu, and B. Zhao are with the School of Computing\nand Artificial Intelligence, Southwest Jiaotong University, Chengdu\n611756, China (Emails: hxx@home.swjtu.edu.cn; zzhu@swjtu.edu.cn;\ncn16bz@icloud.com).\n\n\u2022 Z. Xiao is with Southwest Jiaotong University, Chengdu 611756, China,\nand Chengdu University of Information Technology, Chengdu 610103,\nChina (Email: xiao1994zw@163.com).\n\n\u2022 R. Qu is with the the School of Computer Science, Univer-\nsity of Nottingham, Nottingham NG7 2RD 455356, UK (Email:\nrong.qu@nottingham.ac.uk)\n\nManuscript received XX, XX; revised XX, XX (Corresponding author: Zhi-\nwen Xiao).\n\ncomes from various application domains. Some data may\ncontain private and sensitive information, such as bank\naccount and ECG. However, traditional data collection op-\nerations could not well protect such information, easily\nresulting in users\u2019 privacy leakage during the data collec-\ntion and distribution processes involved in model training.\nTo overcome the problem above, Google [15], [16], [17]\ninvented federated learning (FL). FL allows users to col-\nlectively harvest the advantages of shared models trained\nfrom their local data without sending original data to others.\nFederatedAveraging (FedAvg), federated transfer learning\n(FTL) and federated knowledge distillation (FKD) are the\nthree mainstream research directions.\n\nFedAvg calculates the average weights of the models\nof all users and shares the weights with each user in\nthe FL system [18]. For instance, Ma et al. [19] devised a\ncommunication-efficient federated generalized tensor fac-\ntorization for electronic health records. Liu et al. [20] used\na federated adaptation framework to leverage the spar-\nsity property of neural networks for generating privacy-\npreserving representations. A hierarchical personalized FL\nmethod aggregated heterogeneous user models, with pri-\nvacy heterogeneity and model heterogeneity considered\n[21]. Yang et al. [22] modified the FedAvg method using\npartial networks for COVID-19 detection.\n\nFTL introduces transfer learning techniques to promote\nknowledge transfer between different users, increasing sys-\ntem accuracy [23]. For example, Yang et al. [24] developed an\nFTL framework, FedSteg, for secure image steganalysis. An\nFTL method with dynamic gradient aggregation was pro-\nposed to weight the local gradients during the aggregation\nstep when handling speech recognition tasks [25]. Majeed et\nal. [26] proposed an FTL-based structure to address traffic\nclassification problems.\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n1v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2\n\nUnlike FedAvg and FTL, FKD takes the average of all\nusers\u2019 weights as the weights for all teachers and transfers\neach teacher\u2019s knowledge to its corresponding student via\nknowledge distillation (KD) [27]. A group knowledge trans-\nfer training algorithm was adopted to train small convolu-\ntional neural networks (CNNs) and transfer their knowl-\nedge to a prominent server-side CNN [28]. Mishra et al.\n[29] proposed a resource-aware FKD approach for network\nresource allocation. Sohei et al. [30] devised a distillation-\nbased semi-supervised FL framework for communication-\nefficient collaborative training with private data. Nowadays,\nFKD is attracting increasingly more research attention.\n\nIn addition, there is a variety of FL-based algorithms\nin the literature. For instance, Chen et al. [31] applied\nasynchronous learning and temporally weighted aggrega-\ntion to enhancing system\u2019s performance. Sattler et al. [32]\npresented a sparse ternary compression method to meet\nvarious requirements of FL environment. A cooperative\ngame involving a gradient algorithm was designed to tackle\nimage classification and speech recognition tasks [33]. An\nensemble FL system used a randomly selected subset of\nclients to learn multiple global models against malicious\nclients [34]. Hong et al. [35] combined adversarial learning\nand FL to produce federated adversarial debiasing for fair\nand transferable representations. Zhou et al. [36] proposed a\nprivacy-preserving distributed contextual federated online\nlearning framework with big data support for social recom-\nmender systems. Pan et al. [37] put forward a multi-granular\nfederated neural architecture search framework to enable\nthe automation of model architecture search in a federated\nand privacy-preserved setting.\n\nMost FL algorithms are developed around single-task\nproblems, where multiple users work together to complete\na task, e.g., COVID-19 detection [22], traffic classification\n[26] or speech recognition [25]. It is quite challenging to\ndirectly apply these algorithms to multi-task problems un-\nless efficient knowledge sharing among different tasks is\nenabled. Unfortunately, TSC is usually multi-task-oriented.\nTime series data is collected from various application do-\nmains, such as ECG, traffic flow, human activity recognition.\nEach time series dataset has specific characteristics, e.g.,\nlength and variance, which may differ significantly from\nothers. Thus, time series data is highly imbalanced and\nstrongly non-independent, and identically distributed (Non-\nI.I.D.). In multi-task learning, it is commonly recognized\nthat knowledge sharing among different tasks helps increase\nthe efficiency and accuracy of each task [38]. For most TSC\nalgorithms, how to securely share knowledge of similar expertise\namong different tasks is still challenging. In other words, user\nprivacy and knowledge sharing are two critical issues that need\nto be carefully addressed when devising practical multi-task TSC\nalgorithms. To the best of our knowledge, FL for multi-task\nTSC has not received sufficient research attention.\n\nWe present an efficient federated distillation learning\nsystem (EFDLS) for multi-task TSC. This system consists of a\ncentral server and a number of mobile users running various\nTSC tasks simultaneously. Given two arbitrary users, they\nrun either different tasks (e.g., ECG and motion) or the\nsame task with different data sources to mimic real-world\napplications. EFDLS is characterized by a feature-based\nstudent-teacher (FBST) framework and a distance-based\n\nweights matching (DBWM) scheme. The FBST framework\nis deployed on each user, where the student and teacher\nmodels have identical network structure. Within each user,\nits teacher\u2019s hidden layers\u2019 knowledge is transferred to its\nstudent\u2019s hidden layers, helping the student mine high-\nquality features from the data. The DBWM scheme is de-\nployed on the EFDLS server, where the least square distance\n(LSD) is used to measure the similarity between the weights\nof two models. When all connected users\u2019 weights are\nuploaded completely, for an arbitrary connected user, the\nDBWM scheme finds the one with the most similar weights\namong all connected users. After that, the server sends the\nconnected user\u2019s weights to the found one that then loads\nthe weights to its teacher model\u2019s hidden layers.\n\nOur main contributions are summarized below.\n\n\u2022 We propose EFDLS for multi-task TSC, where each\nuser runs one TSC task at a time and different users\nmay run different TSC tasks. The data generated on\ndifferent users is different. EFDLS aims at provid-\ning secure knowledge sharing of similar expertise\namong different tasks. This problem has not attracted\nenough research attention.\n\n\u2022 In EFDLS, feature-based knowledge distillation is\nused for knowledge transfer within each user. Unlike\nthe traditional FKD that adopts the average weights\nof all users to supervise the feature extraction process\nin each user, EFDLS finds the one with the most sim-\nilar expertise (i.e., a partner) for each user according\nto LSD and offers knowledge sharing between the\nuser and its partner.\n\n\u2022 Experimental results demonstrate that EFDLS out-\nperforms six state-of-the-art FL algorithms con-\nsidering 44 well-known datasets selected in the\nUCR 2018 archive regarding the mean accuracy,\n\u2018win\u2019/\u2018tie\u2019/\u2018lose\u2019 measure, and AVG rank, which are\nall based on the top-1 accuracy. That shows the\neffectiveness of EFDLS in addressing TSC problems.\n\nThe rest of the paper is organized below. Section 2\nreviews the existing TSC algorithms. Section 3 overviews\nthe architecture of EFDLS and describes its key components.\nSection 4 provides and analyzes the experimental results,\nand conclusion is drawn in Section 5.\n\n2 RELATED WORK\n\nA large number of traditional and deep learning algorithms\nhave been developed for TSC.\n\n2.1 Traditional Algorithms\nTwo representative streams of algorithms are distance- and\nfeature-based. For distance-based algorithms, it is quite\ncommon to combine the dynamic time warping (DTW) and\nnearest neighbor (NN), e.g., DTWA, DTWI and DTWD\n\n[39]. Besides, a significant number of DTW-NN-based en-\nsemble algorithms taking advantage of DTW and NN have\nbeen proposed in the community. For example, Line et al.\n[40] presented an elastic ensemble (EE) algorithm for feature\nextraction, with 11 types of 1-NN-based elastic distance\nconsidered. A collective of the transformation-based ensem-\nble (COTE) with 37 NN-based classifiers was adopted to\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 3\n\nFig. 1. The schematic diagram of EFDLS. Note that \u2018FBST Framework\u2019 and \u2018DBWM Scheme\u2019 denote the feature-based student-teacher framework\ndeployed on each user and the distance-based weights matching scheme run on the server. \u2018Conv x 9 128\u2019 represents a 1-dimensional convolutional\nneural network, where its filter size and channel sizes are set to 9 and 128. \u2018BN\u2019 is a batch normalization module, and \u2018ReLU\u2019 is the rectified linear\nunit activation function.\n\naddress various TSC problems [41]. The hierarchical vote\ncollective of transformation-based ensembles (HIVE-COTE)\n[42] and local cascade ensemble [43] are two representative\nensemble algorithms in the literature.\n\nFor feature-based algorithms, their aim is to capture\nsufficient discriminate features from the given data. For\ninstance, Line et al. [44] introduced a shapelet transforma-\ntion method to find representative shapelets that reflected\nthe trend of raw data. A bag-of-features representation\nframework was applied to extracting the information at\ndifferent locations of sequences [45]. Dempster et al. [46]\napplied minimally random convolutional kernel transform\nto exploring the transformed features from data. In addi-\ntion, the learned pattern similarity [47], bag of symbolic\nFourier approximation symbols [48], hidden-unit logistic\nmodel [49], time series forest [50], and multi-feature dic-\ntionary representation and ensemble learning [51] are also\nrepresentative algorithms.\n\n2.2 Deep Learning Algorithms\n\nBy unfolding the internal representation hierarchy of data,\ndeep learning algorithms focus on extracting the intrinsic\nconnections among representations. Most of the existing\ndeep learning models are either single-network- or dual-\nnetwork-based [12]. A single-network-based model captures\nthe significant correlations within the representation hierar-\nchy of data by one (usually hybridized) network, e.g., FCN\n[9], ResNet [9], shapelet-neural network [13], InceptionTime\n\n[52], dynamic temporal pooling [14], multi-process collab-\norative architecture [53], and multi-scale attention convo-\nlutional neural network [54]. In contrast, a dual-network-\nbased model usually consists of two parallel networks, i.e.,\nlocal-feature extraction network (LFN) and global-relation\nextraction network (GRN), such as FCN-LSTM [11], RTFN\n[12], ResNet-Transformer [55], RNTS [56], and TapNet [10].\n\nAlmost all algorithms above emphasized single-task\nTSC, e.g., traffic or gesture classification. However, TSC\nusually involves multiple tasks in real-world scenarios, like\nvarious applications with different TSC tasks run on dif-\nferent mobile devices in a mobile computing environment.\nEnabling efficient knowledge sharing of similar expertise\namong different tasks helps increase the average accuracy\nof these tasks. Nevertheless, sharing knowledge among dif-\nferent TSC tasks securely and efficiently is still a challenge.\nThat is what FL aims for.\n\n3 EFDLS\nThis section first overviews the architecture of EFDLS. Then,\nit introduces the feature-based student-teacher framework,\ndistance-based weights matching scheme, and communica-\ntion overhead.\n\n3.1 System Overview\n\nEFDLS is a secure distributed system for multi-task TSC.\nThere is a central server and multiple mobile users. Let Ntot\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4\n\nand Nconn denote the numbers of total and connected users\nin the system, respectively, where Nconn \u2264 Ntot. Each user\nruns one TSC task at a time and different users might run\ndifferent TSC tasks. For two arbitrary users, they run two\ndifferent tasks, such as gesture and ECG classification, or\nthe same task with different data sources.\n\nThe overview of EFDLS is shown in Fig. 1. In the\nsystem, users train their models locally based on knowledge\ndistillation and share their model weights with users with\nsimilar expertise via the server. We propose FBST, a feature-\nbased student-teacher framework that is deployed on each\nuser as its learning model. Within each user, its teacher\u2019s\nhidden layers\u2019 knowledge is transferred to its student\u2019s\nhidden layers. For each connected user, its student model\u2019s\nhidden layers\u2019 weights are uploaded to the EFDLS server\nperiodically. We propose DBWM, a distance-based weights\nmatching scheme deployed on the server, with the LSD\nadopted to measure the similarity between the weights\nof two given models. After the weights of all connected\nusers are uploaded completely, for each connected user, the\nDBWM scheme is launched to find the one with the most\nsimilar weights among all connected users. In this way,\nevery user has a partner to match with. For each connected\nuser, its uploaded weights are sent to its partner that then\nloads these weights to its teacher model\u2019s hidden layers.\nThe server\u2019s role looks like a telecom-network switch. The\nEFDLS system allows users to benefit from knowledge\nsharing without sacrificing security and privacy.\n\n3.2 Feature-based Student-Teacher Framework\n\nIn the FBST framework, the student and teacher models\nhave identical network structure. Within each user, feature-\nbased KD promotes knowledge transfer from the teacher\u2019s\nhidden layers to its student\u2019s hidden layers, helping the\nstudent capture rich and valuable representations from the\ninput data.\n\n3.2.1 Feature Extractor\n\nThe feature extractor contains multiple hidden layers and\na classifier, as shown in Fig. 1. The hidden layers are\nresponsible for local-feature extraction, including three\nConvolutional Blocks (i.e., ConvBlock1, ConvBlock2, and\nConvBlock3), an average pooling layer, and a dense (i.e.,\nfully-connected) layer. Each ConvBlock consists of a 1-\ndimensional CNN (Conv) module, a batch normalization\n(BN) module, and a rectified linear unit activation (ReLU)\nfunction, defined as:\n\nfconvblock(x) = frelu(fbn(Wconv \u2297 x+ bconv)) (1)\n\nwhere, Wconv and bconv are the weight and bias matrices of\nCNN, respectively.\u2297 represents the convolutional computa-\ntion operation. fbn and frelu denote the batch normalization\nand ReLU functions, respectively.\n\nLet xbn = {x1, x2, ..., xNbn\n} denote the input of batch\n\nnormalization (BN), where xi and Nbn stand for the i-th\n\ninstance and batch size, respectively. fbn(xbn) is defined in\nEq. (2)\n\nfbn(xbn) = fbn(x1, x2, ..., xNbn\n)\n\n= (\u03b1\nx1 \u2212 \u00b5\n\u03b4 + \u03b6\n\n+ \u03b2, \u03b1\nx2 \u2212 \u00b5\n\u03b4 + \u03b6\n\n+ \u03b2, ..., \u03b1\nxNbn\n\n\u2212 \u00b5\n\u03b4 + \u03b6\n\n+ \u03b2)\n\n\u00b5 =\n1\n\nNbn\n\nNbn\u2211\ni=1\n\nxi\n\n\u03b4 =\n\n\u221a\u221a\u221a\u221aNbn\u2211\ni=1\n\n(xi \u2212 \u00b5)2\n\n(2)\nwhere, \u03b1 \u2208 R+ and \u03b2 \u2208 R are the parameters to be learned\nduring training. \u03b6 > 0 is an arbitrarily small number.\n\nThe classifier is composed of a dense layer and a Softmax\nfunction, mapping high-level features extracted from the\nhidden layers to the corresponding label.\n\n3.2.2 Knowledge Distillation\nFeature-based KD regularizes a student model by transfer-\nring knowledge from the corresponding teacher\u2019s hidden\nlayers to the student\u2019s hidden layers [57]. For an arbitrary\nuser, its student model captures sufficient discriminate rep-\nresentations from the data under its teacher model\u2019s super-\nvision.\n\nLet OT,1\ni , OT,2\n\ni , OT,3\ni , and OT,4\n\ni be the outputs of Con-\nvBlock 1, ConvBlock 2, ConvBlock 3, and the dense layer of\nthe teacher\u2019s hidden layers. Let OS,1\n\ni , OS,2\ni , OS,3\n\ni , and OS,4\ni\n\nbe the outputs of ConvBlock 1, ConvBlock 2, ConvBlock 3,\nand the dense layer of the student\u2019s hidden layers. Follow-\ning the previous work [28], we define the KD loss, LKD\n\ni , of\nUi as:\n\nLKD\ni =\n\n4\u2211\nm=1\n\n||OT,m\ni \u2212OS,m\n\ni ||2 (3)\n\nFor Ui, its total loss, Li, consists of KD loss, LKD\ni , and\n\nsupervised loss, LSup\ni . As the previous studies in [10], [11],\n\n[12] suggested, LSup\ni uses the cross-entropy function to\n\nmeasure the average difference between the ground truth\nlabels and their prediction vectors, as shown in Eq. (4).\n\nLSup\ni = \u2212 1\n\nNseg\n\nNseg\u2211\nj=1\n\nyj log(y\u0302j) (4)\n\nwhere, Nseg is the number of input vectors, and yi and y\u0302j\nare the ground label and prediction vector of the j-th input\nvector, respectively.\n\nThe total loss, Li, is defined as:\n\nLi = \u03b5\u00d7 LSup\ni + (1\u2212 \u03b5)\u00d7 LKD\n\ni (5)\n\nwhere, \u03b5 \u2208 (0, 1) is a coefficient to balance LSup\ni and LKD\n\ni .\nIn this paper, we set \u03b5 = 0.9 (More details can be found in\nSection 4.3).\n\n3.3 Distance-based Weights Matching\nThe least square distance (LSD) is used to calculate the sim-\nilarity between the weights of two given models. When the\nweights uploaded by all the connected users are received,\nthe DBWM scheme immediately launches the weights\nmatching process to find a partner for each connected user.\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 5\n\n3.3.1 Least Square Distance\nLet FLEs denote the maximum number of federated learn-\ning epochs. Let WS,k\n\ni and WT,k\ni be the weights of the\n\nstudent and teacher models of Ui at the k-th federated\nlearning epoch, k = 1, 2, ..., FLEs. Denote the hidden\nlayers\u2019 weights of the student and teacher models of Ui by\nWShidden,k\n\ni \u2282 WS,k\ni and WThidden,k\n\ni \u2282 WT,k\ni , respectively.\n\nTo be specific, WShidden,k\ni consists of the weights of Con-\n\nvBlock 1, ConvBlock 2, ConvBlock 3, and the dense layer,\nnamely, WS1,k\n\ni , WS2,k\ni , WS3,k\n\ni , and WS4,k\ni . So, we have\n\nWShidden,k\ni = {WS1,k\n\ni ,WS2,k\ni , WS3,k\n\ni ,WS4,k\ni }.\n\nAt the k-th federated learning epoch, user Ui, i =\n1, 2, ..., Nconn, uploads its student model\u2019s hidden layers\u2019\nweights, WShidden,k\n\ni , to the server. The server stores the\nuploaded weights in the weight set W defined in Eq. (6).\n\nW = [WShidden,k\n1 ,WShidden,k\n\n2 , ...,WShidden,k\nNconn\n\n] (6)\n\nThe server then calculates the weights\u2019 square distance\nset, d, based on W. d is defined as:\n\nd =\n\n\uf8ee\uf8ef\uf8ef\uf8f0\nd1\nd2\n...\n\ndNconn\n\n\uf8f9\uf8fa\uf8fa\uf8fb =\n\n\uf8ee\uf8ef\uf8ef\uf8f0\nd1,2 ... d1,Nconn\n\nd2,1 ... d2,Nconn\n\n... ... ...\ndNconn,1 ... dNconn,Nconn\u22121\n\n\uf8f9\uf8fa\uf8fa\uf8fb (7)\n\nwhere, di,j (i, j \u2208 1, ..., Nconn, i 6= j) is the square distance\nbetween WShidden,k\n\ni and WShidden,k\nj , as defined in Eq. (8).\n\ndi,j = ||WShidden,k\ni \u2212WShidden,k\n\nj ||2\n\n=\n4\u2211\n\nm=1\n\n||WSm,k\ni \u2212WSm,k\n\nj ||2\n(8)\n\nWe adopt the argmin function to return the index of the\nsmallest distance for each row in d and obtain the index set,\nID. ID is defined in Eq. (9).\n\nID = argmin(d) = [ID1, ID2, ..., IDNconn ] (9)\n\nwhere, IDi is the index of the smallest distance for Ui.\nBased on ID, we easily obtain the LSD weight set, WLSD,\n\nfrom W. WLSD is defined in Eq. (10).\n\nWLSD = [WLSD,k\n1 ,WLSD,k\n\n2 , ...,WLSD,k\nNconn\n\n]\n\n= [W(ID1),W(ID2), ...,W(IDNconn\n)]\n\n(10)\n\nwhere, WLSD,k\ni are the weights matched with those of Ui at\n\nthe k-th federated learning epoch.\nOnce Ui receives WLSD,k\n\ni from the server, Ui loads these\nweights to its teacher\u2019s hidden layers at the beginning of the\nnext federated learning epoch, as defined in Eq. (11).\n\nWThidden,k+1\ni \u2190WLSD,k\n\ni (11)\n\nAlg. 1 and Alg. 2 show the user and server implementa-\ntion procedures, respectively.\n\n3.4 Communication Overhead\nEFDLS does not launch the DBWM scheme unless the\nweights from all the Nconn connected users are received.\nIt helps reduce the interaction between the server and\nusers, promoting the system\u2019s service efficiency. For user\nUi, i = 1, 2, ..., Nconn, we analyze the communication over-\nhead of uploading and downloading its weights. Denote the\n\nAlgorithm 1 EFDLS User Implementation Procedure\n1: procedure USERPROCEDURE(Ui, FLEs)\n2: Initialize all global variables;\n3: for k = 1 to FLEs do\n4: if k == 1 then\n5: // The student model is trained alone\n6: Obtain WS,k\n\ni after the initial local training;\n7: // Upload its hidden layers\u2019 weights to server\n8: Upload WShidden,k\n\ni \u2282WS,k\ni ;\n\n9: else\n10: if receiveServer(Active)==1 then\n11: // Connect to the EFDLS server\n12: Receive WLSD,k\n\ni ;\n13: Load WLSD,k\n\ni to the teacher model;\n14: Compute Li by Eq. (5);\n15: Update WS,k+1\n\ni using the gradient decent;\n16: Upload WShidden,k+1\n\ni \u2282WS,k+1\ni ;\n\n17: else\n18: Disconnect from the EFDLS server.\n19: end if\n20: end if\n21: end for\n22: end procedure\n\nAlgorithm 2 EFDLS Server Implementation Procedure\n1: procedure SERVERPROCEDURE(Ntot, Nconn, FLEs)\n2: Initialize all global variables;\n3: Set W = \u2205;\n4: for k = 1 to FLEs do\n5: // Run on the server;\n6: Clear and initialize W;\n7: for i = 1 to Nconn do\n8: // Receive model weights from users;\n9: Receive WShidden,k\n\ni ;\n10: Include WShidden,k\n\ni in W.\n11: end for\n12: for i = 1 to Nconn do\n13: Obtain WLSD,k\n\ni based on W by Eqs. (6)-(10);\n14: Send WLSD,k\n\ni to Ui.\n15: end for\n16: end for\n17: end procedure\n\nbandwidth requirement for uploading the student model\u2019s\nhidden layers\u2019 weights of Ui once byBW . Clearly, the band-\nwidth requirement for downloading the student model\u2019s\nhidden layers\u2019 weights from the server once is also BW .\nThat is because, for an arbitrary connected user, the weights\nuploaded to and those downloaded from the server are\nof the same size, given that each user has exactly the\nsame model structure. At each federated learning epoch,\nthe bandwidth requirement for user Ui, i = 1, 2, ..., Nconn\n\nis estimated as BW + BW = 2BW . For Ui, its total\ncommunication overhead is in proportion to 2BW \u00b7 FLEs.\nHence, the total communication overhead is proportional to\n2BW \u00b7 FLEs \u00b7Nconn.\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6\n\nTABLE 1\nDetails of 44 selected datasets from the UCR 2018.\n\nScale Dataset Train Test Class SeriesLength Type\n\nShort\n\nChinatown 20 345 2 24 Traffic\nMelbournePedestrian 1194 2439 10 24 Traffic\nSonyAIBORobotSur.2 27 953 2 65 Sensor\nSonyAIBORobotSur.1 20 601 2 70 Sensor\nDistalPhalanxO.A.G 400 139 3 80 Image\nDistalPhalanxO.C. 600 276 2 80 Image\nDistalPhalanxTW 400 139 6 80 Image\n\nTwoLeadECG 23 1139 2 82 ECG\nMoteStrain 20 1252 2 84 Sensor\n\nECG200 100 100 2 96 ECG\nCBF 30 900 3 128 Simulated\n\nMedium\n\nDodgerLoopDay 78 80 7 288 Sensor\nDodgerLoopGame 20 138 2 288 Sensor\n\nDodgerLoopWeekend 20 138 2 288 Sensor\nCricketX 390 390 12 300 Motion\nCricketY 390 390 12 300 Motion\nCricketZ 390 390 12 300 Motion\nFaceFour 24 88 4 350 Image\n\nHam 109 105 2 431 Spectro\nMeat 60 60 3 448 Spectro\nFish 175 175 7 463 Image\nBeef 30 30 5 470 Spectro\n\nLong\n\nOliveOil 30 30 4 570 Spectro\nCar 60 60 4 577 Sensor\n\nLightning2 60 61 2 637 Sensor\nComputers 250 250 2 720 Device\n\nMallat 55 2345 8 1024 Simulated\nPhoneme 214 1896 39 1024 Sensor\n\nStarLightCurves 1000 8236 3 1024 Sensor\nMixedShapesRegularT. 500 2425 5 1024 Image\n\nMixedShapesSmallT. 100 2425 5 1024 Image\nACSF1 100 100 10 1460 Device\n\nSemgHandG.Ch2 300 600 2 1500 Spectrum\n\nVary\n\nAllGestureWiimoteX 300 700 10 Vary Sensor\nAllGestureWiimoteY 300 700 10 Vary Sensor\nAllGestureWiimoteZ 300 700 10 Vary Sensor\n\nGestureMidAirD1 208 130 26 Vary Trajectory\nGestureMidAirD2 208 130 26 Vary Trajectory\nGestureMidAirD3 208 130 26 Vary Trajectory\nGesturePebbleZ1 132 172 6 Vary Sensor\nGesturePebbleZ2 146 158 6 Vary Sensor\n\nPickupGestureW.Z 50 50 10 Vary Sensor\nPLAID 537 537 11 Vary Device\n\nShakeGestureW.Z 50 50 10 Vary Sensor\n\n4 PERFORMANCE EVALUATION\n\nThis section first introduces the experimental setup and\nperformance metrics and then focuses on the ablation study.\nFinally, the performance of EFDLS is evaluated.\n\n4.1 Experimental Setup\n\n4.1.1 Data Description\n\nThe UCR 2018 archive is one of the most popular time series\nrepositories with 128 datasets of different lengths in various\napplication domains [58]. Following the previous work [53],\nwe divide the UCR 2018 archive into 4 categories with\nrespect to dataset length, namely, \u2018short\u2019, \u2018medium\u2019, \u2018long\u2019,\nand \u2018vary\u2019. The length of a \u2018short\u2019 dataset is no more than\n200. That of a \u2018medium\u2019 one varies from 200 to 500. A \u2018long\u2019\none has a length of over 500 while a \u2018vary\u2019 one has an indef-\ninite length. The 128 datasets are composed of 41 \u2018short\u2019 , 32\n\n\u2018medium\u2019, 44 \u2018long\u2019, and 11 \u2018vary\u2019 datasets. Unfortunately,\nour limited computing resources do not allow us to consider\nthe whole 128 datasets (detailed hardware specification\ncan be found in Subsection Implementation Details). There\nare seven algorithms for performance comparison and the\naverage training time on the 128 datasets costed more than\n32 hours for a single federated learning epoch. So, we select\n11 datasets from each category, resulting in 44 datasets\nselected. More details are found in Table 1.\n\n4.1.2 Implementation Details\nFollowing previous studies [8], [9], [10], [11], [53], we set\nthe decay value of batch normalization to 0.9. We use the\nL2 regularization to avoid overfitting during the training\nprocess. Meanwhile, we adopt the AdamOptimizer with\nPytorch1, where the initial learning rate is set to 0.0001.\n\n1. https://pytorch.org/\n\nhttps://pytorch.org/\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 7\n\nTABLE 2\nExperimental results of different algorithms on 44 datasets when Nconn = 44 and Ntot = 44.\n\nDataset Baseline FedAvg FedAvgM FedGrad FTL FTLS FKD EFDLS\nChinatown 0.9623 0.2754 0.2754 0.9623 0.9665 0.9537 0.9275 0.9478\n\nMelbournePedestrian 0.9139 0.1 0.1 0.7784 0.8486 0.8922 0.9379 0.9453\nSonyAIBORobotSur.2 0.8961 0.383 0.383 0.8363 0.8688 0.9035 0.915 0.8961\nSonyAIBORobotSur.1 0.8652 0.5707 0.6619 0.7887 0.8236 0.8702 0.8369 0.8819\nDistalPhalanxO.A.G 0.6763 0.1079 0.1079 0.6187 0.6259 0.6475 0.6691 0.6475\nDistalPhalanxO.C. 0.75 0.417 0.6619 0.6776 0.7464 0.7465 0.7536 0.7428\nDistalPhalanxTW 0.6547 0.1295 0.1295 0.554 0.6259 0.6547 0.6835 0.6403\n\nTwoLeadECG 0.7463 0.4996 0.4996 0.7305 0.7287 0.7278 0.8112 0.7665\nMoteStrain 0.7788 0.5391 0.5391 0.6933 0.7923 0.8283 0.8163 0.8203\n\nECG200 0.86 0.36 0.36 0.8 0.84 0.85 0.87 0.85\nCBF 0.987 0.3333 0.5911 0.5911 0.973 0.9922 0.9922 0.9956\n\nDodgerLoopDay 0.575 0.15 0.15 0.3875 0.55 0.525 0.5125 0.5375\nDodgerLoopGame 0.6884 0.5217 0.5217 0.6232 0.7826 0.7609 0.7609 0.7464\n\nDodgerLoopWeekend 0.8261 0.7391 0.7391 0.7319 0.8841 0.8913 0.913 0.9203\nCricketX 0.5897 0.0692 0.1371 0.2256 0.5667 0.6128 0.659 0.6718\nCricketY 0.5051 0.0949 0.1357 0.1949 0.5 0.4949 0.5538 0.5974\nCricketZ 0.6205 0.0846 0.0846 0.2256 0.5692 0.6 0.6692 0.7256\nFaceFour 0.6477 0.1591 0.1591 0.4659 0.6591 0.6932 0.6932 0.6818\n\nHam 0.7143 0.4857 0.4857 0.6762 0.7048 0.7143 0.7048 0.6952\nMeat 0.8667 0.3333 0.3333 0.7333 0.8333 0.8333 0.9 0.917\nFish 0.5657 0.1371 0.1371 0.2857 0.5771 0.6 0.6 0.6229\nBeef 0.7667 0.2 0.2 0.5667 0.7 0.7 0.7 0.7667\n\nOliveOil 0.8333 0.167 0.167 0.7 0.8667 0.8667 0.8333 0.8333\nCar 0.5833 0.233 0.233 0.5 0.5667 0.5833 0.5667 0.6333\n\nLightning2 0.7869 0.459 0.459 0.7705 0.7869 0.8033 0.7541 0.7869\nComputers 0.78 0.5 0.5 0.584 0.688 0.748 0.788 0.804\n\nMallat 0.7446 0.1254 0.1254 0.4141 0.7638 0.7539 0.7906 0.8299\nPhoneme 0.2231 0.02 0.02 0.1108 0.2147 0.2247 0.2859 0.2954\n\nStarLightCurves 0.9534 0.1429 0.1429 0.5062 0.9519 0.9584 0.9571 0.9582\nMixedShapesRegularT. 0.8586 0.1889 0.1889 0.2223 0.8384 0.8598 0.8643 0.8907\n\nMixedShapesSmallT. 0.8029 0.1889 0.1889 0.2421 0.7942 0.8062 0.8318 0.8388\nACSF1 0.77 0.1 0.19 0.19 0.82 0.89 0.87 0.88\n\nSemgHandG.Ch2 0.7067 0.65 0.65 0.555 0.72 0.7383 0.6867 0.72\nAllGestureWiimoteX 0.2643 0.1 0.1 0.1371 0.2729 0.3043 0.2929 0.2914\nAllGestureWiimoteY 0.2585 0.1 0.1 0.1357 0.3186 0.3029 0.2529 0.2829\nAllGestureWiimoteZ 0.2886 0.1 0.1 0.1343 0.2671 0.29 0.4014 0.3786\n\nGestureMidAirD1 0.5538 0.0384 0.0384 0.0923 0.5462 0.5538 0.4615 0.5769\nGestureMidAirD2 0.4231 0.0384 0.0384 0.0923 0.4154 0.4462 0.4692 0.5308\nGestureMidAirD3 0.3 0.0384 0.0384 0.0923 0.2693 0.2615 0.2231 0.2769\nGesturePebbleZ1 0.4419 0.1628 0.1628 0.2558 0.4767 0.4826 0.5 0.4883\nGesturePebbleZ2 0.4241 0.1519 0.1519 0.2722 0.5126 0.557 0.6013 0.5886\n\nPickupGestureW.Z 0.56 0.1 0.1 0.24 0.62 0.6 0.7 0.74\nPLAID 0.203 0.0615 0.0615 0.0615 0.2198 0.2253 0.2924 0.2589\n\nShakeGestureW.Z 0.92 0.1 0.1 0.1 0.96 0.92 0.96 0.96\nWin 4 0 0 0 3 7 10 18\nTie 1 0 0 0 2 1 1 2\n\nLose 39 44 44 44 39 36 33 24\nBest 5 0 0 0 5 8 11 20\n\nMeanACC 0.6622 0.2377 0.2557 0.4445 0.6604 0.6743 0.6878 0.7014\nAVG rank 3.5455 7.5 7.3409 6.0113 3.9204 2.8977 2.6364 2.1478\n\nAll experiments were conducted on a desktop with an\nNvidia GTX 1080Ti GPU with 11GB memory, and an AMD\nR5 1400 CPU with 16G RAM under the Ubuntu 18.04 OS.\n\n4.2 Performance Metrics\nTo evaluate FL algorithms\u2019 performance, we use three\nwell-known metrics: \u2018win\u2019/\u2018tie\u2019/\u2018lose\u2019, mean accuracy\n(MeanACC), and AVG rank, all based on the top-1 accuracy.\nFor an arbitrary algorithm, its \u2018win\u2019, \u2018tie\u2019, and \u2018lose\u2019 values\nindicate on how many datasets it is better than, equal to,\n\nand worse than the others, respectively; its \u2018best\u2019 value is\nthe summation of the corresponding \u2018win\u2019 and \u2018tie\u2019 values.\nThe AVG rank score reflects the average difference between\nthe accuracy values of a model and the best accuracy values\namong all models [9], [10], [11], [12], [56].\n\n4.3 Ablation Study\nWe use the 44 UCR2018 datasets above to study the impact\nof parameter settings on the performance of EFDLS. Assume\nthere are 44 users in the system, i.e., Ntot = 44. Each user\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 8\n\nFig. 2. MeanACC results obtained by EFDLS with different ratios of\nNconn to Ntot on 44 datasets when Ntot = 44.\n\nFig. 3. MeanACC results with different \u03b5 values on 44 datasets when\nNconn = 44 and Ntot = 44.\n\nruns a TSC task with data coming from a specific dataset.\nFor any two users, if they run identical tasks, e.g., motion\nrecognition, their data sources come from different datasets,\ne.g., CricketX and CricketY. In the experiments, each user\u2019s\ndata comes from one of the 44 datasets.\n\n4.3.1 Impact of Nconn\n\nTo investigate the impact of Nconn on the EFDLS\u2019s perfor-\nmance, we select four ratios of Nconn to Ntot, namely 40%,\n60%, 80%, and 100%. For example, 40% means there are 18\nconnected users for weights uploading, given Ntot = 44.\nThe MeanACC results obtained by EFDLS with different\nNconn values on 44 datasets are shown in Fig. 2. One can\neasily observe that a larger Nconn tends to result in a higher\nMeanACC value. That is because as Nconn increases, more\namount of time series data is made use of by the system and\nthus more discriminate representations are captured.\n\n4.3.2 Impact of \u03b5\n\u03b5 is a coefficient to balance each connected user\u2019s supervised\nand KD losses in EFDLS. Fig. 3 shows the MeanACC results\nwith different \u03b5 values when Nconn = 44 and Ntot = 44. It is\nseen that \u03b5 = 0.90 results in the highest MeanACC score, i.e.,\n0.7014. That means \u03b5 = 0.90 is appropriate to reduce each\nuser\u2019s entropy on its data during training.\n\n4.4 Experimental Analysis\nTo evaluate the overall performance of EFDLS, we compare\nit with seven benchmark algorithms listed below against\n\u2018Win\u2019/\u2018Lose\u2019/\u2018Tie\u2019, MeanACC, and AVG rank.\n\n\u2022 Baseline: the single-task TSC algorithm with the\nfeature extractor in Fig. 1 deployed on each user.\nNote that each user has a unique dataset to run and\nknowledge sharing among them is disabled.\n\n\u2022 FedAvg: the FederatedAveraging method using the\nfeature extractor in Fig. 1 [18].\n\n\u2022 FedAvgM: the modified FedAvg using the feature\nextractor in Fig. 1 [27].\n\n\u2022 FedGrad: the federated gradient method using the\nfeature extractor in Fig. 1 [16].\n\n\u2022 FTL: the federated transfer learning method using\nthe feature extractor in Fig. 1 [23].\n\n\u2022 FTLS: FTL [23] based on the DBWM scheme using\nthe feature extractor in Fig. 1.\n\n\u2022 FKD: the federated knowledge distillation using the\nfeature extractor in Fig. 1 [27], [28]. For fair com-\nparison, FKD uses the same student-teacher network\nstructure as EFDLS.\n\nTable 2 shows the top-1 accuracy results with various\nalgorithms on 44 UCR2018 datasets when Nconn = 44 and\nNtot = 44. To visualize the differences between EFDLS and\nthe others, Fig. 4 depicts the accuracy plots of EFDLS against\neach of the remaining algorithms on 44 datasets. In addition,\nthe AVG rank results are shown in Fig. 5.\n\nFirst of all, we study the effectiveness of knowledge shar-\ning among users by comparing EFDLS with Baseline. One\ncan observe that EFDLS beats Baseline in every aspect,\nincluding \u2018Win\u2019/\u2018Lose\u2019/\u2018Tie\u2019, MeanACC, and AVG rank.\nFor example, the former wins 18 out of 44 datasets while\nthe latter wins only 4. The accuracy plot of EFDLS vs.\nBaseline in Fig. 4(a) also supports the finding above. The\nmain difference between EFDLS and Baseline is that the\nlatter only uses standalone feature extractors which do\nnot share the locally collected knowledge with each other.\nOn the other hand, with sufficient knowledge sharing of\nsimilar expertise among users enabled, EFDLS improves the\nsystem\u2019s generalization ability and thus achieves promising\nmulti-task TSC performance.\n\nSecondly, we study the effectiveness of the FBST frame-\nwork by comparing EFDLS with FTLS. It is easily seen that\nEFDLS outperforms FTLS regarding the \u2018best\u2019, MeanACC,\nand AVG rank values. The accuracy plot of EFDLS vs.\nFTLS in Fig. 4(f) also supports this. The FBST framework\nallows efficient knowledge transfer from teacher to stu-\ndent, helping the student capture sufficient discriminate\nrepresentations from the input data. On the contrary, the\nFTLS\u2019s learning model lacks of self-generalization, leading\nto deteriorated performance during knowledge sharing.\n\nThirdly, we study the effectiveness of the DBWM\nscheme by comparing EFDLS with FKD. Apparently, EFDLS\noverweighs FKD with respect to \u2018best\u2019, MeanACC, and\nAVG rank. It is backed by the accuracy plot of EFDLS vs.\nFTLS in Fig. 4(g). As mentioned before, at each federated\nlearning epoch, the DBWM scheme finds a partner for each\nuser and then EFDLS offers weights exchange between each\npair of connected users, which realizes knowledge sharing\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 9\n\nFig. 4. Accuracy plot results showing the performance difference between two given algorithms. (a) Baseline vs. EFDLS; (b) FedAvg vs. EFDLS;\n(c) FedAvgM vs. EFDLS; (d) FedGrad vs. EFDLS; (e) FTL vs. EFDLS; (f) FTLS vs. EFDLS; (g) FKD vs. EFDLS.\n\nof similar expertise among different users. In contrast, FKD\nadopts the average weights to supervise the feature extrac-\ntion process in each user. It is likely to lead to catastrophic\nforgetting in a user whose weights significantly differ from\nthe average weights.\n\nLast but not least, we compare EFDLS with all the\nseven algorithms. One can easily observe that our EFDLS\nis no doubt the best among all algorithms for comparison\nsince ours obtains the highest MeanACC and \u2018best\u2019 values,\nnamely 0.7014 and 20, and the smallest AVG rank value,\nnamely 2.1478. The FKD takes the second position when\nconsidering its \u2018best\u2019, MeanACC, and AVG rank values,\nnamely, 11, 0.6878, and 2.6364. On the other hand, FedAvg\nand its variant, FedAvgM, are the two worst algorithms. The\nfollowing explains the reasons behind the findings above.\nWhen faced with the multi-task TSC problem, each user\nruns one TSC task, and different users may run different\nTSC tasks. The FBST framework and the DBWM scheme\nhelp EFDLS to realize fine-grained knowledge sharing be-\ntween any pair of users with the most similar expertise.\nFKD uses the average of all users\u2019 weights to guide each\nuser to capture valuable features from the data, promoting\ncoarse-grained knowledge sharing among users. On the\nother hand, FedAvg and FedAvgM simply take the average\nweights of all users as each user\u2019s weights, which may\ncause catastrophic forgetting and hence poor performance\non multi-task TSC.\n\n5 CONCLUSION\n\nThe FBST framework promotes knowledge transfer from a\nteacher\u2019s to its student\u2019s hidden layers, helping the student\ncapture instance-level representations from the input. The\nDBWM scheme finds a partner for each user in terms of\nsimilarity between their uploaded weights, enabling knowl-\nedge sharing of similar expertise among different users.\n\nWith FBST and DBWM, the proposed EFDLS securely shares\nknowledge of similar expertise among different tasks for\nmulti-task time series classification. Experimental results\nshow that compared with six benchmark FL algorithms,\nEFDLS is a winner on 44 datasets with respect to the\nMeanACC and AVG rank metrics and on 20 datasets in\nterms of the \u2018best\u2019 measure. In particular, compared with\nsingle-task Baseline, EFDLS obtains 32/4/8 regarding the\n\u2018win\u2019/\u2018tie\u2019/\u2018lose\u2019 metric. That reflects the potential of EFDLS\nto be applied to multi-task TSC problems in various real-\nworld domains.\n\nREFERENCES\n\n[1] G. Pang and C. Aggarwal, \u201cToward explainable deep anomaly\ndetection,\u201d In Proc. ACM KDD\u201921, p. 4056\u20134057, 2021.\n\n[2] J. Li, H. He, H. He, L. Li, and Y. Xiang, \u201cAn end-to-end framework\nwith multisource monitoring data for bridge health anomaly iden-\ntification,\u201d IEEE Trans. Instrum. Meas., vol. 70, pp. 1\u20139, 2021.\n\n[3] X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Sheng, H. Xiong, and\nL. Akoglu, \u201cA comprehensive survey on graph anomaly detection\nwith deep learning,\u201d IEEE Trans. Knowl. Data Eng., pp. 1\u20131, 2021.\n\n[4] H. Tong and J. Zhu, \u201cNew peer effect-based approach for service\nmatching in cloud manufacturing under uncertain preferences,\u201d\nAppl. Soft Comput., vol. 94, pp. 1\u201317, 2020.\n\n[5] L. Shi, Z. Teng, L. Wang, Y. Zhang, and A. Binder, \u201cDeepclue:\nVisual interpretation of text-based deep stock prediction,\u201d IEEE\nTrans Knowl. Data Eng., vol. 31, no. 6, pp. 1094\u20131108, 2019.\n\n[6] D. Nahmias and K. Kontson, \u201cEasy perturbation eeg algorithm\nfor spectral importance (easypeasi): A simple method to identify\nimportant spectral features of eeg in deep learning models,\u201d In\nProc. ACM KDD\u201921, p. 2398\u20132406, 2021.\n\n[7] F. Zhang, Y. Liu, N. Feng, C. Yang, J. Zhai, S. Zhang, B. He, J. Lin,\nX. Zhang, and X. Du, \u201cPeriodic weather-aware lstm with event\nmechanism for parking behavior prediction,\u201d IEEE Trans. Knowl.\nData Eng., pp. 1\u20131, 2021.\n\n[8] H. Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P.-A. Muller,\n\u201cDeep learning for time series classification: a review,\u201d Data Min.\nKnowl. Disc., vol. 33, pp. 917\u2013963, 2019.\n\n[9] \u2014\u2014, \u201cTime series classification from scratch with deep neural\nnetworks: A strong baseline,\u201d In Proc. IEEE IJCNN 2017, pp. 1578\u2013\n1585, 2017.\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 10\n\nFig. 5. Critical difference diagram of the average ranks of various FL algorithms on 44 datasets.\n\n[10] X. Zhang, Y. Gao, J. Lin, and C.-T. Lu, \u201cTapnet: Multivariate\ntime series classification with attentional prototypical network,\u201d\nIn Proc. AAAI 2020, pp. 6845\u20136852, 2020.\n\n[11] F. Karim, S. Majumdar, H. Darabi, and S. Harford, \u201cMultivariate\nlstm-fcns for time series classification,\u201d Neural Networks, vol. 116,\npp. 237\u2013245, 2019.\n\n[12] Z. Xiao, X. Xu, H. Xing, S. Luo, P. Dai, and D. Zhan, \u201cRtfn: A robust\ntemporal feature network for time series classification.\u201d Inform.\nSciences, vol. 571, pp. 65\u201386, 2021.\n\n[13] G. Li, B. Choi, J. Xu, S. Bhowmick, K.-P. Chun, and G. Wong,\n\u201cShapenet: A shapelet-neural network approach for multivariate\ntime series classification,\u201d In Proc. AAAI 2021, vol. 35, no. 9, pp.\n8375\u20138383, 2021.\n\n[14] D. Lee, S. Lee, and H. Yu, \u201cLearnable dynamic temporal pooling\nfor time series classification,\u201d In Proc. AAAI 2021, vol. 35, no. 9, pp.\n8288\u20138296, 2021.\n\n[15] B. Arcas, G. Bacon, K. Bonawitz, and et al, \u201cFederated\nlearning: Collaborative machine learning without centralized\ntraining data,\u201d https://ai.googleblog.com/2017/04/federated-learning-\ncollaborative.html, 2017.\n\n[16] Q. Yang, Y. Liu, T. Chen, and Y. Tong, \u201cFederated machine learn-\ning: Concept and applications,\u201d ACM Trans. Intell. Syst. Technol.,\nvol. 10, no. 2, pp. 1\u201319, 2019.\n\n[17] Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, Y. Li, X. Liu, and B. He,\n\u201cA survey on federated learning systems: Vision, hype and reality\nfor data privacy and protection,\u201d IEEE Trans. Knowl. Data Eng., pp.\n1\u20131, 2021.\n\n[18] M. McMahan, E. Moore, D. Ramage, S. Hampson, and B. Arcas,\n\u201cCommunication-efficient learning of deep networks from decen-\ntralized data,\u201d In Proc. AISTATS 2017, pp. 1\u201311, 2017.\n\n[19] J. Ma, Q. Zhang, J. Lou, L. Xiong, and J. Ho, \u201cCommunication ef-\nficient federated generalized tensor factorization for collaborative\nhealth data analytics,\u201d In Proc. 30th The Web Conference 2021, 2021.\n\n[20] B. Liu, Y. Guo, and X. Chen, \u201cPfa: Privacy-preserving federated\nadaptation for effective model personalization,\u201d In Proc. 30th The\nWeb Conference 2021, 2021.\n\n[21] J. Wu, Z. Huang, Y. Ning, H. Wang, E. Chen, J. Yi, and B. Zhou,\n\u201cHierarchical personalized federated learning for user modeling,\u201d\nIn Proc. 30th The Web Conference 2021, 2021.\n\n[22] Q. Yang, J. Zhang, W. Hao, G. Spell, and L. Carin, \u201cFlop: Federated\nlearning on medical datasets using partial networks,\u201d In Proc.\nACM KDD\u201921, 2021.\n\n[23] Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, \u201cA secure federated\ntransfer learning framework,\u201d IEEE Intell. Syst., vol. 35, no. 4, pp.\n70\u201382, 2020.\n\n[24] H. Yang, H. He, W. Zhang, and X. Cao, \u201cFedsteg: A federated\ntransfer learning framework for secure image steganalysis,\u201d IEEE\nTrans. Netw. Sci. Eng., vol. 8, no. 2, pp. 1084\u20131094, 2021.\n\n[25] D. Dimitriadis, K. Kumatani, R. Gmyr, Y. Gaur, and S. Eskimez,\n\u201cFederated transfer learning with dynamic gradient aggregation,\u201d\narXiv preprint arXiv:2008.02452, 2020.\n\n[26] U. Majeed, S. Hassan, and C. Hong, \u201cCross-silo model-based\nsecure federated transfer learning for flow-based traffic classifi-\ncation,\u201d In Proc. ICOIN 2021, 2021.\n\n[27] H. Seo, J. Park, S. Oh, M. Bennis, and S.-L. Kim, \u201cFederated\nknowledge distillation,\u201d arXiv preprint arXiv:2011.02367, 2020.\n\n[28] C. He, M. Annavaram, and S. Avestimehr, \u201cGroup knowledge\ntransfer: Federated learning of large cnns at the edge,\u201d In Proc.\nNeurIPS 2020, 2020.\n\n[29] R. Mishra, H. Gupta, and T. Dutta, \u201cA network resource aware\nfederated learning approach using knowledge distillation,\u201d In\nProc. INFOCOM 2021, 2021.\n\n[30] S. Itahara, T. Nishio, Y. Koda, M. Morikura, and K. Ya-\nmamoto, \u201cDistillation-based semi-supervised federated learning\nfor communication-efficient collaborative training with non-iid\nprivate data,\u201d IEEE Trans. Mobile Comput., pp. 1\u20131, 2021.\n\n[31] Y. Chen, X. Sun, and Y. Jin, \u201cCommunication-efficient federated\ndeep learning with layer-wise asynchronous model update and\ntemporally weighted aggregation,\u201d IEEE Trans. Neur. Net. Learn.\nSys., vol. 31, no. 10, pp. 4229\u20134238, 2020.\n\n[32] F. Sattler, S. Wiedemann, K.-R. Mu\u0308ller, and W. Samek, \u201cRobust and\ncommunication-efficient federated learning from non-i.i.d. data,\u201d\nIEEE Trans. Neur. Net. Learn. Sys., vol. 31, no. 9, pp. 3400\u20133413,\n2020.\n\n[33] L. Nagalapatti and R. Narayanam, \u201cGame of gradients: Mitigat-\ning irrelevant clients in federated learning,\u201d In Proc. AAAI 2021,\nvol. 35, no. 10, pp. 9046\u20139054, 2021.\n\n[34] X. Cao, J. Jia, and N. Gong, \u201cProvably secure federated learning\nagainst malicious clients,\u201d In Proc. AAAI 2020, vol. 35, no. 8, pp.\n6885\u20136893, 2020.\n\n[35] J. Hong, Z. Zhu, S. Yu, Z. Wang, H. Dodge, and J. Zhou, \u201cFederated\nadversarial debiasing for fair and transferable representations,\u201d In\nProc. ACM KDD\u201921, vol. 1, no. 1, August 2021.\n\n[36] P. Zhou, L. Wang, L. Guo, S. Gong, and B. Zheng, \u201cA privacy-\npreserving distributed contextual federated online learning frame-\nwork with big data support in social recommender systems,\u201d IEEE\nTrans. Knowl. Data Eng., vol. 33, no. 3, pp. 824\u2013838, 2021.\n\n[37] Z. Pan, L. Hu, W. Tang, J. Li, Y. He, and Z. Liu, \u201cPrivacy-\npreserving multi-granular federated neural architecture search a\ngeneral framework,\u201d IEEE Trans. Knowl. Data Eng., pp. 1\u20131, 2021.\n\n[38] M. Crawshaw, \u201cMulti-task learning with deep neural networks: A\nsurvey,\u201d arXiv preprint arXiv: 2009.09796, 2020.\n\n[39] A. Ruiz, M. Flynn, and A. Bagnall, \u201cBenchmarking multivari-\nate time series classification algorithms,\u201d arXiv preprint arXiv:\n2007.13156, 2020.\n\n[40] J. Lines and A. Bagnall, \u201cTime series classification with ensembles\nof elastic distance measures,\u201d Data Min. Knowl. Disc., vol. 29, p.\n565\u2013592, 2015.\n\n[41] A. Bagnall, J. Lines, J. Hills, and A. Bostrom, \u201cTime series classi-\nfication with cote: the collective of transformation-based ensem-\nbles,\u201d In Proc. ICDE 2016, pp. 1548\u20131549, 2016.\n\n[42] J. Lines, S. Taylor, and A. Bagnall, \u201cTime series classification with\nhive-cote: the hierarchical of transformation-based ensembles,\u201d\nACM Trans. Knowl. Discov. D, vol. 21, no. 52, pp. 1\u201335, 2018.\n\n[43] K. Fauvel, E. Fromont, V. Masson, P. Faverdin, and A. Termier, \u201cLo-\ncal cascade ensemble for multivariate data classification,\u201d arXiv\npreprint arXiv:2005.03645, 2020.\n\n[44] J. Lines, L. Davis, J. Hills, and A. Bagnall, \u201cA shapelet transform\nfor time series classification,\u201d In Proc. ACM KDD\u201912, 2012.\n\n[45] M. Baydogan, G. Runger, and E. Tuv, \u201cA bag-of-features frame-\nwork to classify time series,\u201d IEEE Trans. Pattern Anal., vol. 35,\nno. 11, pp. 2796\u20132802, 2013.\n\n[46] A. Dempster, D. Schmidt, and G. Webb, \u201cMinirocket: A very fast\n(almost) deterministic transform for time series classification,\u201d In\nProc. ACM KDD\u201921, 2021.\n\n[47] M. Baydogan and G. Runger, \u201cTime series representation and\nsimilarity based on local auto patterns,\u201d Data Min. Knowl. Disc.,\nvol. 30, p. 476\u2013509, 2016.\n\n[48] J. Large, A. Bagnall, S. Malinowski, and R. Tavenard, \u201cFrom bop to\nboss and beyond: time series classification with dictionary based\nclassifier,\u201d arXiv preprint arXiv:1809.06751, 2018.\n\n[49] W. Pei, H. Dibeklioglu, D. Tax, and L. van der Maaten, \u201cMultivari-\nate time-series classification using the hidden-unit logistic model,\u201d\nIEEE Trans. Neur. Net. Lear., vol. 29, no. 4, pp. 920\u2013931, 2018.\n\n\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 11\n\n[50] H. Deng, G. Runger, E. Tuv, and M. Vladimir, \u201cA time series forest\nfor classification and feature extraction,\u201d Inform. Sciences, vol. 239,\np. 142\u2013153, 2013.\n\n[51] B. Bai, G. Li, S. Wang, Z. Wu, and W. Yan, \u201cTime series clas-\nsification based on multi-feature dictionary representation and\nensemble learning,\u201d Expert Syst. Appl., vol. 169, pp. 1\u201310, 2021.\n\n[52] H. Fawaz, B. Lucas, G. Forestier, C. Pelletier, D. Schmidt, J. Weber,\nG. Webb, L. Idoumghar, P.-A. Muller, and F. Petitjean, \u201cIncep-\ntiontime: finding alexnet for time series classification,\u201d Data Min.\nKnowl. Disc., vol. 34, p. 1936\u20131962, 2020.\n\n[53] Z. Xiao, X. Xu, H. Zhang, and E. Szczerbicki, \u201cA new multi-process\ncollaborative architecture for time series classification,\u201d Knowl.-\nBased Syst., vol. 220, pp. 1\u201311, 2021.\n\n[54] W. Chen and K. Shi, \u201cMulti-scale attention convolutional neural\nnetwork for time series classification,\u201d Neural Networks, vol. 136,\npp. 126\u2013140, 2021.\n\n[55] S. Huang, L. Xu, and C. Jiang, \u201cArtificial intelligence and ad-\nvanced time series classification: Residual attention net for cross-\ndomain modeling,\u201d Fintech with Artificial Intelligence, Big Data, and\nBlockchain, Blockchain Technologies, 2021.\n\n[56] Z. Xiao, X. Xu, H. Xing, R. Qu, F. Song, and B. Zhao, \u201cRnts:\nRobust neural temporal search for time series classification,\u201d In\nProc. IJCNN 2021, 2021.\n\n[57] J. Guo, B. Yu, S. Maybank, and D. Tao, \u201cKnowledge distillation: A\nsurvey,\u201d arXiv preprint arXiv: 2006.05525, 2020.\n\n[58] H. Dau, A. Bagnall, C.-C. M. Yeh, Y. Zhu, S. Gharghabi,\nC. Ratanamahatana, and E. Keogh, \u201cThe ucr time series archive,\u201d\nIEEE/CAA Journal of Automatica Sinica, vol. 6, no. 6, pp. 1293\u20131305,\n2019.\n\n\n\t1 Introduction\n\t2 Related Work\n\t2.1 Traditional Algorithms\n\t2.2 Deep Learning Algorithms\n\n\t3 EFDLS\n\t3.1 System Overview\n\t3.2 Feature-based Student-Teacher Framework\n\t3.2.1 Feature Extractor\n\t3.2.2 Knowledge Distillation\n\n\t3.3 Distance-based Weights Matching\n\t3.3.1 Least Square Distance\n\n\t3.4 Communication Overhead\n\n\t4 Performance Evaluation\n\t4.1 Experimental Setup\n\t4.1.1 Data Description\n\t4.1.2 Implementation Details\n\n\t4.2 Performance Metrics\n\t4.3 Ablation Study\n\t4.3.1 Impact of Nconn\n\t4.3.2 Impact of \n\n\t4.4 Experimental Analysis\n\n\t5 Conclusion\n\tReferences\n\n"}
{"Title": "MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning", "Authors": "Markus Peschl, Arkady Zgonnikov, Frans A. Oliehoek, Luciano C. Siebert", "Abstract": "  Inferring reward functions from demonstrations and pairwise preferences are auspicious approaches for aligning Reinforcement Learning (RL) agents with human intentions. However, state-of-the art methods typically focus on learning a single reward model, thus rendering it difficult to trade off different reward functions from multiple experts. We propose Multi-Objective Reinforced Active Learning (MORAL), a novel method for combining diverse demonstrations of social norms into a Pareto-optimal policy. Through maintaining a distribution over scalarization weights, our approach is able to interactively tune a deep RL agent towards a variety of preferences, while eliminating the need for computing multiple policies. We empirically demonstrate the effectiveness of MORAL in two scenarios, which model a delivery and an emergency task that require an agent to act in the presence of normative conflicts. Overall, we consider our research a step towards multi-objective RL with learned rewards, bridging the gap between current reward learning and machine ethics literature.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00012", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning\n\n\nMORAL: Aligning AI with Human Norms through\nMulti-Objective Reinforced Active Learning\n\nMarkus Peschl\n\nDelft University of Technology\n\nDelft, The Netherlands\n\npeschl@protonmail.com\n\nArkady Zgonnikov\n\nDelft University of Technology\n\nDelft, The Netherlands\n\nA.Zgonnikov@tudelft.nl\n\nFrans A. Oliehoek\n\nDelft University of Technology\n\nDelft, The Netherlands\n\nF.A.Oliehoek@tudelft.nl\n\nLuciano C. Siebert\n\nDelft University of Technology\n\nDelft, The Netherlands\n\nL.CavalcanteSiebert@tudelft.nl\n\nABSTRACT\nInferring reward functions from demonstrations and pairwise pref-\n\nerences are auspicious approaches for aligning Reinforcement Learn-\n\ning (RL) agents with human intentions. However, state-of-the art\n\nmethods typically focus on learning a single reward model, thus\n\nrendering it difficult to trade off different reward functions from\n\nmultiple experts. We propose Multi-Objective Reinforced Active\n\nLearning (MORAL), a novel method for combining diverse demon-\n\nstrations of social norms into a Pareto-optimal policy. Through\n\nmaintaining a distribution over scalarization weights, our approach\n\nis able to interactively tune a deep RL agent towards a variety of\n\npreferences, while eliminating the need for computing multiple\n\npolicies. We empirically demonstrate the effectiveness of MORAL\n\nin two scenarios, which model a delivery and an emergency task\n\nthat require an agent to act in the presence of normative conflicts.\n\nOverall, we consider our research a step towards multi-objective\n\nRL with learned rewards, bridging the gap between current reward\n\nlearning and machine ethics literature.\n\nKEYWORDS\nActive Learning; Inverse Reinforcement Learning; Multi-Objective\n\nDecision-Making; Value Alignment\n\n1 INTRODUCTION\nThe design of adequate reward functions poses a tremendous chal-\n\nlenge for building reinforcement learning (RL) agents that ought to\n\nact in accordance with human intentions [4, 13]. Besides compli-\n\ncating the deployment of RL in the real world [11], this can lead\n\nto major unforeseen societal impacts, which need to be accounted\n\nfor when building autonomous systems [6, 45]. To tackle this, the\n\nfield of value alignment has largely focused on reward learning,\n\nwhich aims to adopt a bottom-up approach of finding goal speci-\n\nfications from observational data instead of manually specifying\n\nthem [22, 30, 40]. However, such technical approaches cannot on\n\ntheir own solve the normative value alignment problem of decid-\n\ning which values should ultimately be encoded into an agent [15].\n\nNonetheless, building methods that allow for learning and trading\n\noff different conflicting values could potentially alleviate this issue,\n\nthus making such methods an important avenue of research for\n\nbeneficial artificial intelligence (AI) [35].\n\nJointly optimizing for different rewards can be cast into multi-\n\nobjective RL (MORL) [32], which constitutes a promising framework\n\nfor building human-aligned AI [42]. Using game-theoretic notions\n\nof optimality,MORL typically aims to find a solution, or a set thereof,\n\nthat can represent a variety of preferences over the components\n\nof a vector-valued reward function. While this can theoretically\n\ntackle the overoptimization of narrowly defined tasks, the designer\n\nstill needs to manually specify multiple reward functions.\n\nInverse RL (IRL) [16, 51] and preference-based RL [10, 46] of-\n\nfer techniques for avoiding the reward design problem altogether\n\nby learning a parametric reward model from demonstrations and\n\npairwise preferences, respectively. In this paper, we combine these\n\napproaches in a multi-objective setting with a focus on learning\n\nhuman norms. The motivation for this is twofold: Firstly, previ-\n\nous research on learning multiple reward functions has mostly\n\nemployed latent-variable IRL models for finding multiagent [19],\n\nhierarchical [41, 43] and multitask [17, 50] rewards, whereas find-\n\ning aggregated rewards from conflicting sequential data has yet\n\nto be addressed. Secondly, a major challenge of value alignment is\n\nensuring that an agent can predict its adherence to norms in the\n\nenvironment. Such adherence is implicitly embedded in human goal\n\nspecifications but missing in manually engineered reward functions\n\n[20]. Our goal therefore is to find a policy that acts on a common\n\nset of social norms while allowing for fine-tuning the agent with\n\nrespect to inherent disagreements that may arise.\n\nContributions. We propose Multi-Objective Reinforced Active\n\nLearning (MORAL), a method that combines active preference learn-\n\ning and IRL to interactively learn a policy of social norms from\n\nexpert demonstrations. MORAL first finds a vector-valued reward\n\nfunction through adversarial IRL, which is subsequently used in an\n\ninteractive MORL loop. By requesting pairwise preferences over\n\ntrajectories of on-policy experience from an expert, MORAL learns\n\na probability distribution over linear combinations of reward func-\n\ntions under which the optimal policy most closely matches the\n\ndesired behavior. We show that our approach directly approximates\n\na Pareto-optimal solution in the space of expert reward functions,\n\nwithout the need of enumerating through a multitude of preference\n\nweights. Finally, we demonstrate that MORAL efficiently captures\n\nnorms in two gridworld scenarios, while being able to adapt the\n\nagent\u2019s behavior to a variety of preferences.\n1\n\n1\nSource code is available at https://github.com/mlpeschl/moral_rl.\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n2v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n0 \nD\n\nec\n 2\n\n02\n1\n\nhttps://github.com/mlpeschl/moral_rl\n\n\n2 PRELIMINARIES\nMulti-Objective RL. We employ a multi-objective Markov deci-\n\nsion process (MOMDP) for framing the problem of aligning an\n\nagent with multiple experts. Formally, a MOMDP is given by the\n\ntuple \u27e8S,A, \ud835\udc5d, r, `0, \ud835\udefe\u27e9, with state space S, the set of actions A,\n\na transition distribution \ud835\udc5d (\ud835\udc60 \u2032 |\ud835\udc60, \ud835\udc4e), a vector-valued reward func-\n\ntion r(\ud835\udc60, \ud835\udc4e) \u2208 R\ud835\udc5a , a starting state distribution `0 and the discount\n\nfactor \ud835\udefe \u2208 [0, 1). We consider optimal solutions to be given by\n\na Pareto frontier F = {\ud835\udf0b |\ufffd\ud835\udf0b \u2032 \u2260 \ud835\udf0b : \ud835\udc3dr (\ud835\udf0b \u2032) \u2265 \ud835\udc3dr (\ud835\udf0b)}, where\n\ud835\udc3dr (\ud835\udf0b) = E\ud835\udf0b [\n\n\u2211\ud835\udc47\n\ud835\udc61=0 \ud835\udefe\n\n\ud835\udc61 r(\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )] is the vector-valued return of a pol-\n\nicy \ud835\udf0b : S \u2192 \u0394A that maps states to a distribution over actions.\n\nFurthermore, we define the convex coverage set (CCS) F \u2217 = {\ud835\udf0b \u2208\nF | \u2203w \u2208 R\ud835\udc5a : w\ud835\udc47 \ud835\udc3dr (\ud835\udf0b) \u2265 w\ud835\udc47 \ud835\udc3dr (\ud835\udf0b \u2032), \u2200\ud835\udf0b \u2032 \u2208 F } to be the subset of\nPareto-optimal solutions that can be obtained through optimizing\n\nfor linear combinations of the different reward components.\n\nProximal Policy Optimization (PPO). Given a weight w \u2208 R\ud835\udc5a ,\n\nwe can optimize for policies on the CCS using PPO [39] on the\n\nscalarized reward \ud835\udc5f (\ud835\udc60, \ud835\udc4e) = w\ud835\udc47 r(\ud835\udc60, \ud835\udc4e). Using on-policy experience,\n\nPPO maximizes the return of a parametrized policy \ud835\udf0b\ud835\udf19 by perform-\n\ning gradient descent on the clipped objective\n\nLCLIP (\ud835\udf19) = E\ud835\udc61 [min(\ud835\udc5f\ud835\udc61 (\ud835\udf19)\ud835\udc34\ud835\udc61 , \ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc5d (\ud835\udc5f\ud835\udc61 (\ud835\udf19), 1 \u2212 \ud835\udf16, 1 + \ud835\udf16)\ud835\udc34\ud835\udc61 )],\n\nwhere E\ud835\udc61 is the expectation at time \ud835\udc61 , \ud835\udc5f\ud835\udc61 is a ratio of the new versus\n\nthe current policy, \ud835\udc34\ud835\udc61 is an estimated advantage at time \ud835\udc61 and\n\n\ud835\udc50\ud835\udc59\ud835\udc56\ud835\udc5d (\ud835\udc65, \ud835\udc4e, \ud835\udc4f) limits the value of \ud835\udc65 to the interval [\ud835\udc4e, \ud835\udc4f].\nAdversarial IRL (AIRL). The maximum entropy IRL [51] goal\n\nis to derive a reward function \ud835\udc5f\\ from a demonstration dataset\n\nD = {\ud835\udf0f\ud835\udc56 }\ud835\udc41\ud835\udc56=1 of expert trajectories \ud835\udf0f = {\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 }\ud835\udc47\ud835\udc61=0 by solving a\n\nmaximum likelihood problem max\ud835\udf19 E\ud835\udf0f\u223cD [log \ud835\udc5d\\ (\ud835\udf0f)], where\n\n\ud835\udc5d\\ (\ud835\udf0f) \u221d `0 (\ud835\udc600)\n\ud835\udc47\u220f\n\ud835\udc61=0\n\n\ud835\udc5d (\ud835\udc60\ud835\udc61+1 |\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 ) exp(\ud835\udc5f\\ (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )) = \ud835\udc5d\\ (\ud835\udf0f). (1)\n\nAIRL [14] approximately solves the IRL problem using generative\n\nadversarial networks [18]. It jointly trains a policy (generator) \ud835\udf0b\ud835\udf19\nalongside a discriminator of the form\n\n\ud835\udc37\\ (\ud835\udc60, \ud835\udc4e) =\nexp(\ud835\udc53\\ (\ud835\udc60, \ud835\udc4e))\n\nexp(\ud835\udc53\\ (\ud835\udc60, \ud835\udc4e)) + \ud835\udf0b\ud835\udf19 (\ud835\udc4e |\ud835\udc60)\n.\n\nWhile \ud835\udc37\\ is trained using a binary cross-entropy loss to distinguish\n\ntrajectories in D from \ud835\udf0b\ud835\udf19 , the agent maximizes its returns using\n\nthe reward \ud835\udc5f (\ud835\udc60, \ud835\udc4e) = log(\ud835\udc37\\ (\ud835\udc60, \ud835\udc4e)) \u2212 log(1 \u2212 \ud835\udc37\\ (\ud835\udc60, \ud835\udc4e)).\n\n3 MULTI-OBJECTIVE REINFORCED ACTIVE\nLEARNING\n\nMORAL uses a two-step procedure that separates reward and policy\n\ntraining to learn from multiple experts (figure 1). In the first step\n\n(IRL), we use a set of trajectories D\ud835\udc38 = \u222a\ud835\udc58\n\ud835\udc56=1\nD\ud835\udc38\ud835\udc56 demonstrated\n\nby \ud835\udc58 distinct experts and run AIRL to obtain a vector of reward\n\nfunctions r = (\ud835\udc53\\1 , . . . , \ud835\udc53\\\ud835\udc58 ) and imitation policies (\ud835\udf0b\u2217\n\ud835\udc381\n, . . . , \ud835\udf0b\u2217\n\n\ud835\udc38\ud835\udc58\n)\n\nfor each subset of trajectories D\ud835\udc38\ud835\udc56 . In step two (active MORL), we\nrun an interactive MORL algorithm for learning a distribution over\n\nweights that determine a linear combination of the different com-\n\nponents in r. We will now explain how this distribution is learned\n\nalongside training a deep RL agent in a single loop. Firstly, active\n\nMORL takes a prior \ud835\udc5d (w) over scalarization weights and initializes a\n\nExpert 1\n\nExpert k\n\nProvides\n\nProvides\n\nStep 1: IRL\n\nAIRL\n\nReward \nFunction\n\nStep 2: Active MORL\n\nPosterior Mean\n\nUpdate\nQuery\n\nPPO\n\nPrior\n\nFigure 1: Multi-Objective Reinforced Active Learning.\n\nreward function \ud835\udc5f (\ud835\udc60, \ud835\udc4e) = Ew [w\ud835\udc47 r(\ud835\udc60, \ud835\udc4e)]. Subsequently, we repeat-\nedly (i) optimize for the scalar reward \ud835\udc5f by running PPO for a given\n\nnumber of steps, (ii) query an expert for a pairwise comparison \ud835\udc5e\ud835\udc5b\nof two trajectories and (iii) update the posterior \ud835\udc5d (w|\ud835\udc5e1, . . . , \ud835\udc5e\ud835\udc5b).\nFinally, the reward function is reinitialized to the posterior mean\n\nscalarization and is used by PPO in the next iteration.\n\nTo query and update, we specify a probabilistic model over expert\n\npreferences. We employ a Bradley-Terry model [7]\n\n\ud835\udc5d (\ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 |w) =\nexp(w\ud835\udc47 r(\ud835\udf0f\ud835\udc56 ))\n\nexp(w\ud835\udc47 r(\ud835\udf0f \ud835\udc57 )) + exp(w\ud835\udc47 r(\ud835\udf0f\ud835\udc56 ))\n, (2)\n\nwith r(\ud835\udf0f) = \u2211\n(\ud835\udc60,\ud835\udc4e,\ud835\udc60\u2032) \u2208\ud835\udf0f r(\ud835\udc60, \ud835\udc4e, \ud835\udc60 \u2032) being the reward obtained from a\n\ntrajectory \ud835\udf0f and \ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 denoting the preference of \ud835\udf0f\ud835\udc56 over \ud835\udf0f \ud835\udc57 . This\n\nway, trajectories that achieve a higher linearly scalarized reward\n\nare ranked exponentially better in proportion. Assuming that a\n\nnumber of pairwise comparisons {\ud835\udc5e1, . . . \ud835\udc5e\ud835\udc5b} have been obtained,\n\nwe can then simply update the posterior in a Bayesian manner\n\n\ud835\udc5d (w|\ud835\udc5e1, . . . , \ud835\udc5e\ud835\udc5b) \u221d \ud835\udc5d (w)\n\ud835\udc5b\u220f\n\ud835\udc61=1\n\n\ud835\udc5d (\ud835\udc5e\ud835\udc61 |w) . (3)\n\nIn our experiments, we choose the prior \ud835\udc5d (w) to be uniform over\n\nall weights w with | |w| | \u2264 1 and w \u2265 0.\n\nThis Bayesian model allows us to maintain a posterior that de-\n\ntermines which reward components should be prioritized at each\n\niteration. By providing pairwise preferences, an expert is then able\n\nto fine-tune the agent to any specific behavior that can theoretically\n\nresult from the linear combination of reward components. Further-\n\nmore, we can leverage the uncertainty of the posterior to enable the\n\nagent to form queries the answers to which are highly informative.\n\nNamely, we use the active learning procedure which forms queries\n\nbased on the amount of removed posterior volume [36]\n\nmax\n\n(\ud835\udf0f\ud835\udc56 ,\ud835\udf0f \ud835\udc57 )\nmin\n\n(\nEw [1 \u2212 \ud835\udc5d (\ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 |w)],Ew [1 \u2212 \ud835\udc5d (\ud835\udf0f \ud835\udc57 \u227b \ud835\udf0f\ud835\udc56 |w)]\n\n)\n, (4)\n\nwhere the expectation overw is approximated using Markov Chain\n\nMonte Carlo (MCMC) [9].\n\nUnfortunately, for sufficiently complex MOMDPs, maximizing\n\nthis expression over all pairs of feasible trajectories proves to be\n\ncomputationally intractable. Instead, we do a discrete search over\n\nrandomly sampled pairs of trajectories that arise during on-policy\n\nRL experience (algorithm 1). Before each policy improvement step,\n\nwe sample pairs (\ud835\udf0f\ud835\udc56 , \ud835\udf0f \ud835\udc57 ) and evaluate the corresponding minimum\n\nin expression (4). If (\ud835\udf0f\ud835\udc56 , \ud835\udf0f \ud835\udc57 ) scores highest among all previous pairs\n\n\n\nobtained since the last posterior update, it is saved in a buffer and\n\nqueued for the next query, unless a better pair is found later on.\n\nOverall, this active learning scheme minimizes the number of\n\nqueries needed during training to converge to a desired reward\n\nscalarization. Nonetheless, forming queries based on on-policy ex-\n\nperience can only lead to locally optimal solutions. Therefore, as-\n\nsuming fixed weights w, we optimize for an entropy-regularized\n\nobjective\n\n\ud835\udf0b\u2217 = argmax\n\n\ud835\udf0b\nE\ud835\udf0b\n\n[\n\ud835\udc47\u2211\ufe01\n\ud835\udc61=0\n\nw\ud835\udc47 r(\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 ) \u2212 log\ud835\udf0b (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\n]\n. (5)\n\nThis way, MORAL can be interpreted as finding an average of\n\nKullback-Leibler (KL) divergences [27] between the policy distri-\n\nbution over trajectories \ud835\udf0b (\ud835\udf0f) = `0 (\ud835\udc600)\n\u220f\ud835\udc47\u22121\n\ud835\udc61=0 \ud835\udc5d (\ud835\udc60\ud835\udc61+1 |\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\ud835\udf0b (\ud835\udc4e\ud835\udc61 |\ud835\udc60\ud835\udc61 )\n\nand the marginal maximum entropy IRL distributions (1).\n\nTheorem 3.1. Given w \u2208 R\ud835\udc58 with w \u2265 0,\n\u2211\n\ud835\udc64\ud835\udc56 = 1, we have that\n\n\ud835\udf0b\u2217 = argmin\n\n\ud835\udf0b\n\n\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\n\n\ud835\udc64\ud835\udc56\ud835\udc37\ud835\udc3e\ud835\udc3f (\ud835\udf0b (\ud835\udf0f)) | |\ud835\udc5d\\\ud835\udc56 (\ud835\udf0f)). (6)\n\nProof: We provide a proof in the appendix.\n\nTheorem 3.1 assumes that all components in r arise from max-\n\nimum entropy IRL. However, in practical applications one might\n\nwant to encode additional prior knowledge into the agent\u2019s behav-\n\nior through a manually engineered primary reward function \ud835\udc5f\ud835\udc43 .\n\nNonetheless, by applying analogous reasoning, expression (5) can\n\nbe interpreted as maximizing the returns E\ud835\udf0b [\n\u2211\ud835\udc47\n\ud835\udc61=0 \ud835\udc5f\ud835\udc43 (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )] with\n\na KL regularizer in the form of expression (6). Under this interpre-\n\ntation, MORAL interactively finds regularization hyperparameters\n\nthat determine which expert\u2019s behavior should be prioritized at\n\nruntime.\n\n3.1 Reward Normalization\nFinding scalarization weights in the presence of reward functions\n\nwith highly different scales is a challenging task for many MORL\n\nalgorithms. MORAL, on the other hand, learns its weights from pref-\n\nerences, thus making it less susceptible to reward functions that are\n\ndifficult to compare. Nevertheless, the scale of the reward indirectly\n\nimpacts the sensitivity of the posterior, since the magnitude of the\n\nlikelihood (2) depends on the scalar products of the form w\ud835\udc47 r(\ud835\udf0f).\nAlthough w is bounded by the prior, its product with the vector-\n\nvalued reward r(\ud835\udf0f) can become arbitrarily large, which introduces\n\na risk of removing significant parts of the posterior support based\n\non a single query. To tackle this, we utilize the policies obtained\n\nfrom AIRL to normalize each reward component by setting\n\n\ud835\udc53\\\ud835\udc56 (\ud835\udc60, \ud835\udc4e) =\n\ud835\udc53\\\ud835\udc56 (\ud835\udc60, \ud835\udc4e)\n|\ud835\udc3d (\ud835\udf0b\u2217\n\n\ud835\udc38\ud835\udc56\n) | , (7)\n\nwhere \ud835\udc3d (\ud835\udf0b\u2217\n\ud835\udc38\ud835\udc56\n) = E\ud835\udf0b\u2217\n\n\ud835\udc38\ud835\udc56\n\n[\u2211\ud835\udc47\ud835\udc61=0 \ud835\udefe\ud835\udc61 \ud835\udc53\\\ud835\udc56 (\ud835\udc60, \ud835\udc4e)] is the scalar return of \ud835\udf0b\u2217\n\ud835\udc38\ud835\udc56\n.\n\nThis does not introduce any computational overhead, andwe simply\n\nestimate \ud835\udc3d (\ud835\udf0b\u2217\n\ud835\udc38\ud835\udc56\n) by taking the average obtained return with respect\n\nto \ud835\udc53\\\ud835\udc56 after running AIRL.\n\n4 EXPERIMENTS\nIn the following, we will demonstrate the ability of MORAL in\n\nsimulation studies of two gridworld environments. To enable a\n\nAlgorithm 1: Multi-Objective Reinforced Active Learning\n\nInput: Expert demonstrations D\ud835\udc38 = {\ud835\udf0f\ud835\udc56 }\ud835\udc41\ud835\udc56=1, prior \ud835\udc5d (w).\nInitialize: Reward function r = (\ud835\udc53\\1 , . . . , \ud835\udc53\\\ud835\udc58 ) by running\n\nAIRL on D\ud835\udc38 , PPO agent \ud835\udf0b\ud835\udf19 .\n\nfor \ud835\udc5b = 0, 1, 2, . . . do\nApproximate \ud835\udc5d (w|\ud835\udc5e1, . . . , \ud835\udc5e\ud835\udc5b) through MCMC.\n\nGet mean reward function \ud835\udc5f \u2190 Ew [w\ud835\udc47 r].\n\ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52 \u2190 \u2212\u221e\nfor \ud835\udc58 = 0, 1, 2, . . . , \ud835\udc41 do\n\nSample trajectories D = {\ud835\udf0f\ud835\udc56 }\ud835\udc5a\ud835\udc56=1 using \ud835\udf0b\ud835\udf19 .\nUpdate \ud835\udf19 using PPO to maximize\n\nE\ud835\udf0b\ud835\udf19\n[\u2211\ud835\udc47\n\n\ud835\udc61=0 \ud835\udefe\n\ud835\udc61\ud835\udc5f (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\n\n]\n.\n\nSample a pair of trajectories (\ud835\udf0f\ud835\udc56 , \ud835\udf0f \ud835\udc57 ) from D.\n\n\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52 \u2190 min(Ew [1 \u2212 \ud835\udc5d (\ud835\udf0f\ud835\udc56 \u227b\n\ud835\udf0f \ud835\udc57 |w)],Ew [1 \u2212 \ud835\udc5d (\ud835\udf0f \ud835\udc57 \u227b \ud835\udf0f\ud835\udc56 |w)]) .\nif \ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52 > \ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52 then\n\n\ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f\ud835\udc66 \u2190 (\ud835\udf0f\ud835\udc56 , \ud835\udf0f \ud835\udc57 )\n\ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52 \u2190 \ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc63\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52\n\nQuery expert using \ud835\udc5b\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5f\ud835\udc66 and save answer \ud835\udc5e\ud835\udc5b .\n\nqualitative analysis of the method, we assume that in both envi-\n\nronments, a ground truth reward function exists, which is used to\n\ngenerate demonstrations and responses to the agent\u2019s queries. Fur-\n\nthermore, by following the experimental setup of related research\n\n[30, 47], we consider environments with a primary reward function\n\n\ud835\udc5f\ud835\udc43 , encoding a generic task that can easily be solved through deep\n\nRL. In this case, we can apply MORAL as before, but add \ud835\udc5f\ud835\udc43 as\n\nan additional reward component to the AIRL reward functions for\n\nthe active learning step. To form the gridworld state, we make a\n\nbinary array \ud835\udc3c \u2208 {0, 1}\ud835\udc36\u00d7\ud835\udc4a \u00d7\ud835\udc3b of width\ud835\udc4a and height \ud835\udc3b , as well as\n\nchannels that encode grid occupancy for all\ud835\udc36 different object types\n\non the grid. Finally, we employ a convolutional neural network\n\narchitecture for PPO, consisting of two base convolutional layers\n\nwith kernel size 2, and 64 as well as 256 output channels respec-\n\ntively. Its activations are then fed into two separate convolutional\n\nlayers with kernel size 2 and 32 output channels each, followed\n\nby a linear layer for the critic and actor heads. The details of our\n\nimplementation are provided in the appendix.\n\n4.1 Emergency\nWe start by illustrating howMORAL can be applied to incorporating\n\nsocial norms from a single expert alongside a primary goal. We\n\ndefine the Emergency gridworld as follows: An agent, as well as 6\n\nhumans are randomly positioned onto a 6 \u00d7 6 grid. The humans\n\nare lost and need to be escorted before a time limit of \ud835\udc47 = 75.\n\nFurthermore, the bottom right corner contains a goal state (e.g. a\n\nfire extinguisher in a burning room), which the agent uses when\n\nstanding on its cell. At each step, the agent can either move in one\n\nof the four directions, interact with an adjacent cell or do nothing.\n\nWe define the agent\u2019s primary goal \ud835\udc5f\ud835\udc43 to give a reward of +0.1\nfor each time step spent in the fire extinguisher cell. On the other\n\nhand, the social norm of helping people is not considered in \ud835\udc5f\ud835\udc43 .\n\nIn order to learn the latter, we find a reward \ud835\udc53\\ by running AIRL\n\non 50 synthetic demonstrations coming from a PPO agent that\n\n\n\n0 10 20 30 40 50 60\nExtinguished Fire\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nPe\nop\n\nle\n S\n\nav\ned\n\nMORAL\nCCS\n\n0.10\n\n0.15\n\n0.20\n\n0.25\n\n0.30\n\nFigure 2: Intermediate policies found during MORAL in the\nEmergency domain, compared to a manually computed CCS.\nMORAL approximates a Pareto-optimal solution that most\nclosely matches the given preferences.\n\nmaximizes the number of people saved. Subsequently, we form a\n\nreward vector r = (\ud835\udc5f\ud835\udc43 , \ud835\udc53\\ ) and run interactive MORL using a total\n\nof 25 queries. Since we would like to incorporate the goal of saving\n\nall people into the primary task of extinguishing fire, we provide\n\npreferences in the following way: Given two trajectories (\ud835\udf0f\ud835\udc56 , \ud835\udf0f \ud835\udc57 ),\nwe return \ud835\udc56 \u227b \ud835\udc57 if the number of people saved in \ud835\udf0f\ud835\udc56 exceeds that of\n\n\ud835\udf0f \ud835\udc57 . If both trajectories save the same number of people, we opt for\n\nthe trajectory that spent more time in the extinguisher cell. Finally,\n\nqueries are spread out evenly over 6 \u00b7 106 environment steps.\n\nFigure 2 shows the set of policies obtained during training of\n\nMORAL and compares it with a CCS found from a manual scalar-\n\nization _\ud835\udc5f\ud835\udc43 + (1 \u2212 _) \ud835\udc53\\ for different choices of _ \u2208 [0, 1]. Also, we\ndo not show solutions corresponding to higher values of _, since\n\nthese collapse to a single trivial solution. To illustrate the evolution\n\nof solutions, we estimate average returns and plot a corresponding\n\npoint before each update of the weight posterior. MORAL directly\n\napproximates a Pareto-optimal point that opts for saving all people\n\npresent in the world, while maximizing the agent\u2019s performance\n\nwith respect to the primary goal. Furthermore, MORAL first learns\n\nto only save people, which correctly corresponds to the way pref-\n\nerences are provided. Thus, MORAL demonstrates to be successful\n\nat directly finding a normative policy while incorporating reward\n\ninformation from multiple sources. To ensure consistency across\n\nmultiple runs, we also plot the average returns for different num-\n\nbers of overall queries in figure 3. We see that although 25 queries\n\nare necessary to converge to a solution that closely matches the\n\ngiven preferences, MORAL learns a reasonable trade-off after 10\n\nqueries, which consistently saves all people at the cost of spending\n\nless time on the primary goal.\n\n4.2 Delivery\nWhile the Emergency domain illustrated the effectiveness ofMORAL\n\nin a simplified setting, we yet have to analyze howMORAL performs\n\nin larger environments, as well as regarding increased diversity\n\nof norms and goals we would like an agent to learn. To better\n\nevaluate MORAL, we therefore define the Delivery environment,\n\na randomly initialized 16 \u00d7 16 grid world (figure 4). As before, the\n\nagent has access to the moving, interaction and null actions, but\n\n5 10 25\n\n# Queries\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\n70\n\nEx\ntin\n\ngu\nish\n\ned\n F\n\nire\n\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nPe\nop\n\nle\n S\n\nav\ned\n\nFigure 3: Query efficiency of MORAL for finding a trade-off\nthatmatches the given preferences. Averaged over three ran-\ndom seeds.\n\ncan now encounter a variety of objects. Its primary goal consists\n\nof delivering packages to 12 locations, which is available to the\n\nagent via a reward \ud835\udc5f\ud835\udc43 of +1 whenever it interacts with a delivery\n\ncell. However, there also exist a multitude of people in need of\n\nsupport that the agent can help and \u201cdirty\u201d tiles that the agent can\n\nclean. The agent chooses to do so by interacting with each of the\n\nrespective cells, after which they turn empty. Finally, we randomly\n\nplace vases throughout the grid, which break whenever the agent\n\nsteps on their position and can not be interacted with.\n\nOverall, we limit the episode length to \ud835\udc47 = 50 time steps and\n\nplace 12 of the help, clean objectives as well as 8 vases on the grid.\n\nWe view this environment as a multi-objective problem including\n\nthree norms, where help and clean are active behaviors, but the\n\nability to avoid vases is passive i.e., an inaction. Besides forcing the\n\nagent to make trade-offs, this choice allows us to effectively study\n\nthe quality of solutions found through MORAL, by introducing a\n\nsymmetry with regard to the three explicit objectives. We assume\n\nthat preferences are automatically provided by a subjective distri-\n\nbution\ud835\udc5a \u2208 \u0394{1,2,3} encoding desired priorities for deliver, help and\n\nclean respectively. Given a pair of trajectories (\ud835\udf0f1, \ud835\udf0f2), we then cal-\n\nculate two vectors \ud835\udc60\ud835\udc56 = (\ud835\udc5c\ud835\udc56\n1\n, . . . , \ud835\udc5c\ud835\udc56\ud835\udc5b), where \ud835\udc5c\ud835\udc56\ud835\udc58 denotes the obtained\n\nreturns in terms of the \ud835\udc58-th objective in trajectory \ud835\udc56 . For example,\n\nFigure 4: The Delivery Environment consists of a primary\ngoal (Deliver) and three different norms (Help a human,\nClean a tile, Avoid the vase).\n\n\n\n2 3 4 5 6 7 8\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nCl\nea\n\nn\n\n3 4 5 6\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nHe\nlp\n\n3 4 5 6\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nCl\nea\n\nn\n\n2 3 4 5 6 7 8\nHelp\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nCl\nea\n\nn\n\n3 4 5 6\nDeliver\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nHe\nlp\n\n3 4 5 6\nDeliver\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nCl\nea\n\nn\n\n3\n\n4\n\n5\n\n6\n\n3\n\n4\n\n5\n\n6\n\n3\n\n4\n\n5\n\n6\n\n0.005\n\n0.010\n\n0.015\n\n0.020\n\n0.025\n\n0.030\n\n0.035\n\n0.040\n\n0.005\n\n0.010\n\n0.015\n\n0.020\n\n0.025\n\n0.030\n\n0.035\n\n0.040\n\n0.005\n\n0.010\n\n0.015\n\n0.020\n\n0.025\n\n0.030\n\n0.035\n\n0.040\n\nFigure 5: The convex coverage set found by MORAL for three reward dimensions. We plot two-dimensional projections of the\nattained explicit objectives, with colors indicating the third objective (top three panels). The colors in the bottom three panels\nshow the deviation (8) to the respective preference vector\ud835\udc5a used during training. Gray circles around each policy indicate the\nrelative amount of broken vases.\n\nif \ud835\udf0f1 delivers 3 packages, helps 1 person and cleans up 3 cells, then\n\n\ud835\udc601 = (3, 1, 3). When normalizing the observed returns into a discrete\n\ndistribution \ud835\udc60\ud835\udc56 = \ud835\udc60\ud835\udc56/| |\ud835\udc60\ud835\udc56 | |1, we can provide preferences according to\n\na KL divergence metric\n\n\ud835\udc56\u2217 = argmin\n\n\ud835\udc56\u2208{1,2}\n\ud835\udc37\ud835\udc3e\ud835\udc3f (\ud835\udc60\ud835\udc56 | |\ud835\udc5a) . (8)\n\nAside from providing preferences in a principled way, we use this\n\ndivergence measure to evaluate the overlap between a policy and\n\nthe provided preferences throughout training.\n\nWe test MORAL using two conflicting demonstration data sets\n\ngenerated by a PPO agent optimizing for (i) helping people and\n\n(ii) cleaning tiles, while both try to avoid stepping on vases. As\n\nbefore, we subsequently use MORAL as a regularizer and form r =\n(\ud835\udc5f\ud835\udc43 , \ud835\udc53\\1 , \ud835\udc53\\2 ), where \\1 and \\2 denote the trained AIRL parameters.\n\nAs opposed to the experiment in the Emergency domain, there\n\nnow exists an inherent normative conflict in the demonstrations.\n\nThus, instead of tuning the agent to respect a specific policy that\n\nincorporates the normative component into the primary goal, we\n\naim to test whether MORAL is able to retrieve solutions that match\n\na variety of preferences. To achieve this, we vary the supplied\n\npreference vector\ud835\udc5a to match all possible ratios in {1, 2, 3}3 during\nthe active learning stage. Furthermore, we choose to use 25 queries\n\noverall, spread evenly throughout 8 \u00b7 106 environment steps.\n\nFigure 5 illustrates the found set of policies, where each point\n\nrepresents a separate run of active learning on different preferences.\n\nSince the objective space is three-dimensional, we only show two-\n\ndimensional projections and add the third objective through color\n\n(figure 5, top three panels). Besides this, the number of broken vases\n\nis shown by gray circles around each point, where a bigger radius\n\nindicates policies that break more vases and a radius of 0 indicates\n\nthat no vases are broken on average. To test whether the found\n\npolicies match the given preferences, we evaluate the KL divergence\n\n(8) of average returns \ud835\udc60 (generated by the learned policy) to the\n\npreference\ud835\udc5a that was used during training (figure 5, bottom three\n\npanels). We found that MORAL is overall able to retrieve a diverse\n\nset of policies, which accurately represent the different preferences:\n\nFirstly, the top three panels show mostly non-dominated policies\n\nthat span a wide variety of trade-offs, which suggests that MORAL\n\nrecovers a large part of the convex coverage set. Secondly, the\n\nbottom three panels indicate that most of the points achieve a near\n\nzero divergence. This means that the agent accurately matches\n\nthe supplied ratios over objectives. As expected, we also see that\n\nthe number of broken vases correlates with the weight put on\n\nthe primary task, since the manually engineered delivery reward\n\nis entirely agnostic regarding the vase object. Nonetheless, for\n\nappropriate choices of\ud835\udc5a, there exist policies which successfully\n\navoid vases despite delivering an adequate number of packages.\n\nThese results indicate that when choosing scalarization weights\n\nappropriately, minimizing a weighted sum of KL divergences to the\n\nrespective maximum entropy IRL distributions can achieve implicit\n\nnormative behaviors without the need of an explicit feedback signal.\n\nTo investigate the robustness of MORAL against adversarial\n\npreferences, we also trained MORAL on r = (\ud835\udc53\\1 , \ud835\udc53\\2 ) by giving 25\n\npreferences such that \ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 , whenever \ud835\udf0f\ud835\udc56 manages to break more\n\nvases. We observe that despite this, the number of broken vases in\n\nfact decreases as a function of training steps. Since both experts\n\nagree on keeping vases intact, the aggregate reward function cannot\n\nbe fine-tuned to exhibit the opposite behavior (figure 6). However,\n\nsuch a guarantee against adversarial preferences only holds when\n\nall marginal reward functions induce safe behavior. Under this as-\n\nsumption, this result provides evidence that automatically adhering\n\nto common implicit behaviors ensures safety against adversarial\n\npreference givers.\n\n\n\nFigure 6: Average number of broken vases over three train-\ning runs.MORAL learns a safe policy, despite being provided\nwith adversarial preferences.\n\n4.3 Comparison to Deep Reinforcement\nLearning from Human Preferences\n\nThrough its two-step procedure, MORAL is able to combine multi-\n\nple reward functions from diverse expert behaviors. However, in\n\nthe active learning stage, we require a single expert to determine\n\nwhich Pareto-optimal policy should ultimately be optimized for.\n\nGiven enough pairwise comparisons, this directly approximates a\n\npolicy that best matches the preferences (figure 2). For these rea-\n\nsons, among the related RL algorithms, MORAL is most directly\n\ncomparable to deep reinforcement learning from human prefer-\n\nences (DRLHP) [10], which directly trains a deep reward model\n\nfrom pairwise preferences. To compare the two, we train DRLHP\n\nuntil convergence in Emergency and Delivery by providing a suffi-\n\ncient number of pairwise comparisons to make up for the missing\n\nprimary reward and demonstrations that MORAL has access to.\n\nTable 1 shows the results when providing DRLHP with 1000\n\npreferences in the same way as MORAL for the Emergency domain.\n\nAs before, trajectories with more people saved are preferred unless\n\nequal, in which case extinguishing fire becomes a priority. Although\n\nthis leads DRLHP to learn a policy that consistently saves most\n\npeople, it significantly lacks in terms of extinguished fire. This is un-\n\nsurprising, since DRLHP is not designed to handle multi-objective\n\nproblems and can not utilize the manually engineered reward signal\n\nin any meaningful way. This is because the deep reward model is\n\nnonstationary, which poses the combination with the stationary\n\nreward \ud835\udc5f\ud835\udc43 to be challenging. As a result, DRLHP needs to maintain\n\na single model for all competing objectives, which can lead to cata-\n\nstrophic forgetting of extinguishing fire when updating the reward\n\nnetwork to save more people.\n\nA similar trend can be observed in the Delivery environment,\n\nwhere we compare mean performance of DRLHP versus MORAL on\n\nthree preference configurations, each of which prefers one of the ob-\n\njectives most strongly. However, since we assumed that avoidance\n\nPeople\n\nSaved\n\nExtinguished\n\nFire\n\nNr. of\n\nQueries\n\nSteps (IRL)\n\nMORAL 5.76(\u00b10.13) 40.08(\u00b12.9) 25 3e6 (3e6)\n\nDRLHP 5.62(\u00b10.17) 12.32(\u00b13.0) 1000 12e6 (-)\n\nTable 1: Comparison of MORAL and DRLHP in Emergency.\n\nFigure 7: Mean training curves of DRLHP and MORAL on\npreference ratios (3, 1, 1) (top), (1, 3, 1) (middle) and (1, 1, 3)\n(bottom).\n\nof vases is encoded in the preferences only implicitly, we cannot\n\nsupply DRLHP with the same set of feedback. Instead, we train\n\nDRLHP to prefer trajectories that have a lower mean squared error\n\nto the vector of expected returns achieved by MORAL. Figure 7\n\nshows training curves of both methods, where each row represents\n\na preference ratio of (3, 1, 1), (1, 3, 1) and (1, 1, 3) respectively. Aim-\n\ning to make the comparison fairer, we offset MORAL by the number\n\nof total training steps needed for IRL. As before, DRLHP manages\n\nto retrieve solutions that loosely resemble the supplied preferences,\n\nbut fails to converge to Pareto-optimal policies. Furthermore, we\n\nnotice that for the latter two preferences, sparse objectives such\n\nas minimizing the number of broken vases are not picked up by\n\nDRLHP. We suspect this to be an exploration issue, where tra-\n\njectories that break fewer vases are unlikely to arise in queries.\n\nThus, DRLHP optimizes for the remaining objectives as they lead\n\nto a higher increase in correctly predicting an expert\u2019s preferences.\n\nOverall, we conclude that MORAL is more suitable than DRLHP\n\nin multi-objective settings that require trading off conflicting ob-\n\njectives from expert data. Nonetheless, MORAL has a theoretical\n\nadvantage in this environment, since it allows for incorporation of\n\nprior knowledge as well as conflicting expert demonstrations.\n\n4.4 Ablation\nIn this section, we evaluate MORAL with respect to the necessity\n\nof active queries, as well as its robustness against noisy preferences.\n\nTo do so, we contrast active versus randomly chosen queries for the\n\nsame set of preferences as in figure 5 and plot the average preference\n\ndeviation (8) in figure 8 (a). In the case of actively generated queries,\n\nthere is a clear decrease in preference deviation as a function of\n\ntotal queries. Random queries do not benefit from the increase in\n\nqueries as much as MORAL, with 50 queries in fact scoring worse\n\nthan 25. We conjecture that this is due to the on-policy sampling of\n\ntrajectories, which strongly restricts the space of trajectories that\n\nthe agent can query for. On the other hand, MORAL will, always\n\nseek pairs of trajectories that naturally exhibit larger variances\n\nbetween competing goals in order to generate queries with high\n\n\n\ninformation content. When ensuring that the agent maintains ad-\n\nequate levels of exploration throughout training, this suffices to\n\nensure a decrease in deviation even in the large query regime.\n\nTo investigate the robustness of MORAL in the presence of con-\n\ntradictory feedback, we train policies on the same set of preferences\n\nas before in figure 8 (b), but provide random answers to each of the\n\n50 queries with a certain probability. Unsurprisingly, we see a sharp\n\nincrease in deviation when injecting a noise level of 0.1, above\n\nwhich the growth in error diminishes. Nonetheless, active queries\n\nwith a random answer probability of 0.3 still retrieve slightly more\n\naccurate representations than random queries without any noise.\n\nSuch robustness with respect to noise is important, since our ex-\n\nperiments only cover synthetic simulation studies, whereas human\n\nfeedback is unlikely to be as consistent. Even though random noise\n\nis only an approximation of human error, we conclude from our\n\nresults that seeking volume removal in the active learning loop\n\ndoes not make the algorithm more susceptible to converging to\n\nlocally optimal scalarization weights in this case.\n\n5 RELATEDWORK\nMachine EthicsUsing the notion of uncertainty and partial observ-\nability, RL has been suggested as a framework for ethical decision-\n\nmaking [2]. We frame the problem of learning norms in a multi-\n\nobjective context, which can be interpreted as inducing partial\n\nobservability over the set of reward scalarizations one would wish\n\nto optimize. Overall, the motivation behind our approach is concep-\n\ntually similar to policy orchestration [30] and ethics shaping [47]\n\n(table 2). Policy orchestration [30] also adopts a multi-objective\n\nview to incorporate ethical values into reward-driven RL agents, by\n\nsolving a bandit problem that uses IRL to alternately play ethical\n\nand reward maximizing actions. Similarly to policy orchestration,\n\nMORAL employs a two-step procedure. However, besides the use\n\nof deep RL, MORAL differs since it learns to combine reward func-\n\ntions, whereas policy orchestration learns to combine policies. This\n\nallows MORAL to learn Pareto optimal policies at the cost of in-\n\nterpretability. Furthermore, policy orchestration requires a manual\n\nspecification of the scalarization parameter, which MORAL can\n\nautomatically infer through the use of active learning.\n\nEthics shaping [47] learns a reward shaping term from demon-\n\nstrations, but does not scale beyond manually engineered features.\n\nBesides that, their approach is constrained to learning from a single\n\nexpert. Although AIRL has been previously suggested to alleviate\n\nthe issue of scalability [31], a method that is able to trade off rewards\n\nfrom multiple sources has not yet been developed in this setting.\n\nFinally, Ecoffet et al. [12] suggest a sequential voting scheme for\n\nlearning conflicting values, but it requires explicit encoding of the\n\ndifferent values at stake.\n\nInverse Reinforcement Learning Similarly to related IRL re-\n\nsearch, our work builds on AIRL [14] for inferring rewards from\n\na multimodal distribution of demonstrations. Unlike previous re-\n\nsearch, which has focused on introducing latent variable models\n\n[19, 23, 28, 41, 43, 50] in the context of multiagent, multitask and hi-\n\nerarchical reward learning, we instead focus on the combination of\n\nlabeled demonstration data. As such, our setup is similar to Gleave\n\nand Habryka [17] and Xu et al. [48], where a reward function is\n\n5 10 15 20 25 30 35 40 45 50\n# Queries\n\n0.02\n\n0.04\n\n0.06\n\n0.08\n\nPr\nef\n\ner\nen\n\nce\n D\n\nev\nia\n\ntio\nn\n\n(a)\nActive\nRandom\n\n0.0 0.1 0.2 0.3\nPreference Noise\n\n0.02\n\n0.03\n\n0.04\n\nPr\nef\n\ner\nen\n\nce\n D\n\nev\nia\n\ntio\nn\n\n(b)\n\nActive\nRandom (0 noise)\n\nFigure 8: (a) Average preference deviation as a function of\nthe number of active and random queries. (b) Average pref-\nerence deviation of active learning as a function of the pro-\nportion of noisy responses to queries.\n\nmeta-learned by having explicit access to different task distribu-\n\ntions. However, we learn from demonstrations in a multi-objective\n\ncontext, which has, to our knowledge, not yet been studied before.\n\nBesides this, IRL has been applied in the context of value align-\n\nment [22], where inverse reward design (IRD) [21] has been pro-\n\nposed to learn a distribution of reward functions through IRL that\n\nleverages uncertainty to avoid unintended behavior. Although we\n\nalso learn a distribution over reward functions, IRD focuses on find-\n\ning safe goal specifications from a single reward function, whereas\n\nwe study the extraction of value-aligned policies from a multitude\n\nof demonstrations. As a result, our research is more similar to mul-\n\ntitask IRD [26], which studies formal criteria for combining reward\n\nfunctions from multiple sources. We, on the other hand, drop the\n\nformal assumptions and propose a practical method for combining\n\nreward functions learned through deep neural networks.\n\nLearning from Expert Feedback Besides IRL, there exist a vari-\n\nety of approaches for training RL agents from expert data, including\n\nscalar-valued input [25, 44], natural language [3], intervention [38]\n\nand pairwise preferences [10, 46]. Similarly to Christiano et al. [10],\n\nwe employ a Bradley-Terry model for training a nonstationary\n\nreward function by comparing trajectories from on-policy RL ex-\n\nperience. However, our model of pairwise preferences operates on\n\na set of abstract high-level reward functions, whereas [10] learn a\n\nsingle end-to-end reward model. Furthermore, our approach com-\n\nbines demonstration and preference data, which is more similar to\n\nIbarz et al. [24]. Nonetheless, [24] uses demonstration data for pre-\n\ntraining a preference-based reward model, which does not account\n\nfor conflicting demonstrations. MORAL, on the other hand, allows\n\nfor the inclusion of multiple experts as well as prior knowledge,\n\nthus making it suitable for resolving normative conflicts.\n\nPreference-based reward learning with multiple experts has been\n\nrecently studied by Myers et al. [29]. They propose an active learn-\n\ning algorithm for efficiently learning multimodal reward functions\n\n\n\nthat can represent different preferences. This differs from our work\n\nin two key points: Firstly, aside from the incorporation of demon-\n\nstrations, we show how to use active learning to find a trade-off\n\nbetween conflicting reward functions. Secondly, unlike their work,\n\nwe study how to learn a policy alongside the reward function.\n\nFinally, by combining different expert reward functions, we have\n\nshown that MORAL interpolates between maximum-entropy IRL\n\ndistributions. From this point of view, we consider our work a\n\ncounterpart to Brown et al. [8], which ranks demonstration data in\n\norder to extrapolate beyond the behavior of a single expert.\n\nMulti-Objective Decision-Making Typically, MORL algorithms\n\ntrade off multiple objectives by learning a policy, or a set thereof,\n\nthat can represent a range of Pareto-optimal solutions [32, 49]. On\n\nthe other hand, our model learns a distribution over reward func-\n\ntions, which interactively guides the search to produce a single\n\nPareto-optimal policy. Aside from sample efficiency, this mitigates\n\nthe problem of varying reward scale, which has previously been\n\naddressed by multi-objective maximum a posteriori policy optimiza-\n\ntion (MO-MPO) [1]. However, MO-MPO requires explicit prefer-\n\nences over objectives, which is not always feasible when combining\n\nlearned rewards that are inherently difficult to compare.\n\nBy using on-policy RL experience to learn scalarization weights,\n\nMORAL can be viewed as an interactive MORL algorithm. To date,\n\ninteractive MORL has mainly been applied to bandits for linear [34]\n\nand nonlinear [33] transformations of the reward components, but\n\nhas not yet been studied in the full RL setting. We believe that this\n\nis the case because MORL research usually assumes environments\n\nwith manually engineered reward functions, in which big parts of\n\nthe Pareto boundary exhibit interesting solutions. In the case of\n\ntrading off learned reward functions, however, we suggest that our\n\ninteractive approach poses a more adequate option.\n\n6 DISCUSSION\nIn our work, we propose MORAL, a method for combining learned\n\nreward functions from multiple experts. We have shown MORAL\n\nto be a technical approach for aligning deep RL agents with hu-\n\nman norms, which uses active learning to resolve value conflicts\n\nwithin expert demonstrations. We consider our research a step to-\n\nwards multi-objective RL with learned rewards, which has not yet\n\nbeen addressed before. Previous approaches such as ethics-shaping\n\n[47] and policy orchestration [30] have highlighted the strength of\n\ncombining reward functions with expert demonstrations for value\n\nEthics-\n\nShaping\n\n[47]\n\nPolicy-\n\nOrchestration\n\n[30]\n\nDRLHP\n\n[10]\n\nMORAL\n\nDeep \u00d7\u00d7\u00d7 \u00d7\u00d7\u00d7 \u2713 \u2713\nLearning\n\nMulti- \u223c \u2713 \u00d7\u00d7\u00d7 \u2713\nObjective\n\nMultiple \u00d7\u00d7\u00d7 \u223c \u00d7\u00d7\u00d7 \u2713\nExperts\n\nTable 2: Comparison of MORAL to previous work in terms\nof supported capabilities.\n\nalignment, whereas DRLHP [10] has demonstrated the scalability\n\nof deep preference-based RL (table 2). MORAL unifies these ideas\n\ninto a single method, which allows it to be applied in the pres-\n\nence of deep function approximation and multiple experts. This\n\ntheoretical advantage is reflected in our experiments, which show\n\nthat, unlike DRLHP, MORAL succeeds in retrieving Pareto-optimal\n\nsolutions. Furthermore, we have shown MORAL to automatically\n\nlearn implicit social norms if expert demonstrations agree on them.\n\nThis informativeness about desirable behavior has been previously\n\nidentified as a desideratum for combining reward information by\n\nKrasheninnikov et al. [26] and we have shown that it allows the\n\nactive queries to focus on higher-level normative conflicts.\n\nNonetheless, several avenues for future research remain to be\n\naddressed. Firstly, generating queries from on-policy experience\n\nputs MORAL at risk of local optimaility. In sparse environments,\n\nwe therefore consider the introduction of a separate exploration\n\npolicy for active learning to be useful. Secondly, combining mul-\n\ntiple forms of expert supervision is challenging, due to a risk of\n\naccumulating errors and modelling assumptions for each type of\n\ninput. We suppose further research in AIRL will be necessary to\n\nprevent overfitting of the reward network. Similarly to Gleave and\n\nHabryka [17], we found the reoptimization of AIRL reward func-\n\ntions to decrease performance, indicating that the learned rewards\n\nare entangled with the state distribution of the generator policy. Al-\n\nthough this will require significant progress in deep IRL, we expect\n\nfuture methods to be easily integrated into MORAL by replacing\n\nAIRL. Furthermore, one could pursue unsupervised techniques to\n\nextend MORAL to unlabeled demonstration datasets. When learn-\n\ning social norms from large scale real-world demonstration data,\n\nit might be infeasible to learn separate reward functions for each\n\nexpert. Unsupervised learning of reward functions that correspond\n\nto the different modes of behavior instead could alleviate this issue.\n\nOverall, our research highlights the importance ofmulti-objective\n\nsequential decision-making without explicitly provided reward\n\nfunctions. Aside from value alignment [42], the ability to detect\n\nand respond to a divergence in values has been recognized as a\n\ncentral trait for building human-like AI [5]. Further, following the\n\nprinciple of meaningful human control [37], MORAL can contribute\n\nto increase an agent\u2019s responsiveness to conflicting human norms,\n\nwhile maintaining human autonomy in determining desired trade-\n\noffs. This research contributes to the broader goal of designing and\n\ndeveloping safe AI systems that can align to human values and\n\nnorms.\n\nREFERENCES\n[1] Abbas Abdolmaleki, Sandy Huang, Leonard Hasenclever, Michael Neunert, Fran-\n\ncis Song, Martina Zambelli, Murilo Martins, Nicolas Heess, Raia Hadsell, and\n\nMartin Riedmiller. 2020. A distributional view on multi-objective policy opti-\n\nmization. In International Conference on Machine Learning. PMLR, 11\u201322.\n\n[2] David Abel, J. MacGlashan, and M. Littman. 2016. Reinforcement Learning as\n\na Framework for Ethical Decision Making. In AAAI Workshop: AI, Ethics, and\nSociety.\n\n[3] Md Sultan Al Nahian, Spencer Frazier, Mark Riedl, and Brent Harrison. 2020.\n\nLearning norms from stories: A prior for value aligned agents. In AIES 2020 -\nProceedings of the AAAI/ACM Conference on AI, Ethics, and Society. Association for\nComputing Machinery, Inc, 124\u2013130. https://doi.org/10.1145/3375627.3375825\n\narXiv:1912.03553\n\n[4] Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and\n\nDan Man\u00e9. 2016. Concrete problems in AI safety. arXiv preprint arXiv:1606.06565\n(2016).\n\nhttps://doi.org/10.1145/3375627.3375825\nhttps://arxiv.org/abs/1912.03553\n\n\n[5] Grady Booch, Francesco Fabiano, Lior Horesh, Kiran Kate, Jon Lenchner, Nick\n\nLinck, Andrea Loreggia, Keerthiram Murugesan, Nicholas Mattei, Francesca\n\nRossi, et al. 2020. Thinking fast and slow in AI. arXiv preprint arXiv:2010.06002\n(2020).\n\n[6] Nick Bostrom. 2014. Superintelligence: Paths, Dangers, Strategies. Oxford Univer-\n\nsity Press.\n\n[7] Ralph Allan Bradley and Milton E Terry. 1952. Rank analysis of incomplete block\n\ndesigns: I. The method of paired comparisons. Biometrika 39, 3/4 (1952), 324\u2013345.\n[8] Daniel Brown,Wonjoon Goo, Prabhat Nagarajan, and Scott Niekum. 2019. Extrap-\n\nolating beyond suboptimal demonstrations via inverse reinforcement learning\n\nfrom observations. In International conference on machine learning. PMLR, 783\u2013\n\n792.\n\n[9] Siddhartha Chib and Edward Greenberg. 1995. Understanding the metropolis-\n\nhastings algorithm. The american statistician 49, 4 (1995), 327\u2013335.\n\n[10] Paul F. Christiano, Jan Leike, Tom B Brown, Miljan Martic, Shane Legg, and\n\nDario Amodei. 2017. Deep reinforcement learning from human preferences. In\n\nAdvances in Neural Information Processing Systems. 4300\u20134308.\n[11] Gabriel Dulac-Arnold, Daniel Mankowitz, and Todd Hester. 2019. Challenges of\n\nreal-world reinforcement learning. arXiv preprint arXiv:1904.12901 (2019).\n[12] Adrien Ecoffet and Joel Lehman. 2021. Reinforcement learning under moral\n\nuncertainty. In International Conference on Machine Learning. PMLR, 2926\u20132936.\n\n[13] Tom Everitt, Victoria Krakovna, Laurent Orseau, Marcus Hutter, and Shane Legg.\n\n2017. Reinforcement learning with a corrupted reward channel. arXiv preprint\narXiv:1705.08417 (2017).\n\n[14] Justin Fu, Katie Luo, and Sergey Levine. 2017. Learning robust rewards with ad-\n\nversarial inverse reinforcement learning. arXiv preprint arXiv:1710.11248 (2017).\n[15] Iason Gabriel. 2020. Artificial intelligence, values, and alignment. Minds and\n\nmachines 30, 3 (2020), 411\u2013437.\n[16] Sanket Gaurav and Brian D Ziebart. 2019. Discriminatively learning inverse opti-\n\nmal control models for predicting human intentions. In International Conference\non Autonomous Agents and Multiagent Systems.\n\n[17] Adam Gleave and Oliver Habryka. 2018. Multi-task maximum entropy inverse\n\nreinforcement learning. arXiv preprint arXiv:1805.08882 (2018).\n[18] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,\n\nSherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial\n\nnets. Advances in neural information processing systems 27 (2014).\n[19] Nate Gruver, Jiaming Song, Mykel J Kochenderfer, and Stefano Ermon. 2020.\n\nMulti-agent adversarial inverse reinforcement learning with latent variables.\n\nIn Proceedings of the 19th International Conference on Autonomous Agents and\nMultiAgent Systems. 1855\u20131857.\n\n[20] Dylan Hadfield-Menell and Gillian K Hadfield. 2019. Incomplete contracting and\n\nAI alignment. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and\nSociety. 417\u2013422.\n\n[21] Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart Russell, and Anca\n\nDragan. 2017. Inverse reward design. arXiv preprint arXiv:1711.02827 (2017).\n\n[22] Dylan Hadfield-Menell, Stuart J Russell, Pieter Abbeel, and Anca Dragan. 2016.\n\nCooperative inverse reinforcement learning. Advances in neural information\nprocessing systems 29 (2016), 3909\u20133917.\n\n[23] Karol Hausman, Yevgen Chebotar, Stefan Schaal, Gaurav Sukhatme, and Joseph\n\nLim. 2017. Multi-modal imitation learning from unstructured demonstrations\n\nusing generative adversarial nets. arXiv preprint arXiv:1705.10479 (2017).\n[24] Borja Ibarz, Jan Leike, Tobias Pohlen, Geoffrey Irving, Shane Legg, and Dario\n\nAmodei. 2018. Reward learning from human preferences and demonstrations in\n\nAtari. arXiv preprint arXiv:1811.06521 (2018).\n[25] W Bradley Knox and Peter Stone. 2009. Interactively shaping agents via human\n\nreinforcement: The TAMER framework. In Proceedings of the fifth international\nconference on Knowledge capture. 9\u201316.\n\n[26] Dmitrii Krasheninnikov, Rohin Shah, and Herke van Hoof. 2021. Combining\n\nreward information frommultiple sources. arXiv preprint arXiv:2103.12142 (2021).\n[27] Solomon Kullback. 1997. Information theory and statistics. Courier Corporation.\n[28] Yunzhu Li, Jiaming Song, and Stefano Ermon. 2017. Infogail: Interpretable imita-\n\ntion learning from visual demonstrations. In Proceedings of the 31st International\nConference on Neural Information Processing Systems. 3815\u20133825.\n\n[29] Vivek Myers, Erdem B\u0131y\u0131k, Nima Anari, and Dorsa Sadigh. 2021. Learning\n\nMultimodal Rewards from Rankings. arXiv preprint arXiv:2109.12750 (2021).\n[30] Ritesh Noothigattu, Djallel Bouneffouf, Nicholas Mattei, Rachita Chandra, Piyush\n\nMadan, Kush R Varshney, Murray Campbell, Moninder Singh, and Francesca\n\nRossi. 2019. Teaching AI agents ethical values using reinforcement learning and\n\npolicy orchestration. IBM Journal of Research and Development 63, 4/5 (2019),\n2\u20131.\n\n[31] Markus Peschl. 2021. Training for Implicit Norms in Deep Reinforcement Learn-\n\ning Agents through Adversarial Multi-Objective Reward Optimization. In Pro-\nceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society. 275\u2013276.\n\n[32] Diederik M. Roijers, Peter Vamplew, Shimon Whiteson, and Richard Dazeley.\n\n2013. A Survey of Multi-Objective Sequential Decision-Making. Journal of\nArtificial Intelligence Research 48, 1 (2013), 67\u2013113.\n\n[33] Diederik M Roijers, Luisa M Zintgraf, Pieter Libin, and Ann Now\u00e9. 2018. Inter-\n\nactive multi-objective reinforcement learning in multi-armed bandits for any\n\nutility function. In ALA workshop at FAIM, Vol. 8.\n\n[34] Diederik M Roijers, Luisa M Zintgraf, and Ann Now\u00e9. 2017. Interactive thompson\n\nsampling for multi-objective multi-armed bandits. In International Conference on\nAlgorithmic Decision Theory. Springer, 18\u201334.\n\n[35] Stuart Russell, Daniel Dewey, and Max Tegmark. 2015. Research priorities for\n\nrobust and beneficial artificial intelligence. AI Magazine 36, 4 (2015), 105\u2013114.\n[36] Dorsa Sadigh, A. Dragan, S. Sastry, and S. Seshia. 2017. Active Preference-Based\n\nLearning of Reward Functions. In Robotics: Science and Systems.\n[37] Filippo Santoni de Sio and Jeroen van den Hoven. 2018. Meaningful Human\n\nControl over Autonomous Systems: A Philosophical Account. Frontiers in Robotics\nand AI 5 (2018), 15. https://doi.org/10.3389/frobt.2018.00015\n\n[38] William Saunders, Andreas Stuhlm\u00fcller, Girish Sastry, and Owain Evans. 2018.\n\nTrial without error: Towards safe reinforcement learning via human intervention.\n\nIn Proceedings of the International Joint Conference on Autonomous Agents and\nMultiagent Systems, AAMAS, Vol. 3. 2067\u20132069. arXiv:1707.05173\n\n[39] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.\n\n2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347\n(2017).\n\n[40] Rohin Shah, Noah Gundotra, Pieter Abbeel, and Anca Dragan. 2019. On the\n\nfeasibility of learning, rather than assuming, human biases for reward inference.\n\nIn International Conference on Machine Learning. PMLR, 5670\u20135679.\n\n[41] Mohit Sharma, Arjun Sharma, Nicholas Rhinehart, and Kris M Kitani. 2018.\n\nDirected-Info GAIL: Learning Hierarchical Policies from Unsegmented Demon-\n\nstrations using Directed Information. In International Conference on Learning\nRepresentations.\n\n[42] Peter Vamplew, Richard Dazeley, Cameron Foale, Sally Firmin, and Jane Mum-\n\nmery. 2018. Human-aligned artificial intelligence is a multiobjective problem.\n\nEthics and Information Technology 20, 1 (2018), 27\u201340.\n\n[43] David Venuto, Jhelum Chakravorty, Leonard Boussioux, Junhao Wang, Gavin\n\nMcCracken, and Doina Precup. 2020. oIRL: Robust Adversarial Inverse Re-\n\ninforcement Learning with Temporally Extended Actions. arXiv preprint\narXiv:2002.09043 (2020).\n\n[44] Garrett Warnell, Nicholas Waytowich, Vernon Lawhern, and Peter Stone. 2018.\n\nDeep tamer: Interactive agent shaping in high-dimensional state spaces. In Thirty-\nSecond AAAI Conference on Artificial Intelligence.\n\n[45] Jess Whittlestone, Kai Arulkumaran, and Matthew Crosby. 2021. The Societal\n\nImplications of Deep Reinforcement Learning. Journal of Artificial Intelligence\nResearch 70 (March 2021).\n\n[46] Christian Wirth, Gerhard Neumann, and Johannes F\u00fcrnkranz. 2017. A Survey of\n\nPreference-Based Reinforcement Learning Methods. Journal of Machine Learning\nResearch 18 (2017), 1\u201346.\n\n[47] Yueh Hua Wu and Shou De Lin. 2018. A low-cost ethics shaping approach for\n\ndesigning reinforcement learning agents. In 32nd AAAI Conference on Artificial\nIntelligence, AAAI 2018. 1687\u20131694. arXiv:1712.04172\n\n[48] Kelvin Xu, Ellis Ratner, Anca Dragan, Sergey Levine, and Chelsea Finn. 2019.\n\nLearning a prior over intent via meta-inverse reinforcement learning. In Interna-\ntional Conference on Machine Learning. PMLR, 6952\u20136962.\n\n[49] Runzhe Yang, Xingyuan Sun, and Karthik Narasimhan. 2019. A Generalized\n\nAlgorithm for Multi-Objective Reinforcement Learning and Policy Adaptation.\n\narXiv:1908.08342 https://github.com/RunzheYang/MORL\n\n[50] Lantao Yu, Tianhe Yu, Chelsea Finn, and Stefano Ermon. 2019. Meta-Inverse\n\nReinforcement Learning with Probabilistic Context Variables. Advances in Neural\nInformation Processing Systems 32 (2019), 11772\u201311783.\n\n[51] Brian D Ziebart, Andrew Maas, J Andrew Bagnell, and Anind K Dey. 2008. Max-\n\nimum entropy inverse reinforcement learning. In Proceedings of the National\nConference on Artificial Intelligence, Vol. 3. 1433\u20131438.\n\nhttps://doi.org/10.3389/frobt.2018.00015\nhttps://arxiv.org/abs/1707.05173\nhttps://arxiv.org/abs/1712.04172\nhttps://arxiv.org/abs/1908.08342\nhttps://github.com/RunzheYang/MORL\n\n\nA ARCHITECTURES\nThis section describes all network architectures used throughout\n\nthe experiments. For ease of exposition, we omit grid world dimen-\n\nsionalities of each environment, and instead only report the amount\n\nof output channels and kernel sizes respectively. Furthermore, each\n\nconvolutional layer uses a stride of 1 and no padding, which we\n\nfound sufficient due to the relatively small sizes of the grids.\n\nA.1 Proximal Policy Optimization\nFor PPO, we employ a convolutional actor-critic architecture with\n\nshared base layers, as illustrated in figure 9. We use two convo-\n\nlutional layers to form a feature array with 256 channels, which\n\nis then passed to the actor and critic in parallel. Finally, the actor\n\nemploys a linear layer with output dimensions equal to the number\n\nof actions |A| = 9 on the flattened feature representations of the\n\nfinal convolutional layer. Similarly, the critic employs a final linear\n\nlayer with a scalar output to predict the current value. To draw\n\naction samples from the actor, a softmax is performed over its last\n\nlinear layer, and we treat the resulting vector as a categorical distri-\n\nbution. In between layers, we employ standard ReLU activations to\n\nfacilitate nonlinearity.\n\nFigure 9: Actor-Critic architecture of the PPO agent consist-\ning of convolutional (yellow) and linear (blue) layers. Re-\ngardless of the input dimension, we use \ud835\udc36\ud835\udc5c\ud835\udc62\ud835\udc61 output chan-\nnels and kernel sizes of 2.\n\nA.2 Reward Network - Emergency\nDue to the small size of the environment, we employ a dense neural\n\nnetwork for the AIRL discriminator architecture in Emergency. In\nthis case, we flatten grid world states into a single vector and pass\n\nthem through each layer, as illustrated in figure 10. Similarly to [14],\n\nwe decompose the network output \ud835\udc53\\ (\ud835\udc60, \ud835\udc60 \u2032) = \ud835\udc54\\ (\ud835\udc60)+\ud835\udefe\u210e\\ (\ud835\udc60 \u2032)\u2212\u210e\\ (\ud835\udc60),\nwhere \ud835\udefe \u2208 [0, 1] is the discount factor. While [14] propose this\n\ndecomposition to retrieve a state-only reward function, we instead\n\nonly use it for matching the AIRL implementation, but use \ud835\udc53\\ as\n\nthe reward function in subsequent steps.\n\nA.3 Convolutional Reward Network - Delivery\nWe found the MLP architecture of the AIRL discriminator shown in\n\nfigure 10 to be insufficient in larger grid world sizes. For this reason,\n\nwe employ a convolutional reward network in Delivery as shown in\n\nfigure 11. In principle, the network follows the same structure as in\n\nEmergency, but replaces linear layers with convolutional ones. To\n\nFigure 10: Linear discriminator architecture. A forward pass\ncalculates activations of the networks \ud835\udc54\\ and \u210e\\ respectively\nand combines them into the reward prediction \ud835\udc53\\ .\n\ndo so, we employ three convolutional layers followed by a single\n\nlinear layer that acts on respective flattened feature maps for both\n\n\u210e\\ and \ud835\udc54\\ and form our reward estimate as before. Finally, we use\n\nLeakyReLU activations with a slope of \ud835\udefc = 0.01 on all hidden layers.\n\nFigure 11: Convolutional discriminator architecture for\ntrainingAIRL in bigger environmentswith a parallel stream\nof convolutional (yellow) and linear (blue) layers.\n\nA.4 Deep Reinforcement Learning from\nHuman Preferences\n\nFor DRLHP we train a PPO agent using the architecture shown in\n\nfigure 9 in parallel with a deep reward model, which we show in\n\nfigure 12. The reward model takes a state-action pair at each time\n\nstep and outputs a predicted reward \ud835\udc5f\\ (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 ). We first one-hot\n\nencode the action \ud835\udc4e\ud835\udc61 and then embed it into a vector with the same\n\ndimensionality as the input state \ud835\udc60\ud835\udc61 . To do so, we train a linear em-\n\nbedding layer with output dimensions \ud835\udc36 \u00b7\ud835\udc4a \u00b7 \ud835\udc3b , where (\ud835\udc36,\ud835\udc4a ,\ud835\udc3b )\ndenote the amount of channels, width and height of the state \ud835\udc60\ud835\udc61\nrespectively. Embedded actions then get reshaped and concatenated\n\nwith \ud835\udc60\ud835\udc61 along the channel dimension to form an array of dimension\n\n(2\ud835\udc36,\ud835\udc4a ,\ud835\udc3b ) (batch dimension omitted). This array is fed through\n\nthree convolutional layers with 128, 64 and 32 output channels\n\nrespectively. Finally, the resulting flattened feature maps are pro-\n\ncessed by a linear layer to produce the reward estimate. As in the\n\nAIRL discriminator architecture, we employ LeakyReLU activations\n\nwith a slope parameter \ud835\udefc = 0.01.\n\n\n\nFigure 12: Reward model architecture for DRLHP with con-\nvolutional (yellow) and linear (blue) layers. Actions are em-\nbedded through a linear layer and concatenatedwith the cur-\nrent state before being fed through subsequent layers.\n\nB PROOF OF THEOREM 2.1\nBy definition of the Kullback-Leibler divergence, we have\n\n\ud835\udc37\ud835\udc3e\ud835\udc3f (\ud835\udf0b (\ud835\udf0f) | |\ud835\udc5d\\\ud835\udc56 (\ud835\udf0f)) = E\ud835\udf0b\n\n[\n\ud835\udc47\u2211\ufe01\n\ud835\udc61=0\n\nlog\ud835\udf0b (\ud835\udc4e\ud835\udc61 |\ud835\udc60\ud835\udc61 ) \u2212 \ud835\udc5f\\\ud835\udc56 (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\n]\n+ log\ud835\udc4d\\\ud835\udc56 ,\n\n(9)\n\nwhere \ud835\udc4d\\ =\n\u222b\n\ud835\udc5d\\ (\ud835\udf0f)\ud835\udc51\ud835\udf0f is the partition function. Using\n\n\u2211\nw\ud835\udc56 = 1,\n\nwe can now take the weighted sum of Kullback-Leibler divergences\n\nand obtain\n\n\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\n\n\ud835\udc64\ud835\udc56E\ud835\udf0b\n\n[\n\ud835\udc47\u2211\ufe01\n\ud835\udc61=0\n\nlog\ud835\udf0b (\ud835\udc4e\ud835\udc61 |\ud835\udc60\ud835\udc61 ) \u2212 \ud835\udc5f\\\ud835\udc56 (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\n]\n+\n\n\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\n\n\ud835\udc64\ud835\udc56 log\ud835\udc4d\\\ud835\udc56\n\n= E\ud835\udf0b\n\n[\n\ud835\udc47\u2211\ufe01\n\ud835\udc61=0\n\nlog\ud835\udf0b (\ud835\udc4e\ud835\udc61 |\ud835\udc60\ud835\udc61 ) \u2212\n(\n\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\n\n\ud835\udc64\ud835\udc56\ud835\udc5f\\\ud835\udc56 (\ud835\udc60\ud835\udc61 , \ud835\udc4e\ud835\udc61 )\n)]\n+\n\n\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\n\n\ud835\udc64\ud835\udc56 log\ud835\udc4d\\\ud835\udc56 .\n\nMinimizing over \ud835\udf0b yields the desired expression, since the normal-\n\nization functions \ud835\udc4d\\\ud835\udc56 as well as the weights\ud835\udc64\ud835\udc56 are constants as a\n\nfunction of the policy \ud835\udf0b . \u25a0\n\nC MARKOV CHAIN MONTE CARLO\nIn our implementation, we follow the procedure by [36] for sim-\n\nplifying the approximation of the Bradley-Terry posterior using\n\nMarkov Chain Monte Carlo (MCMC). Namely, instead of using the\n\noriginal likelihood\n\n\ud835\udc5d (\ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 |w) =\nexp(w\ud835\udc47 r(\ud835\udf0f\ud835\udc56 ))\n\nexp(w\ud835\udc47 r(\ud835\udf0f \ud835\udc57 )) + exp(w\ud835\udc47 r(\ud835\udf0f\ud835\udc56 ))\n, (10)\n\nwe instead opt for a proxy likelihood of the form\n\n\ud835\udc5d (\ud835\udf0f\ud835\udc56 \u227b \ud835\udf0f \ud835\udc57 |w) = min(1, exp(w\ud835\udc47\u0394\ud835\udc56 \ud835\udc57 )), (11)\n\nwhere \u0394\ud835\udc56 \ud835\udc57 = r(\ud835\udf0f\ud835\udc56 ) \u2212 r(\ud835\udf0f \ud835\udc57 ). Its mode always evaluates to 0, which\n\nallows us to efficiently obtain posterior estimates through the\n\nMetropolis-Hastings algorithm [9] with a warm start to the distri-\n\nbution mode.\n\nD HYPERPARAMETERS - EMERGENCY\nIn the following, we will list all hyperparameter configurations used\n\nfor the experiments of the main sections. Aside from algorithm\n\nspecific hyperparameters, we always employ a learning rate for\n\nPPO (lr-PPO) that determines the gradient step size used in the\n\nagent\u2019s Adam optimizer, a trust region clip parameter (\ud835\udf16-clip) that\ndetermines how far the updated policy is allowed to diverge from\n\nthe old, a time discounting parameter \ud835\udefe , the amount of gradient\n\nsteps taken on the policy loss per epoch (Epochs PPO) and the\n\namount of environment episodes used for each epoch in PPO (Batch\nSize PPO). All policies were trained in a vectorized environment\n\nwith 12 instances for Environment Steps amount of interactions.\n\nD.1 AIRL\nIn AIRL, we use an Adam optimizer with its own learning rate\n\nfor the discriminator (lr-Discriminator). Furthermore, Batch Size\nDiscriminator determines the amount of state-action pairs used in\n\na single training batch. Hyperparameters are reported in table 3.\n\nHyperparameter Value\n\nlr-Discriminator 5e-4\n\nlr-PPO 5e-4\n\nBatch Size Discriminator 512\n\nBatch Size PPO 12\n\nEnvironment Steps 3e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 3: AIRL hyperparameters in Emergency.\n\nD.2 Active Learning\nIn the active learning step of MORAL, we query at fixed time in-\n\ntervals with a prespecified amount of total queries (# Queries) that\nget evenly distributed across the amount of available environment\n\nsteps. Besides that, no additional hyperparameters are necessary.\n\nHowever, we note that if the posterior converges to a local optimum\n\nprematurely, one can employ a normalization parameter \ud835\udc50 > 0 to\n\nmultiply the vector valued reward function r(\ud835\udc60, \ud835\udc4e) := \ud835\udc50 \u00b7 r. For small\n\nchoices of \ud835\udc50 , one can expect to make the posterior less sensitive to\n\nupdates at each step. Nonetheless, we found an inclusion of such\n\nhyperparameter to be unnecessary in our experiments, since mar-\n\nginal reward functions are normalized by their respective optimal\n\nvalues regardless. We report active learning hyperparameters in\n\ntable 4.\n\nD.3 DRLHP\nTomakeDRLHP conceptually similar toMORAL,we employ queries\n\nat constant time intervals using a fixed amount of total queries (#\n\nQueries) across the available environment steps. Besides that, we\n\nupdate the deep reward model after a constant amount of envi-\n\nronment steps (Update Reward Model Frequency) with the Adam\n\noptimizer and a corresponding learning rate (lr-Reward Model).\nOverall, higher entropy regularization was necessary to ensure\n\n\n\nHyperparameter Value\n\nlr-PPO 3e-4\n\n# Queries 25\n\nBatch Size PPO 12\n\nEntropy Regularization 0.25\n\nEnvironment Steps 6e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 4: Active learning hyperparameters in Emergency.\n\nadequate exploration for learning an accurate reward model. We\n\nreport DRLHP hyperparameters in table 5.\n\nHyperparameter Value\n\nlr-PPO 3e-4\n\nlr-Reward Model 3e-5\n\nUpdate Reward Model Frequency 50\n\n# Queries 1000\n\nBatch Size PPO 12\n\nBatch Size Reward Model 32\n\nEntropy Regularization 1\n\nEnvironment Steps 12e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 5: Hyperparameter setup for DRLHP in Emergency.\n\nE HYPERPARAMETERS - DELIVERY\nIn Delivery, the choice of hyperparameters is similar, besides a\n\nconsistent increase in environment steps due to a higher task com-\n\nplexity.\n\nE.1 AIRL\nTo avoid overfitting and balance the discriminator and generator\n\nperformances, we lower the learning rate of the discriminator. We\n\nshow AIRL hyperparameters for Delivery in table 6.\n\nHyperparameter Value\n\nlr-Discriminator 5e-5\n\nlr-PPO 5e-4\n\nBatch Size Discriminator 512\n\nBatch Size PPO 4\n\nEnvironment Steps 6e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 6: AIRL hyperparameters in Delivery.\n\nE.2 Active Learning\nThe following table shows the typical hyperparameter setup for\n\nthe active learning step of MORAL. Note, however, that while the\n\namount of total environment steps were held fixed throughout\n\ndifferent runs, the total number of queries varied, as described\n\nin the respective experiments. See table 7 for the active MORL\n\nhyperparameters in Delivery.\n\nHyperparameter Value\n\nlr-PPO 3e-4\n\n# Queries 25\n\nBatch Size PPO 12\n\nEntropy Regularization 0.25\n\nEnvironment Steps 8e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 7: Active learning hyperparameters in Delivery.\n\nE.3 DRLHP\nTo ensure that the DRLHP has a comparable amount of available\n\ninformation about the expert\u2019s underlying preferences, we provide\n\n5000 overall queries over the course of training. We show DRLHP\n\nhyperparameters for Delivery in table 8.\n\nHyperparameter Value\n\nlr-PPO 3e-4\n\nlr-Reward Model 3e-5\n\nUpdate Reward Model Frequency 50\n\n# Queries 5000\n\nBatch Size PPO 12\n\nBatch Size Reward Model 12\n\nEntropy Regularization 1\n\nEnvironment Steps 12e6\n\n\ud835\udf16-clip 0.1\n\n\ud835\udefe 0.999\n\nEpochs PPO 5\n\nTable 8: Hyperparameter setup for DRLHP in Delivery.\n\n\n\tAbstract\n\t1 Introduction\n\t2 Preliminaries\n\t3 Multi-Objective Reinforced Active Learning\n\t3.1 Reward Normalization\n\n\t4 Experiments\n\t4.1 Emergency\n\t4.2 Delivery\n\t4.3 Comparison to Deep Reinforcement Learning from Human Preferences\n\t4.4 Ablation\n\n\t5 Related Work\n\t6 Discussion\n\tReferences\n\tA Architectures\n\tA.1 Proximal Policy Optimization\n\tA.2 Reward Network - Emergency\n\tA.3 Convolutional Reward Network - Delivery\n\tA.4 Deep Reinforcement Learning from Human Preferences\n\n\tB Proof of Theorem 2.1\n\tC Markov Chain Monte Carlo\n\tD Hyperparameters - Emergency\n\tD.1 AIRL\n\tD.2 Active Learning\n\tD.3 DRLHP\n\n\tE Hyperparameters - Delivery\n\tE.1 AIRL\n\tE.2 Active Learning\n\tE.3 DRLHP\n\n\n"}
{"Title": "The International Monetary Funds intervention in education systems and its impact on childrens chances of completing school", "Authors": "Adel Daoud", "Abstract": "  Enabling children to acquire an education is one of the most effective means to reduce inequality, poverty, and ill-health globally. While in normal times a government controls its educational policies, during times of macroeconomic instability, that control may shift to supporting international organizations, such as the International Monetary Fund (IMF). While much research has focused on which sectors has been affected by IMF policies, scholars have devoted little attention to the policy content of IMF interventions affecting the education sector and childrens education outcomes: denoted IMF education policies. This article evaluates the extent which IMF education policies exist in all programs and how these policies and IMF programs affect childrens likelihood of completing schools. While IMF education policies have a small adverse effect yet statistically insignificant on childrens probability of completing school, these policies moderate effect heterogeneity for IMF programs. The effect of IMF programs (joint set of policies) adversely effect childrens chances of completing school by six percentage points. By analyzing how IMF-education policies but also how IMF programs affect the education sector in low and middle-income countries, scholars will gain a deeper understanding of how such policies will likely affect downstream outcomes.      ", "Subject": "General Economics (econ.GN)", "ID": "arXiv:2201.00013", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 \n \n\n \n\nThe International Monetary Fund\u2019s intervention in education systems  \nand  \n\nits impact on children\u2019s chances of completing school  \n \n \n \n \n\nAdel Daoud1,2, *,  \n\n     (Version 22 December 2021) \n \nw \n \n1. Institute for Analytical Sociology, Department of Management and Engineering, Link\u00f6ping \nUniversity, Norrk\u00f6ping, Sweden.w \n2. The Division of Data Science and Artificial Intelligence of the Department of Computer \nScience and Engineering, Chalmers University of Technology, Gothenburg, Sweden \n \n \n* Corresponding author: adel.daoud@liu.se \n\nmailto:adel.daoud@liu.se\nmailto:adel.daoud@liu.se\n\n\n2 \n \n\n  \n\n\n\n3 \n \n\nEnabling children to acquire an education is one of the most effective means to reduce \ninequality, poverty, and ill-health globally. While in normal times a government controls its \neducational policies, during times of macroeconomic instability, that control may shift to \nsupporting international organizations, such as the the International Monetary Fund (IMF). \nWhile much research has focused on which sectors has been affected by IMF policies, \nscholars have devoted little attention to the policy content of IMF interventions affecting the \neducation sector and children\u2019s education outcomes: denoted IMF-education policies. This \narticle evaluates the extent which IMF-education policies exist in all programs and how these \npolicies and IMF programs affect children\u2019s likelihood of completing schools. While IMF-\neducation policies have a small adverse effect yet statistically insignificant on children\u2019s \nprobability of completing school, these policies moderate effect heterogeneity for IMF \nprograms. The effect of IMF programs (joint set of policies) adversely effect children\u2019s \nchances of completing school by six percentage points. By analyzing how IMF-education \npolicies but also how IMF programs affect the education sector in low- and middle-income \ncountries, scholars will gain a deeper understanding of how such policies will likely affect \ndownstream outcomes.  \n \n  \n\n\n\n4 \n \n\nTable of Contents \n1 Introduction ........................................................................................................................ 5 \n\n2 Method and data ................................................................................................................. 6 \n\n2.1 The outcome: child-education deprivation .................................................................. 6 \n\n2.2 The exposures: IMF-education policies and IMF programs ....................................... 7 \n\n2.3 Method ......................................................................................................................... 8 \n\n2.3.1 Identifying IMF-education policies in policy text ................................................ 8 \n\n2.3.2 Statistical analysis: estimating ATE and CATE .................................................. 8 \n\n2.3.3 Generalized random forest ................................................................................. 10 \n\n2.3.4 Handling selection bias ...................................................................................... 11 \n\n3 Results .............................................................................................................................. 12 \n\n3.1 Measuring IMF-education policy .............................................................................. 12 \n\n3.2 Evaluating the effect of IMF-education policies on children\u2019s chances of completing \nschool 12 \n\n3.3 Qualitative analysis of IMF-policy documents: the link between IMF programs and \nchildren\u2019s educational outcomes. ......................................................................................... 14 \n\n4 Discussion ........................................................................................................................ 16 \n\n5 References ........................................................................................................................ 17 \n\n6 Tables ............................................................................................................................... 22 \n\n7 Figures .............................................................................................................................. 25 \n\n8 Appendix .......................................................................................................................... 28 \n\n8.1 Appendix A: Measures .............................................................................................. 28 \n\n8.2 Appendix B: Heckman Selection model ................................................................... 32 \n\n \n \n  \n\n\n\n5 \n \n\n1 Introduction \nEnabling children to acquire an education is one of the most effective means to reduce \ninequality, poverty, and ill-health globally (Banerjee and Duflo 2012; Deaton 2015; Sen \n1999). Having an education is also a critical ingredient for empowering girls in their future \nendeavors and decreasing the gap of unequal life opportunities (Breen and Jonsson 2005). The \nlikelihood of a child completing schools depends on not only micro factors such as family \nliving-conditions but also macro factors: government\u2019s effectiveness, structure of the \neducation system (e.g., private or public schools) (Conklin et al. 2018; Haller\u00f6d et al. 2013; \nNandy, Daoud, and Gordon 2016; Ponce et al. 2017; Rothstein 2011), and the amount of \nsocial spending on its education spending. The quality of the education system determines to a \nconsiderable extent a child\u2019s probability of completing school (Abdullahi 2015). While in \nnormal times a government controls its educational policies, during times of macroeconomic \ninstability, that control may shift to supporting international organizations\u2014eroding their \nsovereignty over domestic affairs. That shift in control is likely to lead to unexpected \nconsequences, and in the worst-case jeopardizing children\u2019s chances to acquire an education \n(Alexander 2001; Buchmann 1996; Daoud et al. 2017; Daoud and Johansson 2020; Moosa \nand Moosa 2019; Nielsen 2006).  \n \nOne of the most powerful international organizations is the International Monetary Fund \n(IMF). As one of the several organizations sanctioned by the United Nation, the IMF\u2019s role is \nto support governments in macroeconomics turmoil (Vreeland 2007). It provides this support \nin an IMF program that contains financial assistance but also a set of policy conditions. In \nexchange for its support, the IMF requires that the government to implement a set of policy \nconditions that the IMF considers addressing the route of these macroeconomics imbalances. \nThese policies are generally of neoliberal nature: liberalizing trade, privatizing state-owned \ncompanies, and deregulating markets (Babb 2005). While much research has focused on \nwhich sectors has been affected by IMF policies (Daoud, Herlitz, and Subramanian 2020; \nDreher 2005, 2006; Vreeland 2007), especially health spending, scholars have devoted little \nattention to the policy content of IMF interventions affecting the education sector and \nchildren\u2019s education outcomes. Existing studies find that IMF policies tend to decrease \neducation spending (Stubbs et al. 2018), but it remains unclear the extent which the IMF \nexplicitly targets education sector directly through what we call IMF-education policies, and \nhow such targeting affects children\u2019s education outcomes. By IMF-education policies we \nmean a policy that explicitly and directly stipulates a change in the education system. An \nIMF-education policy exists predominately as one of several other IMF policies, bundled \ntogether in IMF programs. While several datasets exist on IMF programs (e.g. Vreeland \n2007), only the IMF\u2019s Monitoring of Fund Arrangements database (MONA) offers \ndisaggregated information about the content of these programs. Nonetheless, MONA has been \nshown to be incomplete (Arpac, Bird, and Mandilaras 2008; Daoud, Reinsberg, et al. 2019; \nIEO 2007; Kentikelenis, Stubbs, and King 2016). The IMF conditionality dataset improves on \nthis incompleteness by capturing a range of policy areas. Nonetheless, none of these capture \nIMF-education policies.  \n \nBy analyzing how IMF-education policies but also how IMF programs affect the education \nsector in low- and middle-income countries, scholars will gain a deeper understanding of how \nsuch policies will likely affect downstream outcomes (Stuckler and Basu 2013). These \noutcomes range from not only the number of children graduating but also the quality of \nuniversity studies, number of young adults in employment, and similar outcomes. \nPolicymakers will gain insights into the likely affects should their country implement IMF \nprograms. \n\n\n\n6 \n \n\n \nThe purpose of our article is it to evaluate the extent which IMF-education policies exist in all \nprograms  and how these policies and IMF programs affect children\u2019s likelihood of \ncompleting schools. First, our analysis identifies which IMF policies contain explicit \nreference to the education sector across all IMF policies in the period 1985-2014. Besides \nevaluating extent, this identification shows the temporal and geographical spread of IMF-\neducation policies in the past. This analysis reveals the content of IMF-education policies, and \nhow many conditions contain explicit reference to education. Second, besides deepening the \nscholarly knowledge on how IMF-education policies affect countries around the world, our \nanalysis supplies a dataset that quantifies such policies\u2014supporting future research. Third, \nusing this IMF-education data, our analysis evaluates the impact of IMF-education policies \nand IMF programs on children\u2019s chances of completing primary or secondary school. Our \nanalysis relies on the Demographic and Health Survey (DHS) and Multiple Indicator Cluster \nSurvey (MICS), measuring the living conditions for over one million children living across \nhalf-a-million families and 67 low and middle-income countries. These measurements are \nrepresentative samples of about half the worlds population around the year 2000. \n \n Our policy evaluation captures both the average treatment effect (ATE) and the conditional \naverage treatment effect (CATE). Because IMF policies are likely to affect groups of children \ndifferently, merely reporting ATE mask that variation in effect\u2014called effect heterogeneity. \nAn additional CATE analysis unpacks this effect heterogeneity across children\u2019s country, \nfamily, and individual characteristics. To identify CATE, we use a data-driven approach \nrelying on statistical models for causal inference and machine learning\u2014algorithms that find \npatterns in the data (Athey and Imbens 2017; Daoud and Dubhashi 2021; Hill 2011; Kino et \nal. 2021; Mullainathan and Spiess 2017). \n\n2 Method and data \n\n2.1 The outcome: child-education deprivation  \n \nWe rely on the Bristol method to define children\u2019s education outcomes, denotes as \ud835\udc4c\ud835\udc4c. The \nBristol method is a deprivation approach developed by Peter Townsend, his team, and \nUNICEF in 2003. A child is defined as deprived of an education, if that child \u201chad never been \nto school and were not currently attending school, in other words, no professional education \nof any kind.\u201d The outcome, child-education deprivation, is a binary variable where one means \n\u201cdeprived\u201d and zero means \u201cnot deprived.\u201d This outcome applies to children 7\u201317 years old.  \n \nOur data consists of household data from the DHS and MICS. These surveys are cross-\nsectional and nationally representative household surveys conducted several in middle-income \nand low-income countries. As these two surveys have identical sampling frameworks, we \ncombine their data (Corsi et al. 2012). Using interviews, the response rate for these surveys \nnormally exceed 90%. National samples range from 4,000 to 30,000 households depending on \nthe population size. The DHS (2011) provides further information about the survey design. \n \nWe selected surveys from countries that were sampled around the year 2000. The DHS rolls \nout these surveys at different time points for each country. Our pooled data spans 1995 to \n2005. Our household sample captures 1,150,711 children, representative of about 2.8 billion \nhouseholds, or roughly 50 percent of the world\u2019s population in the year 2000. Figure 1 \nhighlights the sample\u2019s geographical distribution of child poverty.  \n \n\n\n\n7 \n \n\n \n[Figure 1 about here] \n\n2.2 The exposures: IMF-education policies and IMF programs \nOur analysis covers two types of exposures denoted jointly as \ud835\udc4a\ud835\udc4a: IMF-education policies \ud835\udc4a\ud835\udc4a1 \nand IMF programs \ud835\udc4a\ud835\udc4a2. As defined in the Introduction, IMF programs are a set of policies that \nIMF and government officials have signed and agreed to implement in the target country. \nThese programs consist of a set of policies, ranging from a few to up to five dozen. These \npolicies consist of a variety of interventions, from small (e.g., appointing an expert for a \nspecific area) to large ones (e.g., privatizing state-owned companies).  IMF program is a \nbinary variable. We collect these data from the IMF, as they are freely available.  \n \nBy IMF-education policy, we mean a policy that explicitly targets a country\u2019s education \nsystem. Clear cases are when the IMF explicitly requires introducing education fees, \nprivatizing schools, or targeting teachers\u2019 salaries (up or down). While an IMF policy may \nrequire that a government adjusts its fiscal spending to achieve balance, which is not an IMF-\neducation policy as it does not directly reference the education system, but asking to reduce \nsocial or public spending is a borderline case. These are borderline cases, as public or social \nspending often consist or closely overlaps with education spending and priorities in the social \nsystem. Demanding a reduction in public or social spending pushes the agency from the IMF \nto the government in deciding whether the education system should be affected or not. \nAlthough these borderline cases are important determinants for changes in the education \nsystem, they are too general for our purposes. That general case is included in our definition \nof IMF programs. For our purposes, we select a more stringent definition of IMF-education \npolicies. A policy condition must include at least one of the following terms to qualify as an \nIMF-education policy, \n \n\n\"[Ee]duca|[Uu]niversit[y|ies]|[Ss]chool|[Pp]edagog|[Tt]eacher|[Pp]roffesor|[Ll]ectur|[Ss]tu\ndent|[Pp]upil|[Cc]lassroom|[Cc]urricul|[Ll]earn|[Ac]adem\" \n\n \nWe denote this list or dictionary as \ud835\udc37\ud835\udc37. The symbol \u201c[ ]\u201d means the term can be either \ncapitalized or not and \u201c|\u201d means or. Despite that the list is short, it is calibrated to effectively \ncapture policy text predominately relevant for education systems. A broad term list risks \ncapturing irrelevant policies. As described in the Method section, we then match these terms \nto the IMF conditionality dataset, covering all IMF programs between 1985 to 2014. These \ndata are derived from 4,500 IMF-program documents and include 58,406 conditions across \n131 countries. \n \nFor the 67-countries with household data, separate from the 131 countries, we collected \nadditional policy-text data, to substantiate our statistical findings. With that collection, we \nanalyzed IMF program in depth, as documented in the IMF\u2019s Executive Board Specials \n(EBS)\u2014digitally and freely available at the IMF website. An EBS documents lay out the \nnational context and the specific policy conditions that the IMF and the particular government \nhave drafted for a final agreement. These are then submitted\u2014often with no or only minor \namendments\u2014to the IMF executive board for formal approval. As an IMF program usually \nruns for three years, with an additional period of extension (Vreeland 2007), we searched EBS \ndocuments in a six-year window, set to three years before and after the starting date of an IMF \nprogram. This window ensures that we capture policy drafts and updates relevant for program \nimplementation. \n \n\n\n\n8 \n \n\n2.3 Method \n\n2.3.1 Identifying IMF-education policies in policy text \nWe use natural language processing to identify IMF-education policies (\u00c5kerstr\u00f6m, Daoud, \nand Johansson 2019; Daoud, Reinsberg, et al. 2019). As the IMF conditionality data records \nthe actual policy conditions as it is written in its EBS document, we capitalize on this to \nidentify IMF-education policies. Call the policy-condition text or corpus for \ud835\udc36\ud835\udc36\ud835\udc56\ud835\udc56, where i is the \nnumber of policy conditions searched, that is, 58,406. Before the search, used standard \ncleaning procedures recommended in text mining (Jockers 2014), by removing numbers and \nspecial characters as those do not carry qualitative meaning.1 We then processed \ud835\udc36\ud835\udc36\ud835\udc56\ud835\udc56, resulting \nin a document-term (in our case, conditionality-word) matrix, where each is represented as a \nvector of words \ud835\udc64\ud835\udc64\ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc56. The index k captures the number of words in policy condition i.  \n \nWe then use our dictionary \ud835\udc37\ud835\udc37\u2014the list of terms identifying IMF-education policy defined in \nthe Data section\u2014and apply it to a search function \ud835\udc53\ud835\udc53. This function takes \ud835\udc37\ud835\udc37 as input, matches \nwith a regular-expression searches, each word in term by term, whether \ud835\udc64\ud835\udc64\ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc56 matches with any \nof the terms in \ud835\udc37\ud835\udc37. If it does match, then the output of \ud835\udc53\ud835\udc53 is one and conclude that the policy is \nlikely an IMF-education policy; otherwise, the output is zero. More formally, we write this as \nfollows, \n \n\n\ud835\udc53\ud835\udc53(\ud835\udc36\ud835\udc36\ud835\udc56\ud835\udc56) =  \ufffd 1, \ud835\udc56\ud835\udc56\ud835\udc53\ud835\udc53 \ud835\udc64\ud835\udc64\ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc56  \u2208 \ud835\udc37\ud835\udc37  \n0, \ud835\udc56\ud835\udc56\ud835\udc53\ud835\udc53 \ud835\udc64\ud835\udc64\ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc56  \u2209 \ud835\udc37\ud835\udc37  \n\n \nAfter matching, we sampled the results to verify that the whole policy text does indeed \ndirectly affect the education system.  \n\n2.3.2 Statistical analysis: estimating ATE and CATE \n \nWe combine a policy evaluation and machine learning methodology to estimate the impact of \nIMF program on children\u2019s risk of education deprivation (Daoud and Dubhashi 2020). \nMachine learning constitutes a set of nonparametric algorithms. In contrast to other statistical \ntechniques such as generalized linear models, these algorithms are designed to optimize \nprediction without specific programming rules (Hastie, Tibshirani, and Friedman 2009). \nHowever, when combined with a policy-evaluation techniques, these learning algorithms \nprovide at least four capabilities that traditional estimation techniques lack. In the outline that \nfollows, we use the term learning algorithms to refer specifically to those machine learning \nalgorithms that have been adapted for policy evaluation (Athey and Imbens 2017; Athey, \nTibshirani, and Wager 2019). At the core of these adapted algorithms\u2014compared to \ntraditional machine learning algorithms\u2014lay the assumption of an experimental (ignorability \nby randomization) or quasi-experimental design (conditional ignorability). In our case, we \ndraw on the quasi-experimental design that our conceptual framework provides.  \n \nExpected individual counterfactuals. Under an assumption of conditional ignorability, \nlearning algorithms allow us to impute the expected counterfactuals for each child (Daoud and \nDubhashi 2021; K\u00fcnzel et al. 2018). Matching methods is another instance of nonparametric \ntechniques, but they rely instead on finding comparable cases in-sample. In addition, \nmatching methods use all the covariates at their disposal, even those with low statistical \n\n \n1 We tested to lemmatize and stemming the corpus, in contrast to keep the corpus as it is. After validation we \ndecided to rely on regular expression for the text search, as that produce the most robust results (in the sense that \nit gave the most conservative and valid hits regarding food and agricultural issues) \n\n\n\n9 \n \n\nrelevance for the outcome, while learning algorithms use mainly those variables that are \npredictive of the outcome. As long as the treated and control populations are comparable (in \nline with the overlap assumption discussed above), imputing counterfactuals provides a \nflexible method to conduct policy evaluation. We capitalize on this and impute a \ncounterfactual for each child in our sample. The difference between these counterfactuals is \nthe individual-level treatment effect. The difference between these counterfactuals is the \nindividual-level conditional average treatment effect, \ud835\udf0f\ud835\udf0f(\ud835\udc65\ud835\udc65\ud835\udc56\ud835\udc56,\ud835\udc53\ud835\udc53\ud835\udc56\ud835\udc56) =  \ud835\udc38\ud835\udc38[\ud835\udc4c\ud835\udc4c(1) \u2212  \ud835\udc4c\ud835\udc4c(0)|\ud835\udc4b\ud835\udc4b =\n\ud835\udc65\ud835\udc65\ud835\udc56\ud835\udc56 ,\ud835\udc39\ud835\udc39 = \ud835\udc53\ud835\udc53\ud835\udc56\ud835\udc56]. This effect is a function of the observed covariates, \ud835\udc4b\ud835\udc4b = \ud835\udc65\ud835\udc65\ud835\udc56\ud835\udc56, and the type of model \nselected, \ud835\udc39\ud835\udc39 = \ud835\udc53\ud835\udc53\ud835\udc56\ud835\udc56.  \n \nInductive investigation of impact heterogeneity.  Learning algorithms find impact \nheterogeneity inductively. Traditional regression requires that the analysts specify interaction \nvariables explicitly, guided by theory. To manage complexity, they tend to specify two-way \nor at most three-way interactions (Neumayer and Pl\u00fcmper 2017). For example, if a researcher \nhypothesized that the effect of IMF programs (W) differed by a child\u2019s age (X), they would \nspecify an interaction: \ud835\udc4c\ud835\udc4c =  \ud835\udefd\ud835\udefd0 +  \ud835\udefd\ud835\udefd1\ud835\udc4a\ud835\udc4a +  \ud835\udefd\ud835\udefd2\ud835\udc4b\ud835\udc4b + \ud835\udefd\ud835\udefd3\ud835\udc4a\ud835\udc4a \u2219 \ud835\udc4b\ud835\udc4b + \ud835\udc52\ud835\udc52. They would then test this \nmodel against the data to verify whether \ud835\udefd\ud835\udefd3 is significantly different from zero. Learning \nalgorithms, however, do not require such explicit programing. They estimate many different \nmodels\u2014possibly thousands\u2014using random cuts of the data, and thus suggest where impact \nheterogeneity is largest (Shiba et al. 2021). They produce such suggestions by providing a list \nof variables that were important in building these many different models. Child age, for \ninstance, might be relevant in only one percent of these many models, whereas household \nwealth might have been used 50 percent of the times. Accordingly, our learning algorithm \nwill provide such a list to identify the most important variables moderating IMF impact \nheterogeneity.  \n \nGuarding against researcher bias. Learning algorithms guard against the influence of \noutliers, p-hacking, and cherry-picking results. Although this capability does not eradicate \nresearcher discretion, it renders such bias less influential. Traditional regression procedures \ntend to use all the data simultaneously to generate results. Machine learning procedures, \nhowever, split the data into training and testing sets. The algorithm is first applied to the \ntraining set to find optimal regularization parameters. Then the same model is used on the \ntesting set to estimate the quantities of interest. This procedure finds an optimal balance in the \nbias-variance tradeoff (Hastie et al. 2009). We rely on this splitting procedure to produce our \nresults.  \n \nFlexible functional form. Learning algorithms find an optimal and flexible functional form. \nA model with a flexible functional form\u2014imagine adding more and more interaction terms to \na simple OLS regression\u2014will eventually overfit the data. That is, the model will predict the \ngiven sample perfectly, implying that it will predict new data poorly. In machine learning, a \nregularization expression limits how flexible a model can become, thus balancing the trade-\noff between bias in-sample and variation out-of-sample. Selecting optimal regularization \nparameters, called empirical tuning, is done using cross-validation. This validation procedure \ninvolves estimating a model on a portion of the sample, and then evaluating predictive \nperformance in another sample. Such models have been used in a variety in applications in the \nsocial and behavioral sciences (Daoud, Kim, and Subramanian 2019; Kino et al. 2021). \nRelying on novel methodological developments in policy evaluation, we select a function \nclass called generalized random forest (Athey et al. 2019; Nie and Wager 2018).  \n\n\n\n10 \n \n\n2.3.3 Generalized random forest  \n\nGeneralized random forest (grf) adapts the family of random forest (RF) estimators (Breiman \n2001) for efficient non-parametric estimation of causal effects (Athey et al. 2019). RF models \nlearn ensembles of regression (or classification) trees, each fit a different resampled \npopulation and covariate set, to estimate and reduce model variance. Each tree learns a set of \nrules (e.g., Age > 5) which partition the population of units into different leaves of the tree. \nThe predicted outcome for a new unit is the average of outcomes for observed units assigned \nto the same leaf; the prediction of the forest is the average of the predictions of all trees. A \nstrength of non-parametric (or machine learning) estimators such as RF is that they are \ndesigned to optimize predictive accuracy on held-out data by trading off bias and variance \nthrough regularization, rather than learning the parameters of a fixed-size model (Hastie et al. \n2009). For tree-based estimators, many heuristic regularization strategies exist, including \nlimiting the depth or number of leaf nodes in each tree. Generally, growing more trees is \npreferable for out-of-sample generalization. In order to select such tuning parameters, we use \nsample splitting, evaluating the predictive accuracy on a randomly subsampled set of held-out \ndata, never exposed to the model. grf uses a version of sample splitting called \u201cout-of-bag \npredictions.\u201d As it randomly picks a subset of cases from the full sample\u2014hence, the name \nrandom forest\u2014to grow each tree, it does not use all cases for all trees. Out-of-bag prediction \napplies each specific case to only those trees in which the grf did not sample that case to \ngrown those trees. This type of prediction is a more efficient way to use data.  \n\nWhen machine learning is applied na\u00efvely to policy evaluation design, the bias-variance trade-\noff described above may induce regularization bias in treatment effects since minimization of \npredictive error is agnostic to the difference between a treatment variable and other \ncovariates. For example, regularized generalized linear models tend to prefer smaller \ncoefficients and may, therefore, bias treatment effects in either direction, depending on the \ncorrelation between treatment and covariates. To address this issue, researchers have \ndeveloped so-called debiased machine learning estimators which decouple the estimation of \ntreatment propensity and effect heterogeneity (Chernozhukov, Newey, and Robins 2018; Nie \nand Wager 2018). grf implements this structure through the R-learner framework, blending \nregression and propensity score methods to obtain debiased estimates of causal effects (Nie \nand Wager 2018). The R-learner builds on the treatment effect decomposition of Robinson \n(1988) which relates CATE and covariates through a regression of a transformed outcome \nbased on the observed treatment assignment. To achieve statistical efficiency, the R-learner \ndraws on the strength of residualization, in which regressors are fit to residuals, rather than \noutcomes themselves. In particular, the R-learner first fits one model of treatment propensity \n\ud835\udc38\ud835\udc38[\ud835\udc47\ud835\udc47| \ud835\udc7f\ud835\udc7f] and one of marginal effect \ud835\udc38\ud835\udc38[\ud835\udc4c\ud835\udc4c| \ud835\udc7f\ud835\udc7f]. To obtain de-biased effect estimates, the \nresiduals of these models are then explained by a third model\u2014a model of the CATE with \nrespect to X. This approach is also called quasi-oracle estimation as it relies on fitting a model \nto imputations of the treatment effect for each unit. \n\nOnce an estimate of CATE\u2014using all the covariates\u2014has been obtained, the population may \nbe clustered at different levels of granularity to compile average treatment effects within \ngroups. grf uses cluster-robust errors that ensures that the standard errors are computed \ncorrectly and that they are less sensitive to outliers. In our study, the treatment\u2014IMF \nprograms\u2014is assigned at the country-level. Clustered standard errors reflected this \nuncertainty when estimating the quantities of interest. Additionally, we may be interested in \nthe ATE stratified only by educational level. In this case, we average CATE predictions over \nall individuals in each stratum, effectively coarsening our view of treatment effect \n\n\n\n11 \n \n\nheterogeneity. If the set of confounders includes more variables than education, this two-stage \napproach is necessary to deconfound treatment effect estimates. It has the added benefit that \nthe CATE model does not need to be retrained if several different stratifications are of \ninterest. \n\n2.3.4 Handling selection bias \nAs the exposures of interest \ud835\udc4a\ud835\udc4a are not randomized, our analysis is an observational study. \nAny observational study runs the risk of having the results contaminated by confounding. A \nconfounding \ud835\udc4b\ud835\udc4b is a common cause to both the exposure \ud835\udc4a\ud835\udc4a and outcome \ud835\udc4c\ud835\udc4c. If a statistical \nanalysis does not adjust for \ud835\udc4b\ud835\udc4b, the results will likely be biased, contaminated by spurious \neffects (Pearl 2012). Although selection into IMF programs (or individual policies) are not \nlikely driven by children\u2019s education status, it may still be the case that governments select \ninto these programs because its population lives in poverty. And poverty and lack of \neducation are closely related. Thus, we still require adjusting for a set of country- and family-\nlevel confounders. Appendix A shows all sources and definitions.  \n \nThe set of confounders are the following. GDP growth: societies with lower economic \ngrowth are more likely to become economically constrained, and ask for IMF credit. Current \naccount balance: the higher the fiscal imbalance, the more likely the country is to ask for \nIMF help. Log GDP per capita: low-income countries tend to seek concessional IMF \nassistance, whereas middle-income countries with short-term economic disturbances \nfollowing, for example, a currency crisis tend to ask for non-concessional loans. Trade: the \nsum of exports and imports of goods and services measured as a share of the gross domestic \nproduct. Economic globalization index: how integrated a nation is in the global economy \nwill affect how many trade liberalization policies the IMF will aim to include in a program \n(Dreher 2006). High inflation indicator: a rapid price rise indicates structural imbalances in \nthe economy. Negative growth: loss of GDP indicates economic downturn, not necessarily \nrelated to current account imbalances. Although we adjusted for demographic variables \nmainly via the microdata, our analysis includes a population-level variable, dependency \nratio, measuring the ratio of the population aged 0 to 14 or 65 and older to the working-age \npopulation aged 15 to 64. This variable captures how much pressure the population exerts on \npublic services. \n \n\nOur confounder set includes three measures for public spending: Education spending as a \npercentage of total government spending; health spending as a percentage of total \ngovernment spending, and; total government spending, as percentage of GDP. Public \npolicies can be measured with spending measures and institutional qualitative indicators of \npolicies (e.g., family policies, or unemployment insurance indicators) (Beckfield 2018). In the \nabsence of complete institutional indicators, we selected public spending measures to capture \nhow much resource governments allocate to public services that will directly affect children\u2019s \nlikelihood of deprivation.  \n \nWe include central political and institutional measures (Daoud 2015; Haller\u00f6d et al. 2013; \nRothstein 2014). Democracy: Autocratic regimes can solicit the IMF\u2019s advice with less \npolitical cost compared to societies that are more democratic. Political terror: a proxy \nmeasuring how likely social movements could mobilize to change public policies. \nGovernment efficiency: an indirect measure of how effective a government is in \nimplementing public policies. Corruption: more corruption is likely to divert resources from \ncritical public services. Minimum age labor law: a binary variable indicating whether this \nlaw is in place regulating child labor. During economic turmoil, poorer families are more \n\n\n\n12 \n \n\nlikely to let their children work. International war and Civil war: the IMF avoid countries \nengaged in conflict.  \n \nHowever, at least one critical confounder is not directly observable: a government\u2019s political \nwill to implement IMF programs. As these programs contain policies that are often difficult to \nimplement, political will is an important driver of selection bias. A government can opt to \nselect into an IMF program or policy, making the exposure a non-random exposure \nassignment. As discussed in the Appendix, we us an Heckman selection model to indirectly \nmeasure political will.   \n \n\n3 Results \n\n3.1 Measuring IMF-education policy \nOf the 138 countries present in the IMF conditionality dataset, 50 countries had at least one \nIMF-education policy listed in their EBS document between the period 1985-2014. Of the 67 \ncountries in our sample, 39 had IMF programs. Of these 39, we find that 18 had at least one \nIMF-education policy. Counting over the entire period, Sierra Leone received most IMF-\neducation policies: 23. These policies ranged from arguably small interventions\u2014in terms of \nits potential effect on children\u2019s prospects to complete school\u2014such as \u201ccomplete and verify \nnationwide teacher\u2019s census\u201d listed in its 1997 program, to major ones, \u201cIdentify and \nimplement concrete measures to control the teacher\u2019s payroll budget\u201d in its 2002 program.  \n \nOur search identified a total of 137 IMF-education policies\u2014all listed in the Supplementary \ndata. Although this is a small number compared to the over 50 000 conditions that the IMF \nhas issued, even one IMF-education policy can have severe implications for children\u2019s \nchances for completing school their content. In Kenya 1989, an IMF-education policy \nstipulated \u201cfiscal measures in the context of the 1989/90 budget, including user charges in the \nhealth, education, and other sectors.\u201d In Bulgaria 2006, a policy required the \u201cImplementation \nof an employment cut of at least 5,500 positions in the education sector.\u201d In Tajikistan 2004, \nthe IMF wrote \u201cReduce the number of employees in the education sector by 5 percent.\u201d \nMoreover, IMF-education policies affect not only children but also university students. In \nanother of Kenya\u2019s IMF programs in 2001, a policy read, \u201cImplementation of tuition and \ndirect charges for university students as well as reduction in amount of the student loan.\u201d In \nBolivia 2000, \u201cEducation: Develop a reform proposal for higher education in order to reduce \nthe share of public resources for higher education.\u201d Consequently, even if IMF-education \npolicies are few in numbers, when implemented, they are likely to have profound \nconsequences to children and university students.  \n \n\n3.2 Evaluating the effect of IMF-education policies on children\u2019s chances of \ncompleting school \n\n \nBased on the IMF-education policy data, we proceed to analyze the impact of IMF-education \npolicies on children\u2019s educational prospects. The analysis will also evaluate the effect of IMF \nprograms, revealing the extent to which it is educational policies or the set of all policies that \naffect children. Table 1 shows the raw covariate difference between children living in \ncountries with an IMF program containing at least one IMF-education policy versus those that \nhave no such programs. Similarly, Table 2 compares covariate balance by IMF program. For \n\n\n\n13 \n \n\nboth exposures, covariate balance is fairly comparable across the exposed and non-exposed \ngroups.  \n \n\n[Table 2 about here] \n\n \nFigure 2 panel (a), shows the ATE estimates for IMF-education policies and IMF programs. \nWhile the estimate of IMF-education policy has an adverse effect on children\u2019s education \ndeprivation, the effect is not significant at a 95%-confidence interval. The estimate suggests \nan adverse increase in deprivation by about half a percentage point. One statistical reason for \nwhich the effect is insignificant is that the model is underpowered: the data contains only 14 \ncountries with at least on IMF-education policy. A substantive reason for the lack of effect is \nthat IMF programs contain a slew of other policy conditions that dominate any potential effect \nof IMF-educational policies. Corroborating that reason, the model estimates an adverse IMF-\nprogram effect of 6 percentage points (with a standard error of 0.028), shown in panel (b). \nThis effect means that in a country with no IMF program and which would implement such a \nprogram will on average see an increase in children failing to complete school by a proportion \nof six. In a population with 100 children and zero education deprivation to before an IMF \nprogram, 6 children will fail after implementations. Thus, keeping the statistical caveat that \nthe IMF-education data is possibly underpowered, our results show that IMF programs (as a \nset of policies) carry more political power to affect children\u2019s chances of completing school.  \n \nFigure 3 shows the effect of IMF programs by children\u2019s age group.2 Following the trends of \nthe two ATEs, these disaggregated effects reveal that IMF programs induce an adverse effect \non all groups. These effects range from 9 (age seven) to 4 (age eleven) percentage points: \nhovering around 5 points. For younger children (seven to eleven), our models cannot verify \nthat their respective estimates are different from zero at a 95%-confidence interval. For older \nchildren (twelve to seventeen), the effects are significantly different from a zero estimate for \nchildren aged twelve to fourteen and sixteen; for the fifteen-years and seven-years old \nchildren, the effect is only significant at a 90%-confidence interval. These differences in \nsignificance are likely to the power of the data\u2014the age-by-group samples are of different \nsize. As presented in the Discussion, one likely explanation to this finding\u2014that IMF \nprograms are likely affecting the older group more than the younger one\u2014is because the \neducation system for older children required more resources than for younger children. In \ntimes of austerity, governments likely restrain education spending.  \n \nATE estimates reveal informative child-population-wide trends, yet they mask how the effect \nvaries across groups of children. CATE is useful for unpacking these variations. Figure 4 \nshows CATE distribution of estimates for each child (across all ages), revealing a wide \nvariation across the IMF-program ATE. For some child subgroups, IMF programs are likely \nnot affecting them (those around the red line) at all or even improving their situation (those \nbelow the redline). To better understand why some children, react differently to IMF \nprograms, we analyze subgroups of children based on the five quantiles (i.e., quintiles) of the \nCATE distribution.  \n \nA useful property of the GRF model is that it suggests which variables in the covariate set \nmoderate most of the CATE distribution. Figure 5 shows the top-ranking moderators, their \n\n \n2 The IMF-education policy effect follows a similar but statistically weaker estimate and so the analysis show \nIMF program effects.  \n\n\n\n14 \n \n\naverage value, and their variation by quintiles. The analysis focuses on the model for \nseventeen-years-old children, as this group of children are the ones that policy changes are \nlikely affect their living conditions, beyond completing school. They are the ones that are on \nthe verge of leaving childhood and moving into adulthood\u2014with all the complexities that \nmovement entails, from finding a job, shaping a new home, and forming a family. Completing \nthis movement with or without an education makes a large difference.  \n \nThe seven top-ranking moderators jointly capture about 80 percent of the CATE variation. \nFor this top group, Figure 5 start with listing the highest-ranking moderators and end with the \nlowest. The GRF model suggest that their moderating differences are small, they range in \nabout 7 to 10 in importance value. There are at least three striking observations. First, children \nwith the highest impact\u2014those in fifth quantile (Q5)\u2014live in countries with high dependency \nratio. A value of 82 for this ratio means that 82 percent of the population are between 0-14 or \n65 and above. As our sample represents low- and middle-income countries and these \ncountries tend to have a young population, it means that there are more children in these \ncountries relative to adults. The more children, the higher the likelihood that children are \naffected by government cuts. While this finding is logical, the following two are not\u2014at first \nsight.  \n \n \nFamily wealth and government\u2019s education spending seems to have a reversed moderating \neffect on the relationship between the exposure and outcome. Second, family wealth variable \nranges from one (poorest families) to five (wealthiest families). Families with a material-\nwealth value of 2.12 indicates that households with less resources are less affected by IMF \nprograms (first quantile), and families of the middle-class with a value of 3.05 are most \naffected by IMF programs as they are in the fifth quantile of the CATE distribution. Third, \ngovernments that spend more on their education system prior to an IMF program, are also \nencountered with more children failing at school due to IMF programs.  \n \nBy revisiting the content of IMF-education policies, we form a logical explanation to these \ncounterintuitive findings. While our model is unable to quantitatively verify an effect of IMF-\neducation policies, our qualitative analysis provides evidence that IMF-education policies \nmatter for children\u2019s chances of completing school.  \n \n\n3.3 Qualitative analysis of IMF-policy documents: the link between IMF \nprograms and children\u2019s educational outcomes. \n\n \nThe counterintuitive effect heterogeneity shown in Figure 5 has a partly causal and a partly \nassociative explanation. The associative explanation emphasizes that education spending only \nappears to causally moderate child-education deprivation during IMF programs, when this \nmoderation is merely a noncausal correlation. Education spending likely coincides with one or \nseveral unobserved factors that also produce more poor deprivation during IMF programs. \nOne such unobserved factor is parents\u2019 unemployment status\u2014a variable we excluded from \nour model because it would block the IMF effect as it is a post-exposure variable. Many \ngovernments worldwide endorse the importance of countercyclical policies (Stiglitz 2009). \nConsequently, in anticipating the onset of an economic crisis, or during such turmoil but \nbefore the involvement of the IMF, governments are likely to have increased their education \nspending to cushion increasing rates of unemployment.  \n \n\n\n\n15 \n \n\nHowever, when the IMF becomes involved, high education spending merely appears \ncorrelated with education deprivation, even though unemployment causally explains both the \nincreased number of children deprived and more education spending. Therefore, in the \npresence of IMF programs, unemployment is likely a confounder in the relationship between \nhigh education spending and children\u2019s education outcomes. In estimating the total IMF \neffect, our design controls for confounding in the causal relationship between IMF programs \nand education deprivation, not for confounding in the causal relationship between education \nspending and deprivation (VanderWeele 2015). To unravel this mediational effect, we would \nneed a different research design\u2014a key task for future research. \n \nWhen we complement our statistical results with our qualitatively produced archival results, \nwe find that the associative explanation cannot fully account for the links among IMF \nprograms, education spending, and education deprivation. To shed light on these links, based \non our IMF-education-policy data, we further analyzed the content of IMF-policy documents \nfor each country in our study. \n \nAn archetypical example of an adverse IMF program is Tajikistan in 2000. In this program, \nthe IMF and the government agreed to \u201creduce the number of employees in the education \nsector by 5 percent,\u201d aiming at increasing \u201cthe public sector wage bill by 28 percent\u201d (IMF \n2003:13), including setting teachers\u2019 salaries \u201con a merit basis\u201d (IMF 2003:14). However, this \n5 percent reduction turns out to merely constitute the beginning of a larger plan to entirely \nreform the education system. Indeed, the government of Tajikistan committed to the \nfollowing IMF policy adjustments: \n \n\nWe will reduce the number of employees in the education sector by 30 percent over a \nperiod of three to five years. We will begin the process of downsizing by reducing the \nnumber of budgetary employees in the education sector by 5 percent as of July 2004 \n(structural benchmark). Further, the plan will address reform of the education budget \nsystem with a move to more school autonomy; introduction of a fee schedule; \nexpansion of teaching assignments; curriculum reform; and private sector \ninvolvement. (IMF 2003:69)  \n\nSimilarly, in Bolivia\u2019s 1999 program, IMF policies stipulated that the Bolivian government \nhad to \u201cdevelop a reform proposal for higher education in order to reduce the share of public \nresources for higher education\u201d (IMF 1999:73). The reason for this reform was that the \nBolivian government \u201chad done little to smooth income distribution [as\u2026] much of \ngovernment social spending fails to reach the poorest groups of society. A disproportionate \nshare of public spending on education goes to universities\u201d (IMF 1999:12). In other words, \nthe IMF and the Bolivian government agreed to directly target low-income families by \nreallocating a portion of higher education spending in favor of rural-development programs \n(IMF 1999:62). While such reforms may help the rural population, this reform adversely \naffects the middle class, because they attend higher-education at a higher rate than the poorer \nsegments of society (Buchmann 1996; Daoud and Puaca 2011).  \n\nNonetheless, how does cutting higher-education funding at \ud835\udc61\ud835\udc61 \u2212 1 that affects mainly young \nadults (age \u2265 18), increase the probability of material deprivation for children between the \nages 0 to 17 at \ud835\udc61\ud835\udc61? One likely pathway is that these cuts affect young adults that are already \nattending, or planning to attend, university and that these adults also have children that \nindirectly are affected by these cuts. In Bolivia, the IMF suggested \u201craising the tuition fees \ncharged by universities.\u201d (IMF 1999:13). Raising fees put a financial burden on the families \n\n\n\n16 \n \n\nof these young adults as they must start paying more for acquiring a university education than \nthey did before the reform (Alexander 2001; Buchmann 1996). Consequently, such increased \nuniversity fees affect adversely young adults and their children\u2019s risk of failing in school. \n\nAnother likely pathway is via a sibling effect. Older siblings (above the age of 18) who would \nhave attended higher universities now choose to search for a job but find themselves \nunemployed instead. As the youth unemployment rate in low and middle-income countries is \nhigh (Banerjee and Duflo 2012), chances of finding a job is low (Buchmann 1996; Daoud and \nPuaca 2011). If the older sibling remains unemployed, then that indicates that the older sibling \nwill likely not move out of his parents\u2019 home and has to keep sharing scarce resources with \ntheir younger sibling (Daoud 2007, 2010, 2018; Garfinkel, McLanahan, and Wimer 2016). \nThis sharing may burden the younger sibling by diverting resources away from them and thus \nincreasing the younger sibling\u2019s risk of education deprivation. These observations reinforce \nour first key finding that IMF reforms affect the middle class at least as much as low-income \nfamilies but through different causal pathways.  \n\nBoth Tajikistan and Bolivia spent about the sample average (third quantile) on education \nbefore selecting into IMF programs. The combination of spending on education, presence of \nIMF-education policies, and effect on child-education deprivation provide a clue to the likely \ncausal relationship. In high- and medium-education spending countries, the IMF will likely \nidentify a larger fiscal leeway for cutting this spending to balance fiscal deficit than for \ncountries with low education spending. Subsequently, such cutting will increase deprivation. \nIf our reasoning holds empirically, it would suggest that low-education-spending countries \nhave fewer or no adverse IMF-education policies. Indeed, that is also what we find. \n\nIn some countries with low education spending before IMF program enrollment, such as \nGabon and Chad, the IMF introduced education spending floors. In Chad, the IMF and \ngovernment officials decided that they would \u201cfollow pro-poor expenditure more closely, \nindicative minimum targets are set for education and health current spending; a ceiling on the \ngovernment\u2019s total wage bill is also set, with a view to ensuring the attainment of the \nprogram\u2019s fiscal objectives\u201d (IMF 2001:19). These types of pro-poor policies, while paying \nattention to the fiscal ceiling, are common in low-income countries and often set in \ncollaboration with the World Bank. Nonetheless, Kentikelenis et al. (2016) find that these \nspending targets have low priority in the slew of other high-priority IMF policies and thus \ntend to be inadequately implemented\u2014if at all. \n\n4 Discussion  \nBased on natural language processing, we identified the existence which IMF policies target a \ncountry\u2019s education system (\u00c5kerstr\u00f6m et al. 2019; Daoud, Reinsberg, et al. 2019). While \nIMF-education policies exist in several IMF programs, our statistical model finds no effect of \nthese educational policies on children\u2019s probability of completing school. The lack of effect of \nIMF-education policies is likely driven by that these policies are dependent on the presence of \nan IMF program. As IMF-education policies cannot exist without the presence of an IMF \nprogram, this dependence implies that statistically any IMF impact on children is mixed with \nother IMF policies. As IMF programs are dominated by macroeconomic policy conditions, it \nis likely that these conditions drown out any potential direct effect from IMF-education \npolices. But this dependence is a consequence of how IMF programs are designed: IMF and \ngovernment officials design a program to mainly address critical macroeconomic issues rather \nthan issues in the education system. Focusing on macroeconomics will therefore affect the \n\n\n\n17 \n \n\neducational system via indirect channels, mainly reduced education spending. Nevertheless, \nas our archival analysis shows, albeit in small numbers, the IMF requires direct targeting the \neducation system. This mix of direct and indirect targeting are likely the mechanisms through \nwhich children are affected. Consequently, as IMF-education policies are predominately \nbundled into a set of other policies that make up an IMF programs, children are affected by \nthe presence or absence of austerity rather  \n \nOur analysis shows that IMF programs affect mainly children between the age of 12 to 17. \nSchooling for younger children, between the age of 7 and 11, is less resources heavy than for \nolder children. These age groups that the model detects matches with the age groups countries \nuse around the world, although with small differences. Maintained by the United Nations \nEducational, Scientific and Cultural Organization (UNESCO), the International Standard \nClassification of Education (ISCED) defines primary education as the education stage suitable \nfor children from age six to twelve and secondary education for children in the age range \nthirteen to nineteen. These thresholds matches well with our our households data that covers \nthe ages seven to seventeen. Compared to primary education, schooling for secondary \neducation requires more teachers (often with higher salary), increasingly expensive \npedagogical material, and a variety of other educational resources. This makes schooling for \nolder children more dependent on sufficient education spending. Thus, a government must \nspend considerable amounts to maintain high educational standards. Despite that IMF-\neducation policies directly target the educational system, this finding\u2014that the older children \nrather than the younger are most effected by IMF programs\u2014substantiates the argument that \nit is the mix of direct and indirect policies aggravates children\u2019s risk of completing secondary \nschool.  \n \n \n\n5 References \nAbdullahi, Sadiq A. 2015. \u201cGlobal Education.\u201d Pp. 793\u2013806 in Second International \n\nHandbook on Globalisation, Education and Policy Research, edited by J. Zajda. \nDordrecht: Springer Netherlands. \n\n\u00c5kerstr\u00f6m, Joakim, Adel Daoud, and Richard Johansson. 2019. \u201cNatural Language \nProcessing in Policy Evaluation: Extracting Policy Conditions from IMF Loan \nAgreements.\u201d The 22nd Nordic Conference on Computational Linguistics 5. \n\nAlexander, Nancy C. 2001. \u201cPaying for Education: How the World Bank and the International \nMonetary Fund Influence Education in Developing Countries.\u201d Peabody Journal of \nEducation 76(3\u20134):285\u2013338. doi: 10.1080/0161956X.2001.9682002. \n\nArpac, Ozlem, Graham Bird, and Alex Mandilaras. 2008. \u201cStop Interrupting: An Empirical \nAnalysis of the Implementation of IMF Programs.\u201d World Development 36(9):1493\u2013\n1513. doi: 10.1016/j.worlddev.2007.09.001. \n\nAthey, Susan, and Guido W. Imbens. 2017. \u201cThe State of Applied Econometrics: Causality \nand Policy Evaluation.\u201d Journal of Economic Perspectives 31(2):3\u201332. doi: \n10.1257/jep.31.2.3. \n\nAthey, Susan, Julie Tibshirani, and Stefan Wager. 2019. \u201cGeneralized Random Forests.\u201d The \nAnnals of Statistics 47(2):1148\u201378. doi: 10.1214/18-AOS1709. \n\n\n\n18 \n \n\nBabb, Sarah. 2005. \u201cThe Social Consequences of Structural Adjustment: Recent Evidence and \nCurrent Debates.\u201d Annual Review of Sociology 31:199\u2013222. \n\nBanerjee, Abhijit, and Esther Duflo. 2012. Poor Economics: A Radical Rethinking of the Way \nto Fight Global Poverty. Reprint edition. New York: PublicAffairs. \n\nBeckfield, Jason. 2018. Political Sociology and the People\u2019s Health. Oxford: Oxford \nUniversity Press. \n\nBreen, Richard, and Jan O. Jonsson. 2005. \u201cInequality of Opportunity in Comparative \nPerspective: Recent Research on Educational Attainment and Social Mobility.\u201d \nAnnual Review of Sociology 31(1):223\u201343. doi: \n10.1146/annurev.soc.31.041304.122232. \n\nBreiman, Leo. 2001. \u201cRandom Forests.\u201d Machine Learning 45(1):5\u201332. doi: \n10.1023/A:1010933404324. \n\nBuchmann, Claudia. 1996. \u201cThe Debt Crisis, Structural Adjustment and Women\u2019s \nEducation.\u201d International Journal of Comparative Sociology 37(1):5\u201330. doi: \n10.1163/002071596X00208. \n\nChernozhukov, Victor, Whitney Newey, and James Robins. 2018. \u201cDouble/De-Biased \nMachine Learning Using Regularized Riesz Representers.\u201d ArXiv:1802.08667 [Econ, \nMath, Stat]. \n\nConklin, Annalijn I., Adel Daoud, Riti Shimkhada, and Ninez A. Ponce. 2018. \u201cThe Impact of \nRising Food Prices on Obesity in Women: A Longitudinal Analysis of 31 Low-\nIncome and Middle-Income Countries from 2000 to 2014.\u201d International Journal of \nObesity 1. doi: 10.1038/s41366-018-0178-y. \n\nCorsi, Daniel J., Melissa Neuman, Jocelyn E. Finlay, and S. V. Subramanian. 2012. \n\u201cDemographic and Health Surveys: A Profile.\u201d International Journal of Epidemiology \n41(6):1602\u201313. doi: 10.1093/ije/dys184. \n\nDaoud, Adel. 2007. \u201c(Quasi)Scarcity and Global Hunger.\u201d Journal of Critical Realism \n6(2):199\u2013225. doi: 10.1558/jocr.v6i2.199. \n\nDaoud, Adel. 2010. \u201cRobbins and Malthus on Scarcity, Abundance, and Sufficiency.\u201d \nAmerican Journal of Economics and Sociology 69(4):1206\u201329. doi: 10.1111/j.1536-\n7150.2010.00741.x. \n\nDaoud, Adel. 2015. \u201cQuality of Governance, Corruption, and Absolute Child Poverty in \nIndia.\u201d Journal of South Asian Development 10(2):1\u201320. \n\nDaoud, Adel. 2018. \u201cUnifying Studies of Scarcity, Abundance, and Sufficiency.\u201d Ecological \nEconomics 147:208\u201317. doi: 10.1016/j.ecolecon.2018.01.019. \n\nDaoud, Adel, and Devdatt Dubhashi. 2020. \u201cStatistical Modeling: The Three Cultures.\u201d \nArXiv:2012.04570 [Cs, Stat]. \n\nDaoud, Adel, and Devdatt Dubhashi. 2021. \u201cMelting Together Prediction and Inference.\u201d \nObservational Studies 7(1):1\u20137. \n\n\n\n19 \n \n\nDaoud, Adel, Anders Herlitz, and S. V. Subramanian. 2020. \u201cCombining Distributive Ethics \nand Causal Inference to Make Trade-Offs between Austerity and Population Health.\u201d \nArXiv:2007.15550 [Econ, q-Fin]. \n\nDaoud, Adel, and Fredrik Johansson. 2020. \u201cEstimating Treatment Heterogeneity of \nInternational Monetary Fund Programs on Child Poverty with Generalized Random \nForest.\u201d SocArXiv. doi: osf.io/preprints/socarxiv/awfjt. \n\nDaoud, Adel, Rockli Kim, and S. V. Subramanian. 2019. \u201cPredicting Women\u2019s Height from \nTheir Socioeconomic Status: A Machine Learning Approach.\u201d Social Science & \nMedicine 238:112486. doi: 10.1016/j.socscimed.2019.112486. \n\nDaoud, Adel, Elias Nosrati, Bernhard Reinsberg, Alexander E. Kentikelenis, Thomas H. \nStubbs, and Lawrence P. King. 2017. \u201cImpact of International Monetary Fund \nPrograms on Child Health.\u201d Proceedings of the National Academy of Sciences \n114(25):6492\u201397. doi: 10.1073/pnas.1617353114. \n\nDaoud, Adel, and Goran Puaca. 2011. \u201cAn Organic View of Students\u2019 Want Formation: \nPragmatic Rationality, Habitus and Reflexivity.\u201d British Journal of Sociology of \nEducation 32(4):603\u201322. doi: 10.1080/01425692.2011.578440. \n\nDaoud, Adel, Bernhard Reinsberg, Alexander E. Kentikelenis, Thomas H. Stubbs, and \nLawrence P. King. 2019. \u201cThe International Monetary Fund\u2019s Interventions in Food \nand Agriculture: An Analysis of Loans and Conditions.\u201d Food Policy 83:204\u201318. doi: \n10.1016/j.foodpol.2019.01.005. \n\nDeaton, Angus. 2015. The Great Escape: Health, Wealth, and the Origins of Inequality. \nReprint edition. Princeton, NJ: Princeton University Press. \n\nDreher, Axel. 2005. \u201cDoes the IMF Influence Fiscal and Monetary Policy?\u201d The Journal of \nPolicy Reform 8(3):225\u201338. doi: 10.1080/13841280500181726. \n\nDreher, Axel. 2006. \u201cDoes Globalization Affect Growth? Evidence from a New Index of \nGlobalization.\u201d Applied Economics 38(10):1091\u20131110. doi: \n10.1080/00036840500392078. \n\nGarfinkel, Irwin, Sara McLanahan, and Christopher Wimer. 2016. Children of the Great \nRecession. New York: Ruseel Sage Foundation. \n\nGordon, David, Shailen Nandy, Christina Pantazis, Simon Pemberton, and Peter Townsend. \n2003. Child Poverty in the Developing World. Bristol, UK: Polity Press. \n\nHaller\u00f6d, Bj\u00f6rn, Bo Rothstein, Adel Daoud, and Shailen Nandy. 2013. \u201cBad Governance and \nPoor Children: A Comparative Analysis of Government Efficiency and Severe Child \nDeprivation in 68 Low-and Middle-Income Countries.\u201d World Development 48:19\u201331. \n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical \nLearning. 2 edition. Springer New York. \n\nHeckman, James J. 1979. \u201cSample Selection Bias as a Specification Error.\u201d Econometrica \n47(1):153\u201361. \n\n\n\n20 \n \n\nHill, Jennifer L. 2011. \u201cBayesian Nonparametric Modeling for Causal Inference.\u201d Journal of \nComputational and Graphical Statistics 20(1):217\u201340. doi: 10.1198/jcgs.2010.08162. \n\nIEO. 2003. Fiscal Adjustment in IMF-Supported Programs. Washington DC: IMF \nIndependent Evaluation Office. \n\nIEO. 2007. Structural Conditionality in IMF-Supported Programs -- Background Documents. \nWashington DC: IMF Independent Evaluation Office. \n\nIMF. 1999. Bolivia-Staff Report for the 1999 Article IV Consultation and Request for Second \nAnnual Arrangement Under the Poverty Reduction and Growth Facility (EBS/99/235). \nWashington, DC: International Monetary Fund. \n\nIMF. 2001. Chad-Second Review Under the Three-Year Arrangement Under the Poverty \nReduction and Growth Facility (EBS/01/64). Washington, DC: International Monetary \nFund. \n\nIMF. 2003. Republic of Tajikistan-Second Review Under the Three-Year Arrangement Under \nthe Poverty Reduction and Growth Facility, and Request for a Waiver of Performance \nCriterion (EBS/03/171). Washington, DC: International Monetary Fund. \n\nJockers, Matthew L. 2014. Text Analysis with R for Students of Literature. Cham: Springer \nInternational Publishing. \n\nKentikelenis, Alexander, Thomas H. Stubbs, and Lawrence P. King. 2016. \u201cIMF \nConditionality and Development Policy Space, 1985\u20132014.\u201d Review of International \nPolitical Economy 23(0):543\u201382. doi: 10.1080/09692290.2016.1174953. \n\nKino, Shiho, Yu-Tien Hsu, Koichiro Shiba, Yung-Shin Chien, Carol Mita, Ichiro Kawachi, \nand Adel Daoud. 2021. \u201cA Scoping Review on the Use of Machine Learning in \nResearch on Social Determinants of Health: Trends and Research Prospects.\u201d SSM - \nPopulation Health 15:100836. doi: 10.1016/j.ssmph.2021.100836. \n\nK\u00fcnzel, S\u00f6ren R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. 2018. \u201cMeta-Learners for \nEstimating Heterogeneous Treatment Effects Using Machine Learning.\u201d \nArXiv:1706.03461 [Math, Stat]. \n\nMoosa, Imad A., and Nisreen Moosa. 2019. \u201cThe Effects of IMF Operations on Social \nExpenditure.\u201d Pp. 111\u201334 in Eliminating the IMF. Springer. \n\nMoser, Christoph, and Jan-Egbert Sturm. 2011. \u201cExplaining IMF Lending Decisions after the \nCold War.\u201d The Review of International Organizations 6(3\u20134):307\u201340. doi: \n10.1007/s11558-011-9120-y. \n\nMullainathan, Sendhil, and Jann Spiess. 2017. \u201cMachine Learning: An Applied Econometric \nApproach.\u201d Journal of Economic Perspectives 31(2):87\u2013106. doi: \n10.1257/jep.31.2.87. \n\nNandy, Shailen, Adel Daoud, and David Gordon. 2016. \u201cExamining the Changing Profile of \nUndernutrition in the Context of Food Price Rises and Greater Inequality.\u201d Social \nScience & Medicine 149:153\u201363. doi: 10.1016/j.socscimed.2015.11.036. \n\n\n\n21 \n \n\nNeumayer, Eric, and Thomas Pl\u00fcmper. 2017. Robustness Tests for Quantitative Research. \nCambridge, United Kingdom\u202f; New York, NY, USA: Cambridge University Press. \n\nNie, Xinkun, and Stefan Wager. 2018. \u201cQuasi-Oracle Estimation of Heterogeneous Treatment \nEffects.\u201d ArXiv:1712.04912 [Econ, Math, Stat]. \n\nNielsen, H. Dean. 2006. From Schooling Access to Learning Outcomes: An Unfinished \nAgenda: An Evaluation of World Bank Support to Primary Education. Washington \nD.C.: World Bank Independent Evaluation Group. \n\nPearl, Judea. 2012. \u201cThe Causal Foundations of Structural Equation Modeling.\u201d P. 740 in \nHandbook of Structural Equation Modeling, edited by R. H. Hoyle. New York: The \nGuilford Press. \n\nPonce, Ninez, Riti Shimkhada, Amy Raub, Adel Daoud, Arijit Nandi, Linda Richter, and Jody \nHeymann. 2017. \u201cThe Association of Minimum Wage Change on Child Nutritional \nStatus in LMICs: A Quasi-Experimental Multi-Country Study.\u201d Global Public Health \n13(9):1\u201315. doi: 10.1080/17441692.2017.1359327. \n\nRobinson, P. M. 1988. \u201cRoot-N-Consistent Semiparametric Regression.\u201d Econometrica \n56(4):931\u201354. doi: 10.2307/1912705. \n\nRothstein, Bo. 2011. The Quality of Government: Corruption, Social Trust, and Inequality in \nInternational Perspective. Chicago; London: University of Chicago Press. \n\nRothstein, Bo. 2014. \u201cThe Chinese Paradox of High Growth and Low Quality of Government: \nThe Cadre Organization Meets Max Weber.\u201d Governance. doi: 10.1111/gove.12128. \n\nRutstein, S. O. 2008. The DHS Wealth Index: Approaches for Rural and Urban Areas. \npopline.org. \n\nSen, Amartya. 1999. Development as Freedom. 1st. ed. New York: Knopf. \n\nShiba, Koichiro, Adel Daoud, Hiroyuki Hikichi, Aki Yazawa, Jun Aida, Katsunori Kondo, \nand Ichiro Kawachi. 2021. \u201cHeterogeneity in Cognitive Disability after a Major \nDisaster: A Natural Experiment Study.\u201d Science Advances. doi: \n10.1126/sciadv.abj2610. \n\nStiglitz, Joseph. 2009. \u201cGlobal Crisis, Social Protection and Jobs, The.\u201d International Labour \nReview 148(1\u20132). \n\nStubbs, Thomas, Bernhard Reinsberg, Alexander Kentikelenis, and Lawrence King. 2018. \n\u201cHow to Evaluate the Effects of IMF Conditionality.\u201d The Review of International \nOrganizations. doi: 10.1007/s11558-018-9332-5. \n\nStuckler, David, and Sanjay Basu. 2013. The Body Economic: Why Austerity Kills\u202f: \nRecessions, Budget Battles, and the Politics of Life and Death. \n\nTeorell, Jan, Stefan Dahlberg, Holmberg S\u00f6ren, Rothstein Bo, Natalia Alvarado Pachon, and \nRichard Svensson. 2018. The Quality of Government Standard Dataset, Version \nJan18. University of Gothenburg. The Quality of Government Institute. \n\n\n\n22 \n \n\nUSAID. 2011. MEASURE DHS: Demographic and Health Surveys - Quality Information to \nPlan, Monitor, and Improve Population, Health, and Nutrition Programs. Calverton, \nUSA: U.S. Agency for International Development. \n\nVanderWeele, Tyler. 2015. Explanation in Causal Inference: Methods for Mediation and \nInteraction. Oxford, New York: Oxford University Press. \n\nVreeland, James Raymond. 2007. The International Monetary Fund: Politics of Conditional \nLending. New York, NY: Routledge, Taylor & Francis Group. \n\n \n\n6 Tables \n \nTable 1. Covariate balance stratified by IMF exposure status \n\n \nIMF = 0 IMF =1 \n\nn 985805 955929 \n\nChild age (mean (sd)) 8.27 (5.06) 8.08 (5.07) \n\nChild sex = Male (%) 501117 (50.8) 483457 (50.6) \n\nUrban household = rural (%) 613439 (62.2) 603594 (63.1) \n\nFamily wealth (%) \n \n\n1 256662 (26.0) 223967 (23.4) \n\n2 192713 (19.5) 192630 (20.2) \n\n3 187835 (19.1) 190872 (20.0) \n\n4 170723 (17.3) 173794 (18.2) \n\n5 177872 (18.0) 174666 (18.3) \n\nNr of children (mean (sd)) 3.77 (2.44) 4.04 (3.21) \n\nNr of adults (mean (sd)) 2.91 (1.87) 2.97 (2.42) \n\nHead of household education (%) \n\n   noEducation 314602 (31.9) 273742 (28.6) \n\n   Primary 360369 (36.6) 330722 (34.6) \n\n\n\n23 \n \n\n   SecondaryPlus 310834 (31.5) 351465 (36.8) \n\nYear of interview (mean (sd)) 2003.49 (3.68) 2003.35 (2.72) \n\nHealth spending (mean (sd)) 8.32 (5.61) 10.03 (3.51) \n\nDemocracy (mean (sd)) 5.12 (3.23) 5.89 (2.01) \n\nTrade (mean (sd)) 66.07 (39.99) 56.73 (27.38) \n\nExpenses balance (mean (sd)) -2.29 (6.31) -3.40 (2.79) \n\nEconomic develop (mean (sd)) 6.51 (0.86) 6.09 (0.85) \n\nWar (mean (sd)) 0.13 (0.80) 0.21 (0.90) \n\nDependency ratio (mean (sd)) 76.07 (11.95) 80.31 (12.89) \n\nNegative growth (mean (sd)) 6.99 (6.82) 5.04 (2.58) \n\nInflation (mean (sd)) 0.10 (0.29) 0.05 (0.22) \n\nEducation spending (mean (sd)) 12.80 (5.97) 15.15 (5.06) \n\nEconomic globalization (mean (sd)) 41.26 (13.59) 39.88 (13.12) \n\nGov. effectiveness (mean (sd)) -0.53 (0.60) -0.66 (0.36) \n\nPolitical terror (mean (sd)) 3.64 (0.91) 3.22 (0.97) \n\nCorruption (mean (sd)) -0.66 (0.47) -0.80 (0.46) \n\nChild labor law (mean (sd)) 0.51 (0.50) 0.62 (0.49) \n\nPublic spending (mean (sd)) 24.35 (8.44) 22.12 (8.22) \n\n \n\n  \n\n\n\n24 \n \n\n \nTable 2 Covariate balance stratified by IMF-education exposure status \n\n IMF-education = 0 IMF-education =1 \nn 939576 181460 \nEducation deprivation (mean (SD)) 0.14 (0.35) 0.16 (0.36) \nChild age (mean (SD)) 11.73 (3.11) 11.68 (3.11) \nChild sex = Male (%) 475713 (50.6) 91907 (50.6) \nUrban household = rural (%) 589826 (62.8) 104569 (57.6) \nFamily wealth (%)   \n   1 226930 (24.2) 42841 (23.6) \n   2 182837 (19.5) 35725 (19.7) \n   3 182537 (19.4) 35557 (19.6) \n   4 169102 (18.0) 32248 (17.8) \n   5 178170 (19.0) 35089 (19.3) \nNr of children (mean (SD)) 3.95 (2.86) 4.19 (2.70) \nNr of adults (mean (SD)) 3.00 (2.21) 2.88 (1.74) \nHead education (%)   \n   noEducation 276459 (29.4) 62645 (34.5) \n   Primary 338164 (36.0) 60226 (33.2) \n   SecondaryPlus 324953 (34.6) 58589 (32.3) \nYear of interview (mean (SD)) 2003.66 (3.36) 2002.83 (2.41) \nHealth spending (mean (SD)) 8.78 (4.67) 11.84 (3.80) \nDemocracy (mean (SD)) 5.72 (2.70) 5.40 (2.22) \nTrade (mean (SD)) 62.85 (35.37) 52.52 (31.85) \nExpenses balance (mean (SD)) -3.42 (4.73) -2.43 (1.92) \nEconomic develop (mean (SD)) 6.32 (0.88) 6.28 (0.93) \nWar (mean (SD)) 0.19 (0.90) 0.00 (0.00) \nDependency ratio (mean (SD)) 76.64 (12.64) 80.90 (12.02) \nNegative growth (mean (SD)) 5.21 (2.44) 5.83 (2.13) \nInflation (mean (SD)) 0.08 (0.27) 0.08 (0.27) \nPolitical will (mean (SD)) -0.14 (0.50) 0.15 (0.43) \nEducation spending (mean (SD)) 14.48 (5.50) 13.59 (3.38) \nEconomic globalization (mean (SD)) 41.13 (12.95) 41.53 (14.18) \nGov effectivness (mean (SD)) -0.54 (0.48) -0.59 (0.37) \nPolitical terror (mean (SD)) 3.39 (0.89) 3.48 (1.12) \nCorruption (mean (SD)) -0.72 (0.48) -0.65 (0.41) \nChild labor law (mean (SD)) 0.53 (0.50) 0.66 (0.47) \nPublic spending (mean (SD)) 23.54 (8.71) 21.84 (6.60) \nIMF program (mean (SD)) 0.41 (0.49) 0.93 (0.25) \nCountries with IMF (mean (SD)) 58.25 (8.27) 62.45 (6.79) \nUN vote G7 (mean (SD)) 0.62 (0.05) 0.62 (0.05) \nIMFeduc (mean (SD)) 0.00 (0.00) 1.00 (0.00) \n\n \n\n\n\n25 \n \n\n7 Figures \n \n\n \n\nFigure 1. Global distribution of child-education deprivation. Notes: we calculated country averages from the DHS and MICS \n\nmicro data for each of the 67 nations included in the sample. White colored countries are not included in the sample.  \n\n\n\n26 \n \n\n \nPanel a \n \n \n\n \nPanel b \n \nFigure 2: ATE for IMF-education policy \n\n \n \n\n\n\n27 \n \n\n \nFigure 3: ATE for IMF program by child age \n\n \n\n \nFigure 4: CATE distribution for all children (age 7-17) \n\n \n \n\n\n\n28 \n \n\n \nFigure 5: Group characteristics by quantile ATE for IMF program by child age \n\n \n\n8 Appendix \n\n8.1 Appendix A: Measures \n\nVariable Definition Source \n\nCountry-level \n\nvariables \n\n  \n\nHealth spending Measured as a share of GDP, and as a share of total \n\ngovernment expenditures.  \n\nIMF, 2011, and World \n\nDevelopment Indicators \n\nIMF program Dummy variable produced by the IMF: \u2018the starting year \n\nof an IMF-supported program [is defined] as the year in \n\nwhich the program was approved, provided this occurred \n\nin the first half of the year. If the approval date was in the \n\nsecond half of the year, the starting year is the following \n\nyear. The end year is the year in which the program \n\nIMF, 2011. \n\n\n\n29 \n \n\nexpired.\u2019 \n\nGDP per capita Gross domestic product per capita (constant 2000 USD) \u2013 \n\nlogged (to correct for the skewed distribution). \n\nWDI, Sep. 2012. \n\nGovernment \n\nbalance \n\nGeneral government balance (share of GDP). Calculated \n\nby subtracting general government expenditure from \n\ngeneral government revenue. \n\nAuthors\u2019 calculation using IMF-\n\nWEO data. \n\nHigh inflation Dummy variable: = 1 if year-to-year change in inflation \n\nover 20%, 0 otherwise.  \n\nAuthors\u2019 calculation using IMF-\n\nWEO data. \n\nDependency ratio Combined shares of populations aged 0-14 and 65 and \n\nabove. \n\nAuthors\u2019 calculations using \n\nWDI data. \n\nTrade Trade is the sum of exports and imports of goods and \n\nservices measured as a share of gross domestic product. \n\nWDI, Sep. 2012 \n\nDemocracy Democracy, Range: 0-10 (Freedom House/Imputed \n\nPolity). Average of Freedom House and Polity \n\n(transformed to a scale 0-10). Hadenius & Teorell (2005) \n\nshow that this average index performs better both in terms \n\nof validity and reliability than its constituent parts. \n\nQuality of Governance \n\nDatabase, 2011. \n\nNegative growth Dummy variable: = 1 if negative growth in a given year, 0 \n\notherwise.  \n\nAuthors\u2019 calculation using IMF-\n\nWEO data. \n\nODA Net ODA received (% of GNI). WDI, Sep. 2012 \n\nLow income country Dummy variable. Country is eligible for concessional \n\nlending from the IMF \n\nIMF, 2011 \n\nSub-Saharan Africa Dummy variable. Refers to countries located south of the \n\nSahara Desert.  \n\nWorld Development Indicators \n\nCivil war Magnitude score of episode(s) of civil warfare Center for Systemic Peace \n\n\n\n30 \n \n\nEducation \n\nexpenditure (% of \n\nGDP) \n\nPublic education spending as a percentage of GDP Clements, Gupta & Nozaki \n\n2011, What happens to social \n\nspending in IMF-Supported \n\nprograms?  \n\n \n\nEducation \n\nexpenditure (% of \n\ngov. spending) \n\nPublic education spending as a percentage of total \n\ngovernment spending \n\nClements, Gupta & Nozaki \n\n2011, What happens to social \n\nspending in IMF-Supported \n\nprograms? \n\nEconomic \n\nglobalization \n\nThe KOF Globalisation Index measures the economic, \n\nsocial and political dimensions of globalisation. \n\nEconomic globalization, Dreher \n\n2006, KOF Index of \n\nGlobalization (Version: March \n\n2016) \n\nGovernment \n\neffectiveness \n\n\u201cCombines into a single measure of the quality of public \n\nservice provision, the quality of the bureaucracy, the \n\ncompetence of civil servants, the independence of the civil \n\nservice from political pressures, and the credibility of the \n\ngovernment\u2019s commitment to policies. The index focus on \n\nthe \u201dinputs\u201d required for the government to be able to \n\nproduce and implement good policies and deliver public \n\ngoods\u201d. (Teorell et al. 2018) \n\nInterpolated, World Bank, \n\nWorldwide Governance \n\nIndicators  \n\nCorruption \u201cmeasures perceptions of corruption, defined as the \n\nexercise of public power for private gain. It measures \n\naspects of corruption ranging from the frequency of \n\n\u201dadditional payments to get things done\u201d, to the effects of \n\ncorruption on the business environment, to measuring \n\n\u201dgrand corruption\u201d in the political arena or in the tendency \n\nof elite forms to engage in \u201dstate capture\u201d. (Teorell et al. \n\n2018) \n\nInterpolated, World Bank, \n\nWorldwide Governance \n\nIndicators. \n\n\n\n31 \n \n\nPolitical terror Measures political terror on a scale 1 to 5, where 5 is the \n\nmost severe form of terror. This level is defined as, \n\n\u201cTerror has expanded to the whole population. The leaders \n\nof these societies place no limits on the means or \n\nthoroughness with which they pursue personal or \n\nideological goals\u201d (Teorell et al. 2018) \n\nPolitical terror scale (U.S. State \n\nDepartment), Gibney, Cornett & \n\nWood 2013, Political Terror \n\nScale.. \n\nMinimum age labor \n\nlaw \n\nDummy variable: = 1 a law in place regulating minimum \n\nrequired working age , 0 otherwise \n\nMinimum Age Convention, \n\n1973 (No. 138), International \n\nLabour Organization (ILO), \n\nInformation System on \n\nInternational Labour Standards \n\n(NORMLEX) (Retrieved 2014: \n\nhttp://www.ilo.org/normlex \n\nGovernment \n\nspending \n\nGovernment expenditure (Percent of GDP) IMF in Quality of Governance \n\nDatabase, 2011 \n\nFamily-level \n\nvariables \n\n  \n\nNr children Number of individuals under the age of 18 Demographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\nNr of Adults Number of individuals over the age of 18 Demographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\nEducation Ordinal variable (no education, primary, and secondary+). \n\nMeasures the head of household\u2019s level of education.  \n\nDemographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\nWealth index Ordinal variable (Quintiles). The index is a composite \n\nmeasure of the household\u2019s material standard. It is \n\ncalculated from selected assets such as ownership of \n\nDemographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey. (Rutstein 2008) \n\n\n\n32 \n \n\ntelevision, mobile phones, bicycles.  \n\nUrban rural Dummy variables. Captures the geographical location of \n\nhouseholds.  \n\nDemographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\nChild-level variables   \n\nSevere child health \n\ndeprivation \n\nDummy variable. Children under the age of 5 who had not \n\nbeen immunized against diseases or had a recent illness \n\ninvolving diarrhea and had not received any medical \n\nadvice or treatment two weeks prior to the survey \n\nDemographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey. (Gordon et al. \n\n2003:8) \n\nSex of the child Dummy variable.  Demographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\nAge Age of the child in number of years. Demographic and Health \n\nSurvey; Multiple Indicator \n\nCluster Survey \n\n \n\n \n\n8.2 Appendix B: Heckman Selection model \nGovernments select into IMF programs. This produces selection bias where countries that are \nrapidly getting poorer might be more likely to cooperate with the IMF. If so, increases in \npoverty would be correlated with IMF intervention, even if the intervention did not cause \nincreases in poverty. While observable variables affecting both selection into an IMF program \nand child poverty are already included as controls in our model, we cannot directly control for \nunobservable factors such as \u2018political will\u2019, as outlined in our DAG. \n \nFour approaches have been used in the IMF program evaluation literature to address this type \nof selection bias: matching methods; instrumental variable approaches; system GMM \nestimation; and Heckman selection models. For our purposes, Heckman\u2019s two-step method is \nthe most suitable choice to address concerns of selection bias as it produces a proxy for \nunobserved factors that we can include into our set of controls. The Heckman model involves \nfirst modelling IMF participation, and second modelling the outcome of interest using the \ninverse Mills ratio from the first step. Accordingly, in the first step, we estimate a probit \nmodel to predict the likelihood of IMF participation: \n\n \n\n\n\n33 \n \n\n \n \n\nAs a point of reference, we rely on a version of the specification suggested by the Independent \nEvaluation Office of the IMF (IEO 2003): one that retain the best data coverage but which \nstill gives analogous results. The outcome variable, \ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc56\ud835\udc53\ud835\udc53.\ud835\udc5d\ud835\udc5d\ud835\udc5d\ud835\udc5d\ud835\udc5d\ud835\udc5d\ud835\udc54\ud835\udc54. \ud835\udc50\ud835\udc50\ud835\udc54\ud835\udc54\ud835\udc50\ud835\udc50\ud835\udc56\ud835\udc56,\ud835\udc61\ud835\udc61, measures if country k \nhad an IMF program at year t. Our choice of which central mechanism affect selection into \nprograms, builds on Moser and Strum\u2019s suggestions (Moser and Sturm 2011): \n\n \n\u2022 Previous IMF participation (imf.prog.cgn, t-1): a country\u2019s past involvement with the \n\nIMF tend to positively determine future program participation. The nearer historically, \nthe more likely participation is. We use whether the country had a program last year.  \n\n\u2022 GDP growth (gdp.growth): Countries with lower growth are more likely to become \neconomically constrained, and ask for IMF credit.  \n\n\u2022 Current account balance (cab.gdp as share of GDP): One of the key objective of the \nIMF is to support countries to overcome balance of payment issues deriving from \ntrade. The higher the imbalance, the more likely the country is to ask for IMF help.  \n\n\u2022 Democracy (demo.fhpol): Autocratic regimes can with less political cost invite the \nIMF, compared to more democratic countries.  \n\n\u2022 Log GDP per capita (lngdppc): low income countries tend to seek concessional IMF \nassistance, whereas middle income countries with short term economic disturbances \n(e.g. currency crisis) tend to ask for non-concessional loans (e.g. Brazil, Argentina).  \n\n\u2022 Civil war (civilwar): Even if countries with a high degree of domestic civil conflict \nmight need more economic help, the IMF might avoid involvement during violent \nperiods. Also, the political cost to call for IMF assistance might be high.  \n\n\u2022 International war (int.war): Countries involved in armed conflicts between sovereign \nnations deters the IMF.  \n\n\u2022 UN votes with G7 (UN vote G7): this variable captures how often countries vote in \nline with G7. This shows political proximity with the key nations driving the IMF.   \n\n\u2022 Countries on IMF programs (CountriesWithIMF): In any given year, the more \ncountries that have IMF funding, the less likely the IMF is to issue new programs as \nits funds are limited.  \n \n\nThe total number of countries on IMF programmes and UN voting patterns with G7 act as our \nexclusion restrictions: these variable explain significantly the country\u2019s participation decision \nin IMF programs but are not correlated with the dependent variable of the outcome equation, \nin our case child poverty. Voting pattern has stronger relevance as it is significantly correlated \nin all alternative selection specifications. \n\n \nWe choose not to include government balance (lagged one year) as it reduced many \nobservations due to missing data. We would lose 6 countries reducing our data size by 10%. \nWe calculate the inverse Mills ratio and include it in the outcome equation to control for the \nremaining unobserved variation (Heckman 1979). The equation below defines the inverse \nMills ratio, \ud835\udf06\ud835\udf06, which isolates unobserved factors determining IMF participation: \n \n\n\n\n34 \n \n\n \n \nThe Mills ratio is calculated for each observation: country k at time point t, and depending on \ntheir treatment status \ud835\udc47\ud835\udc47\ud835\udc57\ud835\udc57 (present or absent IMF program). The function \ud835\udf19\ud835\udf19 denotes the standard \nnormal density function, and \u03a6 the standard normal cumulative distribution function; \ud835\udc4d\ud835\udc4d\ud835\udc56\ud835\udc56,\ud835\udc61\ud835\udc61 \nrepresents the covariates and \ud835\udefe\ud835\udefe\n\n^\n are the vector of estimated parameter from the first equation. \n\nThe inverse Mills ratio, \ud835\udf06\ud835\udf06, is then used as a covariate, in the outcome equation (in our case, \nthe multilevel models with child poverty as outcomes) controlling for self-selection. In a \nlinear model, its coefficient is interpreted as follows: if significantly negative, then \nunobserved variables that make IMF participation more likely are associated with lower \ngovernment health expenditure; if significantly positive, then unobserved variables that make \nIMF participation more likely are associated with higher government health expenditure; if \nnon-significant, then there is no association. \n \nAlternative selection specifications \n \n\n Dependent variable \nIMF program (t)     \n\n M1  M2 M3   \nIMF program (t-1) 1.910*** 1.959***  \n\n (0.064) (0.094)  \n    \n\nGDP growth (t-1) -0.018*** -0.042*** -0.026*** \n (0.006) (0.010) (0.009)     \n\nCurrent account balance (t-1) -0.007* -0.008 -0.008* \n (0.004) (0.005) (0.005)     \n\nDemocracy (t-1) 0.027** 0.033* 0.046*** \n (0.013) (0.019) (0.016)     \n\nLog GDP per capita (t-1) -0.256*** -0.253*** -0.336*** \n (0.034) (0.053) (0.054)     \n\nLog aid per capita (t-1)   0.004 \n   (0.004)     \n\nCivil war (t-1) -0.026 0.042 0.030 \n (0.035) (0.069) (0.054)     \n\nInternational war (t-1) 0.042 -0.213  \n (0.072) (0.156)  \n    \n\nDependency ratio (t-1)   -0.002 \n   (0.004)     \n\nCountries on IMF programs 0.011*** 0.006 0.001 \n (0.004) (0.005) (0.005)     \n\nUN voting pattern with G7 0.886** 1.041* 3.303*** \n\n\n\n35 \n \n\n (0.419) (0.546) (0.686)     \nConstant -0.570* -0.418 -0.130 \n\n (0.309) (0.478) (0.741)      \nObservations 2,482 1,264 1,066 \nLog Likelihood -1,000.302 -471.559 -631.869 \nAkaike Inf. Crit. 2,020.605 963.118 1,283.739  \nNote: probit models *p <0.1, **p<0.05,p***p<0.01 \n \n \n\n\n\t1 Introduction\n\t2 Method and data\n\t2.1 The outcome: child-education deprivation\n\t2.2 The exposures: IMF-education policies and IMF programs\n\t2.3 Method\n\t2.3.1 Identifying IMF-education policies in policy text\n\t2.3.2 Statistical analysis: estimating ATE and CATE\n\t2.3.3 Generalized random forest\n\t2.3.4 Handling selection bias\n\n\n\t3 Results\n\t3.1 Measuring IMF-education policy\n\t3.2 Evaluating the effect of IMF-education policies on children\u2019s chances of completing school\n\t3.3 Qualitative analysis of IMF-policy documents: the link between IMF programs and children\u2019s educational outcomes.\n\n\t4 Discussion\n\t5 References\n\t6 Tables\n\t7 Figures\n\t8 Appendix\n\t8.1 Appendix A: Measures\n\t8.2 Appendix B: Heckman Selection model\n\n\n"}
{"Title": "Exploiting Bi-directional Global Transition Patterns and Personal Preferences for Missing POI Category Identification", "Authors": "Dongbo Xi, Fuzhen Zhuang, Yanchi Liu, Hengshu Zhu, Pengpeng Zhao, Chang Tan, Qing He", "Abstract": "  Recent years have witnessed the increasing popularity of Location-based Social Network (LBSN) services, which provides unparalleled opportunities to build personalized Point-of-Interest (POI) recommender systems. Existing POI recommendation and location prediction tasks utilize past information for future recommendation or prediction from a single direction perspective, while the missing POI category identification task needs to utilize the check-in information both before and after the missing category. Therefore, a long-standing challenge is how to effectively identify the missing POI categories at any time in the real-world check-in data of mobile users. To this end, in this paper, we propose a novel neural network approach to identify the missing POI categories by integrating both bi-directional global non-personal transition patterns and personal preferences of users. Specifically, we delicately design an attention matching cell to model how well the check-in category information matches their non-personal transition patterns and personal preferences. Finally, we evaluate our model on two real-world datasets, which clearly validate its effectiveness compared with the state-of-the-art baselines. Furthermore, our model can be naturally extended to address next POI category recommendation and prediction tasks with competitive performance.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00014", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploiting Bi-directional Global Transition Patterns and Personal Preferences for\nMissing POI Category Identification\n\nDongbo Xia,c, Fuzhen Zhuangb,a,\u2217, Yanchi Liue, Hengshu Zhuf, Pengpeng Zhaog, Chang Tanh, Qing Hea,d\n\naKey Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS),\nInstitute of Computing Technology, CAS, Beijing 100190, China\n\nbXiamen Data Intelligence Academy of ICT, CAS, China\ncMeituan-Dianping Group, China\n\ndUniversity of Chinese Academy of Sciences, Beijing 100049, China\neManagement Science & Information Systems, Rutgers University, USA\n\nfBaidu Inc., Beijing, China\ngSoochow University, China\n\nhiFLYTEK, China\n\nAbstract\n\nRecent years have witnessed the increasing popularity of Location-based Social Network (LBSN) services, which\nprovides unparalleled opportunities to build personalized Point-of-Interest (POI) recommender systems. Existing\nPOI recommendation and location prediction tasks utilize past information for future recommendation or prediction\nfrom a single direction perspective, while the missing POI category identification task needs to utilize the check-in\ninformation both before and after the missing category. Therefore, a long-standing challenge is how to effectively\nidentify the missing POI categories at any time in the real-world check-in data of mobile users. To this end, in\nthis paper, we propose a novel neural network approach to identify the missing POI categories by integrating both bi-\ndirectional global non-personal transition patterns and personal preferences of users. Specifically, we delicately design\nan attention matching cell to model how well the check-in category information matches their non-personal transition\npatterns and personal preferences. Finally, we evaluate our model on two real-world datasets, which clearly validate\nits effectiveness compared with the state-of-the-art baselines. Furthermore, our model can be naturally extended to\naddress next POI category recommendation and prediction tasks with competitive performance.\n\nKeywords: Global Transition Patterns, Personal Preferences, Missing POI Category Identification\n\n1. Introduction\n\nThe rapid development and increasing popularity of\nLocation-based Social Network (LBSN) services en-\ncourage more and more users to share their real-life\nexperiences. Data collected by various LBSN services\nhave been effectively leveraged for studying users\u2019 on-\nline activities and mobility patterns, which provide un-\nparalleled opportunities to built personalized POI rec-\nommender systems. Generally, the user\u2019s historical vis-\niting records can be regarded as a set of check-ins that\neach one contains a POI, a timestamp, a POI category,\nand so on. Indeed, the category information is con-\n\n\u2217Corresponding author: Fuzhen Zhuang\nEmail addresses: xidongbo@meituan.com (Dongbo Xi),\n\nzhuangfuzhen@ict.ac.cn (Fuzhen Zhuang)\n\nducive to explaining users\u2019 activities and plays a crucial\nrole in various POI-oriented tasks.\n\nMost of the existing POI-oriented studies mainly fo-\ncus on recommending or predicting the category of POI\nwhere a user may go in the future or improve the per-\nformance of next POI recommendation. Recently, con-\nsiderable efforts have been made to address next POI\ncategory prediction (Zhang et al., 2017a), and utilize\nthe category information to solve POI recommendation\nand location prediction problems (Chen et al., 2015; He\net al., 2017; Ye et al., 2013). However, these methods\nutilize past information for future prediction or recom-\nmendation from a single direction perspective, while the\nmissing POI category identification task needs to utilize\nthe check-in information before and after the missing\ncategory, which naturally calls for a bi-directional so-\nlution. Therefore, a long-standing challenge is how to\n\nPreprint submitted to Neural Networks January 4, 2022\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n4v\n1 \n\n [\ncs\n\n.L\nG\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\n\n\neffectively identify the missing POI categories at any\ntime in the real-world check-in data of mobile users.\n\nAlong this line, we propose a novel Bi-directional\nGlobal Transition Patterns and Personal Preferences\nmodel named Bi-GTPPP for missing POI category iden-\ntification. The proposed model takes both non-personal\nand personal preferences into consideration. On the one\nhand, users\u2019 check-in activities usually have some pub-\nlic transition patterns, which are non-personal prefer-\nences. For example, users often go to dinner after work\nand watch a movie after dinner. The transition patterns\nwork \u2192 dinner, dinner \u2192 movie are global and non-\npersonal for all users. Our model is designed to capture\nbi-directional global transition patterns. On the other\nhand, different users have personal preferences that af-\nfect the check-in behaviors of users. These two pref-\nerences are integrated through a delicately designed at-\ntention matching cell between the output of LSTM net-\nwork (Hochreiter and Schmidhuber, 1997) and the pref-\nerences. With the bi-directional global transition pat-\nterns and users\u2019 personal preferences, the Bi-GTPPP\ncan yield more accurate missing POI category identi-\nfication.\n\nThe main contributions of this work are listed as fol-\nlows:\n\n\u2022 The proposed model can address the non-trivial\nmissing POI category identification task via uti-\nlizing bi-directional global transition patterns and\nusers\u2019 personal preferences, and existing next POI\ncategory prediction methods are not suitable for\nour task.\n\n\u2022 The existing next POI category prediction task can\nbe seen as a special case of the missing POI cate-\ngory identification task. The proposed model can\nbe easily extended to address the next POI category\nprediction task by only using forward sequence\ninformation, while the existing prediction models\ncan not address the identification task well.\n\n\u2022 Based on the experiments conducted on real-world\ndatasets, the proposed Bi-GTPPP model achieves\nsignificantly better performance compared with\nexisting various state-of-the-art baselines.\n\n2. Related Work\n\nIn POI-oriented studies, two important tasks are POI\nrecommendation and location prediction. In this sec-\ntion, we present the related work in threefold: general\n\nPOI recommendation and location prediction, category-\naware POI recommendation and location prediction,\nand neural network-based methods.\n\n2.1. General POI Recommendation and Location Pre-\ndiction\n\nFactoring Personalized Markov Chains and Local-\nized Regions (Cheng et al., 2013) takes users\u2019 move-\nment constraint into account via exploiting the person-\nalized Markov chain in the check-in sequence. Person-\nalized Ranking Metric Embedding (PRME) (Feng et al.,\n2015) integrates sequential information, individual pref-\nerence, and geographical influence to improve the rec-\nommendation performance. Graph-based Embedding\n(Xie et al., 2016) jointly captures the sequential effect,\ngeographical influence, temporal cyclic effect and se-\nmantic effect by embedding into low dimensional space.\nMore informations such as temporal effects (Gao et al.,\n2013), spatial-aware (Yin et al., 2017), behavior patterns\n(He et al., 2016), various contexts (Yang et al., 2017a)\nalso have been studied accordingly in POI recommen-\ndation and location prediction tasks.\n\n2.2. Category-aware POI Recommendation and Loca-\ntion Prediction\n\nReal-life POI-oriented tasks usually suffer from huge\nsearch space, which is because the number of POIs is\nlarge and needs a lot of computational costs, while the\nPOI category can help filter candidate POIs and thus re-\nduce the search space for efficiency and improve the rec-\nommendation performance. Context-Aware POI Cat-\negory Prediction (Zhang et al., 2017a) emphasizes the\nsignificance of category information in large-scale POI\nrecommendation. More and more efforts have been\nmade to utilize the category information. Ye et al. (Ye\net al., 2013) proposed a framework which exploits re-\ngion categories to predict the most likely location of\nusers given their previous activities. Liu et al. (Liu et al.,\n2013) employed matrix factorization to predict a user\u2019s\npreference on locations in the corresponding categories.\nA new POI recommendation problem, namely top-K lo-\ncation category based POI recommendation (Chen et al.,\n2015), has been formulated considering that users are\nmore interested in tasting a wide range of location cat-\negories. Listwise Bayesian Personalized Ranking ap-\nproach (He et al., 2017) has been proposed to predict the\ncategory ranking to filter candidate POIs. Category in-\nformation has also been considered in (Zhou and Wang,\n2014) and extended to more applications (Xiao et al.,\n2010; Rodrigues et al., 2012).\n\n2\n\n\n\n2.3. Neural Network for POI Recommendation and Lo-\ncation Prediction\n\nNeural networks have been used in the field of POI\nrecommendation and location prediction (Liu et al.,\n2016; Wang et al., 2017; Yin et al., 2017). For exam-\nples, a method called Spatial Temporal Recurrent Neu-\nral Networks (STRNN) (Liu et al., 2016) was proposed\nto model temporal and spatial contexts in each layer.\nHeterogeneous features and spatial-aware personal pref-\nerences were utilized by Spatial-Aware Hierarchical\nCollaborative Deep Learning model (Yin et al., 2017).\nSome LSTM-based approaches (Zhu et al., 2017; Zhao\net al., 2018) try to capture short-term and long-term\ncharacteristics via specifically designed gates. User\npreference over POIs and context associated with users\nand POIs were predicted simultaneously in PACE (Pref-\nerence And Context Embedding) (Yang et al., 2017a).\nMore neural network-based approaches (Wang et al.,\n2017; Zhang et al., 2017b; Yang et al., 2017b) have also\nbeen adopted to address POI recommendation and lo-\ncation prediction. However, the above methods are not\nspecially designed for missing POI category identifica-\ntion and these efforts fail to capture both bi-directional\nglobal transition patterns and users\u2019 personalized pref-\nerences for missing POI category identification. So they\ncan not address the identification task well.\n\nBesides, the most relevant task to missing POI cate-\ngory identification is the missing POI check-in identifi-\ncation. The work (Xi et al., 2019) is the first to address\nthe missing POI check-in identification by modelling\nof bi-directional spatio-temporal dependence and users\u2019\ndynamic preferences (Bi-STDDP). However, the miss-\ning POI category check-ins identification is different\nfrom the missing POI check-in identification in many\nways. Therefore, the model is not suitable for missing\nPOI category check-ins identification task.\n\n3. Methodology\n\nIn this section, we first formulate the problem of\nmissing POI category identification, and then present\nthe details of the proposed Bi-GTPPP model, which\ncontains three parts of attention matching cell, bi-\ndirectional global transition patterns, and personal pref-\nerences.\n\n3.1. Problem Statement\n\nLet U = {u1, u2, ..., uN} is a set of N users and\nC = {c1, c2, ..., cM} is a set of M POI categories. Each\nsample is associated with a category check-ins list of\n\nuser u Cu = {cu\n1, c\n\nu\n2, ..., c\n\nu\nL}, where cu\n\nl means user u\u2019s l-\nth check-in category is cu\n\nl . Assume the l-th check-in\ncategory cu\n\nl of user u is missing, the task is to identify\nwhich POI category the user u visited according to the\nforward sequence {cu\n\n1, c\nu\n2, ..., c\n\nu\nl\u22121} and the backward se-\n\nquence {cu\nl+1, c\n\nu\nl+2, ..., c\n\nu\nL}.\n\n3.2. Attention Matching cell\nFirstly, we formalize a delicately designed attention\n\nmatching cell which is adopted in our model to weight\ndifferent preference features:\n\ncell(a, b) = (1 \u2212 s) \u00d7 a + s \u00d7 b, (1)\ns = 0.5 + 0.5 \u00d7 cos(a, b) (2)\n\n= 0.5 + 0.5 \u00d7\na>b\n\u2016a\u2016\u2016b\u2016\n\n, (3)\n\nwhere a is the feature extracted based on the existing\ndata (e.g., check-in categories sequence) by LSTM net-\nwork, b expresses the preferences which are global tran-\nsition patterns or personal preferences in our model, and\na and b are in the same space RM . The weight s is the\nnormalized cosine similarity between a and b, and in-\ndicates how much a matches b. If feature a matches\npreference b well, then preference b should have a big-\nger weight s, otherwise the feature a should be retained\nmore. Note that cell(a, b) is not equal to cell(b, a).\n\n3.3. Bi-directional Global Transition Patterns\nIn this subsection, we first extract features from\n\nusers\u2019 check-in categories sequence, and then integrate\nglobal transition patterns.\n\nFirstly, we capture POI category information with\nembedding layer. The embedding layer can be seen as\nperforming the latent factor modeling for category pop-\nularity. It learns one matrix Ec, each row of which rep-\nresents a POI category. If we use one-hot encoded cat-\negory cu\n\nl\u2212k, cu\nl+k \u2208 RM as input vectors, the outputs of\n\nembedding layer can be expressed as\n\ne(cu\nl\u2212k) = E>c cu\n\nl\u2212k, (4)\ne(cu\n\nl+k) = E>c cu\nl+k, (5)\n\nwhere 1 \u2264 k \u2264 w, and w is the window width, Ec \u2208\n\nRM\u00d7d denotes the embedding matrix for categories, d is\nthe dimension of embedding vectors.\n\nLSTM (Hochreiter and Schmidhuber, 1997) is capa-\nble of learning short and long-term dependencies and\nhas become an effective and scalable model for sequen-\ntial prediction problems, we use the basic LSTM to cap-\nture user\u2019s forward and backward check-in information:\n\nlu\nl\u22121 = LS T M(e(cu\n\nl\u2212w:l\u22121)), (6)\nlu\nl+1 = LS T M(e(cu\n\nl+w:l+1)), (7)\n\n3\n\n\n\nwhere e(cu\nl\u2212w:l\u22121) and e(cu\n\nl+w:l+1) are the embedded for-\nward and backward check-in sequences respectively,\nlu\nl\u22121 \u2208 Rh and lu\n\nl+1 \u2208 Rh are the bi-directional features\nextracted from users\u2019 check-in categories sequence by\nLSTM and h is the dimension of the LSTM output\nspace.\n\nNext, we add a hidden layer to transform the output of\nLSTM network to another space for applying attention\nmatching cell:\n\nhu\nl\u22121 = f (W f lu\n\nl\u22121), (8)\nhu\n\nl+1 = f (Wb lu\nl+1), (9)\n\nwhere W f \u2208 RM\u00d7h and Wb \u2208 RM\u00d7h are the parameters\nof transformation matrices.\n\nThen, user\u2019s check-in activities usually have some\npublic transition patterns, for example, users often go to\ndinner after work and watch a movie after dinner. The\ntransition patterns work \u2192 dinner, dinner \u2192 movie are\nglobal for all users. Our Bi-GTPPP model is designed to\ncapture the global transition patterns from bi-direction.\nFor the missing category cu\n\nl , we need to capture the most\nrelevant forward global transition patterns cu\n\nl\u22121 \u2192 cu\nl\n\nand backward cu\nl+1 \u2192 cu\n\nl :\n\ngl\u22121 = f (E>f cu\nl\u22121), (10)\n\ngl+1 = f (E>b cu\nl+1), (11)\n\nwhere E f \u2208 RM\u00d7M and Eb \u2208 RM\u00d7M denote the for-\nward transition embedding matrix and backward transi-\ntion embedding matrix respectively, the activation func-\ntion f (x) is chosen as a tanh function f (x) = ex\u2212e\u2212x\n\nex+e\u2212x . The\noutput gl\u22121 \u2208 RM can be normalized and expresses the\ntransition distribution from category cu\n\nl\u22121 to all candi-\ndate categories, and gl+1 \u2208 RM is the same. However,\nwe don\u2019t do the normalization considering the expres-\nsive power.\n\nNow, we can apply the delicately designed attention\nmatching cell in Equation (1) to model how well the\nuser\u2019s bi-directional check-in information matches the\nglobal transition patterns:\n\nmu\nl\u22121 = cell(hu\n\nl\u22121, gl\u22121), (12)\nmu\n\nl+1 = cell(hu\nl+1, gl+1), (13)\n\nmu\nl = mu\n\nl\u22121 + mu\nl+1. (14)\n\nThe attention matching cell interpolates hu\nl\u22121 and gl\u22121,\n\nhu\nl+1 and gl+1 respectively, and indicates how much hu\n\nl\u22121\nmatches gl\u22121 or hu\n\nl+1 matches gl+1. If user u\u2019s forward\ncheck-in information hu\n\nl\u22121 matches forward preference\ngl\u22121 well, then forward preference gl\u22121 should have a\nbigger weight, otherwise the feature hu\n\nl\u22121 should be re-\ntained more, and cell(hu\n\nl+1, gl+1) is also the same. Fi-\n\nnally, the bi-directional informations are added to cap-\nture the bi-directional global transition patterns mu\n\nl .\n\n3.4. Personal Preferences and the Final Bi-GTPPP\nModel\n\nDifferent users have personal preferences which\nmuch affect the check-in behaviors of users. For exam-\nple, most users usually watch a movie after dinner, but\nsome users have a dinner after the movie. If we iden-\ntify the missing category of the personalized users as\nthe global transition pattern dinner \u2192 movie, the model\nwill have an erroneous identification. So here we need\nto capture users\u2019 personal preferences. If we use one-hot\nencoded user u \u2208 RN as input vectors, then the personal\npreference of user u can be expressed as:\n\npu = f (E>p u), (15)\n\nwhere Ep \u2208 RN\u00d7M , each row of which represents a\nuser\u2019s personal preferences for M categories. And the\nwhole embedding matrix Ep can be seen as performing\nthe latent factor modeling for all users\u2019 personal cate-\ngory preferences. We can initialize the matrix Ep via\ncounting users\u2019 visiting history on all training data and\nfine-tune during model training.\n\nThen, the same structure attention matching cell can\nbe adopted to model how well the user\u2019s recent bi-\ndirectional check-in information and global transition\npatterns match his or her personal preferences:\n\nnu\nl = cell(mu\n\nl , pu). (16)\n\nFinally, the prediction of the l-th category the user u\nhas been can be computed as:\n\nou\nl = so f tmax(Wonu\n\nl ), (17)\n\nwhere Wo \u2208 RM\u00d7M are the parameters in the softmax\nlayer. The ou\n\nl is a distribution which indicates differ-\nent probability of all possible candidate categories the\nuser u might visit l-th. And the categories correspond-\ning to the k maximum probabilities are the top-k identi-\nfications for the missing category.\n\nWe present the final neural network architecture of\nBi-GTPPP in Figure 1. First, bi-directional category\nsequence features are captured by two basic LSTM\nnetwork, and then the inputs of categories and user\nare fed into embedding layer to capture bi-directional\nglobal transition patterns and personal preferences in\nEquations (10), (11) and (15) respectively. Moreover,\nthree same structure attention matching cells model how\nwell the user\u2019s bi-directional category sequence fea-\ntures match the global transition patterns and how well\n\n4\n\n\n\nSoftmax Layer\n\nPersonalized \n\nPreferences\n\nUser u\n\nForward \n\nTransition Patterns\n\nc(l-1)\n\nBackward \n\nTransition Patterns\n\nc(l+1)\n\nCategory \n\nEmbedding\n\nLSTM LSTM\n\nc(l+w:l+1)c(l-w:l-1)\n\nHidden Layer Hidden Layer\n\nMatching Cell Matching Cell\n\nMatching Cell\n\nBi-GTPPP \n\nOutput\n\nEmbedding\n\nAttention \n\nMatching \n\nInput\n\nSequence \n\nFeatures\n\nSum\n\nFigure 1: The proposed Bi-GTPPP model\n\nthe user\u2019s recent bi-directional check-in information and\nglobal transition patterns match his or her personal pref-\nerences in Equations (14) and (16) respectively. Finally,\nthe softmax layer makes the identification for the miss-\ning l-th category.\n\nWe need to minimize the cross entropy of predicted\ndistribution and the actual distribution:\n\nJ(\u03b8) = \u2212\n1\nS\n\nS\u2211\ni=1\n\nM\u2211\nj=1\n\nyi, j log(ou\nl, j|xi, \u03b8), (18)\n\nwhere S is the number of samples, M is the number of\ncategories, yi \u2208 RM is the one-hot label of sample xi and\n\u03b8 is the parameters set.\n\nThe training is performed in an end-to-end manner\nand the Equation (18) is used to train globally the whole\narchitecture. Training is done through stochastic gradi-\nent descent over shuffled mini-batches with the Adam\n(Kingma and Ba, 2014) update rule.\n\n4. Experiments\n\nIn this section, we perform experiments to evaluate\nthe proposed Bi-GTPPP model against various baseline\nmethods on two real-world LBSNs datasets. We first in-\ntroduce the datasets, baseline methods, implementation\ndetails and evaluation metrics of our experiments. Fi-\nnally, we present our experimental results and analysis.\n\n4.1. Datasets\n\nThe statistics of the two public LBSNs datasets are\nlisted in Table 1.\n\nTable 1: Statistics of the two datasets.\nDataset #user #POI #category #check in #Avg.check-in\n\nNYC 1,083 38333 251 227,428 210.0\nTKY 2,293 61858 247 573,703 250.2\n\n\u2022 NYC1 (Yang et al., 2015) is a dataset from\nFoursquare, which includes long-term (about 10\nmonths) check-in data in New York city collected\nfrom April 2012 to February 2013.\n\n\u2022 TKY1 (Yang et al., 2015) is a dataset similar to\nNYC except from Tokyo.\n\nWe eliminate users with fewer than 10 check-ins in\nthese two datasets. Then, we sort each user\u2019s check-\nin records according to timestamp order, taking the first\n80% as training set, the following 10% for the validation\nset and the remaining 10% for the test set. The users\u2019\nhistory category information is intentionally removed as\nground truth for testing the identification performance,\nthis is consistent for all experiments for fair comparison.\n\n4.2. Baselines\n\nWe compare the proposed method with counting\nbased methods (Forward, Backward, TOP1, TOP2),\ntraditional POI recommendation algorithms (PRME,\nPRME-G), neural network-based approaches (RNN,\nLSTM, GRU, STRNN, PACE, Bi-STDDP). Some ear-\nlier methods likes PMF (Salakhutdinov and Mnih,\n2007), FPMC (Rendle et al., 2010), FPMC-LR (Cheng\net al., 2013) have been proved to be not as good as\n\n1https://sites.google.com/site/yangdingqi/home/foursquare-\ndataset\n\n5\n\n\n\nPRME-G (Feng et al., 2015; Liu et al., 2016; He et al.,\n2017), so we don\u2019t compare them with our model.\n\n\u2022 Forward: The forward transition probability be-\ntween categories is taken as the prediction for all\nusers.\n\n\u2022 Backward: The backward transition probability\nbetween categories is taken as the prediction for\nall users.\n\n\u2022 TOP1: The most popular categories in the training\nset are selected as the prediction for all users.\n\n\u2022 TOP2: The most popular categories in the training\nset are selected as the prediction for each user.\n\n\u2022 PRME(Feng et al., 2015): User and POIs are em-\nbedded into the same latent space to capture the\nuser transition patterns.\n\n\u2022 PRME-G(Feng et al., 2015): It takes the distance\nbetween destination POIs and recent visited ones\ninto consideration on the basis of PRME.\n\n\u2022 RNN(Zhang et al., 2014): This is a neural network\nmethod which directly models the dependency on\nuser\u2019s sequential behaviors into the click prediction\nprocess through the recurrent structure in RNN.\n\n\u2022 LSTM(Hochreiter and Schmidhuber, 1997): This\nis a special RNN model, which contains a mem-\nory cell and three multiplicative gates to learn long-\nterm dependency.\n\n\u2022 GRU(Cho et al., 2014): This is another special\nRNN model, which contains two gates and is sim-\npler than LSTM.\n\n\u2022 STRNN(Liu et al., 2016): This is a RNN-based\nmodel for next POI recommendation. It incorpo-\nrates both the time-specific transition matrices and\ndistance-specific transition matrices within recur-\nrent architecture.\n\n\u2022 PACE(Yang et al., 2017a): This is a deep neural\narchitecture that jointly learns the embeddings of\nusers and POIs to predict both user preference over\nPOIs and various context associated with users and\nPOIs.\n\n\u2022 Bi-STDDP(Xi et al., 2019): This is the state-of-\nthe-art missing POI check-in identification model\nwhich captures bi-directional spatio-temporal de-\npendence and users\u2019 dynamic preferences.\n\n4.3. Implementation Details\nFor all datasets we use: embedding dimension d of\n\n128, LSTM output space h of 512, window width w of\n18, mini-batch size of 128 and learning rate of 0.001.\nAll these values are chosen via a grid search on the NYC\nvalidation set. The parameters of Ep are initialized via\ncounting users\u2019 visiting history on training data, and all\nother parameters in the neural network are initialized\nfrom glorot uniform distributions (Glorot and Bengio,\n2010). We do not perform any datasets-specific tuning\nexcept early stopping on validation sets.\n\n4.4. Evaluation Metrics\nTo evaluate the performance of our proposed Bi-\n\nGTPPP model and the baselines described above, we\nfollow the existing works (Liu et al., 2016) to use several\nstandard metrics: Recall@K, F1-score@K and Mean\nAverage Precision (MAP). Recall@K is 1 if the cate-\ngory visited appears in the top-K ranked list; otherwise\nis 0. The final Recall@K is the average value over all\ntest ground truth instances. MAP is a global evaluation\nfor ranking tasks, and it is usually used to evaluate the\nquality of the whole ranked lists. We report Recall@K\nand F1-score@K with K = 1, 5 and 10 in our experi-\nments. The larger the value, the better the performance\nfor all the evaluation metrics. All the metrics reported\nin the experiment are the mean over five runs.\n\n4.5. Performance Comparison and Discussion\nWe present the experimental results evaluated by Re-\n\ncall@K and MAP on NYC and TKY datasets in Table\n2. Besides, we also present the scatter and box plots\nof different methods in term of MAP over five runs in\nFigure 2 and Figure 3. From these results, we have the\nfollowing insightful observations,\n\n- The counting-based methods Forward and Back-\nward have acceptable performances on all two\ndatasets. Similarly, counting-based personalized\nTOP2 also has a good performance on NYC and\nTKY, and these results are even better than PRME\nand PRME-G. This makes sense that users\u2019 behav-\nior patterns are usually regular and follow the long-\ntailed distribution. While the non-personalized\nTOP1 performs differently on two datasets, this\nseems to show that the users\u2019 preferences in Tokyo\nare more consistent than those in New York City.\n\n- PRME-G slightly improves the results comparing\nwith PRME via incorporating distance informa-\ntion. And RNN-based methods (RNN, LSTM,\nGRU) obtain similar performance improvement\n\n6\n\n\n\nTable 2: Evaluation of missing category identification in terms of Recall@K, F1-score@K and MAP. Bi-GTPPP-rand means that our model\nparameters Ep are initialized from glorot uniform distributions, and Bi-GTPPP-nonstatic means that parameters Ep are initialized via counting\nusers\u2019 visiting history on training data and fine-tune during training. Underlined results indicate the best baselines over each dataset and metric.\n\u201c*\u201d indicates that the improvement is statistically significant compared with the best baselines at p-value < 0.05 over independent samples t-tests.\n\nRecall@1 Recall@5 Recall@10 F1-score@1 F1-score@5 F1-score@10 MAP\n\nNYC\n\nForward 0.1576 0.3593 0.4877 0.1576 0.1198 0.0887 0.2636\nBackward 0.1566 0.3505 0.4868 0.1566 0.1168 0.0885 0.2601\n\nTOP1 0.0594 0.2888 0.4127 0.0594 0.0963 0.0750 0.1756\nTOP2 0.1688 0.3842 0.5017 0.1688 0.1281 0.0912 0.3009\n\nPRME 0.1039 0.3249 0.4442 0.1039 0.1083 0.0808 0.2163\nPRME-G 0.1180 0.3532 0.4818 0.1180 0.1177 0.0876 0.2334\n\nRNN 0.1873 0.4954 0.6164 0.1873 0.1651 0.1121 0.3292\nLSTM 0.2095 0.5191 0.6504 0.2095 0.1730 0.1183 0.3555\nGRU 0.2162 0.5234 0.6493 0.2162 0.1745 0.1181 0.3596\n\nSTRNN 0.2331 0.5408 0.6689 0.2331 0.1803 0.1216 0.3787\nPACE 0.2330 0.5401 0.6675 0.2330 0.1800 0.1214 0.3769\n\nBi-STDDP 0.2345 0.5409 0.6677 0.2345 0.1803 0.1214 0.3796\n\nBi-GTPPP-rand 0.2425 0.5591 0.6702 0.2425 0.1864 0.1219 0.3898\nBi-GTPPP-nonstatic 0.2580* 0.5745* 0.6922* 0.2580* 0.1915* 0.1259* 0.4030*\n\nTKY\n\nForward 0.3920 0.5950 0.6899 0.3920 0.1983 0.1254 0.4962\nBackward 0.3924 0.5973 0.6919 0.3924 0.1991 0.1258 0.4965\n\nTOP1 0.3806 0.5376 0.6385 0.3806 0.1792 0.1161 0.4694\nTOP2 0.3967 0.6225 0.7013 0.3967 0.2075 0.1275 0.5109\n\nPRME 0.3612 0.5265 0.6128 0.3612 0.1755 0.1114 0.4512\nPRME-G 0.3638 0.5358 0.6204 0.3638 0.1786 0.1128 0.4558\n\nRNN 0.4051 0.6773 0.7808 0.4051 0.2258 0.1420 0.5298\nLSTM 0.4203 0.6956 0.7930 0.4203 0.2319 0.1442 0.5458\nGRU 0.4189 0.6929 0.7912 0.4189 0.2310 0.1439 0.5445\n\nSTRNN 0.4325 0.7071 0.8036 0.4325 0.2357 0.1461 0.5576\nPACE 0.4251 0.6930 0.8033 0.4251 0.2310 0.1461 0.5568\n\nBi-STDDP 0.4283 0.7065 0.8022 0.4283 0.2355 0.1459 0.5571\n\nBi-GTPPP-rand 0.4412 0.7088 0.8069 0.4412 0.2363 0.1467 0.5652\nBi-GTPPP-nonstatic 0.4454* 0.7211* 0.8146* 0.4454* 0.2404 0.1481 0.5721*\n\nover PRME-G because of their sequence modeling\ncapability.\n\n- PACE predicts user preference over POIs, user\ncontext and POI context together to achieve further\nimprovement over RNN-based methods. Another\ngreat improvement is achieved by STRNN. It in-\ncorporates both the time-specific transition matri-\nces and distance-specific transition matrices within\nrecurrent architecture in each layer. Bi-STDDP\nachieves similar performance improvement over\nSTRNN via incorporating both the bi-directional\nspatio-temporal dependence and users\u2019 dynamic\npreferences, and they are the best methods among\nthe baselines on the two datasets. However, the\nmissing POI category check-ins identification is a\nlittle different from the missing POI check-in iden-\n\ntification. POI check-ins are more dependent on\nspatio-temporal information (e.g., it is impossible\nthat two POI check-ins of the same user are far\napart in space distance, but the time interval is very\nshort.), but POI category check-ins do not have the\nobvious spatio-temporal dependence due to POIs\nat different distances may belong to the same cat-\negory. Therefore, the Bi-STDDP can not address\nthe missing POI category identification well.\n\n- Bi-GTPPP-rand outperforms the baseline methods\nover all evaluation metrics on all two datasets. And\nBi-GTPPP-nonstatic further improves the perfor-\nmance via utilizing priori information and fine-\ntuning during training. On NYC dataset, the\nperformance improvement of Bi-GTPPP-nonstatic\non Recall@1, Recall@5, Recall@10 comparing\n\n7\n\n\n\nForward\n\nBackward\n\nTOP1\nTOP2\n\nPRME\nPRME-G\n\nRNN\nLSTM\n\nGRU\nSTRNN\n\nPACE\nBi-STDDP\n\nBi-GTPPP-rand\n\nBi-GTPPP-nonstatic\nFPR\n\n0.15\n\n0.20\n\n0.25\n\n0.30\n\n0.35\n\n0.40\n\nM\nA\n\nP\n\nNYC\n\nForward\n\nBackward\n\nTOP1\nTOP2\n\nPRME\nPRME-G\n\nRNN\nLSTM\n\nGRU\nSTRNN\n\nPACE\nBi-STDDP\n\nBi-GTPPP-rand\n\nBi-GTPPP-nonstatic\nFPR\n\n0.44\n\n0.46\n\n0.48\n\n0.50\n\n0.52\n\n0.54\n\n0.56\n\n0.58\n\nM\nA\n\nP\n\nTKY\n\nFigure 2: The scatter plot of different methods in term of MAP over five runs.\n\nwith Bi-GTPPP-rand are 6.39%, 2.75%, 3.28% re-\nspectively, and comparing with best baseline Bi-\nSTDDP are 10.02%, 6.21% and 3.67% respec-\ntively which indicates that the Bi-GTPPP-nonstatic\nimproves even more on the higher ranking list.\nSimilar results can also be observed on TKY\ndataset. Besides, the baseline Bi-STDDP is de-\nsigned for missing POI identification and captures\nbi-directional spatio-temporal dependence, which\nis unsuitable for the missing POI category identi-\nfication task. Because POIs in different locations\nmay belong to the same category, which results\nin the spatio-temporal dependence is poor in miss-\ning POI category identification task. As aforesaid,\nPOI-oriented tasks usually suffer from huge search\nspace due to the large amount of POIs, while the\nPOI category can help filter candidate POIs and\nthus reduce the search space for efficiency. For\nthe TKY dataset, the numbers of the POIs and cat-\negories are 61858 and 247, respectively, and one\ncategory corresponds to 250 POIs on average. If\nwe adopt the top 10 categories, the recall@10 is\n0.8146 and we can reduce the candidate POIs from\n\nTable 3: Impact of forward and backward sequences on NYC dataset\nevaluated by Recall@K and MAP.\n\nRecall@1 Recall@5 Recall@10 MAP\n\nF-GTPPP 0.2394 0.5584 0.6787 0.3866\nB-GTPPP 0.2403 0.5590 0.6785 0.3869\nBi-GTPPP 0.2580 0.5745 0.6922 0.4030\n\n61858 to 10 \u00d7 250 = 2500, which is a 25 times\nreduction.\n\nOverall, these improvements indicate the fact that the\nbaseline methods fail to capture both global transition\npatterns and users\u2019 personal preferences, while our pro-\nposed Bi-GTPPP can do this.\n\n4.6. Impact of Different Parts\n\nIn this subsection, we investigate the influence of\nthe forward and backward sequences in our Bi-GTPPP\nmodel. An intuitive feeling is that bi-directional se-\nquences can bring more useful additional informa-\ntion and should have a better performance than sin-\ngle sequence. The results shown in Table 3 confirm\n\n8\n\n\n\nForward\n\nBackward\n\nTOP1\nTOP2\n\nPRME\nPRME-G\n\nRNN\nLSTM\n\nGRU\nSTRNN\n\nPACE\nBi-STDDP\n\nBi-GTPPP-rand\n\nBi-GTPPP-nonstatic\n\n0.15\n\n0.20\n\n0.25\n\n0.30\n\n0.35\n\n0.40\n\nM\nA\n\nP\n\nNYC\n\nForward\n\nBackward\n\nTOP1\nTOP2\n\nPRME\nPRME-G\n\nRNN\nLSTM\n\nGRU\nSTRNN\n\nPACE\nBi-STDDP\n\nBi-GTPPP-rand\n\nBi-GTPPP-nonstatic\n\n0.44\n\n0.46\n\n0.48\n\n0.50\n\n0.52\n\n0.54\n\n0.56\n\n0.58\n\nM\nA\n\nP\n\nTKY\n\nFigure 3: The box plot of different methods in term of MAP over five runs.\n\n1 5 10\nK\n\n0.00\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\n0.25\n\nRe\nca\n\nll@\nK\n\nInitialization\nFine-tuned\n\n(a) Fine-tuned Forward Transition Patterns\n\n1 5 10\nK\n\n0.00\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\n0.25\n\nRe\nca\n\nll@\nK\n\nInitialization\nFine-tuned\n\n(b) Fine-tuned Backward Transition Patterns\n\n1 5 10\nK\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\nRe\nca\n\nll@\nK\n\nInitialization\nFine-tuned\n\n(c) Fine-tuned Personal Preference\n\nFigure 4: Performance of fine-tuned bi-directional global transition patterns and personal preference on NYC dataset evaluated by Recall@K.\n\nthis. The Bi-GTPPP achieves further improvement by\nutilizing bi-directional sequences comparing with F-\nGTPPP and B-GTPPP which only utilize forward or\nbackward information respectively. It must be noted\nthat, although with the single sequence, our proposed\nmodel still achieves substantial performance improve-\nment over various kinds of state-of-the-art methods.\nBased on this fact, we can say that our Bi-GTPPP can be\nnaturally extended to address next POI category recom-\n\nmendation and prediction tasks with competitive perfor-\nmance.\n\nNext, we show that our Bi-GTPPP model can cap-\nture bi-directional global transition patterns and user\u2019s\npersonal preferences. The E f , Eb and Ep denote the\nforward transition embedding matrix, backward transi-\ntion embedding matrix and user\u2019s personal preferences\nrespectively which can be used directly for missing POI\ncategory identification. The Recall@K performance of\n\n9\n\n\n\n0 128 200 300 400 500\nEmbedding Dimension\n\n0.380\n\n0.385\n\n0.390\n\n0.395\n\n0.400\n\nM\nAP\n\n(a) Impact of Embedding Dimension d\n\n0 200 512 800 1100 1400\nLSTM Output Space\n\n0.375\n\n0.380\n\n0.385\n\n0.390\n\n0.395\n\n0.400\n\nM\nAP\n\n(b) Impact of LSTM Output Space h\n\n0 2 4 6 8 10 12 14 16 18 20\nWindow Width\n\n0.380\n\n0.385\n\n0.390\n\n0.395\n\n0.400\n\nM\nAP\n\n(c) Impact of Window Width w\n\nFigure 5: Performance of Bi-GTPPP with varying embedding dimension, LSTM output space and window width on NYC dataset evaluated by\nMAP.\n\ninitialization and fine-tuned E f , Eb and Ep is shown in\nFigure 4. We observe that fine-tuned E f and Eb in Fig-\nure 4(a) and 4(b) greatly improve the identification per-\nformance comparing with random initialized. And fine-\ntuned Ep in Figure 4(c) also performs better than initial-\nization which counts users\u2019 visiting history. It turns out\nthat bi-directional global transition patterns and user\u2019s\npersonalized preferences can be captured in our novel\nmodel.\n\nBesides, we can obviously see that Ep obtains more\ngain than E f and Eb. It is intuitive that user\u2019s per-\nsonal preferences should play a more important role\nin the model than the bi-directional transition patterns.\nBecause user\u2019s personal preference (Ep) captures per-\nsonal preferences for each user while the bi-directional\ntransition patterns (E f and Eb) are global and non-\npersonalized for all users, and personalized identifica-\ntion can obtain more performance improvement.\n\n4.7. Impact of Parameters\n\nTuning model parameters is critical to the perfor-\nmance of the proposed model, such as the embedding\ndimension d, LSTM output space h and window width\nw in our Bi-GTPPP model. Figure 5(a), 5(b) and 5(c)\nshow the results under different settings of d, h and\nw. We present the MAP performance of Bi-GTPPP on\nNYC test set. Note that the best parameters are selected\nby grid search on NYC validation set, while the impact\nof parameters is evaluated on NYC test set. Validation\nand test results are similar under different settings.\n\nThe embedding dimension d and LSTM output space\nh have similar performance as shown in Figure 5(a) and\n5(b). We observe that as the embedding dimension and\nLSTM output space increase, the performance of the\nmodel is quickly improved, and then becomes stable.\nThe embedding dimension and LSTM output space are\n\nrelated to model complexity, smaller values are difficult\nto fit the data, and larger values result in more complex\nmodel and require more computing resources. Making\na balance between performance and efficiency, d = 128\nand h = 512 are proper parameters.\n\nFigure 5(c) investigates the impact of window width\non NYC dataset evaluated by MAP. From the experi-\nmental results, we observe that the performance first im-\nproves quickly with the increase of window width w and\nthen drops down gradually. The reason is that, smaller\nvalue of w prunes too many useful history information,\nand larger value of w brings little useful additional in-\nformation and may even hurt the model performance by\nintroducing noise information due to the long interval.\nWe finally select w = 18 as the window width.\n\nAccording to Table 2 and Figure 5, we can see that\neven without the best parameters, Bi-GTPPP still out-\nperforms other baseline methods. In a word, the perfor-\nmance of Bi-GTPPP stays stable in a large range of val-\nues of parameters and is not very sensitive to embedding\ndimension, LSTM output space and window width.\n\n5. Conclusion and Outlook\n\nIn this paper, we proposed a novel neural network\nmodel named Bi-GTPPP to identify the missing cate-\ngory of POI where a user has visited at any time in\nthe past. The Bi-GTPPP integrated bi-directional global\ntransition patterns and personal preferences via deli-\ncately designed attention matching cells. Specifically,\nthe attention matching cell first bi-directionally models\nhow well the check-in category information captured\nby LSTM network matches the global transition pat-\nterns. And then another attention matching cell models\nhow well the recent check-in category information and\nglobal transition patterns of users match their personal\n\n10\n\n\n\npreferences. Finally, the proposed model blue is evalu-\nated on two large-scale real-world datasets and the re-\nsults demonstrate the performance improvement of our\nproposed model compared with various kinds of state-\nof-the-art baseline methods. Also, the proposed model\ncan be naturally extended to address next POI category\nprediction task with competitive performance by only\nusing forward sequence.\n\nSeveral directions are available for future research\nin the area. First, the missing POI category identifica-\ntion task can be further explored and applied to a wider\nrange of applications, such as the urban function zone\ndividing and urban planning, and even used for crimi-\nnal activities analysis. Second, using POI category in-\nformation to assist POI-oriented research will have a\nbroader application scenario in various real-world ap-\nplications. Third, the explanation and interpretability of\nPOI-oriented research will become more and more im-\nportant. Finally, the identification performance can be\nimproved by combining with other disciplines, for ex-\nample, by learning relevant experience from nonlinear\nsystems (Sun et al., 2020a, 2019, 2020b).\n\n6. Acknowledgements\n\nThe research work supported by the National Key\nResearch and Development Program of China under\nGrant No. 2018YFB1004300, the National Natural Sci-\nence Foundation of China under Grant No. U1836206,\nU1811461, 61773361, the Project of Youth Innovation\nPromotion Association CAS under Grant No. 2017146.\n\nReferences\n\nChen, X., Zeng, Y., Cong, G., Qin, S., Xiang, Y., Dai, Y., 2015. On\ninformation coverage for location category based point-of-interest\nrecommendation., in: AAAI, pp. 37\u201343.\n\nCheng, C., Yang, H., Lyu, M.R., King, I., 2013. Where you like to\ngo next: Successive point-of-interest recommendation., in: IJCAI,\npp. 2605\u20132611.\n\nCho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares,\nF., Schwenk, H., Bengio, Y., 2014. Learning phrase representa-\ntions using rnn encoder-decoder for statistical machine translation.\nComputer Science doi:10.3115/v1/D14-1179.\n\nFeng, S., Li, X., Zeng, Y., Cong, G., Chee, Y.M., Yuan, Q., 2015.\nPersonalized ranking metric embedding for next new poi recom-\nmendation., in: IJCAI, pp. 2069\u20132075.\n\nGao, H., Tang, J., Hu, X., Liu, H., 2013. Exploring temporal effects\nfor location recommendation on location-based social networks,\nin: RecSys, pp. 93\u2013100. doi:10.1145/2507157.2507182.\n\nGlorot, X., Bengio, Y., 2010. Understanding the difficulty of training\ndeep feedforward neural networks, in: AISTATS, pp. 249\u2013256.\n\nHe, J., Li, X., Liao, L., 2017. Category-aware next point-of-interest\nrecommendation via listwise bayesian personalized ranking, in: IJ-\nCAI, pp. 1837\u20131843. doi:10.24963/ijcai.2017/255.\n\nHe, J., Li, X., Liao, L., Song, D., Cheung, W.K., 2016. Inferring\na personalized next point-of-interest recommendation model with\nlatent behavior patterns., in: AAAI, pp. 137\u2013143.\n\nHochreiter, S., Schmidhuber, J., 1997. Long short-term mem-\nory. Neural computation 9, 1735\u20131780. doi:10.1007/\n978-3-642-24797-2_4.\n\nKingma, D., Ba, J., 2014. Adam: A method for stochastic optimiza-\ntion. Computer Science .\n\nLiu, Q., Wu, S., Wang, L., Tan, T., 2016. Predicting the next location:\nA recurrent model with spatial and temporal contexts., in: AAAI,\npp. 194\u2013200.\n\nLiu, X., Liu, Y., Aberer, K., Miao, C., 2013. Personalized point-of-\ninterest recommendation by mining users\u2019 preference transition,\nin: CIKM, pp. 733\u2013738. doi:10.1145/2505515.2505639.\n\nRendle, S., Freudenthaler, C., Schmidt-Thieme, L., 2010. Factorizing\npersonalized markov chains for next-basket recommendation, in:\nWWW, pp. 811\u2013820. doi:10.1145/1772690.1772773.\n\nRodrigues, F., Pereira, F.C., Alves, A., Jiang, S., Ferreira, J., 2012.\nAutomatic classification of points-of-interest for land-use analysis,\nin: Proceedings of the fourth international conference on advanced\ngeographic information systems, applications, and services (GEO-\nProcessing), pp. 41\u201349.\n\nSalakhutdinov, R., Mnih, A., 2007. Probabilistic matrix factorization,\nin: NIPS, pp. 1257\u20131264.\n\nSun, K., Jianbin, Q., Karimi, H.R., Fu, Y., 2020a. Event-triggered ro-\nbust fuzzy adaptive finite-time control of nonlinear systems with\nprescribed performance. IEEE Transactions on Fuzzy Systems\ndoi:10.1109/TFUZZ.2020.2979129.\n\nSun, K., Liu, L., Qiu, J., Feng, G., 2020b. Fuzzy adaptive finite-time\nfault-tolerant control for strict-feedback nonlinear systems. IEEE\nTransactions on Fuzzy Systems doi:10.1109/TFUZZ.2020.\n2965890.\n\nSun, K., Qiu, J., Karimi, H.R., Gao, H., 2019. A novel finite-time con-\ntrol for nonstrict feedback saturated nonlinear systems with track-\ning error constraint. IEEE Transactions on Systems, Man, and Cy-\nbernetics: Systems doi:10.1109/TSMC.2019.2958072.\n\nWang, F., Qu, Y., Zheng, L., Lu, C.T., Philip, S.Y., 2017. Deep and\nbroad learning on content-aware poi recommendation, in: CIC, pp.\n369\u2013378. doi:10.1109/CIC.2017.00054.\n\nXi, D., Zhuang, F., Liu, Y., Gu, J., Xiong, H., He, Q., 2019. Modelling\nof bi-directional spatio-temporal dependence and users\u2019 dynamic\npreferences for missing poi check-in identification, in: AAAI, pp.\n5458\u20135465. doi:10.1609/aaai.v33i01.33015458.\n\nXiao, X., Zheng, Y., Luo, Q., Xie, X., 2010. Finding similar\nusers using category-based location history, in: Proceedings of\nthe 18th SIGSPATIAL International Conference on Advances in\nGeographic Information Systems, pp. 442\u2013445. doi:10.1145/\n1869790.1869857.\n\nXie, M., Yin, H., Wang, H., Xu, F., Chen, W., Wang, S., 2016. Learn-\ning graph-based poi embedding for location-based recommenda-\ntion, in: CIKM, pp. 15\u201324. doi:10.1145/2983323.2983711.\n\nYang, C., Bai, L., Zhang, C., Yuan, Q., Han, J., 2017a. Bridg-\ning collaborative filtering and semi-supervised learning: a neu-\nral approach for poi recommendation, in: KDD, pp. 1245\u20131254.\ndoi:10.1145/3097983.3098094.\n\nYang, C., Sun, M., Zhao, W.X., Liu, Z., Chang, E.Y., 2017b. A neural\nnetwork approach to jointly modeling social networks and mobile\ntrajectories. ACM Transactions on Information Systems (TOIS)\n35, 36. doi:10.1145/3041658.\n\nYang, D., Zhang, D., Zheng, V.W., Yu, Z., 2015. Modeling user activ-\nity preference by leveraging user spatial temporal characteristics\nin lbsns. IEEE Transactions on Systems, Man, and Cybernetics:\nSystems 45, 129\u2013142. doi:10.1109/TSMC.2014.2327053.\n\nYe, J., Zhu, Z., Cheng, H., 2013. What\u2019s your next move: User activity\nprediction in location-based social networks, in: SDM, pp. 171\u2013\n\n11\n\nhttp://dx.doi.org/10.3115/v1/D14-1179\nhttp://dx.doi.org/10.1145/2507157.2507182\nhttp://dx.doi.org/10.24963/ijcai.2017/255\nhttp://dx.doi.org/10.1007/978-3-642-24797-2_4\nhttp://dx.doi.org/10.1007/978-3-642-24797-2_4\nhttp://dx.doi.org/10.1145/2505515.2505639\nhttp://dx.doi.org/10.1145/1772690.1772773\nhttp://dx.doi.org/10.1109/TFUZZ.2020.2979129\nhttp://dx.doi.org/10.1109/TFUZZ.2020.2965890\nhttp://dx.doi.org/10.1109/TFUZZ.2020.2965890\nhttp://dx.doi.org/10.1109/TSMC.2019.2958072\nhttp://dx.doi.org/10.1109/CIC.2017.00054\nhttp://dx.doi.org/10.1609/aaai.v33i01.33015458\nhttp://dx.doi.org/10.1145/1869790.1869857\nhttp://dx.doi.org/10.1145/1869790.1869857\nhttp://dx.doi.org/10.1145/2983323.2983711\nhttp://dx.doi.org/10.1145/3097983.3098094\nhttp://dx.doi.org/10.1145/3041658\nhttp://dx.doi.org/10.1109/TSMC.2014.2327053\n\n\n179. doi:10.1137/1.9781611972832.19.\nYin, H., Wang, W., Wang, H., Chen, L., Zhou, X., 2017. Spatial-aware\n\nhierarchical collaborative deep learning for poi recommendation.\nIEEE Transactions on Knowledge and Data Engineering 29, 2537\u2013\n2551. doi:10.1109/TKDE.2017.2741484.\n\nZhang, D.Y., Wang, D., Zheng, H., Mu, X., Li, Q., Zhang, Y.,\n2017a. Large-scale point-of-interest category prediction using nat-\nural language processing models, in: Big Data, pp. 1027\u20131032.\ndoi:10.1109/BigData.2017.8258026.\n\nZhang, Y., Dai, H., Xu, C., Feng, J., Wang, T., Bian, J., Wang, B., Liu,\nT.Y., 2014. Sequential click prediction for sponsored search with\nrecurrent neural networks., in: AAAI, pp. 1369\u20131375.\n\nZhang, Z., Li, C., Wu, Z., Sun, A., Ye, D., Luo, X., 2017b.\nNext: a neural network framework for next poi recom-\nmendation. arXiv preprint arXiv:1704.04576 doi:10.1007/\ns11704-018-8011-2.\n\nZhao, P., Zhu, H., Liu, Y., Li, Z., Xu, J., Sheng, V.S., 2018. Where to\ngo next: A spatio-temporal lstm model for next poi recommenda-\ntion. arXiv preprint arXiv:1806.06671 .\n\nZhou, D., Wang, X., 2014. Probabilistic category-based location\nrecommendation utilizing temporal influence and geographical in-\nfluence, in: DSAA, pp. 115\u2013121. doi:10.1109/DSAA.2014.\n7058061.\n\nZhu, Y., Li, H., Liao, Y., Wang, B., Guan, Z., Liu, H., Cai, D., 2017.\nWhat to do next: Modeling user behaviors by time-lstm, in: IJCAI,\npp. 3602\u20133608. doi:10.24963/ijcai.2017/504.\n\n12\n\nhttp://dx.doi.org/10.1137/1.9781611972832.19\nhttp://dx.doi.org/10.1109/TKDE.2017.2741484\nhttp://dx.doi.org/10.1109/BigData.2017.8258026\nhttp://dx.doi.org/10.1007/s11704-018-8011-2\nhttp://dx.doi.org/10.1007/s11704-018-8011-2\nhttp://dx.doi.org/10.1109/DSAA.2014.7058061\nhttp://dx.doi.org/10.1109/DSAA.2014.7058061\nhttp://dx.doi.org/10.24963/ijcai.2017/504\n\n\t1 Introduction\n\t2 Related Work\n\t2.1 General POI Recommendation and Location Prediction\n\t2.2 Category-aware POI Recommendation and Location Prediction\n\t2.3 Neural Network for POI Recommendation and Location Prediction\n\n\t3 Methodology\n\t3.1 Problem Statement\n\t3.2 Attention Matching cell\n\t3.3 Bi-directional Global Transition Patterns\n\t3.4 Personal Preferences and the Final Bi-GTPPP Model\n\n\t4 Experiments\n\t4.1 Datasets\n\t4.2 Baselines\n\t4.3 Implementation Details\n\t4.4 Evaluation Metrics\n\t4.5 Performance Comparison and Discussion \n\t4.6 Impact of Different Parts\n\t4.7 Impact of Parameters\n\n\t5 Conclusion and Outlook\n\t6 Acknowledgements\n\n"}
{"Title": "Device Activity Detection for Massive Grant-Free Access Under Frequency-Selective Rayleigh Fading", "Authors": "Yuhang Jia, Ying Cui, Wuyang Jiang", "Abstract": "  Device activity detection and channel estimation for massive grant-free access under frequency-selective fading have unfortunately been an outstanding problem. This paper aims to address the challenge. Specifically, we present an orthogonal frequency division multiplexing (OFDM)-based massive grant-free access scheme for a wideband system with one M-antenna base station (BS), N single-antenna Internet of Things (IoT) devices, and P channel taps. We obtain two different but equivalent models for the received pilot signals under frequency-selective Rayleigh fading. Based on each model, we formulate device activity detection as a non-convex maximum likelihood estimation (MLE) problem and propose an iterative algorithm to obtain a stationary point using optimal techniques. The two proposed MLE-based methods have the identical computational complexity order O(NPL^2), irrespective of M, and degrade to the existing MLE-based device activity detection method when P=1. Conventional channel estimation methods can be readily applied for channel estimation of detected active devices under frequency-selective Rayleigh fading, based on one of the derived models for the received pilot signals. Numerical results show that the two proposed methods have different preferable system parameters and complement each other to offer promising device activity detection design for grant-free massive access under frequency-selective Rayleigh fading.      ", "Subject": "Information Theory (cs.IT)", "ID": "arXiv:2201.00015", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n5v\n1 \n\n [\ncs\n\n.I\nT\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\nDevice Activity Detection for Massive Grant-Free\n\nAccess Under Frequency-Selective Rayleigh Fading\n\nYuhang Jia\n\nShanghai Jiao Tong Univ., China\n\nJay Yoga@sjtu.edu.cn\n\nYing Cui\n\nShanghai Jiao Tong Univ., China\n\ncuiying@sjtu.edu.cn\n\nWuyang Jiang\n\nShanghai Univ. of Engineering Science, China\n\njiang-wuyang@sues.edu.cn\n\nAbstract\u2014Device activity detection and channel estimation for\nmassive grant-free access under frequency-selective fading have\nunfortunately been an outstanding problem. This paper aims\nto address the challenge. Specifically, we present an orthogonal\nfrequency division multiplexing (OFDM)-based massive grant-\nfree access scheme for a wideband system with one M -antenna\nbase station (BS), N single-antenna Internet of Things (IoT)\ndevices, and P channel taps. We obtain two different but\nequivalent models for the received pilot signals under frequency-\nselective Rayleigh fading. Based on each model, we formulate\ndevice activity detection as a non-convex maximum likelihood\nestimation (MLE) problem and propose an iterative algorithm\nto obtain a stationary point using optimal techniques. The two\nproposed MLE-based methods have the identical computational\ncomplexity order O(NPL\n\n2), irrespective of M , and degrade to\nthe existing MLE-based device activity detection method when\nP = 1. Conventional channel estimation methods can be readily\napplied for channel estimation of detected active devices under\nfrequency-selective Rayleigh fading, based on one of the derived\nmodels for the received pilot signals. Numerical results show\nthat the two proposed methods have different preferable system\nparameters and complement each other to offer promising device\nactivity detection design for grant-free massive access under\nfrequency-selective Rayleigh fading.\n\nI. INTRODUCTION\n\nDriven by the proliferation of the Internet of Things (IoT),\n\nmassive machine-type communication (mMTC) plays a vital\n\nrole in the fifth generation (5G) cellular technologies and\n\nbeyond. It is incredibly challenging to support enormous IoT\n\ndevices which are energy-limited and sporadically active, and\n\nhave little data to send once activate. Massive grant-free access\n\nwith multiple-input multiple-output (MIMO) has been recently\n\nproposed to address the challenge. Specifically, devices are\n\npre-assigned specific non-orthogonal pilots, active devices\n\ndirectly send their pilots, and the base station (BS) detects\n\nthe active devices and estimates their channel conditions from\n\nthe received signal of non-orthogonal pilots [1]. Unfortunately,\n\nvast potential non-orthogonal pilots complicate the signal\n\nprocessing at the BS.\n\nDue to inherent sparse device activities in massive grant-free\n\naccess, joint device activity detection and channel estimation\n\ncan be formulated as compressed sensing (CS) problems and\n\nsolved by CS-based algorithms [2]\u2013[4]. Specifically, [2] pro-\n\nposes an approximate message passing (AMP) algorithm with\n\nThis work was supported in part by the National Key Research and\nDevelopment Program of China under Grant 2018YFB1801102 and in part\nby the Natural Science Foundation of Shanghai under Grant 20ZR1425300.\n\na minimum mean square error (MMSE) estimation denoiser.\n\nIn [4], the authors propose an alternating direction method\n\nof multipliers (ADMM)-based algorithm for GROUP LASSO\n\n[3]. Besides, several works focus only on device activity\n\ndetection, as conventional channel estimation methods can\n\nbe directly applied for estimating channel conditions of the\n\ndetected active devices. For instance, [5] formulates device\n\nactivity detection as a maximum likelihood estimation (MLE)\n\nproblem and proposes a coordinate descent method to obtain\n\na stationary point. This MLE-based method is also analyzed\n\nin [5], [6]. Motivated by [5], [7] formulates device activity\n\ndetection with prior activity distribution as a maximum a\n\nposteriori probability (MAP) estimation problem and extends\n\nthe coordinate descent method in [5] to obtain a stationary\n\npoint.\n\nIt is worth noting that all existing works [2], [4]\u2013[7] consider\n\nmassive grant-free access for a narrow band system under flat\n\nfading. However, due to the signal corruption under frequency-\n\nselective fading, the existing methods for activity detection\n\nand channel estimation designed for a narrow band system\n\nunder flat fading are no longer applicable for a wideband\n\nsystem under frequency-selective fading. On the other hand,\n\northogonal frequency division multiplexing (OFDM) provides\n\na high degree of robustness against channel-frequency se-\n\nlectivity. It hence is an attractive choice for 4G-LTE and\n\n5G-NR. In this paper, we would like to shed some light\n\ntoward this direction. Specifically, we present an orthogonal\n\nfrequency division multiplexing (OFDM)-based massive grant-\n\nfree access scheme with one M -antenna BS, N single-antenna\n\nIoT devices, and P channel taps. We obtain two different\n\nbut equivalent models for the received pilot signals under\n\nfrequency-selective Rayleigh fading. Based on each model,\n\nwe formulate device activity detection as a non-convex MLE\n\nproblem and propose an iterative algorithm to obtain a station-\n\nary point using optimal techniques. The two proposed MLE-\n\nbased device activity detection methods have the identical\n\ncomputational complexity order O(NPL2) and degrade to the\n\nexisting MLE-based device activity detection method [5], [6]\n\nwhen P = 1. Notice that conventional channel estimation\n\nmethods can be readily applied for channel estimation of\n\ndetected active devices under frequency-selective Rayleigh\n\nfading, based on one of the derived models for the received\n\npilot signals. Numerical results show that the two proposed\n\nmethods offer promising device activity detection design for\n\nhttp://arxiv.org/abs/2201.00015v1\n\n\nfrequency-selective Rayleigh fading. Furthermore, one method\n\nalways achieves a lower error rate than the other with a shorter\n\ncomputation time if P is small and a longer computation time\n\notherwise. This is the first work investigating massive grant-\n\nfree access under frequency-selective fading to the best of our\n\nknowledge.\n\nNotation : We represent vectors by boldface lowercase\n\nletters (e.g., x), matrices by boldface uppercase letters (e.g.,\n\nX), scalar constants by non-boldface letters (e.g., x), and sets\n\nby calligraphic letters (e.g., X ). The notation xi represents\n\nthe i-th element of vector x, Xi,: represents the i-th row of\n\nmatrix X, and X:,i represents the i-th column of matrix X.\n\nX:,1:K represents the matrix consisting of the first K columns\n\nof the matrix X. XH and tr (X) denote the conjugate transpose\n\nand trace of the matrix X, respectively. diag (x) is a diagonal\n\nmatrix with the entries of x on its main diagonal. |\u00b7| denotes\n\nthe modulus of a complex number. The complex field and\n\nreal field are denoted by C and R, respectively. \u2297 denotes\n\nthe Kronecker product. IL and en denotes the L\u00d7L identity\n\nmatrix and a unit vector whose n-th component is 1, all others\n\n0. Pr[x] denotes the probability of the event x.\n\nII. SYSTEM MODEL\n\nWe consider a single-cell cellular network with one M -\n\nantenna BS and N single-antenna IoT devices. Let M ,\n\n{1, 2, \u00b7 \u00b7 \u00b7 ,M} and N , {1, 2, \u00b7 \u00b7 \u00b7 , N} denote the sets of\n\ndevice and antenna indices, respectively. For all n \u2208 N , let\n\ngn > 0 denote the large-scale fading power of the channel\n\nbetween device n and the BS. Small-scale fading follows the\n\nblock fading model, i.e., small-scale fading coefficients remain\n\nconstant within each coherence block and are independent\n\nand identically distributed (i.i.d.) over coherence blocks. We\n\nconsider a wideband system and adopt the frequency-selective\n\nRayleigh fading channel model for small-scale fading. Let P\n\ndenote the number of channel taps, and let P , {1, 2, \u00b7 \u00b7 \u00b7 , P}\ndenote the set of channel tap indices. Denote hn,m,p \u2208 C as the\n\np-th coefficient of the channel impulse response (CIR) of the\n\nchannel between device n and the BS over antenna m, for all\n\nn \u2208 N ,m \u2208 M, p \u2208 P . We assume hn,m,p \u223c CN (0, 1), n \u2208\nN ,m \u2208 M, p \u2208 P .\n\nWe study the massive access scenario arising from mMTC,\n\nwhere very few devices among a large number of potential\n\ndevices are active and access the BS in each coherence block.\n\nFor all n \u2208 N , let \u03b1n \u2208 {0, 1} denote the activity state of\n\ndevice n, where \u03b1n = 1 indicates that device n is active and\n\n\u03b1n = 0 otherwise. In the considered massive access scenario,\u2211\nn\u2208N \u03b1n \u226a N , i.e., \u03b1 , (\u03b1n)n\u2208N \u2208 {0, 1}N is sparse.\n\nWe adopt an OFDM-based massive grant-free access scheme.\n\nLet L denote the number of subcarriers, and denote L ,\n\n{1, 2, \u00b7 \u00b7 \u00b7 , L} as the set of subcarrier indices. Assume P < L.\n\nEach device n \u2208 N is pre-assigned a specific pilot sequence\n\ns\u0303n , (s\u0303n,\u2113)\u2113\u2208L \u2208 CL consisting of L \u226a N OFDM symbols,\n\neach carried by one subcarrier. In the pilot transmission phase,\n\nactive devices simultaneously send their length-L pilots to the\n\nBS over the L subcarriers, and the BS detects the activity states\n\nof all devices and estimates the channel states of all active\n\ndevices from the LM received OFDM symbols over the M\n\nantennas. In this paper, we focus on device activity detection\n\nunder frequency-selective Rayleigh fading, which is more\n\nchallenging than device activity detection under flat Rayleigh\n\nfading [1], [2], [4]\u2013[7]. We shall see that based on one of\n\nthe derived models for the received pilot signals, conventional\n\nchannel estimation methods can be readily applied for channel\n\nestimation of detected active devices.\n\nThe time domain representation of the OFDM symbols\n\nin s\u0303n \u2208 CL, i.e., the normalized inverse discrete Fourier\n\ntransform (IDFT) of s\u0303n, is given by:\n\nsn = FH s\u0303n \u2208 C\nL, n \u2208 N . (1)\n\nHere, F , (F\u2113,\u2113\u2032)\u2113,\u2113\u2032\u2208L \u2208 CL\u00d7L denotes the discrete Fourier\n\ntransform (DFT) matrix where F\u2113,\u2113\u2032 ,\n1\u221a\nL\ne\u2212\n\nj2\u03c0(\u2113\u22121)(\u2113\u2032\u22121)\nL . At\n\neach device n \u2208 N , a cyclic prefix is appended to sn before\n\ntransmission. After removing the signal corresponding to the\n\ncyclic prefixes, the received signal over the L signal dimen-\n\nsions at antenna m \u2208 M, denoted as rm , (r\u2113,m)\u2113\u2208L \u2208 CL,\n\ncan be written as [8]:\n\nrm =\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nnHn,msn + nm\n\n=\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nnHn,mFH s\u0303n + nm, m \u2208 M, (2)\n\nwhere\n\nHn,m ,\n\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8f0\n\nhn,m,1 hn,m,L \u00b7 \u00b7 \u00b7 hn,m,2\n\nhn,m,2 hn,m,1 \u00b7 \u00b7 \u00b7 hn,m,3\n\n...\n...\n\n. . .\n...\n\nhn,m,L hn,m,L\u22121 \u00b7 \u00b7 \u00b7 hn,m,1\n\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fb \u2208 C\n\nL\u00d7L, (3)\n\nand nm , (n\u2113,m)l\u2208L \u2208 CL with n\u2113,m \u223c CN (0, \u03c32) is the\n\nadditive white Gaussian noise (AWGN). Here, for notation\n\nconvenience, we let hn,m,p = 0, p \u2208 L\\P , n \u2208 N , m \u2208 M.\n\nNote that for all n \u2208 N ,m \u2208 M, each of hn,m,l, l \u2208 L\nappears L times in Hn,m.\n\nFor tractability, we obtain an equivalent expression of rm\nin (2) in the following [8]. Define n\u0303m , Fnm \u2208 C\n\nL. First,\n\nwe obtain the received signal in the frequency domain, i.e.,\n\nr\u0303m =Frm =\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nnFHn,mFH s\u0303n + n\u0303m\n\n=\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nn diag(s\u0303n)F(Hn,m):,1 + n\u0303m, m \u2208 M, (4)\n\nwhere the last equality is due to the fact that FHn,mFH \u2208\nCL\u00d7L is a diagonal matrix [8, Lemma 1]. Define Sn ,\n\n(FHdiag(s\u0303n)F):,1:P and hn,m , (hn,m,p)p\u2208P . Then, apply-\n\ning normalized IDFT to r\u0303m in (4), we rewrite rm in (2) as:\n\nrm =FH r\u0303m =\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nnF\n\nHdiag(s\u0303n)F(Hn,m):,1 + nm\n\n=\n\u2211\n\nn\u2208N\n\u03b1ng\n\n1\n2\nnSnhn,m + nm, m \u2208 M, (5)\n\nwhere the last equality is due to FHF = IL and hn,m,p = 0,\n\np \u2208 L\\P , n \u2208 N , m \u2208 M. In contrast with Hn,m, n \u2208\nN ,m \u2208 M, all elements of hn,m, n \u2208 N ,m \u2208 M are i.i.d.\n\naccording to CN (0, 1), making device activity detection from\n\nrm in (5) more tractable than from rm in (2).\n\n\n\nf (1)\n\u03b1,n(d) , log |IP + dgnS\n\nH\nn \u03a3(1)\u22121\n\n\u03b1 Sn|+ dgntr\n(\n(IP + dgnS\n\nH\nn \u03a3(1)\u22121\n\n\u03b1 Sn)\n\u22121SH\n\nn \u03a3(1)\u22121\n\u03b1 \u03a3\u0302R\u03a3(1)\u22121\n\n\u03b1 Sn\n\n)\n(11)\n\ng(1)\u03b1,n(d) ,d2P\u22121\n\u2211\n\np\u2208P\nv2ph(v\u2212p, 2P \u2212 1) +\n\n2P\u22122\u2211\n\nt=0\n\ndt\n\u2211\n\np\u2208P\n(v2p + vp \u2212 up)h(v\u2212p, t) (12)\n\nFor ease of exposition, we assume that the large-scale fading\n\npowers, gn, n \u2208 N , are known to the BS and propose two\n\nMLE-based device activity detection methods in Section III\n\nand Section IV, respectively. The proposed methods can be\n\nreadily extended to device activity detection with unknown\n\nlarge-scale fading powers [5]. Later in Section V, we shall\n\nsee that compared to the method in Section IV, the method in\n\nSection III achieves high detection accuracy for all P , short\n\ncomputation time for small P , and long computation time for\n\nlarge P . Therefore, we can apply them according to practical\n\nsystem parameters and requirements.\n\nIII. MLE-BASED DEVICE ACTIVITY DETECTION USING\n\nCOORDINATE DESCENT METHOD\n\nIn this section, we propose an MLE-based device activity\n\ndetection method based on the expression of rm in (5) and\n\nthe coordinate descent method.\n\nA. Problem Formulation\n\nhn,m, n \u2208 N ,m \u2208 M are i.i.d. according to CN(0, IP ).\nThus, when \u03b1n, gn, n \u2208 N are given, rm,m \u2208 M, with rm\n\ngiven by (5), are i.i.d. according to CN\n(\n0,\u03a3(1)\n\n\u03b1\n\n)\n[5], where\n\n\u03a3(1)\n\u03b1 ,\n\n\u2211\n\nn\u2208N\n\u03b1ngnSnS\n\nH\nn + \u03c32IL. (6)\n\nNote that \u03a3(1)\n\u03b1 depends on \u03b1. Let R with R:,m , rm,m \u2208 M\n\ndenote the received signal over the M antennas. Thus, the\n\nlikelihood function of R, viewed as a function of \u03b1, is given\n\nby:\n\np(1)(R;\u03b1) ,\nexp\n\n(\n\u2212tr\n\n(\n\u03a3(1)\u22121\n\n\u03b1 RRH\n))\n\n\u03c0LM |\u03a3(1)\n\u03b1 |M\n\n. (7)\n\nThe maximization of p(1)(R;\u03b1) is equivalent to the minimiza-\n\ntion of f (1)(\u03b1), where\n\nf (1)(\u03b1) ,\u2212 log p(1)(R;\u03b1)\u2212 L log\u03c0\n\n= log |\u03a3(1)\n\u03b1 |+ tr\n\n(\n\u03a3(1)\u22121\n\n\u03b1 \u03a3\u0302R\n\n)\n. (8)\n\nHere, \u03a3\u0302R , 1\nM\nRRH represents the sample covariance matrix\n\nof rm,m \u2208 M. Note that \u03a3\u0302R is a sufficient statistics since\n\nf (1)(\u03b1) depends on R only through \u03a3\u0302R. Thus, the MLE\n\nproblem of \u03b1 can be formulated as:1\n\nProblem 1 (MLE for Activity Detection of Actual Devices):\n\nmin\n\u03b1\n\nf (1)(\u03b1)\n\ns.t. \u03b1n \u2208 [0, 1], n \u2208 N . (9)\n\n1In this paper, binary condition \u03b1n \u2208 {0, 1} is relaxed to continuous\ncondition \u03b1n \u2208 [0, 1] in each estimation problem, and binary detection results\nare obtained by performing thresholding after solving the estimation problem\nas in [5], [6].\n\nProblem 1 is a non-convex optimization problem. When\n\nP = 1, Problem 1 is equivalent to the MLE problem for\n\nactivity detection of N devices under flat Rayleigh fading in\n\n[5] and can be converted to the same form as the one in [5].\n\nWhen P \u2208 {2, 3, ...}, Problem 1 is different from the one in\n\n[5] and cannot be converted to its form (as SnS\nH\nn \u2208 CL\u00d7L\n\nis not a rank-one matrix). Later, we shall see that this slight\n\ndifference causes a significant challenge for solving Problem 1.\n\nB. Solution\n\nThe goal of solving a non-convex problem is usually\n\nto obtain a stationary point of the problem. We adopt the\n\ncoordinate descent method to obtain a stationary point of\n\nProblem 1. Specifically, given \u03b1 obtained in the previous step,\n\nthe coordinate descent optimization w.r.t. \u03b1n is equivalent to\n\nthe optimization of the increment d in \u03b1n [5]:\n\nmin\nd\u2208[\u2212\u03b1n,1\u2212\u03b1n]\n\nf (1)(\u03b1+ den). (10)\n\nWe shall see that it is more challenging to solve the coordinate\n\ndescent optimization for P \u2208 {2, 3, ...} in (10) than to solve\n\nthat for P = 1. In the following, we define two important\n\nfunctions based on which we can characterize the optimal\n\nsolution of the problem in (10). Specifically, we first define\n\nf\n(1)\n\u03b1,n(d) in (11), as shown at the top of this page. Applying\n\neigenvalue decomposition, we can write SH\nn \u03a3(1)\u22121\n\n\u03b1 Sn as\n\nUndiag(v)U\nH\nn , where v , (vp)p\u2208P \u2208 RP represents the\n\neigenvalues and Un \u2208 CP\u00d7P represents the corresponding\n\neigenvectors. For all p \u2208 P , let up denote the p-th diagonal\n\nelement of UnS\nH\nn \u03a3(1)\u22121\n\n\u03b1 \u03a3\u0302R\u03a3(1)\u22121\n\u03b1 SnU\n\nH\nn . Define v\u2212p ,\n\n(vp\u2032)p\u2032\u2208P,p\u2032 6=p \u2208 RP\u22121,\n\nS(t) ,\n{\n(x,y)|x,y \u2208 {0, 1}P\u22121, xp + yp \u2264 1, p \u2208 P\\{P},\n\n\u2211\n\np\u2208P\\{P}\n(xp + 2yp) = t\n\n}\n,\n\nh(z, t) ,\n\u2211\n\n(x,y)\u2208S(t)\n\nP\u22121\u220f\n\np=1\n\n2xpzxp+2yp\np , z \u2208 R\n\nP\u22121\n++ ,\n\nwhere t = 0, ..., 2P \u2212 2. Based on the above definitions, we\n\ndefine g\n(1)\n\u03b1,n(d) in (12), as shown at the top of this page.\n\nTheorem 1 (Optimal Solution of Coordinate Descent Opti-\n\nmization in (10)): Given \u03b1, the optimal solution of the problem\n\nin (10) is given by:\n\nd(1)\u2217n , arg min\nd\u2208D(1)\n\nn \u222a{\u2212\u03b1n,1\u2212\u03b1n}\nf (1)\n\u03b1,n(d), (13)\n\nwhere D(1)\nn , {d \u2208 [\u2212\u03b1n, 1\u2212 \u03b1n] : g\n\n(1)\n\u03b1,n(d) = 0}.\n\nProof (Sketch): First, by (6), (8), and\n\n(\u03a3(1)\n\u03b1 + dgnSnS\n\nH\nn )\u22121 = \u03a3\n\n(1)\u22121\n\u03b1 \u2212 dgn\u03a3\n\n(1)\u22121\n\u03b1 Sn(IP +\n\ndgnS\nH\nn \u03a3(1)\u22121\n\n\u03b1 Sn)\n\u22121SH\n\nn \u03a3\u22121\n\u03b1 [5], we show f (1)(\u03b1 + den) =\n\nf (1)(\u03b1) + f\n(1)\n\u03b1,n(d). Thus, the problem in (10) is equivalent\n\n\n\nAlgorithm 1 Coordinate Descent Algorithm for Problem 1\n\nInput: empirical covariance matrix \u03a3\u0302R.\n\nOutput: \u03b1.\n\n1: Initialize \u03a3\n(1)\u22121\n\u03b1 = 1\n\n\u03c32 IL, \u03b1 = 0.\n\n2: repeat\n\n3: for n \u2208 N do\n\n4: Calculate d\n(1)\u2217\nn according to (13) analytically if P \u2264 2\n\nand numerically if P \u2265 3.\n\n5: If d\n(1)\u2217\nn 6= 0\n\n6: Update \u03b1n = \u03b1n + d\n(1)\u2217\nn .\n\n7: Update \u03a3(1)\u22121\n\u03b1 = \u03a3(1)\u22121\n\n\u03b1 \u2212 d\n(1)\u2217\nn gn\u03a3\n\n(1)\u22121\n\u03b1 Sn(IP +\n\nd\n(1)\u2217\nn gnS\n\nH\nn \u03a3(1)\u22121\n\n\u03b1 Sn)\n\u22121SH\n\nn \u03a3(1)\u22121\n\u03b1 .\n\n8: end\n\n9: end for\n\n10: until \u03b1 satisfies some stopping criterion.\n\nto min\nd\u2208D(1)\n\nn \u222a{\u2212\u03b1n,1\u2212\u03b1n}\nf\n(1)\n\u03b1,n(d). Next, based on eigenvalue\n\ndecomposition, we show\n(\nf\n(1)\n\u03b1,n(d)\n\n)\u2032\n\n=\ng(1)\n\u03b1,n(d)\u220f\n\np\u2208P\n(1+vpd)2\n\n. Thus,\n\nthe optimal solution of min\nd\u2208D(1)\n\nn \u222a{\u2212\u03b1n,1\u2212\u03b1n}\nf\n(1)\n\u03b1,n(d) is given\n\nby (13). Therefore, we complete the proof.\n\ng\n(1)\n\u03b1,n(d) is a polynomial with degree 2P \u2212 1 and hence\n\nhas 2P \u2212 1 roots. Note that the roots of a polynomial with\n\ndegree q can be obtained analytically if q \u2208 {1, 2, 3, 4} and\n\nnumerically otherwise [9]. Besides, note that the computa-\n\ntional complexities for obtaining the roots of a polynomial\n\nwith degree q analytically and numerically are O(q) and\n\nO(q3), respectively [9]. Thus, D(1)\nn can be obtained in closed-\n\nform with computational complexity O(P ) if P \u2208 {1, 2} and\n\nnumerically with computational complexity O(P 3) otherwise.\n\nThe details of the coordinate descent algorithm are summa-\n\nrized in Algorithm 1. If each coordinate optimization in (10)\n\nhas a unique optimal solution, Algorithm 1 converges to a\n\nstationary point of Problem 1, as the number of the iteration\n\ngoes to infinity [10, Proposition 2.7.1]. The complexities of\n\nStep 4, Step 6, and Step 7 are O(PL2), O(1), and O(PL2),\nrespectively (note that P < L). Thus, the computational\n\ncomplexity of each iteration of Algorithm 1 is O(NPL2).\n\nIV. MLE-BASED DEVICE ACTIVITY DETECTION USING\n\nPENALTY METHOD AND COORDINATE DESCENT METHOD\n\nIn this section, we propose an MLE-based device activity\n\ndetection method based on an equivalent form of the received\n\nsignal rm in (5). Notice that based on this equivalent form,\n\nconventional channel estimation methods can be directly ap-\n\nplied for channel estimation of detected active devices under\n\nfrequency-selective Rayleigh fading.\n\nA. Problem Formulation\n\nFirst, we formulate an MLE problem for activity detection\n\nof NP virtual devices. Let I , {1, ..., NP} denote the set\n\nof virtual devices. Let \u03b2i denote the activity states of virtual\n\ndevice i, for all i \u2208 I. Virtual devices (n \u2212 1)P + 1, ..., nP\nshare the same activity state and channel condition as actual\n\ndevice n, for all n \u2208 N . Thus, we have:\n\n\u03b2(n\u22121)P+1 = ... = \u03b2nP , n \u2208 N , (14)\n\n\u03b2i \u2208 [0, 1], i \u2208 I, (15)\n\n\u03b1n =\n\n\u2211\np\u2208P \u03b2(n\u22121)P+p\n\nP\n, n \u2208 N . (16)\n\nTherefore, the received signal rm from the N devices, rm in\n\n(5), can be equivalently rewritten as the received signal from\n\nthe NP virtual devices as follows:\n\nrm =SBG\n1\n2hm + nm, m \u2208 M, (17)\n\nwhere S , [S1, ...,SN ] \u2208 CL\u00d7NP , B , diag (\u03b2) with \u03b2 ,\n\n(\u03b2i)i\u2208I , G , diag (g)\u2297 IP \u2208 R\nNP\u00d7NP\n++ with g , (gn)n\u2208N \u2208\n\nRN\n+ . Noting that hm ,\n\n[\nhT\n1,m, ...,hT\n\nN,m\n\n]T \u2208 CNP , hm, m \u2208\nM are i.i.d. according to CN(0, INP ). Thus, when \u03b2i, i \u2208 I,\n\ngn, n \u2208 N are given, rm,m \u2208 M, with rm given by (17), are\n\ni.i.d. according to CN\n(\n0,\u03a3\n\n(2)\n\u03b2\n\n)\n[5], where\n\n\u03a3\n(2)\n\u03b2 , SBGSH + \u03c32IL. (18)\n\nThus, the likelihood function of R, viewed as a function of\n\n\u03b2, can also be expressed as:\n\np(2)(R;\u03b2) ,\nexp\n\n(\n\u2212tr\n\n(\n\u03a3\n\n(2)\u22121\n\u03b2 RRH\n\n))\n\n\u03c0LM |\u03a3(2)\n\u03b2 |M\n\n. (19)\n\nThe maximization of p(2)(R;\u03b2) is equivalent to the minimiza-\n\ntion of f (2)(\u03b2), where\n\nf (2)(\u03b2) ,\u2212 log p(2)(R;\u03b2)\u2212 L log \u03c0\n\n= log |\u03a3(2)\n\u03b2 |+ tr\n\n(\n\u03a3\n\n(2)\u22121\n\u03b2 \u03a3\u0302R\n\n)\n. (20)\n\nThus, the MLE problem of \u03b2 from R given by (19) can be\n\nformulated as follows.\n\nProblem 2 (MLE for Activity Detection of Virtual Devices):\n\nmin\n\u03b2\n\nf (2)(\u03b2)\n\ns.t. (14), (15). (21)\n\nProblem 2 is also a non-convex optimization problem. It\n\ndifferentiates from Problem 1, as \u03a3(1)\n\u03b1 and \u03a3\n\n(2)\n\u03b2 have different\n\nforms. Besides, the objective function of Problem 2 shares\n\nthe same form as the objective function of the MLE problem\n\nfor activity detection of NP devices under flat Rayleigh\n\nfading in [5] except that the dimensions of S \u2208 CL\u00d7NP ,\n\nB \u2208 CNP\u00d7NP , G \u2208 CNP\u00d7NP , and hm \u2208 CNP . However,\n\nunlike Problem 1 and the ML estimation problem in [5],\n\nProblem 2 has extra coupling constraints in (14). To address\n\nthe issue caused by the coupling constraints in (14), we apply\n\nthe penalty method [10] to obtain a stationary point of an\n\nequivalent problem of Problem 2 in Section IV-B. Later in\n\nSection V, we shall see that the device activity detection\n\nmethod based on the penalty method has a higher accuracy\n\nand a higher computational complexity than the method based\n\non relaxation. After solving Problem 2 for \u03b2, we can construct\n\na device activities of the N actual devices \u03b1 according to (16)\n\n\n\nf\n(2)\nb,i (d) , log(1 + dgiS\n\nH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i)\u2212\n\ndgiS\nH\n:,i\u03a3\n\n\u22121\n\u03b2 \u03a3\u0302R\u03a3\n\n\u22121\n\u03b2 S:,i\n\n1 + dgiS\nH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i\n\n+\n\u03c1d\n\nP\n\n(\n1\u2212 d\n\nP\n\u2212 2\n\nP\n\nP\u2211\n\np=1\n\n\u03b2(\u2308 i\nP\n\u2309\u22121)P+p\n\n)\n(23)\n\nAi , \u22122\u03c1g2i\nP 2\n\n(\nSH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i\n\n)2\n\n, Bi ,\n\u03c1g2i\nP\n\n(\n1\u2212 2\n\nP\n\nP\u2211\n\np=1\n\n\u03b2(\u2308 i\nP\n\u2309\u22121)P+p\n\n)(\nSH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i\n\n)2\n\n\u2212 4\u03c1gi\nP 2\n\nSH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i\n\nCi , g2i\n\n(\nSH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i\n\n)2\n\n+\n2\u03c1gi\nP\n\n(\n1\u2212 2\n\nP\n\nP\u2211\n\np=1\n\n\u03b2(\u2308 i\nP\n\u2309\u22121)P+p\n\n)\nSH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i \u2212\n\n2\u03c1\n\nP 2\n\nDi , giS\nH\n:,i\u03a3\n\n\u22121\n\u03b2 S:,i \u2212 giS\n\nH\n:,i\u03a3\n\n\u22121\n\u03b2 \u03a3\u0302R\u03a3\u22121\n\n\u03b2 S:,i +\n\u03c1\n\nP\n\n(\n1\u2212 2\n\nP\n\nP\u2211\n\np=1\n\n\u03b2(\u2308 i\nP\n\u2309\u22121)P+p\n\n)\n\nB. Solution\n\nWe disregard the coupling constraints in (14) and add to the\n\nobjective function of Problem 2 a penalty for violating them.\n\nThen, we can convert Problem 2 to the following problem.\n\nProblem 3 (Penalty Problem of Problem 2):\n\nmin\nb\n\nf\u0303 (2)(\u03b2) , f (2)(\u03b2) + \u03c1\u03b7(\u03b2),\n\ns.t. (15),\n\nwhere \u03c1 > 0 is the penalty parameter, and\n\n\u03b7(\u03b2) ,\n\u2211\n\nn\u2208N\n\n\u2211\np\u2208P\n\n\u03b2(n\u22121)P+p\n\nP\n\n(\n1\u2212\n\n\u2211\np\u2208P\n\n\u03b2(n\u22121)P+p\n\nP\n\n)\n(22)\n\nis the penalty function.\n\nIf \u03c1 is sufficiently large, an optimal solution of Problem 3\n\nis also optimal for Problem 2 (as f (2)(\u03b2) is bounded from\n\nabove) [10]. Now, we adopt the coordinate descent method to\n\nobtain a stationary point of Problem 3 instead of Problem 2.\n\nSpecifically, given \u03b2 obtained in the previous step, the coor-\n\ndinate descent optimization with respect to \u03b2i is equivalent to\n\nthe optimization of the increment d in \u03b2i:\n\nmin\nd\u2208[\u2212\u03b2i,1\u2212\u03b2i]\n\nf\u0303 (2)(\u03b2 + dei). (23)\n\nWe shall see that it is more challenging to solve the coordinate\n\noptimization in (24) than to solve the MLE problem for flat\n\nRayleigh fading in [5]. Similarly, we define two important\n\nfunctions before solving the problem (23), i.e., f\n(2)\n\u03b2,i(d) in (23),\n\nas shown at the top of this page, and\n\ng\u0303\n(2)\n\u03b2,i(d) , Aid\n\n3 +Bid\n2 + Cid+Di, (24)\n\nwhere Ai, Bi, Ci, Di are given at the top of this page. Note\n\nthat g\u0303\n(2)\n\u03b2,i(d) is the numerator of the derivative of f\u0303\n\n(2)\n\u03b2,i(d)\n\n(which is a fraction). By taking the derivative of f\u0303\n(2)\n\u03b2,i (d),\n\nsimplifying it based on activity detection, and setting the\n\nsimplified derivative of f\u0303\n(2)\n\u03b2,i(d) to zero, we derive the optimal\n\nsolution of the problem in (23), which is expressed in terms\n\nof f\u0303\n(2)\n\u03b2,i(d) and g\u0303\n\n(2)\n\u03b2,i(d).\n\nTheorem 2 (Optimal Solution of Coordinate Descent Op-\n\ntimizations in (23)): Given \u03b2, the optimal solution of the\n\nproblem in (23) is given by:\n\nd\n(2)\u2217\ni = arg min\n\nd\u2208D(2)\ni\n\n\u222a{\u2212\u03b2i,1\u2212\u03b2i}\nf\n(2)\n\u03b2,i(d), (25)\n\nwhere D(2)\ni , {d \u2208 [\u2212\u03b2i, 1\u2212 \u03b2i] : g\n\n(2)\n\u03b2,i(d) = 0}.\n\nAlgorithm 2 Coordinate Descent Algorithm for Problem 3\n\nInput: empirical covariance matrix \u03a3\u0302R.\n\nOutput: \u03b2.\n\n1: Initialize \u03a3\u22121\n\u03b2 = 1\n\n\u03c32 IL, \u03b2 = 0.\n\n2: repeat\n\n3: for i \u2208 I do\n\n4: Calculate d\n(2)\u2217\ni according to (25).\n\n5: If d\n(2)\u2217\ni 6= 0\n\n6: Update \u03b2i = \u03b2i + d\n(2)\u2217\ni .\n\n7: Update \u03a3\u22121\n\u03b2 = \u03a3\u22121\n\n\u03b2 \u2212 d\n(2)\u2217\ni gi\u03a3\n\n\u22121\n\u03b2\n\nS:,iS\nH\n:,i\u03a3\n\n\u22121\n\u03b2\n\n1+d\n(2)\u2217\ni\n\ngiS\nH\n:,i\u03a3\n\n\u22121\n\u03b2\n\nS:,i\n\n.\n\n8: end\n\n9: end for\n\n10: until \u03b2 satisfies some stopping criterion.\n\nProof (Sketch): By (18), (20), and (\u03a3\u03b2+dgiS:,iS\nH\ni,:)\n\n\u22121 =\n\n\u03a3\u22121\n\u03b2 \u2212 dgi\u03a3\n\n\u22121\n\u03b2\n\nS:,iS\nH\ni,:\u03a3\n\n\u22121\n\u03b2\n\n1+dgiS\nH\ni,:\u03a3\n\n\u22121\n\u03b2\n\nS:,i\n[5], we show f\u0303 (2)(\u03b2 + dei) =\n\nf\u0303 (2)(\u03b2) + f\n(2)\n\u03b2,i(d). Thus, the problem in (23) is equivalent to\n\nmin\nd\u2208D(2)\n\ni\n\u222a{\u2212\u03b2i,1\u2212\u03b2i}\n\nf\n(2)\n\u03b2,i(d). Next, following the derivation of\n\n(22) in [5], we show\n(\nf\n(2)\n\u03b2,i(d)\n\n)\u2032\n\n=\ng\u03b2,i(d)\n\n(1+dgiS\nH\ni,:\u03a3\n\n\u22121\n\u03b2\n\nS:,i)2\n. Thus,\n\nthe optimal solution of min\nd\u2208D(2)\n\ni\n\u222a{\u2212\u03b2i,1\u2212\u03b2i}\n\nf\n(2)\n\u03b2,i(d) is given by\n\n(25). Therefore, we complete the proof.\n\nAs g\n(2)\n\u03b2,i(d) is a polynomial with degree 3, D(2)\n\ni can be\n\nobtained in closed-form with computational complexity O(P ).\nThe details of the coordinate descent algorithm are sum-\n\nmarized in Algorithm 2. If each coordinate optimization in\n\n(23) has a unique optimal solution, Algorithm 2 converges to\n\na stationary point of Problem 3 as the number of iteration\n\ngoes to infinity [10, Proposition 2.7.1]. The computational\n\ncomplexities of Step 4, Step 6, and Step 7 are O(L2), O(1),\nand O(L2), respectively. Thus, the computational complexity\n\nof each iteration of Algorithm 2 is O\n(\nNPL2\n\n)\n.\n\nV. NUMERICAL RESULTS\n\nIn this section, we evaluate the performance of the proposed\n\nMLE-based device activity detection methods given by Algo-\n\nrithm 1 and Algorithm 2, referred to as Prop.-MLE-Alg. 1 and\n\n\n\n1 2 3 4 5\n0\n\n0.01\n\n0.02\n\n0.03\n\n0.04\n\n0.05\n\n0.06\n\n0.07\n\nE\nrr\n\nor\n r\n\nat\ne\n\nBL-AMP\nBL-GL\nBL-MLE\nProp.-MLE-Alg. 2\nProp.-MLE-Alg. 1\n\n4\n\n0\n\n0.005\n\n(a) Number of channel taps P .\n\n54 60 66 72 78\n0\n\n0.01\n\n0.02\n\n0.03\n\n0.04\n\n0.05\n\n0.06\n\n0.07\n\nE\nrr\n\nor\n r\n\nat\ne BL-AMP\n\nBL-GL\nBL-MLE\nProp.-MLE-Alg. 2\nProp.-MLE-Alg. 1\n\n(b) Pilot length L.\n\nFig. 1: Error rate versus number of channel taps P and pilot length\nL.\n\nProp.-MLE-Alg. 2, respectively. We consider three baseline\n\nschemes, namely, BL-MLE, BL-GL, and BL-AMP, which are\n\nobtained by applying the existing MLE [6], GROUP LASSO\n\n[4], and AMP [2], proposed for flat Rayleigh fading, to detect\n\nthe activities of the NP virtual devices, \u03b2, without considering\n\nthe constraints in (14), and then setting the activities of the\n\nN actual devices, \u03b1, according to \u03b1n =\n\n\u2211\n\np\u2208P\n\n\u03b2(n\u22121)P+p\n\nP\n, n \u2208\n\nN . The thresholds for the MLE-based schemes and BL-\n\nGL are numerically optimized. The threshold for BL-AMP\n\nis chosen as in [2]. We generate pilots according to i.i.d.\n\nCN (0, IL) and normalize their norms to\n\u221a\nL [5], [6]. In the\n\nsimulation, we independently generate 1000 realizations for\n\n\u03b1n \u223c B(1000, 0.07), n \u2208 N , hn,m,p \u223c CN (0, 1), n \u2208 N ,\n\nm \u2208 M, p \u2208 P , and Gaussian pilots in each realization\n\nand evaluate the average error rate over all 1000 realizations.\n\nUnless otherwise stated, we choose N = 1000, L = 72,\n\nM = 128, P = 4, gn = 1, n \u2208 N , and \u03c32 = 0.1.\n\nFig. 1(a) and Fig. 1(b) plot the error rate versus the number\n\nof channel taps P and the pilot length L, respectively. From\n\nthe two figures, we can make the following observations. The\n\nMLE-based schemes significantly outperform the compressed\n\nsensing-based schemes, BL-AMP and BL-GL. Note that at\n\nsmall L, BL-AMP does not work properly, yielding a poor\n\nerror rate. The two proposed MLE-based schemes outperform\n\nBL-MLE, as they rigorously tackle the MLE problems. Prop.-\n\nMLE-Alg. 1 for solving Problem 1 with size N achieves a\n\nsmaller error rate than Prop.-MLE-Alg. 2 for solving Problem 3\n\nwith size NP , as a problem with a smaller size can be more\n\neffectively solved. Besides, the error rates of most schemes\n\nincrease with P and decrease with L. The slight increase of the\n\nerror rate of Prop.-MLE-Alg. 1 with P when P \u2265 3 is mainly\n\ndue to the numerical error for determining D(1)\nn , n \u2208 N . The\n\nincrease of the error rates of the other schemes with P derives\n\nfrom the increase in the number of virtual devices.\n\nFig. 2(a) and Fig. 2(b) plot the ratio between the compu-\n\ntation time of Prop.-MLE-Alg. 1 and the computation time of\n\nProp.-MLE-Alg. 2 versus the number of channel taps P at\n\ndifferent pilot lengths. Prop.-MLE-Alg. 1 has shorter compu-\n\ntation time than Prop.-MLE-Alg. 2 at small P , as the overall\n\ncomputation time for determining D(1)\nn , n \u2208 N analytically\n\nis short at small P . Prop.-MLE-Alg. 1 has larger computation\n\ntime than Prop.-MLE-Alg. 2 at large P , as the overall compu-\n\n8 10 12 14 16\n0.85\n\n1\n\n1.15\n\n1.3\n\nC\nom\n\npu\nta\n\ntio\nn \n\ntim\ne \n\nra\ntio\n\n(a) Length of channel taps P at\nL = 64 and M = 128.\n\n3 4 5 6 7 8\n0.8\n\n1\n\n1.2\n\n1.4\n\n1.6\n\n1.8\n\n2\n\nC\nom\n\npu\nta\n\ntio\nn \n\ntim\ne \n\nra\ntio\n\n(b) Length of channel taps P at\nL = 32 and M = 256.\n\nFig. 2: Computation time ratio versus number of channel taps P .\n\ntation time for determining D(2)\ni , i \u2208 I analytically is shorter\n\nat large P . When L is large, Prop.-MLE-Alg. 1 outperforms\n\nProp.-MLE-Alg. 2 at most practical values of P .\n\nVI. CONCLUSION\n\nIn this paper, we first presented an OFDM-based massive\n\ngrant-free access scheme for a wideband system. Then, we\n\nproposed two MLE-based device activity detection methods\n\nfor frequency-selective Rayleigh fading using statistical esti-\n\nmation and optimization techniques. The two proposed meth-\n\nods have different preferable system parameters and include\n\nthe existing MLE-based method for flat Rayleigh fading as\n\na special case. Conventional channel estimation methods can\n\nbe directly applied for channel estimation of detected active\n\ndevices under frequency selective Rayleigh fading, based on\n\na received pilot signal model derived in this paper.\n\nREFERENCES\n\n[1] L. Liu, E. G. Larsson, W. Yu, P. Popovski, C. Stefanovic, and E. de Car-\nvalho, \u201cSparse Signal Processing for Grant-Free Massive Connectivity:\nA Future Paradigm for Random Access Protocols in the Internet of\nThings,\u201d IEEE Signal Process. Mag., vol. 35, no. 5, pp. 88\u201399, Sept.\n2018.\n\n[2] L. Liu and W. Yu, \u201cMassive Connectivity With Massive MIMO-Part I:\nDevice Activity Detection and Channel Estimation,\u201d IEEE Trans. Signal\n\nProcess., vol. 66, no. 11, pp. 2933\u20132946, Jun. 2018.\n[3] K. S. Z. Qin and D. Goldfarb, \u201cEfficient block-coordinate descent\n\nalgorithms for the group lasso,\u201d Math. Program. Comput., vol. 5, no. 2,\npp. 340\u2013354, Jun. 2013.\n\n[4] Y. Cui, S. Li, and W. Zhang, \u201cJointly Sparse Signal Recovery and\nSupport Recovery via Deep Learning With Applications in MIMO-\nBased Grant-Free Random Access,\u201d IEEE J. Sel. Areas Commun.,\nvol. 39, no. 3, pp. 788\u2013803, Mar. 2021.\n\n[5] A. Fengler, S. Haghighatshoar, P. Jung, and G. Caire, \u201cNon-Bayesian\nActivity Detection, Large-Scale Fading Coefficient Estimation, and\nUnsourced Random Access With a Massive MIMO Receiver,\u201d IEEE\n\nTrans. Inf. Theory, vol. 67, no. 5, pp. 2925\u20132951, May 2021.\n[6] Z. Chen, F. Sohrabi, Y. Liu, and W. Yu, \u201cCovariance based joint activity\n\nand data detection for massive random access with massive MIMO,\u201d in\nProc. IEEE ICC, May 2019, pp. 1\u20136.\n\n[7] D. Jiang and Y. Cui, \u201cML and MAP Device Activity Detections for\nGrant-Free Massive Access in Multi-Cell Networks,\u201d be submitted to\n\nIEEE TWC, 2021.\n[8] J. Choi, \u201cOn Simultaneous Multipacket Channel Estimation and Recep-\n\ntion in Random Access for MTC Under Frequency-Selective Fading,\u201d\nIEEE Trans. Commun., vol. 66, no. 11, pp. 5360\u20135369, Jul. 2018.\n\n[9] W. Press, W. H, S. Teukolsky, W. Vetterling, S. A, and\nB. Flannery, Numerical Recipes 3rd Edition: The Art of Scientific\n\nComputing. Cambridge University Press, 2007. [Online]. Available:\nhttps://books.google.com/books?id=1aAOdzK3FegC\n\n[10] D. Bertsekas, Nonlinear Programming. Athena Scientific, 1999.\n\nhttps://books.google.com/books?id=1aAOdzK3FegC\n\n\tI Introduction\n\tII System Model\n\tIII MLE-based Device Activity Detection Using Coordinate Descent Method\n\tIII-A Problem Formulation\n\tIII-B Solution\n\n\tIV MLE-based Device Activity Detection Using Penalty Method and Coordinate Descent Method\n\tIV-A Problem Formulation\n\tIV-B Solution\n\n\tV Numerical Results\n\tVI Conclusion\n\tReferences\n\n"}
{"Title": "TransLog: A Unified Transformer-based Framework for Log Anomaly Detection", "Authors": "Hongcheng Guo, Xingyu Lin, Jian Yang, Yi Zhuang, Jiaqi Bai, Tieqiao Zheng, Bo Zhang, Zhoujun Li", "Abstract": "  Log anomaly detection is a key component in the field of artificial intelligence for IT operations (AIOps). Considering log data of variant domains, retraining the whole network for unknown domains is inefficient in real industrial scenarios especially for low-resource domains. However, previous deep models merely focused on extracting the semantics of log sequence in the same domain, leading to poor generalization on multi-domain logs. Therefore, we propose a unified Transformer-based framework for log anomaly detection (\\ourmethod{}), which is comprised of the pretraining and adapter-based tuning stage. Our model is first pretrained on the source domain to obtain shared semantic knowledge of log data. Then, we transfer the pretrained model to the target domain via the adapter-based tuning. The proposed method is evaluated on three public datasets including one source domain and two target domains. The experimental results demonstrate that our simple yet efficient approach, with fewer trainable parameters and lower training costs in the target domain, achieves state-of-the-art performance on three benchmarks.      ", "Subject": "Machine Learning (cs.LG)", "ID": "arXiv:2201.00016", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTRANSLOG: A Unified Transformer-based Framework for\nLog Anomaly Detection\n\nHongcheng Guo1\u2217 , Xingyu Lin4? , Jian Yang1 , Yi Zhuang2 , Jiaqi Bai1 , Tieqiao\nZheng3 , Liangfan Zheng3 , Weichao Hou3 , Bo Zhang3 , Zhoujun Li1\u2020\n1State Key Lab of Software Development Environment, Beihang University\n2Bio-robot and human-computer interaction laboratory, Waseda University\n\n3Cloudwise Research 4University of Southern California\n{hongchengguo, jiaya, jiaqi, lizj}@buaa.edu.cn, linxingy@usc.edu,\n\nsyouyi2020@asagi.waseda.jp {steven.zheng,liangfan.zheng,william.hou,bowen.zhang}@cloudwise.com\n\nAbstract\nLog anomaly detection is a key component in\nthe field of artificial intelligence for IT opera-\ntions (AIOps). Considering log data of variant do-\nmains, retraining the whole network for unknown\ndomains is inefficient in real industrial scenarios\nespecially for low-resource domains. However,\nprevious deep models merely focused on extract-\ning the semantics of log sequences in the same\ndomain, leading to poor generalization on multi-\ndomain logs. To alleviate this issue, we propose\na unified Transformer-based framework for Log\nanomaly detection (TRANSLOG), which is com-\nprised of the pretraining and adapter-based tuning\nstage. Our model is first pretrained on the source\ndomain to obtain shared semantic knowledge of log\ndata. Then, we transfer the pretrained model to the\ntarget domain via adapter-based tuning. The pro-\nposed method is evaluated on three public datasets\nincluding one source domain and two target do-\nmains. Experimental results demonstrate that our\nsimple yet efficient approach, with fewer trainable\nparameters and lower training costs in the target\ndomain, achieves state-of-the-art performance on\nthree benchmarks1.\n\n1 Introduction\nWith the rapid development of large-scale IT systems, numer-\nous companies have an increasing demand for high-quality\ncloud services. Anomaly detection [Breier and Branis\u030cova\u0301,\n2015] is a critical substage to monitoring data peculiarly for\nlogs, which describe detailed system events at runtime and\nthe intention of users in the large-scale services [Zhang et\nal., 2015]. The field of artificial intelligence for IT opera-\ntions (AIOps) [Dang et al., 2019] intends to empower IT op-\nerations by integrating advanced deep learning algorithms to\nmeet these challenges, which ensures the stability of company\ndata and maintain high efficiency simultaneously.\n\u2217Equal contribution.\n\u2020Corresponding author.\n1We will release the pretrained model and code.\n\nBGL:\n\ndata storage interrupt\n\nrts: kernel terminated for reason 1004rts: bad message header: [...]\n\nThunderbird: \n\nkernel: mptscsih: ioc0: attempting task abort! (sc=00000101bddee480)\n\nRed Storm: \n\nDMT 310 Command Aborted: SCSI cmd:2A LUN 2 DMT 310 T:299 a: [...]\n\nUnusual End of Program\n\nBGL: \n\nrts panic! - stopping execution\n\nThunderbird: \n\npbs mom: Bad file descriptor (9) in tm request, job [job] not running\n\nSpirit: \n\nkernel: GM: LANai is not running. Allowing port=0 open for debugging\n\nLiberty: \n\nkernel: GM: LANai is not running. Allowing port=0 open for debugging\n\nProgram Not Running\n\nFigure 1: The same anomaly from multiple domains. The top part\ndenotes the \u201cUnusual End of Program\u201d anomaly from three domains\nincluding BGL, Thunderbird, and Red Storm while the bottom part\nis the \u201cProgram Not Running\u201d from four domains including BGL,\nThunderbird, Spirit, and Liberty.\n\nLarge-scale services are usually implemented by hundreds\nof developers, it is error-prone to detect anomalous logs from\na local perspective. In this case, some automatic detection\nmethods based on machine learning are proposed [Xu et al.,\n2010]. Due to the development of IT services, the volume\nof log data has grown to the point where traditional ap-\nproaches are infeasible. Therefore, research has turned to\ndeep learning methods [Zhang et al., 2016; Du et al., 2017;\nZhang et al., 2019; Meng et al., 2019]. As log messages\nare half-structured and have their semantics, which is similar\nto natural language corpus, language models like LSTM and\nTransformer are leveraged to obtain semantics in logs. Re-\ncently proposed methods even adopt fashion pretrained mod-\nels like BERT [Devlin et al., 2018], GPT2 [Radford et al.,\n2018] for better embedding representation.\n\nWe observe that logs from different sources have the same\nanomalous categories. Despite being different in morphology\nand syntax, logs of multiple domains are semantically similar.\nFor example, in Figure 1, three sources (BGL, Thunderbird,\nRed Storm) all have the anomaly called the unusual end of\nprogram, thus we naturally think if the model can identify the\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n6v\n2 \n\n [\ncs\n\n.L\nG\n\n] \n 1\n\n7 \nJa\n\nn \n20\n\n22\n\n\n\nsame anomalies in all domains with shared semantic knowl-\nedge. However, existing approaches mostly focus on a single\ndomain, when new components from a different/similar do-\nmain are introduced to the system, they lack the ability to ac-\ncommodate such unseen log messages. In addition, we need\nto consider the continuous iteration of log data when system\nupgrades, which is costly to retrain different copies of the\nmodel. Therefore, a method based on transfer learning is re-\nquired to perform well on logs from multiple domains.\n\nIn this paper, we address the problems above via a two-\nstage solution called TRANSLOG. TRANSLOG is capable of\npreserving the shared semantic knowledge between different\ndomains. More specifically, we first create a neural network\nmodel based on the self-attention mechanism, which is pre-\ntrained on the source domain to obtain common semantics of\nlog sequences. Second, TRANSLOG utilizes a flexible plugin-\nin component called adapter to transfer knowledge from the\nsource domain to the target domain.\n\nGenerally, the main contributions of this work are listed as\nfollows: (i) We propose TRANSLOG, an end-to-end frame-\nwork using Transformer encoder architecture to automati-\ncally detect log anomalies. (ii) With only a few additional\ntrainable parameters on the target domain, TRANSLOG al-\nlows a high degree of parameter-sharing while reducing time\nand calculation consumption. (iii) Our TRANSLOG performs\nwell under different amounts of training data, especially when\nthe training data is low-resource. (iv) The proposed approach\nis evaluated against three public datasets: HDFS, BGL, and\nThunderbird. TRANSLOG reaches state-of-the-art perfor-\nmance on all these three datasets.\n\n2 Background\nLog Parsing The purpose of log parsing is to convert un-\nstructured log data into the structured event template by re-\nmoving parameters and keeping keywords [Jiang et al., 2008;\nMakanju et al., 2009]. The previous work Drain [He et al.,\n2017] adopts a fixed-depth tree structure to split the log data\nand extracts structured templates. Spell [Du and Li, 2016]\napplies the longest common subsequence algorithm to parse\nlogs efficiently. In Figure 2, we utilize Drain to extract all the\ntemplates, and then each log message and the corresponding\ntemplate is matched. Next, the whole log template sequence\nis fed into anomaly detection models.\n\nAdapter-based Tuning Adapter-based tuning [Houlsby et\nal., 2019; Bapna and Firat, 2019] is proved to be a parameter-\nefficient alternative in many NLP tasks. The structure of\nadapters is lightweight, which is usually composed of sim-\nple projection layers. Adapters are always inserted be-\ntween transformer layers [Vaswani et al., 2017]. When tun-\ning the model on downstream tasks, only the parameters\nof adapters are updated while the weights of the pretrained\nmodel are frozen. Thus, though utilizing much less trainable\nparameters compared to full fine-tuning [Devlin et al., 2018;\nStickland and Murray, 2019], adapter-based tuning reaches\ncomparable performance. In this paper, we design our adapter\nlayer as one down-projection layer, one activation layer, and\none up-projection layer in Figure 4.\n\n\ud835\udc3f1: TIMES 8 crond(pam_unix)[2915]: session closed for user root\n\n\ud835\udc3f2: TIMES dn228/dn228 crond(pam_unix)[2915]: session opened for user root by (uid=0)\n\n\ud835\udc3f3: TIMES (root) CMD (run-parts /etc/cron.hourly)\n\n\ud835\udc3f4: TIMES session closed for user root\n\n\ud835\udc3f5: TIMES session opened for user root by (uid=0)\n\n\ud835\udc3f1: session closed for user <*> \n\n\ud835\udc3f2: session opened for user <*> by <*>\n\n\ud835\udc3f3:(root) CMD (<*> <*>)\n\n\ud835\udc3f4: session closed for user <*> \n\n\ud835\udc3f5: session opened for user <*> by <*>\n\nUnstructured Logs\n\n\ud835\udc471: session closed for user <*> \n\n\ud835\udc472: session opened for user <*> by <*>\n\n\ud835\udc473: (root) CMD (<*> <*>)\n\n\ud835\udc3f1\n\ud835\udc3f2\n\ud835\udc3f3\n\ud835\udc3f4\n\ud835\udc3f5\n\nLog templates\n\nMapping Drain parsing\n\nStructured Inputs\n\nFormatting\n\nFigure 2: Logs and Templates. The top part is unstructured logs, we\nadopt Drain algorithm to extract log templates,then we match each\nlog with its template, which is the middle part. The bottom part is\nstructured inputs.\n\nLog Anomaly Detection There are two main methods for\nlog anomaly detection, including supervised and unsuper-\nvised methods. Supervised methods are often classification-\nbased methods [Breier and Branis\u030cova\u0301, 2015; Huang et al.,\n2020; Lu et al., 2018; Wittkopp et al., 2021b]. LogRo-\nbust [Zhang et al., 2019] utilizes both normal and abnor-\nmal log data for training based on the Bi-LSTM architec-\nture. Furthermore, Neurallog [Le and Zhang, 2021] uses\nBERT to transform raw log messages into semantic em-\nbeddings without log parsing. However, obtaining system-\nspecific labeled samples is costly and impractical. Some\nunsupervised methods [Xu et al., 2010; Yang et al., 2021;\nWittkopp et al., 2021a] have been proposed to alleviate such\nburden. DeepLog [Du et al., 2017] utilizes the LSTM net-\nwork to forecast the next log sequence with the ranked prob-\nabilities. Besides, LogAnomaly [Meng et al., 2019] utilizes\nthe embeddings of logs to capture the semantic information.\n\nAlthough these methods attain the improvement of perfor-\nmance, they ignore sharing semantics between multiple log\nsources, mainly focusing on tackling the single log source\nsetting. Our TRANSLOG leverages such semantic knowledge\nefficiently based on the Transformer-adapter architecture.\n\n3 TRANSLOG\n\nIn this section, we describe the general framework for log\nanomaly detection, named TRANSLOG. The architecture of\nthe TRANSLOG is shown in Figure 3, which contains two\nstages: pretraining and adapter-based tuning. The following\nparts start with the definition of the problem, and then the\ncomponents of the backbone model are presented. Afterward,\nwe illustrate the exhaustive procedure of two stages.\n\n3.1 Problem Definition\nLog anomaly detection problem is defined as a dichotomy\nproblem. The model is supposed to determine whether the in-\n\n\n\ninstruction cache parity error corrected\n<*> double-hummer alignment exceptions\n<*> double-hummer alignment exceptions\n\nLog Event Sequence\n\nSource Domain\n\nsession closed for user root\nsession opened for user root by (uid=<*>)\n(root) CMD <*> <*>\n\nClass Label \n(Normal/Abnomal)\n\nClassifier\n\nTransformer \nEncoder \n\nwith Adapter \n\nLog Event Sequence\n\n......\n\n......\n\nTarget Domain\n\nFeature \nExtractor\n\nTransformer \nEncoder\n\nClassifier\n\nClass Label \n(Normal/Abnomal)\n\nFeature \nExtractor\n\nPretrained   LM\n\nPretraining\n\nAdapter-based Tuning\n\nParameter Initialization\n\nFigure 3: Overview of our proposed architecture. All log event sequence is first fed into the pretrained language model to extract the\nrepresentations. The Transformer encoder is trained on the high-resource source-domain dataset to acquire shared semantic information.\nThen, we initialize the Transformer encoder and only tune the parameters of the adapter on the target-domain dataset to transfer the knowledge\nfrom the source domain to the target domain.\n\nput log is abnormal or normal. For the source domain, assum-\ning that through preprocessing, we achieve the vector repre-\nsentations ofKsrc log sequences, which is denoted as Ssrc =\n\n{Sk}Ksrc\n\nk=1 . Then, Ssrc\ni = {V src\n\nt }T\nsrc\ni\n\nt=1 denotes the i-th log se-\nquence, where T src\n\ni is the length of the i-th log sequence. For\nthe target domain, Stgt = {Stgt\n\nk }\nKtgt\n\nk=1 denotes the represen-\n\ntations of Ktgt log sequences. Stgt\nj = {V tgt\n\nt }\nT tgt\ni\n\nt=1 denotes\nthe i-th log sequence, where T tgt\n\ni is the length of the i-th\nlog sequence. Therefore, the training procedure is defined as\nfollows. We first pretrain the model on the source-domain\ndataset as below:\n\nfp(yi|Ssrc\ni ; \u0398)), (1)\n\nwhere fp represents the pretraining stage,\u0398 is the parameter\nof the model in pretraining stage. Then, the model is trans-\nferred to the target-domain as below:\n\nfa(yj |Ssrc\nj ; \u0398f , \u03b8a). (2)\n\nwhere fa represents the adapter-based tuning stage. \u0398f is\nthe parameter of the transformer encoder transferred from\nthe pretraining stage, which is frozen in adapter-based tuning\nstage. \u03b8a is the parameter of the adapter. y is the groundtruth.\nThrough Equation 1 and 2, TRANSLOG learns the semantic\nrepresentation of template sequences between domains.\n\n3.2 Backbone Model\nFeature Extractor The feature extractor converts session\nsequences (template sequence) to vectors with the same di-\nmension d. Here we use the pretrained sentence-bert[Reimers\nand Gurevych, 2019] model to get the template sequence rep-\nresentation. Recently some methods extract semantic repre-\nsentation from raw log messages, they believe it could prevent\nthe loss of information due to log parsing errors. However,\nembedding every log message is not realistic considering a\nlarge amount of log data. Studies also show that almost all\nanomalies could be detected by template sequence, even if\nthere are parsing errors. Thus, we only embed all existing\nlog templates. Each session has l fixed length, so through the\nlayer, we can obtain the X\u03b5Rl\u00d7d for each session.\n\nLayer Norm\n\nAdapter\n\nMulti-headed\n\nAttention\n\n+\n\nFFN\n\nAdapter\n\n+\n\nLayer Norm\n\nTransformer layer\n\n\u00d7N\n\nDown-projection\n\nUp-projection\n\n+Adapter\n\nFigure 4: Encoder with light adapter. Where N is the number of\ntransformer layers. The left part describes the traditional transformer\nencoder inserted by adapters, the right part is our light adapter,\nwhich is composed of the down- and up-projection layers.\n\nEncoder with Light Adapter As shown in Figure 4, To\nbetter encode the corresponding feature of inputs, we use the\ntransformer encoder as the backbone model. By doing so, our\nencoder with self-attention mechanism overcomes the limita-\ntions of RNN-based models. The core self-attention mecha-\nnism is formally written as:\n\nAttention(Q,K, V ) = softmax(\nQKT\u221a\nd/heads\n\n)V. (3)\n\nwhere heads is the number of the heads, d denotes the di-\nmension of the input, and Q,K, V represent queries, keys,\nand values, respectively.\n\nThe order of a log sequence conveys information of the\nprogram execution sequence. Wrong execution order is also\nconsidered abnormal. Thus, constant positional embedding\nis also used.Component after self-attention layer and feedfor-\nward layer is the adapter. It\u2019s a lightweight neural network be-\ntween the transformer layers. When tuning a pretrained lan-\nguage model to a new domain, adapters are inserted. During\nadapter-based tuning, only a few parameters of the adapters\nare updated on the target domain. More specifically, we use\ndown- and up-scale neural networks as the adapter. Two pro-\n\n\n\njection layers in adapter first map hidden vector from dimen-\nsion d to dimensionm and then map it back to d. The adapter\nalso has a skip-connection operation internally. The output\nvector h\u2032 of the adapter is calculated as follow:\n\nh\u2032 = Wuptanh(Wdownh) + h. (4)\n\nwhere h \u2208 Rd represents a given hidden vector. Wdown \u2208\nRm\u00d7d and Wup \u2208 Rd\u00d7m is the down-projection and the up-\nprojection matrix respectively, by setting m << d, we limit\nthe number of parameters added per adapter, which is the core\nto reduce trainable parameters while retaining semantic infor-\nmation to the maximum extent.\n\n3.3 Pretraining\nInspired by the BERT model [Devlin et al., 2018], which\ntakes a self-supervised method to learn general language fea-\ntures that further be utilized to serve different downstream\ntasks, we acquire the common reason for log anomaly with\nthe stacked transformer encoder. In this stage, the pretrained\nmodel learns the commonalities among different anomalies\nfrom the semantic level, which contributes significantly to\nthe anomalous detection for new log sources. More specifi-\ncally, the objective of this stage is the same as anomaly detec-\ntion, which is a supervised classification task without adapters\nin the model. Then, the parameters of the transformer en-\ncoder, which is trained during this stage, are shared to the\nnext stage. After parameter initialization, we freeze these pa-\nrameters during the adapter-based tuning stage.\n\n3.4 Adapter-based Tuning\nWhen tuning a pretrained model from the source domain\nto a target domain, the way of adapter-based tuning lever-\nages the knowledge obtained from the pretraining stage\nwith lightweight adapters, which are neural networks like\n[Houlsby et al., 2019]. In this paper, our adapter is com-\nposed of one down-projection layer, one activation layer, and\none up-projection layer in Figure 4. Through the pretraining\nstage, we achieve the pretrained model, thus in this second\nstage, we plug adapters into the transformer layers of the pre-\ntrained model, afterward, only the parameters of the adapters\nare updated during target domain adaption. Parameters of\nthe multi-headed attention and the feedforward layers in the\npretrained model are frozen. Unlike fine-tuning, TRANSLOG\nprovides a plug-in mechanism to reuse the pretrained model\nwith only a few additional trainable parameters, without up-\ndating the entire model for a new domain in this stage.\n\n3.5 Training Strategy\nIn this work, we both adopt BCE loss for two stages. Thus,\nwe define the objective loss of the pretraining stage as below.\n\nLp = \u2212Ex,y\u2208Dsrc\nx,y\n\n[logP (y|x; \u0398)], (5)\n\nwhereLp represents the loss in the pre-training stage. \u0398 is the\nparameter of the whole model in the pretraining stage. x and\ny are the input data and label respectively, Dsrc\n\nx,y represents\nthe data coming from the source domain. Then, we define the\nobjective loss in the adapter-based tuning stage as below.\n\nLa = \u2212Ex,y\u2208Dtgt\nx,y\n\n[logP (y|x; \u0398f , \u03b8a)]. (6)\n\nDataset Category #Messages #Anomaly #Templates\n\nHDFS Distributed 11M 17K 49\nBGL Supercomputer 5M 20K 423\nThunderbird Supercomputer 10M 123K 1292\n\nTable 1: A summary of the datasets used in this work. Messages are\nthe raw log strings. Samples are log sequences extracted by ID or\nsliding window of size 20.\n\nwhere La is the loss function in the adapter-based tuning\nstage. \u0398f is the parameter of the encoder module trained\nin the pretraining stage, which is frozen in the adapter-based\ntuning stage. \u03b8a is the parameter of the adapter. Dtgt\n\nx,y repre-\nsents the data coming from the target domain.\n\n4 Experiments\nIn this section, the comprehensive settings of the experiment\nare illustrated. Afterward, we experiment on three public\ndatasets coming from LogHub [He et al., 2020]. Compared\nwith baseline methods, our TRANSLOG reaches the state-of-\nthe-art performance on all datasets.\n\nDatasets We conduct experiments on three public datasets,\nwhich is described in Table 1. 10M/11M/5M continuous\nlog messages from Thunderbird/HDFS/BGL are separately\nleveraged, which is used in prior work [Yao et al., 2020;\nLe and Zhang, 2021]. HDFS [Xu et al., 2010] dataset is gen-\nerated and collected from the Amazon EC2 platform through\nrunning Hadoop-based map-reduce jobs. It contains mes-\nsages about blocks that assign a unique ID to the raw logs.\nThunderbird and BGL datasets[Oliner and Stearley, 2007]\ncontain logs collected from a two supercomputer system at\nSandia National Labs (SNL) in Albuquerque. The log con-\ntains alert and non-alert messages identified by alert category\ntags. Each log message in the datasets was manually labeled\nas anomalous or not.\n\nPreprocessing Different datasets require preprocessing\ncorrespondingly. We extract log sequences by block IDs for\nHDFS, since logs in HDFS with the same block ID are cor-\nrelated. BGL and Thunderbird do not have such IDs, so we\nutilize a sliding window(size of 20) without overlap to gener-\nate a log sequence. 1 shows the detail of datasets. We adopt\nDrain[He et al., 2017] with specifically designed regex to do\nlog parsing, due to its high efficiency. Number of anomaly is\ncounted based on window. Windows containing anomalous\nmessage are considered as anomalies, thus it\u2019s less than the\nnumber of anomalous log messages. For each dataset, we se-\nlect the first 80% (according to the timestamps of logs) log\nsequences for training and the rest 20% for testing.\n\nImplementation Details In the experiment, we try a dif-\nferent number of transformer encoder layers in {1, 2, 4}. The\nnumber of attention heads is 8, and the size of the feedforward\nnetwork that takes the output of the multi-head self-attention\nmechanism is 3072. We optimize using Adam way whose\nlearning rate is scheduled by OneCycleLR, with \u03b21 = 0.9,\n\u03b22 = 0.99, and \u03b5 = 10\u22128. All runs are trained on 4\nNVIDIA v100 with a batch size of 64. For each dataset,\n\n\n\nDataset Method Precision Recall F1 Score\n\nLR 0.96 0.91 0.93\nSVM 0.96 0.97 0.97\n\nDeepLog 0.95 0.96 0.96\nHDFS LogAnomaly 0.96 0.94 0.96\n\nLogRobust 0.98 0.98 0.98\nNeurallog 0.96 1 0.98\n\nTRANSLOG 0.99 0.99 0.99\nLR 0.78 0.79 0.78\n\nSVM 0.89 0.86 0.87\nDeepLog 0.90 0.83 0.86\n\nBGL LogAnomaly 0.97 0.94 0.96\nLogRobust 0.62 0.96 0.73\nNeuralLog 0.61 0.78 0.68\n\nTRANSLOG 0.98 0.98 0.98\nLR 0.46 0.91 0.61\n\nSVM 0.34 0.91 0.50\nDeepLog - - -\n\nThunderbird LogAnomaly 0.61 0.78 0.68\nLogrobust 0.61 0.78 0.68\nNeuralLog 0.93 1 0.96\n\nTRANSLOG 0.99 0.99 0.99\n\nTable 2: Experimental results compared with baseline models on\nThunderbird, BGL and HDFS. The best results are highlighted.\n\nwe tune the maximum learning of OneCycleLR scheduler in\n{1e\u2212 5, 5e\u2212 5, 1e\u2212 6}.\n\nBaselines and Evaluation We compare TRANSLOG with\nthe six baseline methods, including Logistic Regression(LR),\nSupport Vector Machine(SVM), Deeplog [Du et al., 2017],\nLogAnomaly [Meng et al., 2019], LogRobust [Zhang et al.,\n2019] and Neurallog [Le and Zhang, 2021] on the three\ndatasets. These methods are in two categories: machine\nlearning and neural network approaches. Traditional ap-\nproaches usually build models by transforming the log se-\nquence into log count vectors while neural network ap-\nproaches leverage word or contextual embeddings to repre-\nsent log sequences. In our experiments, we use precision\n( TP\nTP+FP ), recall ( TP\n\nTP+FN ) and F1 score ( 2\u2217Precision\u2217Recall\nPrecision+Recall )\n\nto compare our method and previous baselines.\n\nMain Results To test the effectiveness of TRANSLOG, we\ncompare the proposed algorithm with baseline methods on\nHDFS, Thunderbird, and BGL benchmarks. As is shown in\nTABLE. 2. Our TRANSLOG achieves the highest F1 score\non all three datasets, confirming the effectiveness and gener-\nalization of TRANSLOG. To obtain our main results, BGL\nis pretrained as the source domain in the first stage, while\nHDFS and Thunderbird are selected as the target domain in\nthe adapter-based tuning stage. We provide a thorough anal-\nysis of our model in Section 5.\n\n5 Analysis\nIn this section, we conduct the ablation study in four aspects\nfor a penetrating analysis of TRANSLOG, including the ef-\nfect of the pretrained model, the gap between pretrained log\nmodels, the efficiency of adapter-based tuning, and the low-\nresource study.\n\nEffect of Pretrained Log Model To demonstrate the fea-\nsibility of transferring semantic information between various\n\n0\n\n5\n\n10\n\n15\n\n20\n\nLo\nss\n\nHDFS\nfrom scratch\nfine-tuning\n\n0\n\n20\n\n40\n\n60\n\nLo\nss\n\nThunderbird\n\n7.3k steps0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nF1\n S\n\nco\nre\n\n6.3k steps0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\nF1\n S\n\nco\nre\n\nFigure 5: Loss and F1 score on the dev set w.r.t training steps. The\nleft/right part represents Loss/F1 score of the HDFS/Thunderbird.\nWe compare two ways of training including training from scratch\nand fine-tuning from model pretrained on BGL. All results are using\n1-layer Transformer encoder and the same learning rate.\n\ndomains, we compare the performance of two training tech-\nniques, namely training from scratch and fine-tuning. Here,\nthe way of fine-tuning is to update the parameter of the whole\npretrained model. We choose BGL as the source domain for\nits variety in log templates and its huge data volume. Besides,\nfrom the perspective of system kinds, HDFS is a distributed\nsystem while Thunderbird is a supercomputer system similar\nto BGL. Thus, experiments on such different log data distri-\nbutions can demonstrate both the transferability of semantic\nknowledge and the effectiveness of TRANSLOG.\n\nWe compare two methods in terms of their rate of con-\nvergence and final results. Figure 5 displays the loss curves\nand F1 score curves w.r.t training steps. The results show\nthat fine-tuning converges faster than training from scratch,\nwhich demonstrates that semantic knowledge the pretrained\nmodel learned is valuable, besides it also shows the power\nof the model to transfer information between domains. We\nfurthermore discover that fine-tuning is more stable with a\nsmoother curve, which is more obvious on Thunderbird, illus-\ntrating that similar domains share semantics more efficiently.\n\nDue to TRANSLOG achieves good performance even\ntrained from scratch, the final F1 scores of two methods are\nclose. By observing the F1 score curve, we discover that fine-\ntuning requires fewer training steps to gain the best result,\nwhich is noteworthy for reducing costs in industrial scenes.\n\nGap between Pretrained Log Models We analyzed the ef-\nfectiveness of the pretrained log model. The experimental\nresults show the feasibility of pre-training, but we can not\nexplain whether the performance improvement comes from\nthe pretraining way or the pretrained model itself. Therefore,\nin this part, we adopt different pretrained log models to ana-\nlyze the gap between pretrained log models. Specifically, we\nutilize BGL and Thunderbird as the source data respectively.\nFigure 6 shows the loss curves of the two training strategies\n\n\n\n0\n\n5\n\n10\n\n15\n\n20\n\n25\nLo\n\nss\nHDFS\n\nfrom scratch\nfine-tuning\n\n0\n\n20\n\n40\n\n60\n\nLo\nss\n\nThunderbird\n\n7.3k steps0\n\n5\n\n10\n\n15\n\n20\n\n25\n\nLo\nss\n\nHDFS\n\n6.3k steps0\n\n20\n\n40\n\n60\n\nLo\nss\n\nBGL\n\nFigure 6: Loss on the dev set w.r.t training steps. The upper/bottom\nresults are based on parameters pretrained on BGL/Thunderbird,\nthus BGL/Thunderbird are not shown. All results are using 1-layer\nTransformer encoder and the same learning rate.\n\non the target source. From the curves, we can see that the fine-\ntuning loss of each model decreases faster than training from\nscratch. At the same time, comparing the two pre-training\nmodels, it is obvious that, for the HDFS dataset, the model\npretrained on BGL brings greater performance improvement.\nIn conclusion, different pre-training models provide different\ngains for model performance, which is the gap between pre-\ntrained log models.\nEfficiency of Adapter-based Tuning Although we have\nverified that parameters transfer could accelerate convergence\nwithout reducing performance, fine-tuning each component\nis expensive and inconvenient. Thus, we adopt a parameter-\nefficient strategy, called adapter-based tuning, to allow a high\ndegree of sharing knowledge between domains. By utilizing\nthe adapter, we acquire a compact model for log anomaly de-\ntection by adding a few additional parameters.\n\nTo confirm the efficiency of our TRANSLOG, general trans-\nfer performance of fine-tuning and adapter-based tuning are\ncompared. Experiments are based on a model trained on the\nBGL and Thunderbird datasets. On each dataset, we utilize\nbatch size 64 and tune the model in learning rate selected\nfrom {1e\u2212 5, 5e\u2212 5, 1e\u2212 6}. Results show that 5e\u2212 5 is the\nmost satisfactory for HDFS, 1e\u22125 is the best for Thunderbird.\nWe conduct the ablation study by adjusting the number of en-\ncoder layers in {1, 2, 4}. Table 3 summarizes the results. We\nobserve that our TRANSLOG with adapters generates a com-\npetitive score but adopts 3.5%\u22125.5% of the parameters in the\nwhole original model. In addition, experiments on the various\nnumber of transformer encoders are executed. Results indi-\ncate that more encoder layers for fine-tuning do not always\ngenerate better results. Simultaneously, adapter-based tuning\nperforms more robust when we stack more encoder layers.\nLow-resource Study To verify the influence of training\nsize, we plot the performances with a varying number of\ntraining samples in Figure 7. It presents the comparison re-\n\nMethod Layers Parameters HDFS Thunderbird\n\n1 7.2M 0.998 0.997\nFine-tuning 2 14.3M 0.998 0.997\n\n4 28.5M 0.997 0.998\n\n1 0.4M 0.997 0.990\nAdapter 2 0.6M 0.997 0.996\n\n4 1M 0.998 0.996\n\nTable 3: Transfer result using fine-tuning and adapter based fine-\ntuning. Layers is the number of transformer encoder layers. Param-\neters is the number of trainable parameters in the model.\n\nsults on the BGL dataset. We consider tasks with fewer than\n50k training examples as low-resource tasks, as log data is\neasy to obtain and be labeled manually. We train models for\n30 epochs to make sure they are sufficiently trained.\n\nWe find that adapter-based tuning consistently outperforms\ntraining and fine-tuning. The improvement is more significant\nwhen the training size is small. With the number of train-\ning samples increasing, both methods will gradually catch up\nand finally achieve similar results. Another finding is that the\nquality of the model across runs is more robust, with a sim-\nilar standard deviation across different training sizes. How-\never, training and fine-tuning yield large variances when the\nnumber of the training sample is 5k and 20k.\n\nTo summarize, adapter tuning is highly parameter-efficient,\nand shared parameters contain semantic information that\nhelps the model to detect anomalies. Training adapters with\nsizes less than 5%, performance decreases nearly 1%.\n\n5k 10k 20k 50k\nTraining Samples\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\nF1\n S\n\nco\nre\n\nfrom scratch\nfine-tuning\nadapter\n\nFigure 7: Test performance on BGL (pretrained on Thunderbird)\nw.r.t.the number of training examples. 5k, 10k, 20k, 50k correspond-\ning to the font 2.5%, 5%, 10%, 25% training data respectively. We\nshow mean and standard deviation across 3 runs for all methods.\n\n6 Conclusion\nIn this paper, we propose TRANSLOG, a unified transformer-\nbased framework for log anomaly detection, which contains\nthe pretraining stage and the adapter-based tuning stage. Ex-\ntensive experiments demonstrate that our TRANSLOG, with\nfewer trainable parameters and lower training costs, outper-\nforms all previous baselines. We foresee the semantic migra-\ntion between log sources for a unified multiple sources detec-\ntion.\n\n\n\nReferences\n[Bapna and Firat, 2019] Ankur Bapna and Orhan Firat. Sim-\n\nple, scalable adaptation for neural machine translation. In\nEMNLP 2019, pages 1538\u20131548, 2019.\n\n[Breier and Branis\u030cova\u0301, 2015] Jakub Breier and Jana\nBranis\u030cova\u0301. Anomaly detection from log files using\ndata mining techniques. In Information Science and\nApplications. 2015.\n\n[Dang et al., 2019] Yingnong Dang, Qingwei Lin, and Peng\nHuang. Aiops: real-world challenges and research innova-\ntions. In ICSE 2019, 2019.\n\n[Devlin et al., 2018] Jacob Devlin, Ming-Wei Chang, Ken-\nton Lee, and Kristina Toutanova. Bert: Pre-training of\ndeep bidirectional transformers for language understand-\ning. NAACL 2019, 2018.\n\n[Du and Li, 2016] Min Du and Feifei Li. Spell: Streaming\nparsing of system event logs. In ICDM 2016, 2016.\n\n[Du et al., 2017] Min Du, Feifei Li, Guineng Zheng, and\nVivek Srikumar. Deeplog: Anomaly detection and diag-\nnosis from system logs through deep learning. In CCS\n2017, 2017.\n\n[He et al., 2017] Pinjia He, Jieming Zhu, Zibin Zheng, and\nMichael R Lyu. Drain: An online log parsing approach\nwith fixed depth tree. In ICWS 2017, pages 33\u201340, 2017.\n\n[He et al., 2020] Shilin He, Jieming Zhu, Pinjia He, and\nMichael R. Lyu. Loghub: A large collection of sys-\ntem log datasets towards automated log analytics. CoRR,\nabs/2008.06448, 2020.\n\n[Houlsby et al., 2019] Neil Houlsby, Andrei Giurgiu, Stanis-\nlaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe,\nAndrea Gesmundo, Mona Attariyan, and Sylvain Gelly.\nParameter-efficient transfer learning for nlp. In ICML\n2019, 2019.\n\n[Huang et al., 2020] Shaohan Huang, Yi Liu, Carol Fung,\nRong He, Yining Zhao, Hailong Yang, and Zhongzhi\nLuan. Hitanomaly: Hierarchical transformers for anomaly\ndetection in system log. TNSM, 17(4):2064\u20132076, 2020.\n\n[Jiang et al., 2008] Zhen Ming Jiang, Ahmed E. Hassan, Par-\nminder Flora, and Gilbert Hamann. Abstracting execution\nlogs to execution events for enterprise applications (short\npaper). In QSIC 2008, pages 181\u2013186, 2008.\n\n[Le and Zhang, 2021] Van-Hoang Le and Hongyu Zhang.\nLog-based anomaly detection without log parsing. arXiv\npreprint arXiv:2108.01955, abs/2108.01955, 2021.\n\n[Lu et al., 2018] Siyang Lu, Xiang Wei, Yandong Li, and\nLiqiang Wang. Detecting anomaly in big data system logs\nusing convolutional neural network. In DASC 2018, pages\n151\u2013158, 2018.\n\n[Makanju et al., 2009] Adetokunbo Makanju, A. Nur Zincir-\nHeywood, and Evangelos E. Milios. Clustering event logs\nusing iterative partitioning. In KDD 2009, pages 1255\u2013\n1264, 2009.\n\n[Meng et al., 2019] Weibin Meng, Ying Liu, Yichen Zhu,\nShenglin Zhang, Dan Pei, Yuqing Liu, Yihao Chen, Ruizhi\n\nZhang, Shimin Tao, Pei Sun, et al. Loganomaly: Unsuper-\nvised detection of sequential and quantitative anomalies in\nunstructured logs. In IJCAI 2019, 2019.\n\n[Oliner and Stearley, 2007] Adam J. Oliner and Jon Stearley.\nWhat supercomputers say: A study of five system logs. In\nDSN 2007, pages 575\u2013584, 2007.\n\n[Radford et al., 2018] Alec Radford, Karthik Narasimhan,\nTim Salimans, and Ilya Sutskever. Improving language\nunderstanding by generative pre-training. 2018.\n\n[Reimers and Gurevych, 2019] Nils Reimers and Iryna\nGurevych. Sentence-bert: Sentence embeddings us-\ning siamese bert-networks. In EMNLP 2019, pages\n3980\u20133990, 2019.\n\n[Stickland and Murray, 2019] Asa Cooper Stickland and Iain\nMurray. BERT and pals: Projected attention layers for\nefficient adaptation in multi-task learning. In ICML 2019,\npages 5986\u20135995, 2019.\n\n[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki\nParmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin. Attention is all you\nneed. NIPS 2017, 2017.\n\n[Wittkopp et al., 2021a] Thorsten Wittkopp, Alexander\nAcker, Sasho Nedelkoski, Jasmin Bogatinovski, Dominik\nScheinert, Wu Fan, and Odej Kao. A2log: Attentive\naugmented log anomaly detection. CoRR, 2021.\n\n[Wittkopp et al., 2021b] Thorsten Wittkopp, Philipp Wies-\nner, Dominik Scheinert, and Alexander Acker. Loglab:\nAttention-based labeling of log data anomalies via weak\nsupervision. In ICSOC 2021, pages 700\u2013707, 2021.\n\n[Xu et al., 2010] Wei Xu, Ling Huang, Armando Fox, David\nPatterson, and Michael I Jordan. Detecting large-scale sys-\ntem problems by mining console logs. In ICML 2010,\n2010.\n\n[Yang et al., 2021] Lin Yang, Junjie Chen, Zan Wang, Wei-\njing Wang, Jiajun Jiang, Xuyuan Dong, and Wenbin\nZhang. Semi-supervised log-based anomaly detection via\nprobabilistic label estimation. In ICSE 2021, pages 1448\u2013\n1460, 2021.\n\n[Yao et al., 2020] Kundi Yao, Heng Li, Weiyi Shang, and\nAhmed E. Hassan. A study of the performance of general\ncompressors on log files. ESE, 25(5):3043\u20133085, 2020.\n\n[Zhang et al., 2015] Shenglin Zhang, Ying Liu, Dan Pei,\nYu Chen, Xianping Qu, Shimin Tao, and Zhi Zang. Rap-\nidand robust impact assessment of software changes in\nlarge internet-based services. In ENET 2015, 2015.\n\n[Zhang et al., 2016] Ke Zhang, Jianwu Xu, Martin Renqiang\nMin, Guofei Jiang, Konstantinos Pelechrinis, and Hui\nZhang. Automated it system failure prediction: A deep\nlearning approach. In BigData 2016, 2016.\n\n[Zhang et al., 2019] Xu Zhang, Yong Xu, Qingwei Lin,\nBo Qiao, Hongyu Zhang, Yingnong Dang, Chunyu Xie,\nXinsheng Yang, Qian Cheng, Ze Li, et al. Robust log-\nbased anomaly detection on unstable log data. In FSE\n2019, 2019.\n\n\n\t1 Introduction\n\t2 Background\n\t3 TransLog\n\t3.1 Problem Definition\n\t3.2 Backbone Model\n\t3.3 Pretraining\n\t3.4 Adapter-based Tuning\n\t3.5 Training Strategy\n\n\t4 Experiments\n\t5 Analysis\n\t6 Conclusion\n\n"}
{"Title": "Fast ultrametric matrix-vector multiplication", "Authors": "Tobias Hofmann, Andy Oertel", "Abstract": "  We study the properties of ultrametric matrices aiming to design methods for fast ultrametric matrix-vector multiplication. We show how to encode such a matrix as a tree structure in quadratic time and demonstrate how to use the resulting representation to perform matrix-vector multiplications in linear time. Accompanying this article, we provide an implementation of the proposed algorithms and present empirical results on their practical performance.      ", "Subject": "Numerical Analysis (math.NA)", "ID": "arXiv:2201.00017", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n7v\n1 \n\n [\nm\n\nat\nh.\n\nN\nA\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\nFast ultrametric matrix-vector multiplication\n\nTobias Hofmann1, Andy Oertel2\n\nChemnitz University of Technology\n1tobias.hofmann@math.tu-chemnitz.de,\n\nLund University\n2andy.oertel@cs.lth.se\n\nAbstract. We study the properties of ultrametric matrices aiming to\ndesign methods for fast ultrametric matrix-vector multiplication. We\nshow how to encode such a matrix as a tree structure in quadratic\ntime and demonstrate how to use the resulting representation to per-\nform matrix-vector multiplications in linear time. Accompanying this\narticle, we provide an implementation of the proposed algorithms and\npresent empirical results on their practical performance.\n\nKeywords. ultrametric matrices, tree representations, fast matrix-\nvector multiplication\n\nMSC Subject classification. 05-08, 15-04, 15B99, 68R10, 05C50\n\n1 Introduction\n\nUltrametricity is a remarkable, occasionally a little counterintuitive, but often nat-\nural and interesting property. Examples in which ultrametric distances arise range\nfrom the p-adic number system to phylogenetic trees, which is illustrated nicely\nby Holly [10]. Accordingly, ultrametric matrices appear in various mathematical\nfields. The monograph of Dellacherie, Mart\u00ednez, and Mart\u00edn [2] describes how\nultrametric matrices are related to M-matrices and underlines their relevance in\ndiscrete potential theory or the analysis of Markov chains. Another remarkable\nproperty, established by Mart\u00ednez, Michon, and San Mart\u00edn in [13], is that ultra-\nmetric matrices are nonsingular and their inverses are strictly diagonally dominant\nStieltjes matrices. We learned about their rich properties while investigating edge-\nconnectivity matrices, whose off-diagonal entries satisfy an ultrametric inequality.\nThis is a classical result of Gomory and Hu [7], which links ultrametricity with\n\n1\n\nhttp://arxiv.org/abs/2201.00017v1\n\n\ntopics from combinatorics and spectral graph theory, as is discussed in Hofmann\nand Schwerdtfeger [9]. Furthermore, ultrametric matrices play a role in statistics\nand data analysis. Chehreghani [1] develops a machine learning framework that\nbuilds on minimax, and herewith ultrametric, distance measures. Lauritzen, Uh-\nler, and Zwiernik [11] show that ultrametric matrices are relevant in maximum\nlikelihood estimation problems for specific Gau\u00dfian distributions. Another exam-\nple is an ultrametric spectral clustering approach developed by Little, Maggioni,\nand Murphy [12].\n\nAs interest in applications involving ultrametric matrices grows, the question of\nhow to perform efficient ultrametric matrix computations arises. This is the focus\nof this article. Building on the well-known fact that ultrametric matrices are\ncompletely reducible, our main contributions are explicit algorithmic ideas how to\nencode an ultrametric matrix as its associated tree structure and how to use this\ndata structure to perform fast ultrametric matrix-vector multiplications.\n\nOutline. We review basic facts about ultrametric matrices and point out how\nthese matrices are related to tree structures in Section 2. Section 3 is about\nutilizing these data structures to perform fast matrix-vector multiplications. In\nSection 4, we summarize results about the performance of the methods we propose.\nAccompanying our computational insights, we provide an implementation of our\nalgorithms.\n\nWe conclude this section with certain concepts and notations that are particularly\nimportant for our investigation. We use 1 to denote the all ones column vector\nof appropriate dimensions. The symbol ei represents the standard column basis\nvector of appropriate dimensions, whose entries are defined via (ei)j := 1 if i = j\n\nand (ei)j := 0 if i 6= j. For a matrix A \u2208 R\nn\u00d7n, we use index sets I, J \u2282 {1, . . . , n}\n\nto specify AIJ as the submatrix that contains those rows of A that belong to the\nindices in I and those columns of A that belong to indices in J . If I = J , we\nmay use the shorthand AI instead of AII = AIJ . We denote diagonal matrices\nwhose entries are given by a sequence (ai)\n\nn\ni=1 by diag(ai : i = 1, . . . , n). For graph\n\ntheoretical terminology, we refer to the monograph of Diestel [3].\n\n2 Basic Properties of ultrametric matrices\n\nThe investigation of ultrametric matrices gained in importance with the article by\nMart\u00ednez, Michon, and San Mart\u00edn [13] who give in essence the following definition.\n\n2\n\n\n\nDefinition 2.1. A nonnegative symmetric matrix A = [aij ] \u2208 R\nn\u00d7n is said to be\n\nultrametric if it satisfies the inequalities\n\n(a) aij \u2265 min{aik, akj} for all i 6= j 6= k 6= i,\n\n(b) aii \u2265 max{aij : j \u2208 {1, . . . , n} \\ {i}} for all i.\n\nThe inequalities in (a) are known as ultrametric inequalities and a matrix that sat-\nisfies (b) is referred to as column pointwise diagonal dominant. If A satisfies (a),\nbut not necessarily (b), we call A essentially ultrametric. If A satisfies the in-\nequalities in (b) with equality, we call A special ultrametric, and if A satisfies the\ninequalities in (b) strictly, we call A strictly ultrametric. A matrix of size n = 1 is\nstrictly ultrametric only if its entry is positive, whereas there is no such convention\nfor special or essentially ultrametric matrices.\n\nThe focus in the article of Mart\u00ednez, Michon, and San Mart\u00edn [13] is on strictly ul-\ntrametric matrices, whereas Fiedler [4] studied special ultrametric matrices, which\ncan be seen as extremal matrices in the boundary of the set of ultrametric matri-\nces. The term essentially ultrametric is to emphasize situations in which specific\ndiagonal entries are not of interest. For example, this is the case for the edge-\nconnectivity matrices in [9]. A central property of strictly ultrametric matrices is\nthat they are nonsingular and their inverses are diagonally dominant M-matrices.\nMart\u00ednez, Michon, and San Mart\u00edn prove this fact in [13] by probabilistic argu-\nments. A linear algebra proof is given by Nabben and Varga [14]. Their arguments\nessentially rely on the fact that ultrametric matrices are completely reducible, which\nis what they state in the following way.\n\nTheorem 2.2. Let A = [aij ] be a nonnegative symmetric matrix in R\nn\u00d7n. If n > 1,\n\nthen A is essentially ultrametric if and only if there is an integer k with 1 \u2264 k < n\n\nand a suitable permutation matrix P \u2208 R\nn\u00d7n such that\n\nP\n(\n\nA\u2212min{aij : i 6= j}11\u22a4\n)\n\nP \u22a4 =\n\n[\n\nB 0\n0 C\n\n]\n\n,\n\nwhere B and C are essentially ultrametric matrices in R\nk\u00d7k and R\n\n(n\u2212k)\u00d7(n\u2212k),\nrespectively.\n\nNote that in [14] the above statement is formulated for a strictly ultrametric ma-\ntrix A. In this case, the matrices B and C follow to be strictly ultrametric as\nwell. However, the idea of the proof presented in [14] actually does not require\nany particular diagonal entries. Fiedler [4], for example, follows the same line of\nreasoning to obtain Theorem 2.2 except that A, B, and C are special ultrametric.\nIn our statement above, we simply ignore the diagonal entries of A and accord-\ningly claim nothing about the diagonal entries of B and C. Also note that whereas\n\n3\n\n\n\nTheorem 2.2 only states the existence of a suitable integer k and a permutation\nmatrix P , the focus of this article is on algorithms to determine P explicitly. The\nfollowing simple but useful observation is our first step in that direction.\n\nLemma 2.3. In each row and column of an essentially ultrametric matrix A = [aij]\nthere is an entry equal to min{aij : i 6= j}.\n\nProof. Theorem 2.2 tells us that there is an entry equal to zero in each row and\ncolumn of P\n\n(\n\nA\u2212min{aij : i 6= j}11\u22a4\n)\n\nP \u22a4, where P is some permutation matrix.\nPermuting rows and columns, however, preserves this property. So there is an\nentry equal to zero in each row and column of A\u2212min{aij : i 6= j}11\u22a4. In other\nwords, there is an entry equal to min{aij : i 6= j} in each row and column of A.\n\nTheorem 2.2 essentially is a decomposition statement showing that there is a tree\nstructure inherent in an ultrametric matrix. Lemma 2.3 emphasizes the fact that\nwe can find the global minimum of the off-diagonal entries of an ultrametric matrix\nin each of its rows or columns. This is the reason why we may process such a\nmatrix row by row when asking for its underlying tree structure. For the explicit\n\nAlgorithm 1 Ultrametric Tree Construction\n\nInput: essentially ultrametric matrix A = [aij ] \u2208 R\nn\u00d7n\n\nOutput: ultrametric tree (V, E) associated with A\n\n1: V \u2190 {r}\n2: E \u2190 \u2205\n3: I(r)\u2190 {1, . . . , n}\n4: TreeRecursion(r)\n\n5: procedure TreeRecursion(u)\n6: i\u2190 min(I(u))\n7: if |I(u)| = 1 then\n\n8: f(u)\u2190 aii\n\n9: else\n\n10: f(u)\u2190 min{aij : j \u2208 I(u) \\ {i}}\n11: V \u2190 V \u222a {v, w}\n12: E \u2190 E \u222a {(u, v), (u, w)}\n13: I(v) \u2190 {j \u2208 I(u) : aij > f(u)} \u222a {i}\n14: I(w)\u2190 {j \u2208 I(u) \\ {i} : aij = f(u)}\n15: TreeRecursion(v)\n16: TreeRecursion(w)\n\n4\n\n\n\nA =\n\n\uf8ee\n\n\uf8ef\n\n\uf8ef\n\n\uf8ef\n\n\uf8f0\n\n0 1 3 1\n1 3 1 2\n3 1 5 1\n1 2 1 1\n\n\uf8f9\n\n\uf8fa\n\n\uf8fa\n\n\uf8fa\n\n\uf8fb\n\nr\n\nu a\n\nv w b c\n\nI(r)={1, 2, 3, 4} f(r)=1\n\nI(u)={1, 3} f(u)=3 I(a)={2, 4} f(a)=2\n\nI(v)={1}\nf(v)=0\n\nI(w)={3}\nf(w)=5\n\nI(b)={2}\nf(b)=3\n\nI(c)={4}\nf(c)=1\n\nFigure 1: An essentially ultrametric matrix A and its associated tree constructed\nby Algorithm 1\n\ncomputation of a tree (V, E) associated with an ultrametric matrix, we propose\nAlgorithm 1. Here, an edge ij \u2208 E is to be understood as directed and we address i\n\nas parent and j is its child. Furthermore, each vertex u \u2208 V takes an index set I(u)\nand a value f(u). For an example of how Algorithm 1 works, we may take a\nlook at Figure 1. It shows an essentially ultrametric matrix A and the tree that\nresults when applying Algorithm 1 to it. It is indeed possible to go on pruning the\nresulting tree while retaining all the information about the matrix A by contracting\na vertex v and its parent u if f(u) = f(v). This may be useful in some situations\nand is an option our implementation supports. In general, however, pruning may\nnot be possible at all and as it would otherwise overcomplicate our notation, we\nconsider unpruned trees when analyzing the characteristics of Algorithm 1.\n\nTheorem 2.4. Algorithm 1 that has been given an essentially ultrametric ma-\ntrix A = [aij ] \u2208 R\n\nn\u00d7n as input terminates after 2n\u22121 recursion calls and its output\nis a rooted directed tree (V, E) in which each vertex can be reached from the root r\n\nby a unique directed path. Moreover, the tree (V, E) has the following properties.\n\n(i) A submatrix AI(u) is essentially ultrametric for each u \u2208 V .\n\n(ii) For each i \u2208 {1, . . . , n}, there is a leaf u \u2208 V with I(u) = {i} and f(u) = aii.\n\n(iii) If u has a child v, then f(u) = aij for all i \u2208 I(v) and all j \u2208 I(u) \\ I(v).\n\nProof. At first, we examine that for a vertex u with index set I(u) of size |I(u)| \u2265 2\na recursion step of Algorithm 1 sets i = min(I(u)), f(u) = min{aij : j \u2208 I(u)\\{i}},\nand divides the set I(u) into two subsets\n\nI(v) = {j \u2208 I(u) : aij > f(u)} \u222a {i} and\n\nI(w) = {j \u2208 I(u) \\ {i} : aij = f(u)}.\n\n5\n\n\n\nSo we conclude that I(v) 6= \u2205, I(w) 6= \u2205, I(v)\u2229 I(w) = \u2205, and I(u) = I(v) \u222a I(w).\nThis means that subsequent recursion steps operate on a nonempty, but smaller\nindex set. This also implies that Algorithm 1, initializing I(u) = {1, . . . , n} in\nLine 3, has to process n\u2212 1 recursion steps that run through their else case to\ndecompose the initial index set completely and eventually, the recursion is called\nwith input u for which I(u) = {i} for each i \u2208 {1, . . . , n} at some point. This\nleads into the recursion\u2019s if case and thus causes the respective recursion branch to\nterminate. In such a case, the algorithm assigns f(u) = aii by Line 8, which proves\nStatement (ii). Since this happens n times, we count a total of 2n \u2212 1 recursion\nsteps.\n\nThe graph (V, E) that Algorithm 1 constructs is initialized by V = {r} and E = \u2205\nin Lines 1 and 2. This graph gets assigned new vertices and edges only in the else\ncase of our recursion and there we always append two vertices by two edges to\nthe graph constructed up to that point. This provides us with a connected graph\nthat contains 2n\u2212 1 vertices and 2n\u2212 2 edges. So Algorithm 1 outputs a tree and\nsince the direction in which the edges are included follows exactly the layout of\nthe recursion tree, we find the vertex r that is initialized in line 1 to be the root,\nfrom which all other vertices can be reached by a unique directed path.\n\nTo prove Statement (i), we proceed inductively. We are given that AI(r) = A is\nessentially ultrametric. So let us consider a recursion step with input u for which\nwe suppose that |I(u)| \u2265 2 and AI(u) is essentially ultrametric. Denoting \u2113 := |I(u)|\nas well as I(v) = {i1, . . . , ik} and I(w) = {ik+1, . . . , i\u2113}, we define the permutation\nmatrix\n\nP \u22a4 = [ei1\n, . . . , eik\n\n, eik+1\n, . . . , ei\u2113\n\n]\n\nan consider\n\nP AI(u)P\n\u22a4 =\n\n[\n\nAI(v) AI(v)I(w)\n\nAI(w)I(v) AI(w)\n\n]\n\n.\n\nSince the algorithm sets i = min(I(u)) and I(w) = {j \u2208 I(u) \\ {i} : aij = f(u)},\nall the entries in row i of AI(v)I(w) are equal to f(u) = min{aij : j \u2208 I(u) \\ {i}}.\nWe already observed in Lemma 2.3 that in this way we find the smallest global off-\ndiagonal entry f(u) = {aij : i 6= j}. Theorem 2.2 thus tells us that indeed all the\nentries in AI(v)I(w) are equal to f(u). Consequently, we observe that f(u) = aij\n\nfor all i \u2208 I(v) and all j \u2208 I(u) \\ I(v) and, by symmetry, that f(u) = aij for\nall i \u2208 I(w) and all j \u2208 I(u) \\ I(w). This proves Statement (iii) since we have\nchosen u to be an arbitrary vertex among those that have children. Furthermore,\nTheorem 2.2 implies that AI(v) and AI(w) are again essentially ultrametric, which\nwas to be shown for Statement (i).\n\n6\n\n\n\nCorollary 2.5. Algorithm 1 requires O(n2) floating-point operations to encode\nan essentially ultrametric matrix A \u2208 R\n\nn\u00d7n as its associated tree structure.\n\nProof. The algorithm terminates after 2n\u22121 recursion calls by Theorem 2.4. Each\nrecursion step requires O(n) floating-point operations to determine f(u), I(v),\nand I(w), as for each of them at most n comparisons have to be performed. So in\ntotal we count O(n2) floating-point operations.\n\n3 Fast matrix-vector multiplication\n\nThe following algorithm is designed to perform fast matrix-vector multiplications\nfor a matrix that is given in its ultrametric tree representation (V, E) constructed\nby Algorithm 1. As before, each vertex u \u2208 V is provided with an index set I(u)\nand a value f(u). In addition, we assign values s(u), t(u) and p(u) in what follows.\n\nAlgorithm 2 Ultrametric Multiplication\n\nInput: ultrametric tree (V, E) with root vertex r constructed by Algorithm 1 for\nan essentially ultrametric matrix A \u2208 R\n\nn\u00d7n, vector x \u2208 R\nn\n\nOutput: product y = Ax\n\n1: PartialProduct(r, 0)\n2: TotalProduct(r, 0)\n\n3: procedure PartialProduct(u, z)\n4: if |I(u)| = 1 then\n\n5: s(u)\u2190 xi where i \u2208 I(u)\n6: else\n\n7: s(u)\u2190\n\u2211\n\nv\u2208V :(u,v)\u2208E\n\nPartialProduct(v, f(u))\n\n8: t(u)\u2190 (f(u)\u2212 z)s(u)\n9: return s(u)\n\n10: procedure TotalProduct(u, q)\n11: p(u)\u2190 q + t(u)\n12: if |I(u)| = 1 then\n\n13: yi \u2190 p(u) where i \u2208 I(u)\n14: else\n\n15: for all v \u2208 V : (u, v) \u2208 E do\n\n16: TotalProduct(v, p(u))\n\n7\n\n\n\n\uf8ee\n\n\uf8ef\n\n\uf8ef\n\n\uf8ef\n\n\uf8f0\n\n0 1 3 1\n1 3 1 2\n3 1 5 1\n1 2 1 1\n\n\uf8f9\n\n\uf8fa\n\n\uf8fa\n\n\uf8fa\n\n\uf8fb\n\n\uf8ee\n\n\uf8ef\n\n\uf8ef\n\n\uf8ef\n\n\uf8f0\n\n1\n\u22121\n\n0\n2\n\n\uf8f9\n\n\uf8fa\n\n\uf8fa\n\n\uf8fa\n\n\uf8fb\n\n=\n\n\uf8ee\n\n\uf8ef\n\n\uf8ef\n\n\uf8ef\n\n\uf8f0\n\n1\n2\n4\n1\n\n\uf8f9\n\n\uf8fa\n\n\uf8fa\n\n\uf8fa\n\n\uf8fb\n\nA x = y\n\nr\n\nu a\n\nv w b c\n\nI(r)={1, 2, 3, 4} f(r)=1\n\ns(r)=2\nt(r)=2\np(r)=2\n\nI(u)={1, 3} f(u)=3\n\ns(u)=1\nt(u)=2\np(u)=4\n\nI(a)={2, 4} f(a)=2\n\ns(a)=1\nt(a)=1\np(a)=3\n\nI(v)={1}\nf(v)=0\n\nx1 =s(v)=1\nt(v)=\u22123\n\ny1 =p(v)=1\n\nI(w)={3}\nf(w)=5\n\nx3 =s(w)=0\nt(w)=0\n\ny3 =p(w)=4\n\nI(b)={2}\nf(b)=3\n\nx2 =s(b)=\u22121\nt(b)=\u22121\n\ny2 =p(b)=2\n\nI(c)={4}\nf(c)=1\n\nx4 =s(c)=2\nt(c)=\u22122\n\ny4 =p(c)=1\n\nFigure 2: An ultrametric matrix-vector multiplication Ax = y performed by Algo-\nrithm 2. The annotations in gray belong to the input generated by Algorithm 1,\nthose in black are the values Algorithm 2 determines.\n\nTheorem 3.1. Let (V, E) be an ultrametric tree with root vertex r constructed by\nAlgorithm 1 for an essentially ultrametric matrix A \u2208 R\n\nn\u00d7n and let x be a vector\nin R\n\nn. Then Algorithm 2 with input (V, E) and x terminates with output y = Ax.\n\nProof. In case n = 1, both procedures of Algorithm 2 only activate their if case.\nSo they terminate after their first iteration and sequentially assign s(r) = x1 in\nLine 5, t(r) = f(r)s(r) = a11x1 in Line 8, p(r) = t(r) = a11x1 in Line 11, and\neventually y1 = p(r) = a11x1 in Line 13, which shows the correctness of Algorithm 2\nfor n = 1.\n\nBy Theorem 2.4, each vertex in V can be reached from the root r by a unique\ndirected path. So each vertex in V is either a leaf or has outgoing edges to child\nvertices and each vertex except the root r has a uniquely determined parent.\nBoth procedures of Algorithm 2 initially get the root r as input. A recursion step\nreceiving a vertex u calls, in case u is not a leaf, recursion procedures for all children\nof u, due to Lines 7, 15 and 16. This causes the algorithm to terminate and also\nshows that both procedures of Algorithm 2 are called for each vertex in V at some\npoint and thus that the assignments in Lines 5 and 13 eventually are realized for\neach i \u2208 {1, . . . , n}. So the algorithm\u2019s output y is well-defined. Recall for this\nconclusion that Theorem 2.4 ensures that there is a leaf u \u2208 V with I(u) = {i}\nfor each i \u2208 {1, . . . , n}. In view of Lines 5 and 7, this also implies that\n\ns(u) =\n\u2211\n\nv\u2208V :(u,v)\u2208E\n\ns(v) = . . . =\n\u2211\n\nj\u2208I(u)\n\nxj .\n\n8\n\n\n\nWe use this relationship in the following steps whose purpose is to show that\nindeed y = Ax holds for n \u2265 2. Let us consider an arbitrary i \u2208 {1, . . . , n} and\nlet u0, . . . , um be the vertices on the unique directed path in (V, E) that leads\nfrom the root r = u0 to the vertex um with I(um) = {i}. Since we discussed\nthe case n = 1, we can assume that m \u2265 1 and we know that f(um) = aii by\nStatement (ii) of Theorem 2.4. Line 13 tells us that yi = p(um). In view of\nLines 11 and 8, this provides us with\n\nyi = p(um) = p(um\u22121) + t(um) = . . . =\nm\n\n\u2211\n\nk=0\n\nt(uk)\n\n=\n[ m\n\n\u2211\n\nk=1\n\n(\n\nf(uk)\u2212 f(uk\u22121)\n)\n\ns(uk)\n]\n\n+ f(u0)s(u0)\n\n=\n[ m\n\n\u2211\n\nk=1\n\n(\n\n(f(uk)\u2212 f(uk\u22121)\n)\n\n\u2211\n\nj\u2208I(uk)\n\nxj\n\n]\n\n+ f(u0)\n\u2211\n\nj\u2208I(u0)\n\nxj\n\n= f(um)\n\u2211\n\nj\u2208I(um)\n\nxj +\nm\n\n\u2211\n\nk=1\n\nf(uk\u22121)\n[\n\n\u2211\n\nj\u2208I(uk\u22121)\n\nxj \u2212\n\u2211\n\nj\u2208I(uk)\n\nxj\n\n]\n\n= f(um)xi +\nm\n\n\u2211\n\nk=1\n\n\u2211\n\nj\u2208I(uk\u22121)\\I(uk)\n\nf(uk\u22121)xj\n\n= aii xi +\nm\n\n\u2211\n\nk=1\n\n\u2211\n\nj\u2208I(uk\u22121)\\I(uk)\n\naij xj =\nn\n\n\u2211\n\nj=1\n\naij xj .\n\nwhich is the relation to be shown. Note for the second to last equality that i \u2208 I(uk)\nfor all k \u2208 {0, . . . , m} and therefore Statement (iii) of Theorem 2.4 tells us\nthat f(uk\u22121) = aij for j \u2208 I(uk\u22121) \\ I(uk).\n\nCorollary 3.2. Algorithm 2 requires O(n) floating-point operations to multiply\nan essentially ultrametric matrix A \u2208 R\n\nn\u00d7n given in its tree representation (V, E)\nby a vector x \u2208 R\n\nn.\n\nProof. Both procedures of Algorithm 2 are called exactly once per vertex in V .\nWe know that |V | = 2n \u2212 1 by the proof of Theorem 2.4. Since each call of one\nof the procedures involves O(1) floating-point operations, Algorithm 2 requires a\ntotal of O(n) floating-point operations.\n\nNote that whereas the running time of Algorithm 2 is linear, it requires a matrix\nthat has been encoded as an ultrametric tree. By Corollary 2.5, this can be done\nin quadratic time using Algorithm 1.\n\n9\n\n\n\n4 Empirical Insights\n\nThis section is intended to evaluate the practical performance of the algorithms\ndiscussed in the previous sections. We begin by presenting computation times\nfor constructing ultrametric trees by Algorithm 1 as well as times that matrix-\nvector multiplications require when using Algorithm 2. We compare this to the\neffort involved in standard matrix-vector multiplications. By the term standard\n\nwe refer to a routine that determines the matrix-vector product y = Ax simply by\ncomputing yi =\n\n\u2211n\nj=1 aijxj for each i \u2208 {1, . . . , n}. The second half of this section\n\nextends this investigation to scenarios in which we want to multiply repeatedly.\n\nOur experiments are conducted on randomly generated matrices for whose gener-\nation we rely on the following characterization by Fiedler [5].\n\nTheorem 4.1. Up to a simultaneous permutation of rows and columns, each\nspecial ultrametric matrix A = [aij] \u2208 R\n\nn\u00d7n with n \u2265 2 can be obtained by\nchoosing n\u2212 1 numbers a12, a23, . . . , an\u22121,n and setting\n\na11 = a12, aii = max{ai\u22121,i, ai,i+1} for i = 2, . . . , n\u2212 1, ann = an\u22121,n,\n\naik = min{ai,k\u22121, ai+1,k} for all i, k where 1 \u2264 i < k \u2212 1 \u2264 n\u2212 1,\n\naki = aik for all i, k where i > k.\n\nIn our tests, the numbers a12, a23, . . . , an\u22121,n are taken uniformly at random from\n{1, . . . , n\u22121} and all the other matrix entries are determined as described in The-\norem 4.1. Having generated such a matrix, we randomly perform a simultaneous\npermutation of its rows and columns. This is to avoid unintended advantages for\nour algorithms, which is to be expected when the entries of the input matrices are\nalready presorted. As well, the entries of the vectors to be multiplied are chosen\nuniformly at random from {1, . . . , n \u2212 1}. The source code used to generate the\ndata as well as implementations of Algorithms 1 and 2 are available under Hofmann\nand Oertel [8]. Figure 4 shows computation times for a single multiplication of an\nultrametric matrix by a vector. We compare the time a standard multiplication\ntakes with the time for multiplying by Algorithm 2. The latter algorithm requires\nthat the input matrix is given in its tree representation. So we additionally con-\nsider the time that Algorithm 1 needs to construct a corresponding ultrametric\ntree. All the computation times are averaged over 10 runs with varied matrices\nand vectors.\n\nFor very small matrices, the standard routine is faster than the tree multiplication\nby Algorithm 2, even without counting the effort for encoding an ultrametric ma-\ntrix as its associated tree structure. For matrices up to a size of about n = 27, the\ntree multiplication may be faster than the standard method. However, counting\n\n10\n\n\n\n23 25 27 29 211 213 215\n\n10\u22127\n\n10\u22126\n\n10\u22125\n\n10\u22124\n\n10\u22123\n\n10\u22122\n\n10\u22121\n\n100\n\n101\n\n102\n\nmatrix size n\n\nse\nco\n\nn\nd\ns\n\nUltrametric Tree Construction\n\nUltrametric Multiplication\n\nUltrametric Tree Construction and Multiplication\n\nStandard Multiplication\n\n23 25 27 29 211 213 215\n\n10\u22127\n\n10\u22126\n\n10\u22125\n\n10\u22124\n\n10\u22123\n\n10\u22122\n\n10\u22121\n\n100\n\n101\n\n102\n\nmatrix size n\n\nUltrametric Tree Construction\n\nUltrametric Multiplication\n\nUltrametric Tree Construction and Multiplication\n\nStandard Multiplication\n\nFigure 3: Computation times for matrix-vector products. The results in this chart\nare averaged over 10 runs with random ultrametric matrices as input.\n\nthe total duration, including the time required to encode the given matrix as its\nultrametric tree, the standard routine is still to be preferred. For larger matrix\nsizes, the methods we propose consume considerably less time than a standard rou-\ntine. For example, multiplying a matrix of size n = 215 by a vector is about 780\ntimes faster compared to using a standard multiplication. Within our methods,\nthe largest portion of the computation time is required by the tree construction.\nSo applying the proposed methods may especially pay off in situations where we\nwant to multiply repeatedly. To demonstrate this, we conclude this section with\nan example in which our ultrametric multiplication techniques are used as part of\nan iterative matrix method.\n\nSuppose we want to compute an approximate solution x \u2208 R\nn to a system of linear\n\nequations Ax = b with b \u2208 R\nn where A = [aij] \u2208 R\n\nn\u00d7n is a diagonal dominant\nultrametric matrix. A classical iterative scheme to solve such a system is the\nJacobi method, presented by Golub and Van Loan [6, Chapter 11], for example.\nThe basic idea behind this method is to compute a sequence (xk) that, under\ncertain conditions, converges to x = A\u22121b by iterating\n\nxk+1 = D\u22121\n(\n\nb\u2212 Bxk\n)\n\n,\n\n11\n\n\n\n23 25 27 29 211 213 215\n10\u22126\n\n10\u22125\n\n10\u22124\n\n10\u22123\n\n10\u22122\n\n10\u22121\n\n100\n\n101\n\n102\n\n103\n\nmatrix size n\n\nse\nco\n\nn\nd\ns\n\nUltrametric Tree Construction\n\nJacobi Method using Ultrametric Multiplication\nUltrametric Tree Construction and Jacobi\nMethod using Ultrametric Multiplication\n\nJacobi Method using Standard Multiplication\n\n23 25 27 29 211 213 215\n10\u22126\n\n10\u22125\n\n10\u22124\n\n10\u22123\n\n10\u22122\n\n10\u22121\n\n100\n\n101\n\n102\n\n103\n\nmatrix size n\n\nUltrametric Tree Construction\n\nJacobi Method using Ultrametric Multiplication\n\nUltrametric Tree Construction and Jacobi\nMethod using Ultrametric Multiplication\n\nJacobi Method using Standard Multiplication\n\nFigure 4: Computation times for solving linear systems. The results in this chart\nare averaged over 10 runs with random ultrametric matrices as input.\n\nwhere D := diag(aii : i = 1, . . . , n) contains the diagonal of A and B := A \u2212 D\n\ncontains the off-diagonal elements of A. Since here the inversion of the diagonal\nmatrix D is computationally simple, the effort of an iteration is largely determined\nby the cost of the matrix-vector multiplication Bxk, for which we propose our\nultrametric multiplication techniques. Since a lot of iterative matrix methods\nrely on repeated matrix-vector multiplications, our techniques may be of use in\nmany of them, provided that the ultrametric structure is preserved throughout the\niterations to be performed.\n\nFigure 4 shows empirical results on the performance of our methods when us-\ning them as a subroutine within the Jacobi method to solve a system of linear\nequations Ax = b. The matrices on which our tests are based are constructed\nas described above with the only exception that we now require them to be\nstrictly diagonal dominant. More precisely, we choose the diagonal elements aii\n\nfor i \u2208 {1, . . . , n} uniformly at random from {d + 1, . . . , d2} where d =\n\u2211n\n\nj=1 aij,\nwhich guarantees a reasonable convergence rate of the Jacobi method.\n\nAs with the results described in Figure 4, the initial effort involved in the tree\nconstruction begins to pay off already for relatively small matrix sizes. For the\n\n12\n\n\n\nscenario at hand, the breakpoint is reached at a size of about n = 26, which is\nearlier than in the experiments illustrated in Figure 4. Also, compared to using\nnaive matrix multiplication within an iterative scheme, the difference in perfor-\nmance becomes considerably larger. For example, for a system of size n = 215,\nusing our methods within the Jacobi method is about 2750 times faster than the\nstandard version. This underlines the potential of the proposed methods for large\nscale computations.\n\nAcknowledgments\n\nOur research was partially funded by the Deutsche Forschungsgemeinschaft (DFG,\nGerman Research Foundation) \u2013 Project-ID 416228727 \u2013 SFB 1410 and by the\nWallenberg AI, Autonomous Systems and Software Program (WASP) funded by\nthe Knut and Alice Wallenberg Foundation.\n\nReferences\n\n[1] Morteza H. Chehreghani. Unsupervised representation learning with minimax\ndistance measures. Machine Learning, 109(11):2063\u20132097, 2020.\n\n[2] Claude Dellacherie, Servet Mart\u00ednez, and Jaime S. Mart\u00edn. Inverse M-\n\nMatrices and Ultrametric Matrices. Lecture Notes in Mathematics. Springer,\n2014.\n\n[3] Reinhard Diestel. Graph Theory. Springer, 2017.\n\n[4] Miroslav Fiedler. Special ultrametric matrices and graphs. SIAM Journal on\n\nMatrix Analysis and Applications, 22(1):106\u2013113, 2000.\n\n[5] Miroslav Fiedler. Remarks on monge matrices. Mathematica Bohemica,\n127(1):27\u201332, 2002.\n\n[6] Gene H. Golub and Charles F. Van Loan. Matrix Computations. Johns\nHopkins University Press, 2013.\n\n[7] Ralph E. Gomory and Tien Chung Hu. Multi-terminal network flows. SIAM\n\nJournal, 9(4):551\u2013570, 1961.\n\n[8] Tobias Hofmann and Andy Oertel. Ultrametric matrix tools, 2021. Version:\n0.1.1. url: https://doi.org/10.5281/zenodo.5809300.\n\n[9] Tobias Hofmann and Uwe Schwerdtfeger. Edge-connectivity matrices and\ntheir spectra. arXiv:2102.04541, 2021.\n\n13\n\nhttps://doi.org/10.5281/zenodo.5809300\n\n\n[10] Jan E. Holly. Pictures of ultrametric spaces, the p-adic numbers, and valued\nfields. The American Mathematical Monthly, 108(8):721\u2013728, 2001.\n\n[11] Steffen Lauritzen, Caroline Uhler, and Piotr Zwiernik. Maximum likelihood\nestimation in gaussian models under total positivity. The Annals of Statistics,\n47(4):1835\u20131863, 2019.\n\n[12] Anna V. Little, Mauro Maggioni, and James M. Murphy. Path-based spectral\nclustering: guarantees, robustness to outliers, and fast algorithms. Journal of\n\nMachine Learning Research, 21, 2020.\n\n[13] Servet Mart\u00ednez, G\u00e9rard Michon, and Jaime S. Mart\u00edn. Inverse of strictly\nultrametric matrices are of Stieltjes type. SIAM Journal on Matrix Analysis\n\nand Applications, 15(1):98\u2013106, 1994.\n\n[14] Reinhard Nabben and Richard S. Varga. A linear algebra proof that the in-\nverse of a strictly ultrametric matrix is a strictly diagonally dominant Stieltjes\nmatrix. SIAM Journal on Matrix Analysis and Applications, 15(1):107\u2013113,\n1994.\n\n14\n\n\n\t1 Introduction\n\t2 Basic Properties of ultrametric matrices\n\t3 Fast matrix-vector multiplication\n\t4 Empirical Insights\n\n"}
{"Title": "Relative Defects in Relative Theories: Trapped Higher-Form Symmetries and Irregular Punctures in Class S", "Authors": "Lakshya Bhardwaj, Simone Giacomelli, Max Hubner, Sakura Schafer-Nameki", "Abstract": "  A relative theory is a boundary condition of a higher-dimensional topological quantum field theory (TQFT), and carries a non-trivial defect group formed by mutually non-local defects living in the relative theory. Prime examples are 6d N=(2,0) theories that are boundary conditions of 7d TQFTs, with the defect group arising from surface defects. In this paper, we study codimension-two defects in 6d N=(2,0) theories, and find that the line defects living inside these codimension-two defects are mutually non-local and hence also form a defect group. Thus, codimension-two defects in a 6d N=(2,0) theory are relative defects living inside a relative theory. These relative defects provide boundary conditions for topological defects of the 7d bulk TQFT. A codimension-two defect carrying a non-trivial defect group acts as an irregular puncture when used in the construction of 4d N=2 Class S theories. The defect group associated to such an irregular puncture provides extra \"trapped\" contributions to the 1-form symmetries of the resulting Class S theories. We determine the defect groups associated to large classes of both conformal and non-conformal irregular punctures. Along the way, we discover many new classes of irregular punctures. A key role in the analysis of defect groups is played by two different geometric descriptions of the punctures in Type IIB string theory: one provided by isolated hypersurface singularities in Calabi-Yau threefolds, and the other provided by ALE fibrations with monodromies.      ", "Subject": "High Energy Physics - Theory (hep-th)", "ID": "arXiv:2201.00018", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelative Defects in Relative Theories:\nTrapped Higher-Form Symmetries and Irregular Punctures in Class S\n\nLakshya Bhardwaj1, Simone Giacomelli1,2,3, Max H\u00fcbner1,4, Sakura Sch\u00e4fer-Nameki1\n\n1Mathematical Institute, University of Oxford,\nAndrew-Wiles Building, Woodstock Road, Oxford, OX2 6GG, UK\n\n2Dipartimento di Fisica, Universit\u00e0 di Milano-Bicocca, and\n3 INFN, sezione di Milano-Bicocca,\n\nPiazza della Scienza 3, I-20126 Milano, Italy\n4Department of Physics and Astronomy, University of Pennsylvania,\n\nPhiladelphia, PA 19104, USA\n\nA relative theory is a boundary condition of a higher-dimensional topological quantum field\ntheory (TQFT), and carries a non-trivial defect group formed by mutually non-local defects\nliving in the relative theory. Prime examples are 6d N = (2, 0) theories that are boundary\nconditions of 7d TQFTs, with the defect group arising from surface defects. In this paper, we\nstudy codimension-two defects in 6d N = (2, 0) theories, and find that the line defects living\ninside these codimension-two defects are mutually non-local and hence also form a defect\ngroup. Thus, codimension-two defects in a 6d N = (2, 0) theory are relative defects living\ninside a relative theory. These relative defects provide boundary conditions for topological\ndefects of the 7d bulk TQFT. A codimension-two defect carrying a non-trivial defect group\nacts as an irregular puncture when used in the construction of 4d N = 2 Class S theories. The\ndefect group associated to such an irregular puncture provides extra \u201ctrapped\u201d contributions\nto the 1-form symmetries of the resulting Class S theories. We determine the defect groups\nassociated to large classes of both conformal and non-conformal irregular punctures. Along\nthe way, we discover many new classes of irregular punctures. A key role in the analysis of\ndefect groups is played by two different geometric descriptions of the punctures in Type IIB\nstring theory: one provided by isolated hypersurface singularities in Calabi-Yau threefolds,\nand the other provided by ALE fibrations with monodromies.\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n8v\n1 \n\n [\nhe\n\np-\nth\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\n\n\nContents\n\n1 Introduction 4\n\n2 Relative Defects and Relative Theories 8\n2.1 Relative Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2 Absolute Theories from Relative Theories . . . . . . . . . . . . . . . . . . . . . 12\n2.3 Relative Defects in Absolute Theories . . . . . . . . . . . . . . . . . . . . . . . 15\n2.4 Relative Defects in Relative Theories . . . . . . . . . . . . . . . . . . . . . . . . 16\n2.5 Relative Defects in 6d (2, 0) Theories . . . . . . . . . . . . . . . . . . . . . . . . 25\n2.6 Compactification: Relative Theories from Relative Defects . . . . . . . . . . . . 26\n\n3 Evidence for Trapped 1-Form Symmetries 27\n3.1 The Defect Group of Type IIB on IHS . . . . . . . . . . . . . . . . . . . . . . . 27\n3.2 Collisions of Regular Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\n\n4 1-Form Symmetries of Arbitrary Class S Theories 31\n4.1 The Defect Group of a Puncture . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.2 Defect Groups of Special Punctures . . . . . . . . . . . . . . . . . . . . . . . . . 37\n4.3 Defect Groups of Class S Theories from Defect Groups of Punctures . . . . . . 39\n\n5 Computing Defect Groups of Punctures 44\n5.1 Special Class S Theories Associated to a Puncture . . . . . . . . . . . . . . . . 44\n5.2 Generalized Quivers: Classes GQ and GQ\u2032 . . . . . . . . . . . . . . . . . . . . . 47\n5.3 Spectral Cover Monodromies and ALE Fibrations in IIB . . . . . . . . . . . . . 51\n\n6 Type IIB on Canonical Singularities and Irregular Punctures 55\n6.1 Untwisted Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n6.2 Twisted Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n6.3 Extracting the IHS for twisted A3 . . . . . . . . . . . . . . . . . . . . . . . . . 59\n6.4 IHS for twisted irregular punctures . . . . . . . . . . . . . . . . . . . . . . . . . 61\n\n6.4.1 Twisted Aodd theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n6.4.2 Twisted Aeven theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n6.4.3 Twisted DN+1 theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n6.4.4 Z3-twisted D4 theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n6.4.5 Twisted E6 theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n\n6.5 IHS for Trinions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n\n2\n\n\n\n6.5.1 Trinions of Db\np(G) Theories from Type IIB . . . . . . . . . . . . . . . . 67\n\n6.5.2 The Defect Group of Trinions from Punctures . . . . . . . . . . . . . . . 69\n\n7 Untwisted A 70\n7.1 Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n7.2 1-Form Symmetry from Class GQ . . . . . . . . . . . . . . . . . . . . . . . . . . 71\n7.3 Class GQ\u2032 \u2013 Type IIA Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . 72\n7.4 Checks Via Circle Reduction \u2013 Electric Quiver EQ4 . . . . . . . . . . . . . . . 73\n7.5 Spectral Cover Monodromies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n7.6 Trapped Defect Group from Type IIB on CY3 . . . . . . . . . . . . . . . . . . 75\n\n8 Untwisted D 76\n8.1 Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n8.2 Class GQ of Generalized Quivers . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n\n8.2.1 Class GQ\u2032 and Type IIA Punctures . . . . . . . . . . . . . . . . . . . . . 79\n8.3 The C(m) and D(m) SCFTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n\n8.3.1 The C(m) SCFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n8.3.2 The D(m) SCFT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n\n8.4 1-Form Symmetries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n8.5 Spectral Cover Monodromies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n8.6 Trapped Defect Group from Type IIB on CY3 . . . . . . . . . . . . . . . . . . 88\n\n8.6.1 Trapped Parts of IHS Punctures . . . . . . . . . . . . . . . . . . . . . . 88\n8.6.2 Trinions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n\n9 Twisted D 91\n9.1 Punctures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n9.2 Class GQ of Generalized Quivers . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n\n9.2.1 Class GQ\u2032 and Type IIA Punctures . . . . . . . . . . . . . . . . . . . . . 94\n9.3 1-Form Symmetries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n9.4 Spectral Cover Monodromies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n9.5 Trapped Defect Group from Type IIB on CY3 . . . . . . . . . . . . . . . . . . 97\n\n10 Untwisted E 99\n10.1 Spectral Covers and Weights Systems . . . . . . . . . . . . . . . . . . . . . . . 103\n10.2 Spectral Cover Monodromies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n10.3 Trapped Defect Group from Type IIB on CY3 . . . . . . . . . . . . . . . . . . 107\n\n3\n\n\n\n11 Conclusions and Outlook 107\n\nA Glossary 110\nA.1 Glossary for Sections 2.1 and 2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . 110\nA.2 Glossary for Section 2.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\nA.3 Glossary for the Rest of the Paper . . . . . . . . . . . . . . . . . . . . . . . . . 112\n\nB Spectral Cover Monodromies 114\n\n1 Introduction\n\nRecently, the study of higher-form symmetries [1\u20133] has gained momentum [4\u201358], as these\nsymmetries provide a lot of insight into deep physical phenomena in quantum field theories.\nOn the one hand, they provide insights into the phase structure and confinement properties in\nthe IR, while on the other hand, they provide insights into the properties of extended defects\nin the UV. More abstractly, they encode information about the class of observables that can\nbe computed in a given quantum field theory, as a higher-symmetry is associated to a class of\nbackgrounds that can be turned on while computing correlation functions.\n\nHigher-form symmetries are often entwined with a larger structure known as defect group1.\nThese are groups formed by equivalence classes of mutually non-local defects in a theory. The\nnon-locality of the defects implies that the theory is ill-defined on its own. For it to be well-\ndefined, the theory needs to arise on the boundary of a topological quantum field theory\n(TQFT) in one higher dimension. We call such theories as relative theories2. On the other\nhand, theories without mutually non-local defects are called absolute theories.\n\nA natural generalization of the notion of a relative theory is the notion of a relative defect\ninside a bulk theory. We define a relative defect to be a defect that carries mutually non-local\nsub-defects. As a consequence, for a relative defect to be well-defined, it needs to be attached\nto a topological system in one higher dimension. For a relative defect inside an absolute bulk\ntheory, the corresponding topological system is a TQFT. On the other hand, for a relative\ndefect inside a relative bulk theory, the corresponding system is a topological defect of the\nTQFT associated to the relative bulk theory. The defect group of a relative defect captures\n\n1This terminology was introduced in [4].\n2An important note on terminology: Our definition of \u2018relative theory\u2019 differs from the definition employed\n\nin the work [59] in a key manner. In that work, any theory arising on the boundary of a higher-dimensional\nTQFT is called a relative theory, while a theory existing independently of a higher-dimensional TQFT is called\nan absolute theory. According to this definition, the theories having a \u2019t Hooft anomaly, which can be thought\nof as theories living on the boundaries of SPT phases in one higher dimension, are relative theories. For us,\none important feature defining a relative theory is the existence of mutually non-local defects. Thus, we would\ncall a theory having a \u2019t Hooft anomaly as an absolute theory rather than a relative theory.\n\n4\n\n\n\nhigher-form symmetries localized on the worldvolume of the defect, along with its interplay\nwith the higher-form symmetries of the bulk theory.\n\nIn this paper, we show that codimension-two defects inside a bulk 6d N = (2, 0) theory\nprovide examples of relative defects inside a relative bulk theory. We find that line sub-defects\ninside the codimension-two defects are mutually non-local and hence form a non-trivial defect\ngroup in general.\n\nOne necessary (but not sufficient) condition for a codimension-two defect to be relative is\nthat it should provide an irregular puncture when used for the Class S construction of 4dN = 2\ntheories via compactification of 6d N = (2, 0) theories on punctured Riemann surfaces [60\u201372].\nIn this context, an irregular puncture is defined as a singularity of a Higgs field (participating\nin a Hitchin system on the Riemann surface) where poles of order higher than a simple pole\nappear. On the other hand, a regular puncture is a singularity where only simple poles of the\nHiggs field appear. This follows from the results of [31], which can be rephrased to state that\na codimension-two defect associated to a regular puncture carries a trivial defect group.\n\nOne interesting application of the defect groups associated to codimension-two defects is\nin the computation of the 1-form symmetry of a 4d N = 2 Class S theory constructed using\nirregular punctures. There are many interesting 4d N = 2 theories that lie in this class,\nincluding 4d N = 2 Argyres-Douglas SCFTs and asymptotically free 4d N = 2 theories. Prior\nwork [31], building upon the works [1,73,74], has provided a general recipe for computing the\n1-form symmetries of 4d N = 2 Class S theories involving only regular punctures. In this\nwork, we extend their analysis to include arbitrary irregular punctures. The defect groups\nassociated to the irregular punctures play a key role in this analysis.\n\nWhen only regular punctures are involved, the 1-form symmetry is determined roughly\nby the 1-cycles on the Riemann surface. When irregular punctures are involved, there are\nextra contributions to the 1-form symmetry that are localized at the locations of the irregular\npunctures. We call such extra contributions as trapped 1-form symmetries.\n\nStriking examples of trapped 1-form symmetries are provided by Argyres-Douglas (AD)\ntheories of type AD[G,G\u2032] that are constructed by compactifying 6d N = (2, 0) theories on\na sphere with a single puncture that is irregular. Such AD theories, and also a vast number\nof other 4d N = 2 SCFTs, can also be constructed by compactifying Type IIB on canonical\nisolated hypersurface Calabi-Yau three-fold singularities (IHS) X [17,29,30,36,55,75\u201386], for a\nrecent review see [87]. Using string theoretic methods, the 1-form symmetries of these 4d N =\n2 SCFTs can be computed from the topology of the boundary 5-manifold \u2202X [17,29,30,36,55].\nIt is found that the 1-form symmetries of such AD theories are generally non-trivial. Since\nthe sphere used in the Class S construction does not carry any non-trivial 1-cycles, the 1-\n\n5\n\n\n\nform symmetries of these AD theories must be entirely trapped. Indeed, the general analysis\ndeveloped in this paper correctly reproduces the 1-form symmetries of these AD theories from\nthe defect groups associated to the irregular puncture.\n\nThe irregular punctures introduced in [81, 88, 89] will be called IHS punctures because\nthe 4d N = 2 SCFTs obtained by compactifying 6d N = (2, 0) theories on spheres with\nthese punctures can also be constructed by compactifying Type IIB on IHS singularities. For\nuntwisted punctures, this relationship was discussed in [81]. In this paper, we show that this\nrelationship can also be extended to the twisted punctures introduced in [81,89].\n\nIn addition to the punctures introduced in [81, 88, 89], we study many other classes of\nirregular punctures. Many of these punctures have not appeared in prior literature. We\ndivide punctures into two classes: conformal and non-conformal punctures. The distinction is\nmade by considering the 4d N = 2 theory obtained by compactifying the 6d N = (2, 0) theory\ncorresponding to the puncture on a sphere with the puncture inserted at one point (and no\nother punctures). If this 4d N = 2 theory is (super)conformal, then we call the puncture a\nconformal puncture. On the other hand, if this 4d N = 2 theory is not conformal, then we\ncall the puncture a non-conformal puncture. For example, the IHS punctures are conformal\npunctures. However, they are not all the conformal punctures, and we study many other\nclasses of conformal punctures that correspond to non-isolated singularities. In addition to\nthese, we also study many classes of non-conformal punctures. A subclass of the conformal and\nnon-conformal punctures considered in this paper can be constructed using Hanany-Witten\nbrane constructions [90\u201393] in Type IIA superstring theory.\n\nThe bulk of this paper is devoted to the computation of defect groups associated to\ncodimension-two defects in 6d N = (2, 0) theories of types A, D and E. To each (confor-\nmal or non-conformal) puncture, we associate a 4d N = 2 generalized quiver theory having\nthe property that the 1-form symmetry of the generalized quiver determines completely the\ndata associated to the defect group of the puncture. Such a theory is a gauge theory con-\ntaining various kinds of gauge algebras, but the matter content can be provided not only by\nhypermultiplets, but also by strongly coupled 4d N = 2 SCFTs that we call \u201cmatter SCFTs\u201d.\nThe 1-form symmetry of the generalized quiver theory, and hence all the data associated to\nthe defect group of the puncture, is computed using the properties of the matter SCFTs.\n\nFor the punctures admitting a Type IIA construction, the generalized quiver is simply read\noff from the associated brane configuration. On the other hand, for punctures not admitting a\nType IIA construction, the associated generalized quiver is conjectural, and we provide many\npieces of evidence to support this conjecture, that we discuss below.\n\nFirst of all, a piece of the defect group (that contains both trapped and non-trapped\n\n6\n\n\n\nparts) can be computed by using the data of the Higgs field in the vicinity of the puncture.\nUsing the data of the Higgs field, one can realize the puncture by compactifying Type IIB\non an ALE fibration over a punctured plane. The monodromy of the Higgs field around\nthe puncture captures the monodromy of the ALE fibration. Now one can apply the tools\ndeveloped in [17,29,30,36,55] to deduce this piece of the defect group of the puncture from the\ndata of the monodromy of the ALE fibration. However, this doesn\u2019t provide full information\nrelated to the defect group.\n\nSecond, for the IHS punctures, the trapped part of the defect group can be computed using\nType IIB compactified on the corresponding IHS singularity, using the technology developed\nin [17, 29, 30, 36, 55]. The obtained trapped defect group can then be checked against the\ntrapped defect group predicted by the conjecture. However, this does not provide information\non the non-trapped part of the defect group.\n\nThird, we use other types of IHS singularities discussed in [29] that construct 4d N =\n2 trinion theories. These trinion theories are composed out of the data of three irregular\npunctures. The defect group of a trinion theory can be obtained using the data of the defect\ngroups of the three punctures, and it involves not only the trapped parts of these defect groups,\nbut also some of the non-trapped parts. On the other hand, the defect group of the trinion\ntheory can be independently obtained as in [29]. Matching the two results provides a check\nfor the non-trapped part of the defect groups of punctures predicted by our proposal.\n\nFinally, for untwisted A type punctures, the defect group of the puncture can be read from\nthe 1-form symmetry of a 3d Lagrangian theory obtained by circle reduction of a 4d N = 2\nClass S theory constructed using the puncture (and a P0 puncture). This provides another\ncheck for our proposal.\n\nWe also study the defect groups of untwisted IHS punctures for the E-type (2, 0) theory.\nFor such punctures, we can compute the trapped part of the defect group using the IHS\nsingularity. Moreover, using the ALE fibration description, we can also compute a piece\ncontaining a combination of trapped and non-trapped parts. Now, it turns out for such IHS\npunctures, that these two pieces of information is enough to determine the whole information\nabout the defect group associated to these punctures.\n\nThe rest of this paper is structured as follows: Section 2 discusses generalities about\nrelative theories and relative defects. Section 3 provides evidence for the existence of 1-form\nsymmetries trapped inside irregular punctures. Section 4 describes how the 1-form symmetry\nof an arbitrary class S theory can be described in terms of defect groups associated to the\nparticipating punctures. Section 5 discusses various techniques we use for computing the\ndefect groups associated to punctures. In particular, subsection 5.3 discusses the computation\n\n7\n\n\n\nof (part of) defect group associated to a puncture by realizing it as an ALE fibration with a\nmonodromy in Type IIB string theory. Section 6 discusses the map between IHS punctures\nand IHS singularities. Using these IHS singularities, we compute the trapped parts of the\ndefect groups associated to IHS punctures. Sections 7, 8 and 9 discuss our main proposals for\ncomputing defect groups associated to large classes of untwisted A- and D-types, and twisted\nD-type punctures. The explicit forms of the defect groups are provided, and many checks are\nperformed by computing parts of these defect groups via other methods. Section 10 computes\nthe defect groups of untwisted E-type IHS punctures by combining the results of the IHS\ncomputation with the results of the ALE fibration computation. Finally, we have a couple\nof appendices. Appendix A provides a glossary of the most frequently used notations in the\npaper. Appendix B presents the Mathematica code used to derive the monodromy action on\nthe spectral cover sheets about arbitrary punctures which is the key piece of data informing\nthe boundary topology in ALE fibration picture.\n\n2 Relative Defects and Relative Theories\n\nWe begin by discussing the notions of relative theories and relative defects. This is important\nbecause our starting point, namely 6d N = (2, 0) theories, are relative theories. We are\ninterested in understanding the 1-form symmetries of 4d N = 2 Class S theories obtained\nby compactifying 6d N = (2, 0) theories with arbitrary regular and irregular punctures. The\ncontribution to the 1-form symmetry of the irregular puncture is encoded in a defect group\nassociated to the puncture, which in turn is associated to the fact that these punctures are\nrelative codimension-two defects inside 6d N = (2, 0) theories.\n\n2.1 Relative Theories\n\nNon-locality of defects. Many interesting theories are relative [3, 4, 25, 59, 94\u201396]. That\nis, they carry defects that are mutually non-local. In such theories, the non-locality occurs\nbetween p-dimensional defects and (d \u2212 p \u2212 2)-dimensional defects, where d is the spacetime\ndimension of the relative theory. The non-locality exhibits itself as a phase ambiguity in defin-\ning correlation functions of these defects. Consider such a relative theory Td on a Euclidean\nspacetime manifoldMd. Consider the correlation function onMd of a p-dimensional defect Dp\n\ninserted along a sub-manifold \u03a3p, and a (d\u2212 p\u2212 2)-dimensional defect Dd\u2212p\u22122 inserted along\na sub-manifold \u03a3d\u2212p\u22122. As \u03a3p is moved in a loop around \u03a3d\u2212p\u22122, the correlation function\ncomes back to itself along with an additional phase\n\nexp\n(\n2\u03c0i\n\n\u2329\nDp,Dd\u2212p\u22122\n\n\u232a)\n, (2.1)\n\n8\n\n\n\nwhere\n\u2329\nDp,Dd\u2212p\u22122\n\n\u232a\n\u2208 R/Z captures the mutual non-locality between the defects Dp and\n\nDd\u2212p\u22122. Thus the correlation function under consideration suffers from the above phase\nambiguity.\n\nExamples of relative theories. Well-known examples of relative theories are 2d chiral\nRCFTs [97\u2013102], for which the non-locality is exhibited by local operators (i.e. 0-dimensional\ndefects) associated to modules of the chiral algebras. Another class of well-known examples\nare 6d N = (2, 0) SCFTs [94] specified by Lie algebras Am, Dn, E6 and E7 (but not E8), for\nwhich the non-locality is exhibited by 2-dimensional surface defects in these theories.\n\nTQFT associated to a relative theory. Such a relative theory Td is better understood\nas a non-topological boundary condition of a non-invertible (d+1)-dimensional TQFT Sd+1\n\n3.\nThe TQFT carries invertible topological defects4 described by a group\n\nL =\nd\u22121\u220f\np=1\nLp = L1 \u00d7 L2 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Ld\u22122 \u00d7 Ld\u22121 , (2.2)\n\nwhere Lp is the abelian group formed by p-dimensional topological defects under fusion. The p-\ndimensional topological defects braid non-trivially with (d\u2212p)-dimensional topological defects.\nThe braiding defines a bi-homomorphism\n\n\u3008\u00b7, \u00b7\u3009 : Lp \u00d7 Ld\u2212p \u2192 R/Z . (2.3)\n\nMoreover the bi-homomorphism is such that it makes Ld\u2212p isomorphic to the Pontraygin dual\nL\u0302p of Lp. That is,\n\nLd\u2212p \u223c= L\u0302p . (2.4)\n\nThese bihomomorphisms define what we call a pairing on the group L. In addition to the\nLp participating in L, one can additionally consider a group Ld of d-dimensional invertible\ntopological defects in the TQFT Sd+1, that may have a non-trivial action on the topological\ndefects in Lp<d.\n\nThe group Lp forms the (d\u2212p)-form symmetry group of the TQFT Sd+1. Thus L captures\nthe higher-form symmetries of Sd+1, and Ld captures 0-form symmetries (that can act on the\nhigher-form symmetries valued in L). The pairing on L describes \u2019t Hooft anomalies between\nthese higher-form symmetries.\n\n3This is sometimes also referred to as the Symmetry TFT, or SymTFT in [57].\n4There can also be non-invertible topological defects that we ignore in what follows. We will consider some\n\nproperties of such non-invertible topological defects when we discuss relative defects in relative theories later.\n\n9\n\n\n\nDp\n\nDd\u2212p\u22122\n\n\u03b1p\n\n\u03b1d\u2212p\u22122\n\nTd Sd+1\n\nDp\n\nDd\u2212p\u22122\n\n\u03b1p\n\n\u03b1d\u2212p\u22122\n\nTd Sd+1\n\nFigure 1: Moving a defect Dd\u2212p\u22122 of the relative theory Td around another defect Dp of\nthe relative theory Td creates a braiding between the topological defects \u03b1p \u2208 Lp+1 and\n\u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121 of the TQFT Sd+1.\n\nNon-locality from braiding. The p-dimensional defects Dp of the relative theory Td arise\nat the end-points of the (p + 1)-dimensional topological defects of the TQFT Sd+1. This\nincludes both invertible and non-invertible (p + 1)-dimensional defects. For example, for\nthe surface defects of 6d N = (2, 0) theories, the corresponding topological 3-dimensional\ndefects are all invertible. On the other hand, for the local operators of chiral RCFTs, the\ncorresponding topological line defects include both invertible and non-invertible ones. The\nnon-locality of these defects of the relative theory can now be understood in terms of braiding\nof the corresponding topological defects of the TQFT.\n\nRestricting ourselves to the invertibles, let us consider two defects Dp and Dd\u2212p\u22122 of the\nrelative theory arising at the end-points of topological defects \u03b1p \u2208 Lp+1 and \u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121\n\nrespectively. Then, we have the equality\u2329\nDp,Dd\u2212p\u22122\n\n\u232a\n= \u3008\u03b1p, \u03b1d\u2212p\u22122\u3009 , (2.5)\n\nwhere the left hand side captures the non-locality betweenDp andDd\u2212p\u22122, while the right hand\nside captures the braiding between the topological defects \u03b1p \u2208 Lp+1 and \u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121.\nSee figure 1.\n\nEquivalence classes of defects under screenings. For p > 0, each (p + 1)-dimensional\ntopological defect (that cannot be expressed as a sum of other (p+ 1)-dimensional topological\ndefects) of the TQFT Sd+1 characterizes an equivalence class of p-dimensional defects of the\nrelative theory Td. Two p-dimensional defects Dp and D\u2032p are in the same equivalence class if\nthere exists a (p\u2212 1)-dimensional junction Jp\u22121 defect at the intersection of Dp and D\u2032p. See\nfigure 2. One also says that, such a Jp\u22121 screens Dp to D\u2032p.\n\n10\n\n\n\nDp D\u2032p\nJp\u22121\n\n=\u21d2 Dp \u223c D\u2032p\n\nFigure 2: An equivalence relation in which two defects Dp and D\u2032p are equivalent if there exists\na non-trivial junction Jp\u22121 between them.\n\ng L3 Og \u3008\u00b7, \u00b7\u3009\n\nAn\u22121 Zn Z2 \u3008f, f\u3009 = 1\nn\n\nD4 Z2 \u00d7 Z2 S3 \u3008s, s\u3009 = 0, \u3008c, c\u3009 = 0, \u3008s, c\u3009 = 1\n2\n\nD4n+1 Z4 Z2 \u3008s, s\u3009 = 3\n4\n\nD4n+2 Z2 \u00d7 Z2 Z2 \u3008s, s\u3009 = 1\n2 , \u3008c, c\u3009 = 1\n\n2 , \u3008s, c\u3009 = 0\n\nD4n+3 Z4 Z2 \u3008s, s\u3009 = 1\n4\n\nD4n+4 Z2 \u00d7 Z2 Z2 \u3008s, s\u3009 = 0, \u3008c, c\u3009 = 0, \u3008s, c\u3009 = 1\n2\n\nE6 Z3 Z2 \u3008f, f\u3009 = 2\n3\n\nE7 Z2 0 \u3008f, f\u3009 = 1\n2\n\nE8 0 0 \u2212\n\nTable 1: Defect group L3, its pairing \u3008\u00b7, \u00b7\u3009 and the 0-form group Og for 6d N = (2, 0) theory of\ntype g. Trivial groups are denoted by zero. We denote a generator of L3 for g = An\u22121, E6, E7\nas f ; a generator of L3 for g = D2n+1 as s; and generators of L3 ' Z2 \u00d7 Z2 for g = D2n as\ns, c. S3 denotes the group formed by permutations of three objects.\n\n6d N = (2, 0) theories as relative theories. The group L, along with the pairing on it, is\noften referred to as the defect group of the relative theory Td. For example, the defect group\nof a 6d N = (2, 0) SCFT specified by an A, D, E algebra g is completely localized in L3 and\ntakes the form\n\nL = L3 = Z\u0302G , (2.6)\n\nwhere Z\u0302G is the Pontryagin dual of the center ZG of the simply connected group G associated\nto the Lie algebra g. The pairing on L is just a bi-homomorphism L3\u00d7L3 = Z\u0302G\u00d7 Z\u0302G \u2192 R/Z.\nThe above bi-homomorphism Z\u0302G \u00d7 Z\u0302G \u2192 R/Z provides an isomorphism Z\u0302G \u2192 ZG that will\nfeature prominently in the later parts of the paper. A 6d N = (2, 0) SCFT of type g also\ncontains a non-trivial\n\nLd = L6 = Og , (2.7)\n\nwhere Og is the group formed by outer-automorphisms of g. There is furthermore an action of\nLd on L, which is just the natural action of Og on Z\u0302G. The data of the defect group, pairing\nand outer-automorphism group for different values of g is tabulated in table 1.\n\n11\n\n\n\nTQFT Sd+1Td\n\nB\u039b\nd\n\n= T\u039b\ndSPT A\u039b\u0302\n\nd+1 SPT A\u039b\u0302\nd+1\n\nFigure 3: A polarization \u039b is associated to a topological interface (that we refer to as a\n\u201cboundary condition\u201d) between the TQFT Sd+1 and an SPT phase A\u039b\u0302\n\nd+1. A compactification\nof the TQFT Sd+1 on a segment with the relative theory Td at one end and B\u039b\n\nd at the other\nend, leads to the absolute theory T\u039b\n\nd , which comes attached to the SPT phase A\u039b\u0302\nd+1. The SPT\n\nphase captures the \u2019t Hooft anomaly of the higher-form symmetry \u039b\u0302 of the absolute theory\nT\u039b\nd .\n\n2.2 Absolute Theories from Relative Theories\n\nPolarization. Starting from a relative theory, one can construct many absolute theories,\nwhere an absolute theory is defined by the fact that its genuine5 defects do not have any\nnon-locality. Thus the correlation functions of genuine defects in an absolute theory do not\nsuffer from phase ambiguities. A general procedure for constructing absolute theories out of\na relative theory Td employs the use of a topological boundary condition6 B\u039b\n\nd of the TQFT\nSd+1. An absolute d-dimensional theory T\u039b\n\nd is then obtained by compactifying the TQFT\nSd+1 on an interval, with the relative theory Td placed at one end of the interval, and the\ntopological boundary condition B\u039b\n\nd placed at the other end of the interval. See figure 3.\nThe essential data of the boundary conditionB\u039b\n\nd , as far as the invertible topological defects\nare concerned, is the polarization7 \u039b \u2286 L, which is a maximal group of the form\n\n\u039b =\nd\u22121\u220f\np=1\n\n\u039bp , (2.8)\n\nwhere each \u039bp is a subgroup of Lp, such that\n\n\u3008\u03b1p, \u03b1d\u2212p\u22122\u3009 = 0 (2.9)\n5We call a defect genuine if it can be defined independently of any higher-dimensional defects. On the other\n\nhand, a non-genuine defect is one that arises at the junctions, boundaries or corners of other higher-dimensional\ndefects.\n\n6Since we regard theories with anomalies as absolute theories, what we call a topological boundary condition\nis not actually a boundary condition when there are anomalies. In general, B\u039b\n\nd is a topological interface between\nthe TQFT Sd+1 and the (d+ 1)-dimensional SPT phase capturing the anomaly. See figure 3. For convenience,\nwe will refer to B\u039b\n\nd as a \u2018topological boundary condition of the TQFT Sd+1\u2019 in what follows.\n7Here we only consider what are called pure polarizations in [25]. There can also be mixed polarizations\n\nthat are discussed in that paper.\n\n12\n\n\n\nDp \u03b1p \u2208 \u039bp+1\n\nTd Sd+1\n\n=\n\nB\u039b\nd T\u039b\n\nd\n\nDp\n\nFigure 4: A defect Dp of the relative theory Td attached to a topological defect \u03b1p \u2208 \u039bp+1 of\nthe TQFT Sd+1 becomes a genuine defect of the absolute theory T\u039b\n\nd , as \u03b1p can end on the\ntopological boundary B\u039b\n\nd .\n\nfor arbitrary \u03b1p \u2208 \u039bp+1 and \u03b1d\u2212p\u22122 \u2208 \u039bd\u2212p\u22121. In other words, a polarization \u039b is a maximal\nsubset of the defect group L such that the pairing on L trivializes when restricted to \u039b.\n\nGenuine defects. The group \u039bp characterizes the subgroup of p-dimensional topological\ndefects valued in Lp of the TQFT Sd+1 that can end on the boundary B\u039b\n\nd . Thus, the\np-dimensional defects of the relative theory Td that lie in the equivalence classes lying in\n\u039bp+1 \u2286 Lp+1 become genuine p-dimensional defects of the absolute theory T\u039b\n\nd . See figure\n4. The condition (2.9) now ensures that these genuine defects are mutually local, which is\nrequired for T\u039b\n\nd to be an absolute theory.\n\nHigher-form symmetries. Since p-dimensional topological defects valued in \u039bp of the\nTQFT Sd+1 can end on the boundary B\u039b\n\nd , they descend to the trivial p-dimensional topolog-\nical defect in the absolute theory T\u039b\n\nd . More generally, the p-dimensional topological defects\nvalued in Lp of the TQFT Sd+1 descend to p-dimensional topological defects of the absolute\ntheory T\u039b\n\nd valued in Lp/\u039bp. In total, the invertible topological defects of the absolute theory\nT\u039b\nd form a group\n\nL/\u039b =\nd\u22121\u220f\np=1\nLp/\u039bp . (2.10)\n\nSee figure 5. These topological defects give rise to higher-form symmetries of the the absolute\ntheory T\u039b\n\nd . The p-form symmetry group \u0393(p)\n[\nT\u039b\nd\n\n]\nof the absolute theory T\u039b\n\nd is\n\n\u0393(p)\n[\nT\u039b\nd\n\n]\n= Ld\u2212p\u22121/\u039bd\u2212p\u22121 \u223c= \u039b\u0302p+1 , (2.11)\n\nwhere \u039b\u0302p+1 denotes the Pontryagin dual of \u039bp+1. The isomorphism Ld\u2212p\u22121/\u039bd\u2212p\u22121 \u223c= \u039b\u0302p+1\n\nfollows from the isomorphism (2.4) and the fact that the pairing between \u039bp+1 and \u039bd\u2212p\u22121 is\n\n13\n\n\n\n\u03b1p \u2208 Lp+1\n\nTd Sd+1\n\n=\n\nB\u039b\nd T\u039b\n\nd\n\n[\u03b1p] \u2208 Lp+1/\u039bp+1\n\nFigure 5: A topological defect \u03b1p \u2208 Lp+1 of the TQFT Sd+1 descends to a (p+1)-dimensional\ntopological defect [\u03b1p] \u2208 Lp+1/\u039bp+1 of the absolute theory T\u039b\n\nd .\n\ntrivial.\nThe genuine p-dimensional defects of T\u039b\n\nd lying in equivalence classes in \u039bp+1 are charged\nobjects under the p-form symmetry \u0393(p)\n\n[\nT\u039b\nd\n\n]\n. Consider a p-dimensional defect Dp of T\u039b\n\nd lying\nin an equivalence class \u03b1p \u2208 \u039bp+1. The action of a p-form symmetry element \u03b1\u0302p \u2208 \u039b\u0302p+1 on\nthe defect Dp is given by the phase factor\n\n\u03b1\u0302p(\u03b1p) \u2208 U(1) , (2.12)\n\nwhich is the image of the element \u03b1p \u2208 \u039bp+1 under the homomorphism \u03b1\u0302p : \u039b\u0302p+1 \u2192 U(1).\nAlternatively, let \u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121 be a lift of the element of Ld\u2212p\u22121/\u039bd\u2212p\u22121 obtained by\napplying the isomorphism \u039b\u0302p+1 \u2192 Ld\u2212p\u22121/\u039bd\u2212p\u22121 on the element \u03b1\u0302p \u2208 \u039b\u0302p+1. Then, the\nphase factor (2.12) can be also be expressed as\n\n\u03b1\u0302p(\u03b1p) = \u3008\u03b1d\u2212p\u22122, \u03b1p\u3009 (2.13)\n\nin terms of the pairing on L. This has a nice pictorial representation shown in figure 6.\n\nNon-genuine defects. The p-dimensional defects of the relative theory Td lying in equiv-\nalence classes in the set Lp+1 \u2212 \u039bp+1 become non-genuine defects of the absolute theory T\u039b\n\nd .\nConsider a defect Dp lying in an equivalence class \u03b1p \u2208 Lp+1\u2212\u039bp+1. It arises on the boundary\nof a topological defect of the absolute theory T\u039b\n\nd described by the element [\u03b1p] \u2208 Lp+1/\u039bp+1\n\nobtained by projecting \u03b1p \u2208 Lp+1 to Lp+1/\u039bp+1. In other words, Dp is a defect arising in the\ntwisted sector of the absolute theory T\u039b\n\nd associated to the higher-form symmetry element [\u03b1p].\n\nAbsolute N = (2, 0) theories. One can now construct absolute 6d N = (2, 0) theories by\nclassifying polarizations of L = Z\u0302G. The result of the classification can be found in the table\n\n14\n\n\n\nDp \u03b1p \u2208 \u039bp+1\n\nTd Sd+1\n\n=\n\nB\u039b\nd T\u039b\n\nd\n\nDp\n\n\u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121 \u03b1\u0302p = [\u03b1d\u2212p\u22122] \u2208 Ld\u2212p\u22121/\u039bd\u2212p\u22121\n\nFigure 6: The action of a p-form symmetry \u03b1\u0302p on a genuine defect Dp of the absolute theory\nT\u039b\nd is obtained by braiding a topological defect \u03b1d\u2212p\u22122 \u2208 Ld\u2212p\u22121 with a topological defect\n\n\u03b1p \u2208 Lp+1 of the TQFT Sd+1, where Dp arises at the end of \u03b1p and \u03b1\u0302p descends from \u03b1d\u2212p\u22122.\n\nTD\n\nTd\n\nDp\n\nFigure 7: A sub-defect Dp living inside a relative defect Td of a theory TD.\n\nright before table 1 of [25]. For example, for g = so(2n), there always exists a polarization\n\u039bSO which is a Z2 subgroup of L = Z\u0302Spin(2n). For g = su(n), a polarization exists only if\nn = m2.\n\n2.3 Relative Defects in Absolute Theories\n\nIn an analogous way, we define relative defects as those defects that carry mutually non-local\nsub-defects. The sub-defects are constrained to live in the worldvolume of the relative defect.\nSee figure 7.\n\nLet us begin by considering relative defects in absolute theories. The structure of such a\nrelative defect is very similar to that of a relative theory. In fact, we can apply the whole ma-\nchinery discussed in previous subsections, but now regarding Td not as a relative d-dimensional\ntheory, but instead a relative d-dimensional defect inside an absolute D-dimensional theory\n\n15\n\n\n\nTD\n\nTd\n\nSd+1\n\nFigure 8: Relative defect Td in absolute theory TD with TQFT Sd+1 attached.\n\nTD, where D > d.\nSd+1 is now a TQFT which is attached to the absolute theory TD along the relative defect\n\nTd. See figure 8. L again describes higher-form symmetries of this TQFT. The defects Dp\n\nare sub-defects living inside the relative defect Td, and L captures equivalence classes and\nnon-locality of (some of) these sub-defects. We refer to L as the defect group of the relative\ndefect Td.\n\nChoosing a topological boundary condition8 B\u039b\nd , associated to a polarization \u039b of L, of\n\nthe TQFT Sd+1 leads to an absolute defect T\u039b\nd of the absolute theory TD. See figure 9. The\n\ngroup L/\u039b = \u039b\u0302 describes invertible topological sub-defects of the absolute defect T\u039b\nd . These\n\ntopological sub-defects give rise to higher-form symmetries of the absolute defect T\u039b\nd . The\n\nbackground fields for such higher-form symmetries live along the worldvolume of T\u039b\nd .\n\nThe sub-defects lying in equivalence classes in \u039b become genuine sub-defects of the absolute\ndefect T\u039b\n\nd . These genuine sub-defects are charged objects under the higher-form symmetries\nL/\u039b of the absolute defect T\u039b\n\nd . On the other hand, the sub-defects lying in equivalence\nclasses in L \u2212 \u039b become non-genuine sub-defects of the absolute defect T\u039b\n\nd . The sub-defects\nbelonging to L \u2212 \u039b arise at the ends of topological sub-defects valued in L/\u039b = \u039b\u0302 associated\nto higher-form symmetries of the absolute defect T\u039b\n\nd .\n\n2.4 Relative Defects in Relative Theories\n\nNow let us consider relative defects in relative theories, which is the main topic of this paper.\nThe structure of such a relative defect (in a relative theory) is much more interesting than\n\n8Whenever the topological boundary condition is actually a topological interface converting the TQFT\nSd+1 to an SPT phase, the SPT phase captures the anomaly of the higher-form symmetries localized along the\nabsolute defect discussed in what follows.\n\n16\n\n\n\nTD\n\nB\u039b\ndTd\n\nSd+1\n\n=\n\nTD\n\nT\u039b\nd\n\nFigure 9: Absolute defect T\u039b\nd in absolute theory TD. The absolute defect follows from the\n\nrelative defect Td by choosing a topological boundary condition B\u039b\nd for the defect TQFT\n\nSd+1.\n\nthe structure of a relative defect in an absolute theory, as now the defect group of the relative\ndefect interacts non-trivially with the defect group of relative theory itself.\n\nTopological defect associated to relative defect. We consider a d-dimensional relative\ndefect Td in a D-dimensional relative theory TD for d < D. The relative theory is attached\nto a (D+ 1)-dimensional TQFT SD+1, and the relative defect is attached to a non-invertible\n(d+ 1)-dimensional topological defect Sd+1 of the TQFT SD+1. See figure 10.\n\nLet LD be the defect group of the TQFT SD+1. The (p + 1)-dimensional topological\ndefects of SD+1 valued in LD,p+1 can end on the topological defect Sd+1 as long as p \u2264 d.\nThus, a general invertible p-dimensional topological sub-defect of the topological defect Sd+1\n\ncomes attached to an invertible (p + 1)-dimensional topological defect of the TQFT SD+1.\nSee figure 11. Let Ld,p be the group of invertible p-dimensional sub-defects of Sd+1. Then,\nwe have a map\n\n\u03c0p : Ld,p \u2192 LD,p+1 (2.14)\n\nthat maps a p-dimensional sub-defect of Sd+1 to the bulk (p + 1)-dimensional topological\ndefect to which the p-dimensional sub-defect is attached to. The kernel of this projection map\n\nL0\nd,p = ker(\u03c0p) (2.15)\n\ndescribes invertible p-dimensional sub-defects of Sd+1 that can exist independently without\nthe presence of a (p+ 1)-dimensional bulk topological defect.\n\nAnother interplay between the groups Ld,p and LD is as follows. Let SD\u2212d\u22121 be a (D \u2212\nd \u2212 1)-dimensional sphere that links the worldvolume of Sd+1 in a small neighborhood of\n\n17\n\n\n\nTD\n\nTd\n\nSD+1\n\nTd+1\n\nFigure 10: Relative defect Td inside a relative theory TD. The relative theory TD is attached\nto a TQFT SD+1, while the relative defect Td is attached to a topological defect Sd+1 of the\nTQFT SD+1.\n\nSD+1\n\nSd+1\n\n\u03b1p\n\n\u03c0p+1(\u03b1p)\n\nFigure 11: A topological sub-defect \u03b1p \u2208 Ld,p+1 of the topological defect Sd+1 arises at the\nend of a topological defect \u03c0p+1(\u03b1p) \u2208 LD,p+2 of the TQFT SD+1.\n\n18\n\n\n\nsd\u2212p(\u03b1D\u2212p\u22122) \u2208 L0\nd,d\u2212p\n\nSd+1\n\n=\u03b1D\u2212p\u22122 \u2208 LD,D\u2212p\u22121\n\nSd+1\n\nFigure 12: Wrapping a topological defect \u03b1D\u2212p\u22122 \u2208 LD,D\u2212p\u22121 of the TQFT SD+1 along\na sphere SD\u2212d\u22121 surrounding the topological defect Sd+1, and squeezing it, gives rise to a\nsub-defect sd\u2212p(\u03b1D\u2212p\u22122) \u2208 Ld,d\u2212p of the topological defect Sd+1. Since the sub-defect is not\nattached to any other topological defect, it is actually valued in L0\n\nd,d\u2212p.\n\nthe worldvolume. Wrapping a (D\u2212 p\u2212 1)-dimensional topological defect valued in LD,D\u2212p\u22121\n\nalong SD\u2212d\u22121 and squeezing the sphere SD\u2212d\u22121 onto the worldvolume of Sd+1, leaves behind\na (d\u2212 p)-dimensional topological sub-defect of Sd+1 valued in L0\n\nd,d\u2212p. See figure 12. That is,\nwe have a map\n\nsd\u2212p : LD,D\u2212p\u22121 \u2192 L0\nd,d\u2212p . (2.16)\n\nLet us define\nLTd,p := L0\n\nd,p/ Im(sp) , (2.17)\n\nwhich we refer to as the trapped part of Ld,p. This is because LTd,p roughly describes the\ntopological p-dimensional invertible sub-defects of Sd+1 that neither arise at the ends of\ntopological defects of the bulk theory SD+1, nor can be obtained from them via the squeezing\nprocedure discussed above.\n\nWe have non-trivial braidings between elements of Ld,p and elements of Ld,d\u2212p that imply\n\nLd,d\u2212p \u223c= L\u0302d,p , (2.18)\n\nwhere L\u0302d,p is the Pontryagin dual of Ld,p for 1 \u2264 p \u2264 d\u2212 1. These braidings define a pairing\n\u3008\u00b7, \u00b7\u3009Ld on\n\nLd :=\nd\u22121\u220f\np=1\nLd,p (2.19)\n\nthat needs to be consistent with the pairing \u3008\u00b7, \u00b7\u3009LD on LD, such that\n\n\u3008\u03b1p, \u03b1d\u2212p\u3009Ld = \u3008\u03c0p(\u03b1p), \u03b1\u0303d\u2212p\u3009LD (2.20)\n\n19\n\n\n\nfor all \u03b1p \u2208 Ld,p and \u03b1d\u2212p \u2208 Ld,d\u2212p, where \u03b1\u0303d\u2212p is any element of LD,D\u2212p\u22121 such that\nsd\u2212p(\u03b1\u0303d\u2212p) = \u03b1d\u2212p.\n\nNon-locality of sub-defects. We call Ld the defect group associated to the relative defect\nTd. We have seen above that this defect group has a non-trivial interplay with the defect\ngroup LD of the relative theory TD. Ld,p+1 captures (some of) the equivalence classes of p-\ndimensional sub-defects of the relative defect Td. The p-dimensional sub-defects of the relative\ndefect Td in general arise at the ends of the (p+ 1)-dimensional defects of the relative theory\nTD. Consider such a p-dimensional sub-defect Dd,p of the relative defect Td that arises at\nthe end of a (p + 1)-dimensional defect DD,p+1 of the relative theory TD. Moreover, let the\ndefect DD,p+1 lie in an equivalence class \u03b1D,p+1 \u2208 LD,p+2, and the sub-defect Dd,p lie in an\nequivalence class \u03b1d,p \u2208 Ld,p+1. Then, we have the relation\n\n\u03b1D,p+1 = \u03c0p+1(\u03b1d,p) . (2.21)\n\nThe pairing on Ld captures non-locality of these sub-defects as they are moved around within\nthe worldvolume of the relative defect Td.\n\nPolarizations. Now suppose we have picked an absolute theory T\u039bD\nD from the relative theory\n\nTD by choosing a topological boundary conditionB\u039bD\nD of the TQFTSD+1, with the associated\n\npolarization being\n\n\u039bD =\nD\u22121\u220f\np=1\n\n\u039bD,p \u2282 LD . (2.22)\n\nWe want to understand the possible polarizations associated to the absolute defects that can\nbe obtained out of the relative defect Td with the above fixed choice of absolute theory T\u039bD\n\nD .\nAbstractly, we need a d-dimensional topological sub-defect9 B\u039bd\n\nd of the topological boundary\ncondition B\u039bD\n\nD on which one can end the topological defect Sd+1 of the TQFT SD+1. See\nfigure 13. The essential data of B\u039bd\n\nd , as far as invertible sub-defects of Sd+1 are concerned, is\na polarization\n\n\u039bd =\nd\u22121\u220f\np=1\n\n\u039bd,p \u2282 Ld , (2.23)\n\n9Just like B\u039bD\nD is a topological interface with a (D + 1)-dimensional SPT phase in general, the topological\n\nsub-defect B\u039bd\nd is also in general a topological interface between the topological defect Sd+1 and a topological\n\ndefect inside the SPT phase associated to B\u039bD\nD . Even when the (D + 1)-dimensional SPT phase associated to\n\nB\u039bD\nD is trivial, B\u039bd\n\nd is still in general a topological interface, which now converts Sd+1 into a (d+1)-dimensional\nSPT phase. Again, for brevity, we will ignore the interface nature of B\u039bd\n\nd .\n\n20\n\n\n\nTD\n\nTd\n\nSD+1\n\nSd+1\n\nB\u039bd\nd\n\nB\u039bD\nD\n\n=\nT\u039bd\nd\n\nT\u039bD\nD\n\nFigure 13: Choosing a topological sub-defect B\u039bd\nd of the boundary condition B\u039bD\n\nD of the\nTQFT SD+1 constructs an absolute defect T\u039bd\n\nd of the absolute theory T\u039bD\nD .\n\nwhere \u039bd,p \u2286 Ld,p describes the subgroup of p-dimensional invertible sub-defects of Sd+1 that\ncan end on B\u039bd\n\nd . A consistency condition is that\n\n\u03c0p(\u039bd,p) \u2286 \u039bD,p+1 . (2.24)\n\nThat is, if a p-dimensional topological sub-defect \u03b1p \u2208 Ld,p of Sd+1 can end, then the bulk\ntopological defect \u03c0p(\u03b1p) \u2208 LD,p+1 it is attached to ends as well. Another consistency condition\nis that\n\nsd\u2212p(\u039bD,D\u2212p\u22121) \u2286 \u039bd,d\u2212p . (2.25)\n\nThat is, if a topological defect \u03b1D\u2212p\u22121 \u2208 LD,D\u2212p\u22121 can end, then the topological sub-defect\nsd\u2212p(\u03b1D\u2212p\u22121) \u2208 Ld,d\u2212p (obtained by squeezing \u03b1D\u2212p\u22121) must end as well. Choosing such a\nB\u039bd\nd gives us an absolute defect T\u039bd\n\nd living inside the absolute theory T\u039bD\nD .\n\nHigher-form symmetries. As discussed earlier, LD/\u039bD = \u039b\u0302D captures higher-form sym-\nmetries of the absolute theory T\u039bD\n\nD . Similarly, Ld/\u039bd = \u039b\u0302d captures \u2018higher-form symmetries\nof the absolute defect\u2019 T\u039bd\n\nd . The p-form symmetry group \u0393(p)\n[\nT\u039bd\nd\n\n]\nof the absolute defect T\u039bd\n\nd\n\nis\n\u0393(p)\n\n[\nT\u039bd\nd\n\n]\n= Ld,d\u2212p\u22121/\u039bd,d\u2212p\u22121 \u223c= \u039b\u0302d,p+1 . (2.26)\n\nThe background field Bd,p+1 \u2208 Cp+1(\u03a3d, \u039b\u0302d,p+1) of the p-form symmetry \u0393(p)\n[\nT\u039bd\nd\n\n]\nof the\n\nabsolute defect T\u039bd\nd is a (p + 1)-cochain valued in \u039b\u0302d,p+1 on the d-dimensional worldvolume\n\n\u03a3d of the absolute defect T\u039bd\nd .\n\nHowever, these background fields interact non-trivially with the background fields for the\nhigher-form symmetries \u039b\u0302D of the bulk absolute theory T\u039bD\n\nD . Let the background field for the\n\n21\n\n\n\nbulk p-form symmetry be denoted by BD,p+1 \u2208 Cp+1(\u03a3D, \u039b\u0302D,p+1), which is a (p+ 1)-cochain\nvalued in \u039b\u0302D,p+1 on the D-dimensional spacetime manifold \u03a3D where the absolute theory T\u039bD\n\nD\n\nlives. For example, the fact that topological defects valued in \u039bD can end on T\u039bd\nd to give rise\n\nto topological defects valued in \u039bd imposes the following relationship on the background fields\n\n\u03b4BD,D\u2212d+p = \u03c0\u2228d\u2212p\u22121(Bd,p+1) \u2227 \u03b4\u03a3d\nD\u2212d , (2.27)\n\nwhere \u03b4\u03a3d\nD\u2212d is the cochain Poincar\u00e9 dual to \u03a3d inside \u03a3D, and\n\n\u03c0\u2228d\u2212p\u22121 : \u039b\u0302d,p+1 \u2192 \u039b\u0302D,D\u2212d+p (2.28)\n\ndescends from the map \u03c0d\u2212p\u22121 : Ld,d\u2212p\u22121 \u2192 LD,d\u2212p along with the use of isomorphisms\nLd,d\u2212p\u22121 \u223c= \u039b\u0302d,p+1 and LD,d\u2212p \u223c= \u039b\u0302D,D\u2212d+p. The reader can check that (2.28) is a well-defined\nmap constructed this way, thanks to the condition (2.24).\n\nGenuine and non-genuine defects. Let us now look at the fate of the non-topological\ndefects after choosing the polarizations \u039bD and \u039bd. These defects provide charged objects\nunder the higher-form symmetries discussed above. Consider a sub-defect Dp of the relative\ndefect Td lying in an equivalence class in \u039bd,p+1. Let Dp be attached to a defect Dp+1 of\nthe relative theory TD. Then, (2.24) implies that Dp+1 is a genuine defect of the absolute\ntheory T\u039bD\n\nD . Moreover, Dp is a sub-defect of the absolute defect T\u039bd\nd arising at the end of\n\nDp+1 on T\u039bd\nd , without any additional topological sub-defects of T\u039bd\n\nd attached to the defect-\nsubdefect configuration formed by Dp+1 and Dp. See figure 14. Let \u03b1p \u2208 \u039bd,p+1 be the\nequivalence class associated to Dp. The transformation of Dp under a p-form symmetry\nelement \u03b1\u0302p \u2208 \u0393(p)\n\n[\nT\u039bd\nd\n\n]\n\u223c= \u039b\u0302d,p+1 living on the absolute defect T\u039bd\n\nd is given by evaluating\n\n\u03b1\u0302p(\u03b1p) \u2208 U(1) (2.29)\n\nNow consider the situation when the sub-defect Dp lies in an equivalence class \u03b1p in\nLd,p+1 \u2212 \u039bd,p+1 while the equivalence class \u03c0p+1(\u03b1p) of the defect Dp+1 (that Dp is attached\nto) lies in \u039bD,p+2. This means that while Dp+1 is a genuine defect of the absolute theory\nT\u039bD\nD , the sub-defect Dp of the absolute defect T\u039bd\n\nd arising at the end of Dp+1 is not completely\ngenuine, in the sense that it is attached to an additional (p+ 1)-dimensional topological sub-\ndefect of T\u039bd\n\nd . See figure 15. The (p+ 1)-dimensional topological sub-defect is specified by the\nelement [\u03b1p] \u2208 Ld,p+1/\u039bd,p+1 \u223c= \u039b\u0302d,d\u2212p\u22121.\n\nFinally, consider the situation when the equivalence class \u03b1p lies in Ld,p+1 \u2212 \u039bd,p+1 and\nthe equivalence class \u03c0p+1(\u03b1p) lies in LD,p+2 \u2212\u039bD,p+2. In this case, the defect Dp+1 is a non-\ngenuine defect of the absolute defect T\u039bd\n\nd attached to the (p+2)-dimensional topological defect\n\n22\n\n\n\nDp Dp+1\n\nT\u039bd\nd\n\nT\u039bD\nD\n\nFigure 14: A \u201cgenuine\u201d sub-defect Dp of the absolute defect T\u039bd\nd arising at the end of a genuine\n\ndefect Dp+1 of the absolute theory T\u039bD\nD . Such a configuration occurs when the equivalence\n\nclass [Dp] of Dp is in \u039bd,p+1 (which implies [Dp+1] = \u03c0p+1([Dp]) \u2208 \u039bD,p+2).\n\nDp Dp+1\n\nT\u039bd\nd\n\nT\u039bD\nD\n\n[\u03b1p]\n\nFigure 15: A \u201cnon-genuine\u201d sub-defect Dp of the absolute defect T\u039bd\nd arising at the end of\n\na genuine defect Dp+1 of the absolute theory T\u039bD\nD . Such a configuration occurs when the\n\nequivalence class \u03b1p = [Dp] \u2208 Ld,p+1 \u2212 \u039bd,p+1 and [Dp+1] = \u03c0p+1(\u03b1p) \u2208 \u039bD,p+2. In such a\nsituation, the non-topological sub-defect Dp is further attached to a topological sub-defect\n[\u03b1p] \u2208 Ld,p+1/\u039bd,p+1 of the absolute defect T\u039bd\n\nd .\n\n23\n\n\n\nDp Dp+1\n\nT\u039bd\nd\n\nT\u039bD\nD\n\n[\u03b1p]\n[\u03c0p+1(\u03b1p)]\n\nFigure 16: A \u201cnon-genuine\u201d sub-defect Dp of the absolute defect T\u039bd\nd arising at the end of a\n\nnon-genuine defect Dp+1 of the absolute theory T\u039bD\nD . Such a configuration occurs when the\n\nequivalence class \u03b1p = [Dp] \u2208 Ld,p+1 \u2212 \u039bd,p+1 and [Dp+1] = \u03c0p+1(\u03b1p) \u2208 LD,p+2 \u2212 \u039bD,p+2. In\nsuch a situation, the non-topological sub-defect Dp is attached to a topological sub-defect\n[\u03b1p] \u2208 Ld,p+1/\u039bd,p+1 of the absolute defect T\u039bd\n\nd , and the non-topological defect Dp+1 is\nattached to a topological defect [\u03c0p+1(\u03b1p)] \u2208 LD,p+2/\u039bD,p+2 of the absolute theory T\u039bD\n\nD .\n[\u03c0p+1(\u03b1p)] ends on T\u039bd\n\nd and [\u03b1p] arises at this end.\n\nof the absolute theory T\u039bD\nD specified by the element [\u03c0p+1(\u03b1p)] \u2208 LD,p+2/\u039bD,p+2 \u223c= \u039b\u0302D,D\u2212p\u22122.\n\nSimilarly, the sub-defect Dp of the absolute defect T\u039bd\nd arising at the end of Dp+1 is also\n\nnot genuine, being attached to the (p+ 1)-dimensional topological sub-defect of the absolute\ndefect T\u039bd\n\nd specified by the element [\u03b1p] \u2208 Ld,p+1/\u039bd,p+1 \u223c= \u039b\u0302d,d\u2212p\u22121. Moreover, the (p + 1)-\ndimensional topological sub-defect [\u03b1p] lives at the intersection of the (p + 2)-dimensional\ntopological defect [\u03c0p+1(\u03b1p)] and the absolute defect T\u039bd\n\nd . See figure 16.\n\nTwisted sector relative defects. Assume that the TQFT SD+1 has a 0-form symmetry\ngroup LD,D. Let the ends of the topological defects valued in LD,D at the location of the\nrelative theory TD give rise to topological defects of the relative theory TD that are also valued\nin LD,D. Then, we can consider codimension-two relative defects Td=D\u22122 of the relative theory\nTD that arise at the end of a topological codimension-one defect \u03b1 \u2208 LD,D of TD. For such\na relative defect, the non-invertible topological defect Sd+1=D\u22121 also arises at the end of the\ncodimension-one topological defect \u03b1 \u2208 LD,D of the TQFT SD+1.\n\nThe (not necessarily topological) defects that arise at the ends of p-form symmetry gen-\nerating topological defects are called twisted sector defects for the p-form symmetry. In this\nlanguage, the above discussed codimension-two relative defects and the topological defect\nSd+1=D\u22121 are twisted sector defects for the 0-form symmetry LD,D.\n\n24\n\n\n\nThe defect group of such a twisted sector relative defect has almost the same structure as\nfor the untwisted relative defects discussed above, though there are slight modifications due\nto the action of LD,D on LD,p for p < D. The co-domain of the map \u03c0p is the group obtained\nby modding out LD,p+1 by the action of \u03b1 \u2208 LD,D. On the other hand, the domain of the\nmap sd\u2212p is the subgroup of LD,D\u2212p\u22121 left invariant by the action of \u03b1 \u2208 LD,D.\n\n2.5 Relative Defects in 6d (2, 0) Theories\n\nIn this paper we study codimension-two defects of 6d N = (2, 0) theories, and find that in\ngeneral such defects are relative defects. Since 6d N = (2, 0) theories are relative theories, we\nobtain examples of the case of relative defects inside relative theories discussed in the previous\nsubsection. This is a specialization of the general analysis so far to the case of\n\nD = 6 , d = 4 . (2.30)\n\nBelow, we will keep the subscripts d and D for ease of comparison with the earlier analysis.\nRecall that a 6d (2, 0) theory of type g has defect group\n\nLD = LD,3 = Z\u0302G . (2.31)\n\nA codimension-two defect (meaning d = 4) of the 6d (2, 0) theory has in general a defect group\n\nLd = Ld,1 \u00d7 Ld,2 \u00d7 Ld,3 . (2.32)\n\nIn this paper, we study only the Ld,2 part of the defect group, while leaving the study of\nLd,1 \u00d7Ld,3 part of the defect group to future works. In fact, Ld,2 is the more interesting part\nof Ld as it can interact with the defect group LD = LD,3 of the 6d (2, 0) theory itself. Ld,2\ncaptures equivalence classes of non-topological line defects in the relative codimension-two\ndefect.\n\nWe find that Ld,2 can be expressed as\n\nLd,2 =W \u00d7H (2.33)\n\nwith the pairing on Ld,2 being such that it provides an isomorphism W \u2192 H\u0302. That is, we can\nwrite\n\nW \u223c= H\u0302 , (2.34)\n\nwhere H\u0302 is the Pontryagin dual of H. Moreover, we have\n\nL0\nd,2 =W \u00d7HT , (2.35)\n\n25\n\n\n\nwhere HT is a subgroup of H and L0\nd,2 is the kernel of the map\n\n\u03c02 : Ld,2 \u2192 LD,3 (2.36)\n\ndescribing which line defects of the codimension-two defect arise at the ends of surface defects\nof the bulk 6d N = (2, 0) theory.\n\nDually, the image Im(s2) of the map\n\ns2 : LD,3 \u2192 Ld,2 (2.37)\n\nrelating surface defects of the (2, 0) theory and line defects of the codimension-two defect via\nthe squeezing procedure, is such that\n\nIm(s2) \u2286 W \u2282 Ld,2 . (2.38)\n\nLet us define\nWT :=W/Im(s2) . (2.39)\n\nThis allows us to express the trapped part LTd,2 of Ld,2 as\n\nLTd,2 = L0\nd,2/Im(s2) =WT \u00d7HT . (2.40)\n\nThe pairing on Ld,2 descends to a pairing on LTd,2 which is such that it provides an isomorphism\n\nWT \u223c= H\u0302T , (2.41)\n\nwhere H\u0302T is the Pontryagin dual of HT . We also discuss twisted codimension-two defects that\narise at the ends of topological codimension-one defects implementing the outer-automorphism\n0-form symmetries, and they have a similar structure as discussed above.\n\n2.6 Compactification: Relative Theories from Relative Defects\n\nSuppose we compactify a relative theory TD on a (D\u2212d)-dimensional compactification mani-\nfold \u03a3D\u2212d. Moreover, let us place d-dimensional relative defects Tid of various types i at points\npi on \u03a3D\u2212d. Such a compactification yields a relative d-dimensional theory T\u0303d.\n\nThe defect group L\u0303d of the resulting theory T\u0303d obtains contributions not only from the\ndefect group LD of the parent theory TD, but also from the defect group Lid of the relative\ndefects Tid employed in the compactification. In particular, the component L\u0303d,p will obtain\ncontributions not only from LD,q for q \u2265 p, but also from Lid,p.\n\nOne of main topics of study in this paper is to study a class of these kinds of compacti-\nfications. For us TD is a 6d N = (2, 0) theory, which is compactified on a Riemann surface\n\n26\n\n\n\n\u03a32. The relative defects Tid are codimension-two defects of the 6d N = (2, 0) theory. Since\nthese relative defects are inserted at points on the Riemann surface, they are also referred to\nas punctures on the Riemann surface. The resulting theory T\u0303d is a 4d N = 2 Class S theory.\n\nWe are interested in computing the component L\u0303d,2 of the defect group L\u0303d of the Class\nS theory T\u0303d. This component characterizes equivalence classes of line defects in the Class\nS theory. It receives contributions from the surface defects of the (2, 0) theory valued in\nLD = LD,3 and compactified along 1-cycles of the Riemann surface \u03a32. These kinds of\ncontributions have been studied extensively in the past literature [1, 31,73,74].\n\nHowever, as discussed above, there are also contributions from the line defects of the\nrelative defects valued in Lid,2 that we determine in this paper.\n\n3 Evidence for Trapped 1-Form Symmetries\n\nThere is much evidence for the existence of additional sources of 1-form symmetries in Class\nS theories, coming from the punctures used in the Class S construction. We will present two:\nType IIB constructions of 4d N = 2 SCFTs using isolated hypersurface singularities (IHS)\ncan have non-trivial 1-form symmetries. In turn, some of these theories have a realization\nas class S theories based on a sphere with a single irregular puncture. We will develop the\ndictionary between irregular punctures and IHS in section 6. This correspondence then very\nstrongly suggests that irregular punctures have trapped 1-form symmetries! This is because\na sphere has no non-trivial 1-cycles that can give rise to the usual type of 1-form symmetries\nin Class S theories that were discussed in [31].\n\nThe second motivation comes from the collision of regular punctures, to result in irregular\nones. If the setup with regular punctures had 1-form symmetry, then again it is indicative that\nthe resulting theory with irregular punctures should also have this symmetry, again pointing\ntowards the existence of trapped 1-form symmetries.\n\n3.1 The Defect Group of Type IIB on IHS\n\nType IIB compactification on canonical non-compact Calabi-Yau three-fold singularities X\nengineers 4d N = 2 SCFTs [78, 82]. A singularity X that admit a resolution \u03c0 : X\u0303 \u2192 X,\nwhich satisfy\n\nKX\u0303 = \u03c0\u2217KX +\n\u2211\ni\n\naiSi (3.1)\n\nwith ai \u2265 0, where K is the canonical class, and Si the exceptional divisors of the resolution,\nare called canonical singularities. When ai > 0 the singularity is terminal, and if ai = 0 for\nall i it admits a crepant (i.e. Calabi-Yau) resolution.\n\n27\n\n\n\nThe type of Calabi-Yau singularities that we will consider in this paper are so-called\nisolated hypersurface singularities (IHS): these are hypersurface equations in C4, of the type\n\nP (x1, x2, x3, x4) = 0 , (3.2)\n\nwhere P is a polynomnial in xi, satisfying various requirements, e.g. the existence of an\nisolated canonical singularity. IHSs can be classified and we refer to this as the Kreuzer-\nSkarke-Yau-Yu (KS-YY) classification [79, 85]. To specify an IHS we will use the notation\nin [55], which indicates the type and vanishing orders of P .\n\nIn [17, 29, 30, 36, 55] the deformation theory of the isolated hypersurface singularity (IHS)\nrealization of such 4d N = 2 theories was used to compute the line defects, and thereby 1-form\nsymmetry. This is computed from the homology of the link\n\nLX = Tor ker(h2) \u2286 H2(\u2202X,Z) , (3.3)\n\nwhere\nh2 : H2(\u2202X,Z)\u2192 H2(X,Z) (3.4)\n\nis the map lifting a 2-cycle on the boundary \u2202X to a 2-cycle in the bulk X. The pairing on\nLX descends from the linking pairing on H2(\u2202X,Z).\n\nThe line defects are D3-branes wrapped on relative 3-cycles, (modulo screening by local\noperators realized as D3-branes on compact 3-cycles). This in turn can be identified with the\nhomology H2(\u2202X,Z) of the link, under the assumption that there is no torsion in the second\nhomology of the bulk X. We will provide explicit examples of these defect groups in the\nfollowing. Here we should note that they can be computed from the hypersurface singularity\nusing the code in [55]. Examples are AD theories of type AD[G,G\u2032], with certain choices for\n(G,G\u2032) = (A,D), (A,E), (D,D).\n\nThe non-triviality of the defect groups of lines for such IHS has an important, quite central,\nimplication for class S construction: We will see in section 6 that many of these hypersurfaces\nhave realizations as class S with a single irregular puncture P on a sphere. The results from\nthe IHS realization imply that there are trapped line operators denoted by LTP in such class\nS theories. In their Type IIB realization on the singularity XP correspond to the relative\nhomology groups (3.3):\n\nLTP = LXP . (3.5)\n\nThus, the trapped defect group LTP of a puncture P lying in the IHS class can be computed\nfrom the data of the Calabi-Yau singularity XP associated to P using the techniques of [30,55],\nwhich can be applied to any IHS. The relative homology groups are computed in these cases by\n\n28\n\n\n\nusing the deformation data of the IHS. We will not review this, but provide the results from\nthese computations in the subsequent sections, which provide a prediction for the trapped\npart of the defect group for Class S theories.\n\n3.2 Collisions of Regular Punctures\n\n4d N = 2 theories of class S constructed purely from regular twisted punctures can carry a\nnon-trivial defect group of lines [31]. In many cases irregular punctures arise from operations\non these theories, examples for such operations include the collision of punctures, gauging\nof flavor symmetries and (de)coupling of matter. The defect group associated with irregular\npunctures can therefore be bootstrapped from the results in [31] whenever the consequences\nof these operations on defect groups is understood. Here we will adopt this approach to show\nthat irregular punctures must in general carry a nontrivial trapped defect group. It is enough\nto consider a simple set of Lagrangian theories to illustrate this.\n\nAs is well known, most 4d N = 2 conformal linear quivers admit a class S description\ninvolving a collection of regular punctures on a sphere and in particular we will be concerned\nhere with orthosymplectic quivers (alternating so and usp gauge algebras with bifundamental\nhalf-hypermultiplets in between), which are realized by compactifying the 6dN = (2, 0) theory\nof type D on a sphere with both twisted and untwisted regular punctures. Qualitatively, the\nstructure of such theories is as follows: there is a central part of the quiver in which the ranks\nof the gauge algebras stay constant and the quiver locally looks like . . . usp(2N\u22122)\u2212so(2N)\u2212\nusp(2N\u22122) . . . This pattern is reproduced by gluing together a collection of trinions with a full\nuntwisted and two twisted punctures, one full and the other minimal. This trinion describes\nthe half-hypermultiplet in the bifundamental of usp(2N \u2212 2) \u00d7 so(2N). This central part of\nthe quiver is decorated at both ends by tails, whose gauge nodes display decreasing rank as we\nmove towards the ends of the quiver. Many such tails are possible and in the class S formalism\nthe choice of tail translates into the choice of regular puncture. The dictionary between DN\n\npunctures (both twisted and untwisted) and quiver tails is described in detail in [61]. Overall,\nif we have a conformal linear quiver with k gauge groups, the class S description involves\nk + 3 regular punctures on the sphere. k + 1 of them are minimal twisted and the other two\ndetermine the structure of the tails.\n\nAs a special case of this construction, we can consider the following linear quivers:\nk even : N + n\u2212 1\u2212 so(2N)\u2212 usp(2N \u2212 2n\u2212 2)\u2212 \u00b7 \u00b7 \u00b7 \u2212 so(4n+ 2)\u2212 usp(2n)\u2212 1\n\nk odd : N + n\u2212 1\u2212 so(2N)\u2212 usp(2N \u2212 2n\u2212 2)\u2212 \u00b7 \u00b7 \u00b7 \u2212 usp(4n)\u2212 so(2n+ 2) .\n(3.6)\n\nwhich carry a non-trivial defect group of lines. Every so gauge algebra contributes a Z2\n2 factor\n\nto the defect group. For every n < N these linear quivers can be realized using the 6d theory\n\n29\n\n\n\nFull\n\nReg\nMin\n\nMin\n\nMin\n\nMin\n\nMin\n\nFull\n\nRegMin\n\nMin\n\nMin\n\nMin\n\nMin\n\nMin\n\nk even k odd\n\nFigure 17: Class S configurations for the quivers in (3.6). In both cases the UV curve is a\nsphere, quivers with an even or odd number of gauge nodes are distinguished by the puncture\nstructure.\n\nof type DN with regular punctures only. We display the corresponding punctured spheres in\nfigure 17. The tails on the left are trivial and the corresponding puncture is full twisted.\n\nNotice that the flavor symmetry of our quivers is larger than that we naively expect from\nthe class S description, since the full twisted puncture carries usp(2N \u2212 2) flavor symmetry\nbut from the flavors on the left end of the quivers we get usp(2N + 2n\u22122). This is the crucial\nfeature we need for our analysis, as we will now see.\n\nThe next step is to give infinite mass to n fundamentals of so(2N) in (3.6), so that they\ndecouple. This move clearly does not change the defect group of lines of the theory since we\nare not decoupling N \u2212 1 of the remaining flavors. After this modification the so(2N) gauge\nalgebra is no longer conformal and therefore the new quivers cannot be described using regular\npunctures only. We therefore ask if we can still provide a class S description. The answer is\nyes but we need to introduce irregular punctures. Indeed the conformal quivers\n\nk even : N\u2212 usp(2N \u2212 2n\u2212 2)\u2212 \u00b7 \u00b7 \u00b7 \u2212 so(4n+ 2)\u2212 usp(2n)\u2212 1\n\nk odd : N\u2212 usp(2N \u2212 2n\u2212 2)\u2212 \u00b7 \u00b7 \u00b7 \u2212 usp(4n)\u2212 so(2n+ 2) .\n(3.7)\n\nare known to be described by a 6dN = (2, 0)DN theory on a sphere with a full untwisted punc-\nture and an irregular puncture [103]. In that reference these theories were dubbedDk(SO(2N))\nand we will discuss them more in detail later. The only difference between the quivers (3.7)\nand those in (3.6) after the mass deformation is the gauging of the so(2N) flavor symmetry\nand the addition of the N\u22121 flavors. This modification is easily implemented in class S since it\nsimply corresponds to gluing the sphere with the irregular puncture together with the trinion\nwe described before (full and minimal twisted punctures and full untwisted puncture). The\nresulting Riemann surface is a sphere with the irregular puncture and two twisted punctures,\none full and one minimal. This is depicted in figure 18 where we denote with Pk the irregular\npuncture.\n\nBy comparing figures 17 and 18 we see that the effect of the mass deformation, which does\n\n30\n\n\n\nFull PkMin\n\nFigure 18: The Class S construction for conformal quivers (3.7).\n\nA\n\nB\n\nFigure 19: Picture of four twisted punctures in some patch of the UV curve together with\none-cycles A,B associated with lines.\n\nnot change the defect group, is to induce the collision of the k + 1 regular punctures into the\nirregular puncture Pk. This irregular puncture must carry trapped defect group of lines, as\nthe 1-cycles on the Riemann surface shown in figure 18 do not give rise to any non-trivial\ndefect group.\n\nIn fact, the existence of trapped defect groups inside Pk can be understood as follows.\nConsider a configuration of four twisted regular punctures shown in figure 19. As discussed\nin [31], each of the cycles A and B contributes a Z2 group of line defects. As we collide the\nfour punctures together, the A and B cycles, and hence the contributions associated to them,\nbecome trapped at the puncture.\n\nThe above analysis shows that irregular punctures can carry nontrivial trapped defect\ngroups that can provide trapped contributions to one-form symmetries of absolute 4d N = 2\nClass S theories. The Lagrangian theories we have just discussed represent special cases of this\nphenomenon and in the rest of this paper we will explain how to determine the contribution\nfrom irregular punctures to the defect group of line defects.\n\n4 1-Form Symmetries of Arbitrary Class S Theories\n\nHere we discuss the computation of 1-form symmetry of an arbitrary Class S theory obtained\nby compactifying a 6d N = (2, 0) theory of A, D, E type an arbitrary genus g Riemann surface\ncontaining arbitrary number of twisted and untwisted, regular and irregular punctures, along\n\n31\n\n\n\nwith an arbitrary number of closed outer-automorphism twist lines.\nThe 1-form symmetry of the Class S theory can be expressed in terms of data associated\n\nto the punctures participating in the class S construction. This data associated to punctures\nis referred to as the defect group associated to the punctures.\n\nThus, using the analysis presented in this section, one can reduce the computation of 1-form\nsymmetries of Class S theories to the computation of defect groups associated to punctures.\nWe discuss the computations of defect groups of punctures in the following sections.\n\n4.1 The Defect Group of a Puncture\n\nDecomposition into electric and magnetic lines. A codimension-two defect (i.e. a\npuncture10) P is characterized by a defect group of line defects\n\nLP =WP \u00d7HP . (4.1)\n\nThe \u201celectric\u201d part WP is Pontryagin dual to the \u201cmagnetic\u201d part HP , i.e.\n\nWP = H\u0302P . (4.2)\n\nThe pairing for two elements (w1, h1), (w2, h2) \u2208 WP \u00d7HP is given by\n\n\u3008w1, h2\u3009 \u2212 \u3008w2, h1\u3009 \u2208 R/Z , (4.3)\n\nwhere \u3008w, h\u3009 \u2208 R/Z is given by applying the element w \u2208 H\u0302P on the element h \u2208 HP .\n\nMagnetic lines and their relationship to surface defects. The elements of HP are line\ndefects living on P that arise at the ends of surface defects11 of the bulk 6d N = (2, 0) theory\nending on the co-dimension-two defect P. See figure 20.\n\nThus, for an untwisted puncture, there is a natural projection map\n\n\u03c0\u0303P : HP \u2192 S6d (4.4)\n\nthat forgets the data of the line defect arising at the end, and spits out only the bulk surface\ndefect. The bulk surface defects are valued in a group S6d which we identify with the group\n\n10Here we consider both untwisted and twisted punctures. The codimension-two defect associated to an\nuntwisted puncture is a genuine codimension-two defect of the 6d theory. On the other hand, the codimension-\ntwo defect associated to a twisted puncture is a non-genuine codimension-two defect of the 6d theory that lives\nat the end of a codimension-one topological defect associated to an outer-automorphism 0-form symmetry of\nthe 6d theory.\n\n11These are not all such line defects: In fact, a general element of \u03b1 \u2208 HP \u00d7WP arises at the end of a surface\ndefect. The key point is that the bulk surface defect depends only on the projection of \u03b1 onto the HP factor,\nbut does not depend on the projection of \u03b1 onto the WP factor.\n\n32\n\n\n\nP\n\n\u0393\u03a3\n\nFigure 20: Bulk surface defect \u03a3 supporting g \u2208 ZP \u2282 S6d, ending on the co-dimension-two\ndefect P and bound by the line defect \u0393 supporting h \u2208 HP . This implies \u03c0\u0303P(h) = g.\n\nZ\u0302G Pontryagin dual to the center ZG of the simply connected group G associated to the A,D,E\nalgebra g specifying the 6d N = (2, 0) theory. The mutual non-locality of the surface defects\nis captured by a pairing on S6d = Z\u0302G, which provides an isomorphism p6d between Z\u0302G and\nZG. See table 1 in section 2.1.\n\nOn the other hand, for a twisted puncture, the analogous projection map is\n\n\u03c0\u0303P : HP \u2192 So6d (4.5)\n\nwhere o is the outer-automorphism symmetry element that the twisted puncture P is attached\nto, and So6d is obtained from S6d by modding out by the action of o as follows\n\nSo6d = S6d\n(1\u2212 o) \u00b7 S6d\n\n(4.6)\n\nwhere\nS6d \u2287 (1\u2212 o) \u00b7 S6d :=\n\n{\n\u03b1\u2212 o \u00b7 \u03b1 \u2208 S6d\n\n\u2223\u2223\u2223\u03b1 \u2208 S6d\n}\n\n(4.7)\n\nand o\u00b7\u03b1 \u2208 S6d is obtained by applying the action of the outer-automorphism o on \u03b1 \u2208 S6d. The\nco-domain of \u03c0\u0303P is So6d because the move shown in figure 21 relates a line defect arising at the\nend of \u03b1 \u2208 (1\u2212 o) \u00b7 S6d to a line defect arising at the end of a trivial line defect. Thus, modulo\nscreenings, line defects living on P arising at the ends of surface defects in (1 \u2212 o) \u00b7 S6d are\nequivalent to genuine line defects living on P. For future purposes, let us define the projection\nmap\n\n\u03c0o : S6d \u2192 So6d (4.8)\n\nassociated to (4.6).\nMoving forwards, we often combine the twisted and untwisted cases by regarding the\n\nuntwisted case as a special case of the twisted cases obtained by choosing o to be the identity\nelement in the outer-automorphism group.\n\n33\n\n\n\n\u03b1\n\no \u00b7 \u03b1\n(1\u2212 o) \u00b7 \u03b1\n\no o=\nP P\n\nFigure 21: A surface defect (1\u2212 o) \u00b7\u03b1 ending on an o-twisted puncture P can be topologically\nrelated to surface defect not ending on the puncture.\n\nTrapped magnetic lines. Now consider two elements h1, h2 \u2208 HP whose image in So6d is\nthe same. Then, h1\u2212h2 \u2208 HP describes a line defect living on P which is not attached to any\nbulk surface defect. We call such a line defect as a line defect trapped at the codimension-two\ndefect (or puncture) P. There is a subgroup HTP \u2286 HP which are trapped line defects. In\ntotal, we have a short exact sequence\n\n0 \u2192 HTP \u2192 HP \u2192 ZP \u2192 0 , (4.9)\n\nwhere the map\niP : HTP \u2192 HP (4.10)\n\nin (4.9) is the inclusion map making HTP a subgroup of HP , and\n\nZP = \u03c0\u0303P(HP) \u2286 So6d (4.11)\n\nis the subgroup of bulk surface defects in S6d that can end on P. The map\n\n\u03c0P : HP \u2192 ZP (4.12)\n\nin (4.9) is the map \u03c0\u0303P with co-domain restricted to the image ZP \u2286 So6d of \u03c0\u0303P .\n\nElectric lines and their relationship to surface defects. The elements of WP are\ngenuine line defects living on P that are mutually non-local with the line defects in HP . A\nsubgroup WSP of WP is obtained from bulk surface defects by the following procedure. First\ndefine\n\nS6d \u2287 S6d,o :=\n{\n\u03b1 \u2208 S6d\n\n\u2223\u2223\u2223o \u00b7 \u03b1 = \u03b1\n}\n. (4.13)\n\nFor an untwisted puncture, o is identity and hence S6d,o = S6d. The bulk surface defects\nin S6d,o can be wrapped along a loop linking P as the outer-automorphism codimension-one\ntopological defect associated to o leaves them invariant. Now take a surface defect in S6d,o\n\n34\n\n\n\nP\n\n\u03a3\n\u03b3\n\nP\n\no = o\n\nFigure 22: The bulk surface defect \u03a3 labelled by v \u2208 S6d,o links the o-twisted co-dimension-two\ndefect P (left). The \u2018squeezing\u2019 operation gives a line defect \u03b3 labelled by w \u2208 WSP (right).\nThis implies \u03c0SP(v) = w.\n\nand wrap it along such a loop. Squeezing the loop to zero size leaves behind a line defect in\nWSP living on P. See figure 22. In other words, we define WSP to be the subgroup of genuine\nline defects living on P that can be \u2019lifted\u2019 to bulk surface defects of the 6d theory. Thus, we\nhave a projection map\n\n\u03c0SP : S6d,o \u2192WSP . (4.14)\n\nBefore moving forward, notice that the pairing on S6d descends to a pairing between S6d,o and\nSo6d. To show this, we need to show that \u3008\u03b1, \u03b2\u3009 = 0 if \u03b1 \u2208 S6d,o \u2286 S6d and \u03b2 \u2208 (1\u2212o)\u00b7S6d \u2286 S6d.\nIndeed,\n\n\u3008\u03b1, \u03b2\u3009 = \u3008\u03b1, \u03b3\u3009 \u2212 \u3008\u03b1, o \u00b7 \u03b3\u3009 = \u3008\u03b1, \u03b3\u3009 \u2212 \u3008o \u00b7 \u03b1, o \u00b7 \u03b3\u3009 = \u3008\u03b1, \u03b3\u3009 \u2212 \u3008\u03b1, \u03b3\u3009 = 0 (4.15)\n\nestablishing the well-defined-ness of the pairing between S6d,o and So6d.\nWe now argue that\n\nWSP ' Z\u0302P (4.16)\n\nThat is, WSP can be identified as the Pontryagin dual of ZP . Because of the lifting procedure,\nthe pairing of a line defect \u03b1 \u2208 WSP with a line defect \u03b2 \u2208 HP depends only on the bulk surface\ndefect \u03c0P(\u03b2) \u2208 ZP . Thus\n\n\u03b1 \u2208 Z\u0302P (4.17)\n\nand we have a map\niSP :WSP \u2192 Z\u0302P . (4.18)\n\nThis map is injective because if a non-zero element of WSP has trivial pairing with ZP , then\nit has a trivial pairing with the whole of HP , which is in contradiction to the definition of\nWP . To see that the map is surjective, notice that for each element \u03b2 \u2208 Z\u0302P there is always\n\n35\n\n\n\nan element \u03b1 \u2208 S6d,o such that iSP \u25e6 \u03c0SP(\u03b1) = \u03b2, because we can write\n\niSP \u25e6 \u03c0SP = j\u0302P \u25e6 po6d , (4.19)\n\nwhere j\u0302P \u25e6 po6d is surjective, as\nj\u0302P : S\u0302o6d \u2192 Z\u0302P (4.20)\n\nis the Pontryagin dual of the natural inclusion map\n\njP : ZP \u2192 So6d (4.21)\n\nand\npo6d : S6d,o \u2192 S\u0302o6d (4.22)\n\nis the isomorphism between S6d,o and S\u0302o6d induced by the pairing between So6d and S6d,o. In\nwhat follows, we sometimes use Z\u0302P to denote the line defects in WSP .\n\nLet us also define\nS6d,o \u2287 YP := ker( j\u0302P \u25e6 po6d) , (4.23)\n\nwhich allows us to write\nZ\u0302P = S6d,o/YP . (4.24)\n\nYP \u2286 S6d,o is physically the subgroup of bulk surface defects which give rise to the identity\nline defect (up to screening) on P after performing the above \u201csqueezing\u201d procedure.\n\nTrapped electric lines. The groups WP and Z\u0302P sit in a short exact sequence\n\n0 \u2192 Z\u0302P \u2192 WP \u2192 WT\nP \u2192 0 , (4.25)\n\nwhich is Pontryagin dual to the short exact sequence (4.9). We have\n\nWT\nP = H\u0302TP , (4.26)\n\nwhich characterizes the trapped part of WP , capturing the line defects that cannot be \u201clifted\u201d\nto bulk surface defects. Correspondingly, we call the defect group\n\nLTP :=WT\nP \u00d7HTP (4.27)\n\nas the trapped defect group associated to P. The pairing for two elements (w1, h1), (w2, h2) \u2208\nWT\nP \u00d7HTP is given by\n\n\u3008w1, h2\u3009T \u2212 \u3008w2, h1\u3009T \u2208 R/Z , (4.28)\n\nwhere \u3008w, h\u3009T \u2208 R/Z is given by applying the element w \u2208 H\u0302TP on the element h \u2208 HTP .\n\n36\n\n\n\nGenuine lines and summary. For future purposes, let us also define\n\nL0\nP :=WP \u00d7HTP , (4.29)\n\nwhich is the group formed by all \u201cgenuine\u201d line defects living on P that do not arise at the\nends of any non-trivial bulk surface defect.\n\nIn summary, the defect group associated to a puncture is uniquely determined by the\nmagnetic data which fits into a nested pair of short exact sequences as\n\n0 HTP HP ZP 0\n\nSo6d\n\nY\u0302P\n\n0\n\n0\n\niP \u03c0P\n\n\u03c0\u0303P jP\n\n(4.30)\n\nwith the electric data given by Pontryagin dual diagram. The horizontal sequence relates line\ndefects living on the codimension-two defect P. The vertical sequence relates surface defects\nof the 6d bulk theory.\n\n4.2 Defect Groups of Special Punctures\n\nRegular Punctures. For any regular puncture P, we can rephrase the claims of [31] as\nstating that LTP = 0 and YP = S6d,o, which taken together imply that\n\nLP = 0 . (4.31)\n\nP0 Puncture. Consider 6d N = (2, 0) theory of type g. This theory carries a special\nuntwisted puncture that we call P0. This puncture has the property that\n\nHP0 = ZP0 = S6d (4.32)\n\nThis implies that it has\nWT\nP0 = HTP0 = YP0 = 0 (4.33)\n\n37\n\n\n\nand\nWP0 =WSP0 = S6d . (4.34)\n\nThe P0 puncture is obtained by starting from the maximal untwisted regular puncture, which\ncarries flavor symmetry g, and then gauging this flavor symmetry by adding 4d N = 2 g vector\nmultiplet along the codimension-two defect. To show that the defect data of the puncture\nobtained after g gauging is as claimed above, we simply notice that squeezing bulk surface\ndefects onto the maximal untwisted regular puncture leads to flavor Wilson lines valued in\nZ\u0302G = S6d. This means that, after the gauging, squeezing bulk surface defects onto the P0\n\npuncture leads to gauge Wilson line defects valued in S6d, implying that\n\nWSP0 = S6d . (4.35)\n\nMoreover, the full set of electric line defects on P0 puncture is given by\n\nWP0 = S6d . (4.36)\n\nThese two properties reproduce all the other properties claimed above.\n\nPo0 Puncture. Consider 6d N = (2, 0) theory of type g and an outer-automorphism o. Then\nwe have a special twisted puncture Po0 attached to the outer-automorphism o. This puncture\nhas the property that\n\nHPo0 = ZPo0 = So6d . (4.37)\n\nThis implies that it has\nWT\nPo0 = HTPo0 = YPo0 = 0 (4.38)\n\nand\nWPo0 =WSPo0 = S6d,o . (4.39)\n\nThe Po0 puncture is obtained by starting from the maximal twisted regular puncture associated\nto o, which carries flavor symmetry h\u2228o which is the Langlands dual of the subalgebra12 ho of\ng left invariant by the action of o. Let us note that, except for the case of g = su(2n+ 1) and\nnon-trivial o, there is an isomorphism between S6d,o and the group Z\u0302H\u2228o Pontryagin dual to\nthe center ZH\u2228o of the simply connected group H\u2228o associated to the algebra h\u2228o . Depending\non g and o, both S6d,o and Z\u0302H\u2228o are either trivial or form a Z2. In both cases, there is a unique\npossible isomorphism between the two groups. For the case of g = su(2n+ 1) and non-trivial\no, S6d,o = 0 and Z\u0302H\u2228o = Z2.\n\n12The choices of ho for various g and o can be found in Table 1 of [104].\n\n38\n\n\n\nThis flavor symmetry h\u2228o is then gauged by adding 4d N = 2 h\u2228o vector multiplet along\nthe codimension-two defect. To show that the defect data of the puncture obtained after\nh\u2228o gauging is as claimed above, we simply notice that squeezing bulk surface defects valued\nin S6d,o onto the maximal twisted regular puncture leads to flavor Wilson lines valued in\nS6d,o ' Z\u0302H\u2228o . Now we divide further analysis into two cases:\n\n\u2022 For all cases except g = su(2n + 1) and non-trivial o, the flavor Wilson lines in Z\u0302H\u2228o\n\nare not screened by any genuine local operators, or in other words, there are no genuine\nlocal operators carrying non-trivial flavor center charges valued in Z\u0302H\u2228o . This means\nthat, after the gauging, squeezing bulk surface defects onto the Po0 puncture leads to\ngauge Wilson line defects valued in S6d,o ' Z\u0302H\u2228o , implying that\n\nWSPo0 = S6d,o . (4.40)\n\nMoreover, the full set of electric line defects on Po0 puncture is given by\n\nWPo0 = Z\u0302H\u2228o ' S6d,o . (4.41)\n\nThese two properties reproduce all the other properties claimed above.\n\n\u2022 For the case of g = su(2n+ 1) and non-trivial o, the flavor Wilson lines in Z\u0302H\u2228o = Z2 are\nscreened by genuine local operators [104]. Thus, after gauging, there are no non-trivial\nelectric line operators (modulo screenings) carried by such a Po0 puncture. This leads to\nthe properties claimed above.\n\n4.3 Defect Groups of Class S Theories from Defect Groups of Punctures\n\nWe now combine the defect groups of punctures discussed in the last subsection together with\nthe surface defect contributions discussed in [31], to determine the defect group of an arbitrary\nclass S theory, containing an arbitrary number of twisted and untwisted, irregular and regular\npunctures, on an arbitrary genus Riemann surface.\n\nVarious types of possible lines. Consider a general compactification of a 6d N = (2, 0)\ntheory of type g, leading to a 4d N = 2 theory T. Let Pi with i = 1, 2, \u00b7 \u00b7 \u00b7 , k label the various\npunctures on the compactification manifold \u03a3g of genus g. Additionally, we have an outer-\nautomorphism background [B] \u2208 H1(\u03a3\u2217g,Og), where \u03a3\u2217g is the compactification manifold with\npunctures removed, and Og is the group of outer-automorphisms of g. Near a puncture Pi,\nthe background [B] has a holonomy oi \u2208 Og around Pi, where oi is the outer-automorphism\nelement associated to Pi.\n\n39\n\n\n\nFirst of all, wrapping bulk surface defects along compact 1-cycles of \u03a3g, we generate 4d\nline defects in\n\nK := H\n[B]\n1 (\u03a3\u2217g,S6d) , (4.42)\n\nwhich is the first homology group of \u03a3\u2217g twisted by [B].\nWe moreover have the line defects living on each Pi that are not attached to any bulk\n\nsurface defect. These form the group \u220f\ni\n\nHTPi \u00d7\n\u220f\ni\n\nWPi (4.43)\n\nFinally, we include line defects arising from the bulk surface defects ending on punctures. For\nthis purpose, we pick a non-self-intersecting path Ci,i+1 from puncture i to puncture i+ 1 for\neach 1 \u2264 i \u2264 k \u2212 1. We additionally require that there is no intersection between two paths\nCi,i+1 and Cj,j+1 for i 6= j. Let us also define for 1 \u2264 i < j \u2264 k\n\nCi,j =\nj\u22121\u2211\np=i\n\nCp,p+1 (4.44)\n\nMore precisely, Ci,j is a path from i to j obtained by taking the \u2211j\u22121\np=i Cp,p+1 and perturbing\n\nit slightly away from the punctures i + 1, i + 2, \u00b7 \u00b7 \u00b7 , j \u2212 1, so that Ci,j doesn\u2019t hit those\npunctures. Moreover, let Zi,j be the subgroup of S6d generated by 0 \u2208 S6d and non-zero\nelements \u03b1 \u2208 Yi,j \u2286 S6d having the property that either \u03c0oi(\u03b1) or \u03c0oj (\u03b1) is non-zero, where\n\nYi,j := \u03c0\u22121\noi (ZPi) \u2229 \u03c0\u22121\n\noj (ZPj ) (4.45)\n\n4d line defects arising from bulk surface defects wrapped along the path Ci,j form a group\nHi,j which as a set is\n\nHi,j =\n\u2294\n\n\u03b1\u2208Zi,j\nH\u03b1i,j (4.46)\n\nwhere\nH\u03b1i,j =\n\n{\n(\u03b2, \u03b3) \u2208 HPi \u00d7HPj\n\n\u2223\u2223\u2223\u03c0Pi(\u03b2) = \u03c0oi(\u03b1), \u03c0Pj (\u03b3) = \u03c0oj (\u2212\u03b1)\n}\n\n(4.47)\n\nThe group structure on Hi,j is as follows. Take an element (\u03b21, \u03b31) \u2208 H\u03b11\ni,j and an element\n\n(\u03b22, \u03b32) \u2208 H\u03b12\ni,j . Then we have\n\n(\u03b21, \u03b31) + (\u03b22, \u03b32) = (\u03b21 + \u03b22, \u03b31 + \u03b32) \u2208 H\u03b11+\u03b12\ni,j (4.48)\n\nNotice that any other 4d line defect can be written as a linear combination of the 4d line\ndefects discussed above, which form the group\n\nKT := K \u00d7\nk\u220f\ni=1\nHTPi \u00d7\n\nk\u220f\ni=1\nWPi \u00d7\n\n\u220f\n1\u2264i<j\u2264k\n\nHi,j (4.49)\n\n40\n\n\n\nPi Pj\noi\n\n\u03b2 \u2208 S6d\n\nC\n\n=\nPi Pj\n\noi\n\n\u03b2\n\n\u2212\u03b2\n\n=\nPi Pj\n\noi\n\n\u03b2 \u2212 oi \u00b7 \u03b2\n\nFigure 23: Topological move showing that a 4d line defect obtained by wrapping the surface\ndefect \u03b2 \u2208 S6d along the loop C encircling punctures Pi and Pj is equivalent to a 4d line\ndefect obtained by wrapping \u03b2 \u2212 oi \u00b7 \u03b2 along the path Ci,j going from the puncture Pi to the\npuncture Pj . Here the dashed line denotes the outer-automorphism twist line.\n\nEquivalences between lines and the defect group. Not all the elements lying in KT\n\ngive rise to distinct line defects modulo screenings. First of all, Hi,j contains line defects lying\nin HTPi \u00d7H\n\nT\nPj . This imposes the identification\n\nHi,j \u2287 H\u03b1=0\ni,j 3 (\u03b2, \u03b3) \u223c (i\u22121\n\nPi \u03b2, i\n\u22121\nPj \u03b3) \u2208 HTPi \u00d7H\n\nT\nPj (4.50)\n\nSecond type of identification arises if oi = o\u22121\nj :\n\nHi,j \u2283 H\u03b1i,j 3 (\u03b3, \u03b4) \u223c i\u22121\nPi (\u03b3) + i\u22121\n\nPj (\u03b4) + \u03b2[C] \u2208 HTPi \u00d7H\nT\nPj \u00d7K (4.51)\n\nwhere \u03b1 = \u03b2\u2212 oi \u00b7\u03b2 for some \u03b2 \u2208 S6d, and \u03b2[C] \u2208 K is obtained by wrapping \u03b2 along the loop\nC encircling the two punctures Pi and Pj in a frame obtained by choosing a representative B\nof the outer-automorphism background [B] in which the outer-automorphism twist lines can\nbe represented in the vicinity of Ci,j as shown in figure 23.\n\nTo describe the third identification, pick punctures 1 \u2264 i1 < i2 < i3 \u2264 k. Define\n\nZi1,i2,i3 := Zi1,i2 \u2229 Zi2,i3 (4.52)\n\nand pick \u03b1 \u2208 Zi1,i2,i3 . Then, we have the identification\n\nH\u03b1i1,i2 \u00d7H\n\u03b1\ni2,i3 3 (\u03b2, \u03b3) + (\u2212\u03b3, \u03b4) \u223c (\u03b2, \u03b4) \u2208 H\u03b1i1,i3 (4.53)\n\nfor elements (\u03b2, \u03b3) \u2208 H\u03b1i1,i2 and (\u2212\u03b3, \u03b4) \u2208 H\u03b1i2,i3 .\n\n41\n\n\n\nFinally, consider the 4d line defect \u03b1[Ci] \u2208 K obtained by wrapping an element \u03b1 \u2208 S6d,oi\n\nalong a loop Ci linking the puncture Pi as shown below\n\nPi\noi\n\n\u03b1 \u2208 S6d,oi\n\nCi (4.54)\n\nAs we have discussed in the previous subsection, we have the following identification\n\nK 3 \u03b1[Ci] \u223c \u03c0SPi(\u03b1) \u2208 WSPi \u2286 WPi . (4.55)\n\nIn particular, the 4d line defect \u03b1[Ci] \u2208 K is equivalent to trivial line defect for \u03b1 \u2208 YPi .\nThus, in total, we find that the defect group of line defects of the 4d N = 2 Class S theory\n\nT is\nLT = KT/ \u223c (4.56)\n\nwith the identifications \u223c generated by (4.50), (4.51), (4.53) and (4.55).\n\nPairing on the defect group. The pairing on LT descends from the pairing on KT, which\ncan be concretely described after choosing a representative co-chain B \u2208 C1(\u03a3\u2217g,Og) of the\nouter-automorphism background [B] \u2208 H1(\u03a3\u2217g,Og). Let b \u2208 C1(\u03a3\u2217g,Og) be the chain obtained\nfrom B by applying Poincar\u00e9 duality. Notice that the chain b ends on each twisted puncture\nPi carrying the element oi in the neighborhood of Pi. We additionally require that b does not\nintersect the paths Ci,j .\n\nPicking such a representative allows us to construct elements of K as follows. Pick a non-\nself-intersecting loop C and a point p in C. As we traverse the loop C starting from p, we find\nthat it intersects b at n number of points p1, p2, \u00b7 \u00b7 \u00b7 pn. Thus the loop is divided into segments\nCi,i+1 lying between points pi, pi+1. Let b carry the element oi at the intersection point pi.\nThen, we obtain an element \u03b1p[C] \u2208 K by inserting an element \u03b1 \u2208 S6d at point p. The\nelement \u03b1 must satisfy on \u00b7 on\u22121 \u00b7 \u00b7 \u00b7 o2 \u00b7 o1 \u00b7 \u03b1 = \u03b1. The element of S6d inserted at any other\npoint q along the loop is then determined uniquely in terms of \u03b1. Along the segment between\npn and p1, it is \u03b1. And along the segment Ci,i+1 it is oi \u00b7 oi\u22121 \u00b7 \u00b7 \u00b7 o2 \u00b7 o1 \u00b7\u03b1. See figure 24. Such\nelements \u03b1p[C] for all choices of \u03b1, p, C generate via linear combinations the whole of K.\n\nThe pairing can now be concretely described as follows:\n\n42\n\n\n\np\n\n\u03b1\n\nCn,1\n\no1\n\no2\n\no3\n\non\u22121 on\n\no1 \u00b7 \u03b1\nC1,2\n\no2 \u00b7 o1 \u00b7 \u03b1\nC2,3\n\non\u22121 \u00b7 \u00b7 \u00b7 o2 \u00b7 o1 \u00b7 \u03b1\n\nCn\u22121,n\n\nFigure 24: A loop C on \u03a3g. As one traverses the loop counter-clockwise starting from point\np, the loop intersects various outer-automorphism twist lines o1, o2, \u00b7 \u00b7 \u00b7 , on. The sub-segment\nof C between the locations of intersections with oi and oi+1 is called Ci,i+1. Once the element\n\u03b1 \u2208 S6d carried by C at point p is specified, the element carried by the sub-segment Ci,i+1 is\nfixed to be oi \u00b7 oi\u22121 \u00b7 \u00b7 \u00b7 o2 \u00b7 o1 \u00b7 \u03b1.\n\n\u2022 There is a self-pairing on the K subfactor of KT provided by combining the pairing on\nS6d with the intersection pairing on H1(\u03a3g,Z). More concretely, consider two elements\n\u03b1p[C], \u03b2q[D] \u2208 K. Let C and D intersect at points r1, r2, \u00b7 \u00b7 \u00b7 , rm. Let \u03b1ri and \u03b2ri be\nthe elements of S6d carried by \u03b1p[C] and \u03b2q[D] respectively at the point ri. Then the\npairing can be described as\n\n\u3008\u03b1p[C], \u03b2q[D]\u3009KT\n=\n\nm\u2211\ni=1\n\n(\u22121)\u03c3i\u3008\u03b1ri , \u03b2ri\u3009S6d , (4.57)\n\nwhere (\u22121)\u03c3i captures the intersection pairing of C and D in the neighborhood of the\npoint ri.\n\n\u2022 Consider elements \u03b1p[C] \u2208 K and (\u03b3, \u03b4) \u2208 H\u03b2i,j . Let C intersect Ci,j at the points\nr1, r2, \u00b7 \u00b7 \u00b7 , rm. Let \u03b1ra be the element of S6d carried by \u03b1p[C] at the point ra. Then the\npairing between the two elements is given by\n\n\u3008\u03b1([C]), (\u03b3, \u03b4)\u3009KT\n=\n\nm\u2211\na=1\n\n(\u22121)\u03c3a\u3008\u03b1ra , \u03b2\u3009S6d (4.58)\n\nwhere (\u22121)\u03c3a captures the intersection pairing of C and Ci,j in the neighborhood of the\npoint ra.\n\n43\n\n\n\n\u2022 There is a pairing between \u03b1 \u2208 WPi and (\u03b3, \u03b4) \u2208 H\u03b2i,j given by\n\n\u3008\u03b1, (\u03b3, \u03b4)\u3009KT\n= \u3008\u03b1, \u03b3\u3009LPi (4.59)\n\nand a pairing between \u03b1 \u2208 WPj and (\u03b3, \u03b4) \u2208 H\u03b2i,j given by\n\n\u3008\u03b1, (\u03b3, \u03b4)\u3009KT\n= \u3008\u03b1, \u03b4\u3009LPj (4.60)\n\n\u2022 Finally, there is a pairing between HTPi and WPi given by the pairing on LPi .\n\n\u2022 All other pairings are trivial.\n\nThe elements of KT identified by (4.50), (4.51), (4.53) and (4.55) have the same pairings\nwith all the elements of KT. Thus LT obtains a well-defined pairing \u3008\u00b7, \u00b7\u3009LT descending from\nthe pairing \u3008\u00b7, \u00b7\u3009KT\n\non KT. Conversely, if we have two elements \u03b1, \u03b2 \u2208 KT such that\n\n\u3008\u03b1, \u03b3\u3009KT\n= \u3008\u03b2, \u03b3\u3009KT\n\n(4.61)\n\nfor all \u03b3 \u2208 KT, then \u03b1 and \u03b2 are identified by the identifications (4.50), (4.51), (4.53) and\n(4.55). Thus, there is no element \u03b1 \u2208 LT such that\n\n\u3008\u03b1, \u03b2\u3009LT = 0 (4.62)\n\nfor all \u03b2 \u2208 LT.\n\n1-form symmetry from the defect group. So far we have been discussing the 4d N = 2\ntheory T obtained directly using the Class S construction, without any additional choices.\nSuch a 4d theory is relative and has a defect group that we discussed in detail above in this\nsubsection. An absolute 4d N = 2 Class S theory T\u039b can be chosen from this relative Class\nS theory T by choosing a polarization \u039b, which is a maximal subgroup of LT on which the\npairing trivializes. The 1-form symmetry OT\u039b of the absolute 4d N = 2 Class S theory T\u039b\n\ncan then be described as\nOT\u039b = \u039b\u0302 . (4.63)\n\n5 Computing Defect Groups of Punctures\n\n5.1 Special Class S Theories Associated to a Puncture\n\nIn the previous section we discussed how the defect group of a Class S theory can be computed\nin terms of defect groups of punctures participating in the compactification. In this subsection,\nwe discuss how the defect group of a puncture can be computed in terms of the defect groups\n\n44\n\n\n\nassociated to some special Class S theories whose construction involves the puncture under\nconsideration. If an alternative way of computing the defect groups of the special Class S\ntheories is known, then one obtains the defect group associated to the puncture. We will\ndiscuss such alternative ways in subsequent sections.\n\nComputing the trapped defect group. Consider an untwisted puncture P of 6d N =\n(2, 0) theory of type g. Our first claim is that the trapped defect group LTP associated to P is\nobtained as the defect group of line defects of the 4d N = 2 Class S theory TP obtained by\ncompactifying the 6d N = (2, 0) theory on a sphere carrying only a single puncture, with the\npuncture being of type P. Let us compute the defect group of this Class S theory TP using\nthe formalism developed in the previous section. First of all, we have\n\nK = H1(\u03a3\u2217g,S6d) = 0 . (5.1)\n\nMoreover, since we have a single puncture P, we can write\n\nKTP = HTP \u00d7WP . (5.2)\n\nThe loop Ci linking Pi is homologically trivial. So the identification (4.55) imposes that\n\nZ\u0302P 3 \u03b1 \u223c 0 \u2208 LTP . (5.3)\n\nModding out by this identification, we find that the defect group of this Class S theory is\n\nLTP = L\u0303TP/ \u223c = HTP \u00d7WT\nP = LTP (5.4)\n\nas claimed above.\nNote that if we add untwisted regular punctures on the sphere, then the defect group of\n\nthe resulting Class S theory is also LTP . In particular, we will often consider the Class S theory\nT\u2217P obtained by compactifying N = (2, 0) theory on a sphere containing a single puncture of\ntype P and a single untwisted maximal regular puncture, for computing LTP via\n\nLT\u2217P = LTP . (5.5)\n\nFor a twisted puncture P, we define TP to be the 4d N = 2 Class S theory obtained by\ncompactifying 6d (2, 0) theory on a sphere with two punctures: one of them being of type P,\nand the other being a minimal regular twisted puncture. One can easily show, in a similar\nfashion as above, that\n\nLTP = LTP . (5.6)\n\n45\n\n\n\nWe can replace the minimal regular twisted puncture by any other regular twisted puncture,\nand the defect group of the resulting Class S theory is also LTP . In particular, we will often\nconsider the Class S theory T\u2217P obtained by replacing the minimal regular twisted puncture\nby a maximal regular twisted puncture, for computing LTP via\n\nLT\u2217P = LTP . (5.7)\n\nComputing the full defect group. Our second claim is that LP for a puncture P asso-\nciated to outer-automorphism o\u22121 is the defect group of the Class S theory T\n\nPo0\nP obtained by\n\nconsidering compactification of (2, 0) theory on a sphere with a single puncture Pi of type P\nand a single puncture Pj of type Po0 . We have\n\nK\nT\nPo0\nP\n\n= K \u00d7HTP \u00d7WP \u00d7WPo0 \u00d7Hi,j (5.8)\n\nwith\nWPo0 ' S6d,o (5.9)\n\nand\nK ' S6d,o (5.10)\n\ngenerated by wrapping bulk surface defects on a loop C on the sphere that divides the sphere\ninto two hemispheres such that each hemisphere contains exactly one puncture. We choose\nCij to be a path from P to P0 such that Cij intersects C at one point. We have\n\n\u2022 For trivial o, i.e. for an untwisted puncture P, Zi,j = ZP and Hi,j = HP . The identi-\nfication (4.50) identifies HTP subfactor of K\n\nT\nP0\nP\n\nas the HTP subgroup of Hi,j = HP . The\nidentification (4.55) identifies K ' S6d with WP0 when squeezed onto P0, and with the\nZ\u0302P subgroup of WP when squeezed onto P. In total, we obtain\n\nL\nT\nP0\nP\n\n=\nK\n\nT\nP0\nP\n\n\u223c\n=WP \u00d7Hi,j =WP \u00d7HP = LP (5.11)\n\nas claimed.\n\n\u2022 For non-trivial o and ZP 6= 0, Zi,j = \u03c0\u22121\no (ZP) and so\n\nHi,j =\n\u2294\n\n\u03b1\u2208\u03c0\u22121\no (ZP )\n\nH\u03b1i,j (5.12)\n\nwith\nH\u03b1i,j = \u03c0\u22121\n\nP \u03c0o(\u03b1) (5.13)\n\n46\n\n\n\nUsing (4.51) and (4.50), we see that H\u03b1i,j is equivalent to HTP subfactor of K\nT\nPo0\nP\n\nfor all\n\n\u03b1 \u2208 \u03c0\u22121\no (0). These identifications project HTP \u00d7 Hi,j to HP . The identification (4.55)\n\nidentifies K ' S6d,o withWPo0 when squeezed onto Po0 , and with the Z\u0302P subgroup ofWP\nwhen squeezed onto P. In total, we obtain\n\nL\nT\nPo0\nP\n\n=\nK\n\nT\nPo0\nP\n\n\u223c\n=WP \u00d7HP = LP (5.14)\n\nas claimed.\n\n\u2022 For non-trivial o and ZP = 0, Zi,j = 0 and so\n\nHi,j ' HTP (5.15)\n\nThe identification (4.50) identifies HTP subfactor of K\nT\nPo0\nP\n\nwith Hi,j ' HTP . The iden-\ntification (4.55) identifies K ' S6d,o with WPo0 when squeezed onto Po0 , and with the\nZ\u0302P = 0 subgroup of WP when squeezed onto P. In total, we obtain\n\nL\nT\nPo0\nP\n\n=\nK\n\nT\nPo0\nP\n\n\u223c\n=WT\n\nP \u00d7HTP = LTP = LP (5.16)\n\nThe last equality LTP = LP follows from the fact that ZP = Z\u0302P = 0.\n\n5.2 Generalized Quivers: Classes GQ and GQ\u2032\n\nWe will conjecture (and in some cases argue) that the defect groups of lines associated to a\nlarge class of (conformal and non-conformal) punctures can be computed as the defect groups\nof lines of generalized quiver gauge theories lying in a subclass GQ of all 4d N = 2 generalized\nquiver gauge theories.\n\nRelating defect groups of punctures and generalized quivers. A generalized quiver\n\u03c4 \u2208 GQ takes the following form\n\ng0 M1 g1 M2 g2 \u00b7 \u00b7 \u00b7 gk\u22121 Mk [gk] (5.17)\n\nwhere gi are gauge algebras for 0 \u2264 i \u2264 k \u2212 1 and gk is a flavor algebra. Moreover, we have\n\ng0 = h\u2228o , (5.18)\n\nwhere h\u2228o is the Langlands dual to the subalgebra ho of the 6d A,D,E algebra g left invariant by\nthe outer-automorphism o associated to the puncture under study. Each edgeMi for 1 \u2264 i \u2264 k\n\n47\n\n\n\ndenotes a 4d N = 2 \u2018matter\u2019 SCFT whose flavor algebra is gauged by the neighboring gauge\nalgebra nodes.\n\nThen, the conjecture states that there is a large family F\u03c4 of o-twisted punctures of 6d\nN = (2, 0) theory of type g such that the defect group associated to a puncture P \u2208 F\u03c4 is the\nsame as the defect group associated to \u03c4\n\nLP = L\u03c4 . (5.19)\n\nMoreover, the trapped part of the defect group associated to P is computed as the defect\ngroup associated to the generalized quiver \u03c4\u0303 obtained from \u03c4 by treating g0 = g as a flavor\nalgebra\n\nLTP = L\u03c4\u0303 (5.20)\n\nwhere \u03c4\u0303 takes the form\n\n[g0] M1 g1 M2 g2 \u00b7 \u00b7 \u00b7 gk\u22121 Mk [gk] (5.21)\n\nRelating generalized quivers and special Class S theories. A subclass GQ\u2032 \u2286 GQ of\ngeneralized quivers has the property that \u03c4 \u2032 \u2208 GQ\u2032 can be realized as the 4d N = 2 Class S\ntheory T\n\nPo0\nP \u2032\n\n\u03c4 \u2032 = T\nPo0\nP \u2032 (5.22)\n\nassociated to an o-twisted puncture P \u2032 of type g (2, 0) theory. In such a situation, we also\nhave the relationship\n\n\u03c4\u0303 \u2032 = T\u2217P \u2032 . (5.23)\n\nStructure of the defect group of a generalized quiver. The line defects participating\nin the defect group of the quiver theory \u03c4 arise from \u2018t Hooft-Wilson line defects associated\nto the gauge algebras. Each gauge factor gi provides\n\nLi = Hi \u00d7Wi (5.24)\n\ndefect group of lines, with Hi being the \u2018t Hooft lines and Wi being the Wilson lines. We can\ntake\n\nHi = ZGi (5.25)\n\nand\nWi = Z\u0302Gi (5.26)\n\nwhere ZGi is the center of the simply connected group Gi associated to the simple Lie algebra\ngi, and Z\u0302Gi is the Pontryagin dual of ZGi . The matter SCFTs for \u03c4 \u2208 GQ have the special\n\n48\n\n\n\nproperty that they do not provide any line defects modulo screenings. Thus, before accounting\nfor local operators coming from the matter SCFTs, we have an initial defect group\n\nL = H\u00d7W =\nk\u22121\u220f\ni=0\nHi \u00d7\n\nk\u22121\u220f\ni=0\nWi (5.27)\n\nLet us now include the local operators. The genuine local operators of the matter SCFT\nMi charged non-trivially under the gauged subgroup of the flavor symmetry fi of Mi become\nnon-genuine local operators of the quiver theory obtained after the gauging procedure. The\ngauge center charges of non-genuine local operators arising from Mi span a sub-lattice\n\n\u0393i \u2286 Z\u0302Gi\u22121 \u00d7 Z\u0302Gi . (5.28)\n\nLet\n\n\u0393 \u2286\nk\u22121\u220f\ni=0\n\nZ\u0302Gi (5.29)\n\nbe the sub-lattice generated by combining the contributions \u0393i from all matter SCFTs Mi.\nThen, we can write the defect group of lines of the quiver theory \u03c4 as\n\nL\u03c4 = H\u03c4 \u00d7W\u03c4 (5.30)\n\nwhere the Wilson line contribution W\u03c4 is obtained by screening the Wilson lines in W by \u0393\n\nW\u03c4 =W/\u0393 =\n\u220fk\u22121\ni=0 Wi\n\n\u0393 (5.31)\n\nand the \u2018t Hooft line contribution H\u03c4 is constrained to be a subgroup of the \u2018t Hooft lines in\nH as they have to be mutually local with \u0393. Notice that this is just the Pontryagin dual of\nW\u03c4 . Thus, we have\n\nH\u03c4 = W\u0302\u03c4 . (5.32)\n\nComputing defect groups using 1-form symmetry. In fact, the defect group L\u03c4 can be\ncomputed in terms of the 1-form symmetry group of an absolute theory obtained by choosing\nthe electric polarization\n\n\u039be\u03c4 =W\u03c4 \u2282 L\u03c4 . (5.33)\n\nThis polarization corresponds to choosing the gauge group G\u03c4 of the quiver theory \u03c4 as\n\nG\u03c4 =\nk\u22121\u220f\ni=0\n\nGi , (5.34)\n\n49\n\n\n\nwhere each Gi is simply connected. The 1-form symmetry Oe\u03c4 of this absolute theory is the\nPontryagin dual of the corresponding polarization\n\nOe\u03c4 = \u039b\u0302e\u03c4 = H\u03c4 . (5.35)\n\nThus\nHP = H\u03c4 (5.36)\n\nfor a puncture P \u2208 F\u03c4 can be computed by computing the 1-form symmetry Oe\u03c4 of the\ngeneralized quiver theory \u03c4 with all gauge groups chosen to be simply connected. Then,\n\nWP =W\u03c4 (5.37)\n\nis readily computed as the Pontryagin dual O\u0302e\u03c4 of the 1-form symmetry group Oe\u03c4 . In total,\nthe defect group associated to puncture P can be computed as\n\nLP = HP \u00d7WP\nHP = Oe\u03c4\nWP = O\u0302e\u03c4\n\n(5.38)\n\nand the pairing on LP is obtained simply as the natural pairing of O\u0302e\u03c4 with Oe\u03c4 .\nTo compute the trapped part LTP we use the quiver theory \u03c4\u0303\n\n[g0] M1 g1 M2 g2 \u00b7 \u00b7 \u00b7 gk\u22121 Mk [gk] (5.39)\n\nLet us write the defect group associated to this theory as\n\nL\u03c4\u0303 = H\u03c4\u0303 \u00d7W\u03c4\u0303 (5.40)\n\nwhich we can easily compute using the same trick as above. We choose the absolute theory\nwith gauge group\n\nG\u03c4\u0303 =\nk\u22121\u220f\ni=1\n\nGi (5.41)\n\nbeing the product of simply connected groups associated to the simple factors in the gauge\nalgebra. Let Oe\n\n\u03c4\u0303\nbe the 1-form symmetry group of this absolute theory. Then we can identify\n\nLTP = HTP \u00d7WT\nP\n\nHTP = Oe\n\u03c4\u0303\n\nWT\nP = O\u0302e\n\n\u03c4\u0303\n\n(5.42)\n\nwith the pairing on LTP \u2032 being simply the natural pairing of O\u0302e\n\u03c4\u0303\nwith Oe\n\n\u03c4\u0303\n.\n\n50\n\n\n\nComputing maps participating in the defect group. Let us now describe the compu-\ntation of various maps appearing in (4.30) for the puncture P \u2208 F\u03c4 . Oe\u03c4 is a subgroup of the\ncenter\n\nZG\u03c4 :=\nk\u22121\u220f\ni=0\n\nZGi (5.43)\n\nof the gauge group G\u03c4 appearing in (5.34). Let us define maps\n\n\u03c0i : ZG\u03c4 \u2192 ZGi (5.44)\n\nthat project ZG\u03c4 onto its ZGi subfactor. We can then describe\n\nOe\n\u03c4\u0303\n\n=\n{\n\u03b1 \u2208 Oe\u03c4\n\n\u2223\u2223\u2223\u03c00(\u03b1) = 0 \u2208 ZG0\n\n}\n(5.45)\n\nidentifying HTP = Oe\n\u03c4\u0303\nas a subgroup of HP = Oe\u03c4 . This implies that we can identify\n\n\u03c0P = \u03c00 (5.46)\n\nand hence\nZP = \u03c00\n\n(\nOe\u03c4\n)\n\u2286 ZG0 = ZH\u2228o . (5.47)\n\nTo obtain ZP as a subgroup of So6d, we employ the following isomorphism between ZH\u2228o and\nSo6d:\n\n\u2022 For trivial o, we have ZH\u2228o = ZG which can be mapped to S6d = Z\u0302G by using the pairing\non S6d.\n\n\u2022 For trivial o, we have only two possibilities: either ZH\u2228o ' Z2 and So6d ' Z2, or ZH\u2228o =\nSo6d = 0. In both cases, there is a unique isomorphism between ZH\u2228o and S6d.\n\nThus we have computed all the maps appearing in (4.30), which capture the magnetic part\nof LP . As discussed earlier, the data about the electric part is obtained simply by taking\nPontryagin dual of the data about the magnetic part.\n\n5.3 Spectral Cover Monodromies and ALE Fibrations in IIB\n\nWe will now discuss how the part L0\nP of the full defect group, as defined in (4.29), can be\n\neasily computed using the monodromy of the Hitchin field \u03c6 as one encircles the puncture P.\nNote that the information about L0\n\nP is insufficient in providing the full information about LP .\n\n51\n\n\n\nHiggs field for a general Class S compactification. The Higgs field \u03c6 of a relative\ntheory of class S with bulk Lie algebra g and UV curve C is a g valued meromorphic section of\nthe canonical bundle KC modulo gauge transformations. We consider Higgs fields which are\nglobally diagonalizable by some gauge transformation, that is their profile lies along a Cartan\nsubalgebra h \u2282 g. Gauge transformations bringing Higgs fields into this diagonal form are\nfixed up to conjugation by elements in the Weyl group wg which maps h onto itself. The Higgs\nfield is therefore a meromorphic section of KC \u2297 (h/wg).\n\nThe spectral curve of a Higgs field \u03c6 with respect to a representation r of g is13\n\n\u03a3r = {(z, \u03bbz) \u2208 KC | det(\u03bbz \u2212 \u03c6r(z)) = 0} \u2282 KC , (5.48)\n\nwhere \u03c6r is the presentation of the Higgs field \u03c6 as acting on r. Denote the dimension of the\nrepresentation by dim r = r, then the spectral curve \u03a3r is a ramified r-fold covering of C away\nfrom the poles of \u03c6r. The r sheets of the covering are permuted by Weyl transformations\nwhen encircling untwisted punctures and branch points and by outer automorphisms Og when\ncrossing twist lines.\n\nHiggs field in a generic small open set. Consider the spectral curve \u03a3r restricted to\na local patch U \u2282 C away from punctures, branch points and twist lines. Across U the\nsheets of \u03a3r can be distinguished and labelled by weights of r and the Higgs field \u03c6 lifts to a\nmeromorphic section of KU \u2297h. The weights of the representation r are r elements in the dual\nspace h\u2217 of the Cartan subalgebra h and we denote these by wi with i = 1, . . . , r. To label\nthe sheets of \u03a3r across U we consider the canonical Weyl-invariant pairing ( \u00b7 , \u00b7 ) : h\u2217\u2297 h\u2192 C\nand define\n\n\u03bbz,i = xi(z)dz = (wi, \u03c6(z)) , (5.49)\n\nwhich gives precisely r solutions (sheets) to the spectral equation det(\u03bbz \u2212 \u03c6r(z)) = 0. Given\ngauge equivalent Higgs fields as sections in KC \u2297 h their labelling of sheets by weights are\nrelated by Weyl transformations. There are |wg| equivalent labelings of spectral cover sheets\nby weights.\n\nHiggs field near a puncture and monodromy. Next consider the spectral curve \u03a3r\n\nrestricted to a local patch V \u2282 C containing a single puncture P. Choose complex coordinate\nt centered on the puncture and coordinate v on the cotangent fiber such that \u03bbi = vidt/t\n\nwhich will prove convenient later in relation to IIA Hanay-Witten brane constructions. In a\nsubset U \u2282 V we can label the sheets vi by weights wi. Encircling P the sheets and weights\n\n13Here we abbreviate by KC the total space of the canonical bundle over C.\n\n52\n\n\n\nare permuted by a Weyl transformation and possibly an outer-automorphism if the puncture\nis twisted. This gives a monodromy action on the weight lattice \u039bweight. The weight lattice\ncontains the root lattice \u039broot \u2282 \u039bweight and therefore the monodromy lifts to an action on\nthe root lattice. We obtain a monodromy action MP of the puncture P on the root lattice of\nthe bulk algebra g\n\nMP : \u039broot \u2192 \u039broot . (5.50)\n\nThis monodromy action can be read off from any spectral curve \u03a3r for which the weight system\nof the representation r spans \u039bweight or equivalently that contains the set of fundamental\nweights. For Lie algebras g = An\u22121, Dn\u22654, E6, E7 the lowest-dimensional representations with\nthis property are the n-dimensional fundamental representation, the 2n-dimensional vector\nrepresentation and the representations 27,56 respectively.\n\nALE-fibration in Type IIB. We discuss the physical consequences of the monodromy\naction MP in the IIB dual description where the above configurations are recast in a purely\ngeometric framework. In this picture the Higgs field is the period map for the ALE fibration\n\nC\u03032/\u0393g \u21aa\u2192 X \u20323 \u2192 V \u2032 , (5.51)\n\nwith respect to the holomorphic top form \u2126 of the Calabi-Yau three-fold X \u20323. Here C\u03032/\u0393g\n\ndenotes the hyperkahler unfolding of the ADE singularity C2/\u0393g to an ALE space and V \u2032\n\ndenotes V with the puncture P at t = 0 excised. The ALE fibration degenerates approaching\nthe puncture. We obtain a non-degenerate ALE fibration by restricting to V \u2217 which is defined\nas V with an open disk containing t = 0 removed. The geometry modelling each puncture is\n\nC\u03032/\u0393g \u21aa\u2192 X3 \u2192 V \u2217 . (5.52)\n\nThe boundary of this geometry has two components BP and BX . These are fibered as\n\nC\u03032/\u0393g \u21aa\u2192 BP \u2192 S1\n\nS3/\u0393g \u21aa\u2192 BX \u2192 V \u2217 .\n(5.53)\n\nHere S1 bounds the open disk excised from V . See figure 25. The two five-dimensional\nboundary components intersect along a four-dimensional corner BX \u2229 BP = \u2202BP which is\nfibered as\n\nS3/\u0393g \u21aa\u2192 \u2202BP \u2192 S1 . (5.54)\n\nWe are interested in the torsional two-cycles of the boundary components BP and BX which\ncan arise as the intersection of non-compact three-cycles in the full IIB ALE fibration. D3\n\n53\n\n\n\nP\nV \u2217\n\nS1\n\nC\u03032/\u0393g\n\nX3 : BP :\n\nS1\n\nC\u03032/\u0393g\n\nBX :\nV \u2217\n\nS1\n\nS3/\u0393g\n\nFigure 25: We depict the IIB geometry X3 associated with a neigbourhood of the puncture\nP. The boundary of the ALE fibration X3 is given by \u2202X3 = BP \u222aBX .\n\nbranes wrapping such three-cycles engineer line defects. Both boundary components con-\ntribute to the spectrum of such two-cycles.\n\nWe begin by considering BX which is fibered over V \u2217. The base V \u2217 is topologically an\nannulus and deformation retracts onto a circle. The homology groups of BX therefore follow\nfrom the monodromy action on Hk(S3/\u0393g,Z). A non-trivial monodromy can only occur for\nH1(S3/\u0393g,Z) \u223c= Z\u0302G \u223c= \u039bweights/\u039broots. The monodromy action on H1(S3/\u0393g,Z) can therefore\nbe inferred from the action on weights and we find it to be trivial, this implies\n\nH2(BX ,Z) \u223c= \u0393ab\ng\n\u223c= Z\u0302G . (5.55)\n\nHere, the superscript ab denotes the abelianization of the group.\nNext consider BP . Its ALE fibers contain rank g rational curves. These rational curves\n\ndecompactify when S1 shrinks onto the puncture. Therefore, any three-cycle in the IIB ALE\nfibration which intersects BP in such a rational curve is in fact non-compact. The monodromy\naction associated with the puncture introduces redundancies among these rational curves with\nindependent classes counted by H2(BP ,Z). According to the results of [13], the contribution\nof the boundary component BP to the defect group LP takes the form TorH2(BP ,Z). The\nrational curves are associated with the simple roots of the Lie algebra g by the McKay corre-\nspondence. The monodromy action on rational curves is therefore the one described in (5.50)\nwhich is now geometrized as\n\nMP : H2(C\u03032/\u0393g,Z)\u2192 H2(C\u03032/\u0393g,Z) . (5.56)\n\nAs all smooth manifolds fibered over a circle the homology groups of BP are determined by\nthe monodromy mappings\n\nMk : Hk(C\u03032/\u0393g,Z)\u2192 Hk(C\u03032/\u0393g,Z) , (5.57)\n\nwhich enter into the short exact sequence\n\n0 \u2192 coker (Mk \u2212 1) \u2192 Hk(BP ,Z) \u2192 ker (Mk\u22121 \u2212 1) \u2192 0 . (5.58)\n\n54\n\n\n\nOf these mappings only M2 \u2261MP differs from the identity. With this we derive\n\nTorH2(BP ,Z) \u223c= Tor coker (MP \u2212 1) . (5.59)\n\nUpon checking against predictions for defect groups via other methods, we find that\n\nTor coker (MP \u2212 1) \u223c= L0\nP =WP \u00d7HTP . (5.60)\n\nNotice that all trapped contributions are accounted for.\nFinally we require a map from the boundary component BX into the total boundary \u2202X\n\nwhich determines the projection H2(BX ,Z) \u223c= Z\u0302G onto Z\u0302P . The cycles in the image of this\nmap are expected to link with the cycles associated to L0\n\nP defining a Dirac pairing from which\nthe full data of the puncture (4.30) can be derived as follows. The pairing defines a Pontryagin\ndual pairing between L\u03020\n\nP = HP \u00d7WT\nP and ZP . The elements of L\u03020\n\nP that have trivial pairing\nwith all the elements of ZP form the subgroup LTP = HTP \u00d7WT\n\nP . From this we can determine\n\nHTP =\n\u221a\nLTP (5.61)\n\nand we obtain the injection\niP : HTP \u2192 HP (5.62)\n\nallowing us to determine all the relevant data about the full defect group LP of the puncture\nP.\n\nWhen discussing the ALE-fibration, we will in the following restrict our attention only\nto L0\n\nP , while leaving the geometric determination of the above-mentioned projection map\nZ\u0302G \u2192 Z\u0302P to future work. Morally, this projection map is the geometric avatar of the squeezing\nmap (4.14).\n\n6 Type IIB on Canonical Singularities and Irregular Punctures\n\nThere is a special class of punctures (that we refer to as IHS punctures) for which the 4d\nN = 2 theory TP defined in section 5.1 can be constructed as IIB compactified on an isolated\nhypersurface singularity (IHS). This provides a map between IHS singularities and irregular\npunctures of IHS type. The subsection 6.1 discusses this map for untwisted irregular punctures\nof IHS type, which is quite well-known in the literature. The following subsections 6.2\u20136.4\ndiscuss the map for twisted irregular punctures. Some of the twisted cases have been discussed\nin prior literature, while some others are being discussed for the first time. Using the IHS\ndescription presented here, we can compute the defect groups LTP associated to the theories\nTP , which as discussed in section 5.1, coincide with the trapped parts LTP of the defect groups\n\n55\n\n\n\nLP associated to the IHS punctures P. Thus the IIB IHS description provides a concrete\nand simple way of computing the trapped defect groups of IHS punctures, which can be\nused as strong counter-checks for the various proposals regarding the defect groups of general\npunctures made in this paper.\n\nFinally, in subsection 6.5, we discuss another class of IHS singularities that have the\nproperty that compactifying IIB on such IHS singularities leads to 4d N = 2 \u201ctrinion\u201d SCFTs\nthat are obtained by gauging a diagonal flavor symmetry of three T\u2217Pi (with i = 1, 2, 3) theories,\nwhere Pi are IHS punctures. Thus, one can compute the defect groups of these trinion theories\nusing the IHS techniques. On the other hand, as discussed in this subsection, the same defect\ngroup can also be expressed in terms of the defect groups LPi associated to the punctures\nPi. It turns out that the defect group of the trinion theory sees not only the trapped parts\nLTPi of LPi , but also some of the non-trapped parts. Thus, matching the defect group of\ntrinion theories as obtained using IHS, against the defect groups predicted using our proposal,\nprovides strong checks for the proposed non-trapped parts of the defect groups of punctures.\n\n6.1 Untwisted Punctures\n\nLet us begin the discussion by considering untwisted irregular punctures discussed in [81,88].\nSuch punctures are characterized by two integers k, b, where k takes infinitely many values,\nwhile b takes either two or three possible values. We call such punctures IHS punctures. This\nis because the 4d N = 2 Class S theory TP , obtained by compactifying the 6d (2, 0) theory\non a sphere with a single puncture P, can be constructed by compactifying Type IIB on an\nIHS singularity, for almost all punctures P discussed in [81,88], except for the punctures with\nextremely small values of k.\n\nThe defining equation is given by an ADE singularity, of the same type as the 6d N =\n(2, 0) theory relevant for the Class S realization, fibered over a complex plane. This is not\nsurprising since 6d N = (2, 0) theories are engineered in Type IIB by compactification on the\ncorresponding ADE singularity and the complex plane parametrizes the punctured sphere,\nwith the puncture located at infinity. The defining equation for the IHS is\n\nP (x1, x2, x3, z) = x2\n1 + F (x2, x3, z) = 0\n\n\u21263 = dx1 \u2227 dx2 \u2227 dx3 \u2227 dz\ndP\n\n,\n(6.1)\n\nwhere we use the coordinate z to parametrize the sphere and \u21263 denotes the holomorphic\nthree-form.\n\nWe now summarize briefly the properties and types of such IHS punctures. Concerning\nuntwisted irregular punctures, we are interested in the case when the Higgs field for a 6d (2, 0)\n\n56\n\n\n\n6d G b Singularity after closure Type(a, b, c, d) AD[G,G\u2032]\nAN\u22121 N x2\n\n1 + x2\n2 + xN3 + zk\u2212N {1, 1}(2, 2, N, k \u2212 b) (AN\u22121, Ak\u2212N\u22121)\n\nN \u2212 1 x2\n1 + x2\n\n2 + xN3 + x3z\nk\u2212N+1 {2, 1}(2, 2, N, k \u2212N + 1)\n\nDN 2N \u2212 2 x2\n1 + xN\u22121\n\n2 + x2x\n2\n3 + zk\u22122N+2 {2, 1}(2, k \u2212 2N + 2, N \u2212 1, 2) (Ak\u22122N+1, DN )\n\nN x2\n1 + xN\u22121\n\n2 + x2x\n2\n3 + x3z\n\nk\u2212N {7, 1}(2, N \u2212 1, 2, k \u2212N)\nE6 12 x2\n\n1 + x3\n2 + x4\n\n3 + zk\u221212 {1, 1}(2, 3, 4, k \u2212 12) (Ak\u221213, E6)\n9 x2\n\n1 + x3\n2 + x4\n\n3 + x3z\nk\u22129 {2, 1}(2, 3, 4, k \u2212 9)\n\n8 x2\n1 + x3\n\n2 + x4\n3 + x2z\n\nk\u22128 {2, 1}(2, 4, 3, k \u2212 8)\nE7 18 x2\n\n1 + x3\n2 + x2x\n\n3\n3 + zk\u221218 {2, 1}(2, k \u2212 18, 3, 3) (Ak\u221219, E7)\n\n14 x2\n1 + x3\n\n2 + x2x\n3\n3 + x3z\n\nk\u221214 {7, 1}(2, 3, 3, k \u2212 14)\nE8 30 x2\n\n1 + x3\n2 + x5\n\n3 + zk\u221230 {1, 1}(2, 3, 5, k \u2212 30) (Ak\u221231, E8)\n24 x2\n\n1 + x3\n2 + x5\n\n3 + x3z\nk\u221224 {2, 1}(2, 3, 5, k \u2212 24)\n\n20 x2\n1 + x3\n\n2 + x5\n3 + x2z\n\nk\u221220 {2, 1}(2, 5, 3, k \u2212 20)\n\nTable 2: Untwisted irregular punctures of IHS type and their hypersurface realization. We\nprovide the hypersurface equations in C4, which correspond to class S theories with one irreg-\nular puncture of type (G, b, k). Note that in order for the IHS to be well-defined k needs to be\nlarge enough. The Type indicates the description of the singularity in KS-YY classification of\nIHS (see [55] for our conventions).\n\ntheory of type G has the form\n\u03a6 = 1\n\nz1+ k\nb\n\n\u00b7 \u00b7 \u00b7 . (6.2)\n\nThe values of (G, k, b) are constrained and lead to the hypersurfaces in table 2, as was discussed\nin [82]. In table 2 we also provide the identifications with AD theories when appropriate.\n\nWe will also consider the closely-related family of theories T\u2217P whose class S description is\nin terms of a sphere with one irregular puncture P of type IHS and a full regular puncture.\nAlso these have a Type IIB description since they can be realized as hypersurfaces in C3\u00d7C\u2217.\nThe defining equations are essentially the same as in table 2. The only difference is that the\ncoordinate z is now C\u2217-valued (and accordingly we replace dz with d(logz) in \u21263) and the\nparameter k should be replaced by k+b (see [105]). Said differently, we see that geometrically\nclosing the regular puncture amounts to shifting k \u2192 k\u2212b. Note that k has to be large enough\nfor the equation in table 2 to be regular. In the class S description this corresponds to the\nfact that unless k is large enough, the full regular puncture cannot be closed [105].\n\n6.2 Twisted Punctures\n\nThe situation is more subtle in the case of twisted punctures since the twist line must neces-\nsarily end at a second puncture, invalidating the above argment. We will however find that,\nonce the second puncture is taken to be regular and minimal, the resulting SCFT can still be\n\n57\n\n\n\n6d Type Twist bt Singularity after closure Type (a, b, c, d)\n\nA2N Z2\n4N + 2\n\n2N\nu2 + x2N+1 + y\u03ba\u2212N + yz2 = 0\nu2 + x2N+1 + xy\u03ba\u2212N + yz2 = 0\n\n{2, 1}(2, 2N + 1, \u03ba\u2212N, 2)\n{7, 1}(2, 2N + 1, \u03ba\u2212N, 2)\n\nA2N\u22121 Z2\n2N\n\n4N \u2212 2\nu2 + x\u03ba\u2212N\u22121 + xy2 + yzN = 0\nu2 + xy\u03ba\u2212N + yz2 + zxN = 0\n\n{7, 1}(2, \u03ba\u2212N \u2212 1, 2, N)\n{10, 1}(2, \u03ba\u2212N,N, 2)\n\nDN+1 Z2\n2N\n\n2N + 2\nu2 + x\u03ba+1\u22122N + xyN + yz2 = 0\nu2 + xy2 + yz\u03ba\u2212N + zxN = 0\n\n{7, 1}(2, \u03ba+ 1\u2212 2N,N, 2)\n{10, 1}(2, 2, N, \u03ba\u2212N)\n\nD4 Z3\n\n12\n12\n6\n\nu2 + x3 + yz3 + zy\u03ba\u22122 = 0\nu2 + x3 + yz3 + xy\u03ba\u22123 = 0\nu2 + x3 + yz3 + y\u03ba\u22124 = 0\n\n{3, 1}/(2, 3, 3, \u03ba\u2212 2)\n{7, 1}(2, 3, \u03ba\u2212 3, 3)\n{2, 1}(2, 3, \u03ba\u2212 4, 3)\n\nE6 Z2\n\n18\n12\n8\n\nu2 + x3 + yz4 + zy\u03ba\u22126 = 0\nu2 + x3 + yz4 + y\u03ba\u22129 = 0\nu2 + x3 + yz4 + xy\u03ba\u22126 = 0\n\n{3, 1}(2, 3, 4, \u03ba\u2212 6)\n{2, 1}(2, 3, \u03ba\u2212 9, 4)\n{7, 1}(2, 3, \u03ba\u2212 6, 4)\n\nTable 3: Twisted irregular punctures of IHS type: In the fourth column the relevant hy-\npersurface singularity in C4 is provided and in the last column we report the corresponding\nsingularity type according to the KS-YY classification (see [55] for our conventions). Entries\nin red are those already identified in [106]. In the first column we provide the corresponding\n6d N = (2, 0) theory and in the second column we indicate the outer-automorphism twist\nconsidered.\n\ndescribed by a IHS. In order to derive this statement, we start from the theory with a twisted\nfull puncture whose Type IIB geometric description in terms of a hypersurface in C3 \u00d7 C\u2217 is\nknown explicitly [89].\n\nOur strategy is to show that upon closure of the regular puncture we find a model which\nadmits a IHS description in Type IIB. We provide the corresponding equations in the fourth\ncolumn of table 3. Furthermore, in the last column of the table we include the singularity\ntype in the notation of [55].\n\nThe defining equation of the hypersurface is derived as follows: We assume that, as in the\nuntwisted case, the singularity is of the form u2 + F (x, y, z) = 0 and then we determine the\nexplicit form of F by matching the Coulomb Branch (CB) spectra of the two theories. This\nwill now be exemplified for a few twisted irregular punctures.\n\nBefore entering the details of the derivation, let us remind the reader how to determine\nCB operators and physical parameters of a N = 2 SCFT geometrically engineered in Type\nIIB string theory. The procedure exploits the fact that (extended) CB moduli are associated\nwith complex structure deformations of the geometry and therefore what we need to do is to\ndeform the hypersurface singularity and determine the scaling dimension of the corresponding\n\n58\n\n\n\nparameters. This information is extracted via the following procedure [78]:\n\n1. We impose the normalization condition that the holomorphic three-form \u21263 has dimen-\nsion one. This must be required since its periods compute the mass of BPS states in the\ntheory.\n\n2. We require that all the terms appearing in the equation describing the deformed singu-\nlarity have the same dimension.\n\nOnce we have the full list of parameters together with their scaling dimension is known, we can\nexploit the rule that parameters whose dimension is smaller than one correspond to coupling\nconstants of the theory, those with dimension exactly one are mass parameters and those with\ndimension larger than one describe the expectation value of Coulomb branch operators14. We\ntherefore see that we can extract the CB spectrum of the theory with this method.\n\n6.3 Extracting the IHS for twisted A3\n\nSince the procedure is rather involved, let us start by illustrating our method with a specific\nexample, namely a A3 twisted theory described by the Type IIB geometry\n\nW (u, v, x, z) \u2261 uv + x4 + z\u03ba + subleading = 0; \u21263 = du \u2227 dv \u2227 dx \u2227 dz\nzdW\n\n. (6.3)\n\nThe subleading terms encode all the physical parameters of the theory and can be uniformly\ndescribed as z-dependent versal deformations of the ADE singularity (in this case A3). When\nthe corresponding Casimir is invariant under the action of the outer-automorphism, the sub-\nleading terms are proportional to integer powers of z; otherwise they are proportional to a\nfractional (half-integer in all cases apart from Z3 twisted D4) power of z. In the case at\nhand the Casimirs of degree 2 and 4 lead therefore to terms of the form x2z2u2,n and znu4,n\n\nrespectively, whose scaling dimensions are\n\nD(u2,n) = 2\u2212 n4\n\u03ba\n\n; D(u4,n) = 4\u2212 n4\n\u03ba\n\n(6.4)\n\nfrom (6.3). The cubic Casimir instead leads to terms of the form xzn\u22121/2u3,n and their\ndimension is\n\nD(u3,n) = 3\u2212\n(\nn\u2212 1\n\n2\n\n) 4\n\u03ba\n. (6.5)\n\nFrom (6.3) we see that allowing all terms with n a positive integer, the degree k differentials\nappearing in the spectral curve have at z = 0 a pole of order 1, 5\n\n2 , 3 for k = 2, 3, 4 respectively.\n14There is potentially an exception to this rule in the case of hypersurfaces in C3\u00d7C\u2217, since some parameters\n\nwith dimension larger than one might actually correspond to mass parameters rather than CB operators. These\ncan be singled out by looking at the behaviour of \u21263, since residues for the holomorphic three-form always\ncorrespond to mass parameters and not CB operators, regardless of their dimension.\n\n59\n\n\n\nThe leading singular terms are those with n = 0. Let us now explain how the spectrum\nchanges upon closure of the regular puncture.\n\nSince for a minimal twisted puncture the pole degrees of the k-differentials are reduced to\n1, 1\n\n2 , 2 (see [71]), we conclude that we need to remove u3,1, u3,2 and u4,1. This is not the end of\nthe story though, since we also need to take into account constraints: It is known that for each\nk-differential a puncture can introduce a constraint which can be either of a-type or of c-type.\nThe latter says that the leading singular term is actually the product of other terms appearing\nin the spectral curve, therefore reducing by one the number of independent parameters. A\nconstraint of a-type instead tells us that the leading term is the square of a more fundamental\nobject. Full punctures never exhibit constraints however, a minimal twisted A3 puncture has a\nc-constraint for k = 4. This tells us that u4,2 is not an independent operator and therefore we\ncan discard it from the spectrum of the theory. If it had been a constraint of type a we should\nhave replaced u4,2, whose dimension is 4 \u2212 8/\u03ba, with another of dimension 2 \u2212 4/\u03ba. Overall,\nupon closure of the puncture we find the following spectrum from the quadratic differential\n\n2\u2212 4n\n\u03ba\n\n(n \u2265 1), (6.6)\n\nand from cubic and quartic differentials\n\n3\u2212 4n\u2212 2\n\u03ba\n\n; 4\u2212 4n\n\u03ba\n\n(n \u2265 3). (6.7)\n\nAs we have explained before, parameters with dimension larger than one are Coulomb branch\noperators, those with dimension exactly one are mass parameters and the others are coupling\nconstants.\n\nFrom these data we will now try to guess the IHS equation, assuming, as we have mentioned\nbefore, that the general structure is\n\nW (u, x, y, z) \u2261 u2 + F (x, y, z) = 0; \u21263 = du \u2227 dx \u2227 dy \u2227 dz\ndW\n\n. (6.8)\n\nA useful observation at this stage is that the CB operator of largest dimension is u4,3. Since\nfor a singularity of the form (6.8) a constant term (i.e. which does not depend on any of the\nfour coordinates) is always an allowed deformation and the corresponding parameter is clearly\nthe CB operator of highest dimension, we identify it with u4,3 and therefore we conclude that\nD(u) = D(u4,3)\n\n2 = 2 \u2212 6\n\u03ba . We can also notice that the parameters coming from a given k-\n\ndifferential have scaling dimension spaced by 4/m and therefore it is natural to guess that one\nof the coordinates (say x) has precisely that dimension. We can further guess the dimension\nof y by noticing that D(u4,n) \u2212 D(u3,n) = D(u3,n) \u2212 D(u2,n\u22122) for every n and therefore\nthe most natural option is that the corresponding terms in the IHS equation are obtained\n\n60\n\n\n\nby gradully increasing the power of one of the coordinates, whose dimension is therefore\nnecessarily D(u4,n)\u2212D(u3,n) = 1\u2212 2\n\n\u03ba . Now that we have a guess for the scaling dimension of\nall the coordinates except z, we can notice that requiring \u21263 to have dimension one we find\nthe equation\n\nD(x) +D(y) +D(z) = 1 +D(u), (6.9)\n\nfrom which we conclude that D(z) = 2 \u2212 8\n\u03ba . The last step is to construct a homogeneous\n\nsingularity of the form (6.8) compatible with our prediction for the scaling dimensions. We\nfind that\n\nF = x\u03ba\u22123 + xz2 + zy2 (6.10)\n\ndoes the job. We can indeed check that the spectrum derived from this IHS reproduces (6.6)\nand (6.7). We therefore recover the result reported in Table 3.\n\n6.4 IHS for twisted irregular punctures\n\nThe strategy we will follow to identify the IHS equations is to implement for all cases the\nanalysis presented in 6.3 for the A3 case. We will now review for each case the relevant\nproperties of twisted punctures and then explain how to construct the relevant IHS singularity.\nWe have checked in all cases that the CB spectrum of the IHS reproduces that of the class S\ntheory on the sphere with minimal and irregular twisted punctures.\n\n6.4.1 Twisted Aodd theories\n\nIn this case all Casimirs of odd degree change sign under the action of the outer-automorphism,\ntherefore all the k-differentials with k odd are proportional to half-integer powers of z and\nthose with k even are proportional to integer powers of z. The properties of twisted Aodd\n\nregular punctures were derived in [71]. The full puncture introduces at z = 0 poles of order\n3k\n2 \u2212\n\n\u230a\nk\n\n2\n\n\u230b\n\u2212 1; k = 2, . . . , 2N, (6.11)\n\nwhere b c denotes the integer part. It turns out that there are no a-type constraints for the\nminimal twisted puncture. Since we are only interested in determining the spectrum of the\ntheory, we can directly consider the combined effect of c-type constraints and the different\npole orders. Overall, the order of poles minus the number of c-constraints is\n\nk\n\n2 \u2212\n\u230a\nk \u2212 1\nN\n\n\u230b\n; k = 2, . . . , 2N. (6.12)\n\nTherefore, starting from the SW geometry of the theory with a full twisted puncture, if we\nremove from the spectrum the first k\u2212 1\u2212\n\n\u230a\nk\n2\n\n\u230b\n+\n\u230a\nk\u22121\nN\n\n\u230b\nfor every k (those with largest scaling\n\ndimension as in 6.3) we find the spectrum of the theory with a minimal puncture.\n\n61\n\n\n\nModels with bt = 2N . The relevant SW geometry is\n\nuv + x2N + z\u03ba + subleading = 0 (6.13)\n\nand generalizes the A3 family we have discussed before. As in 6.3 we expect in the IHS\none coordinate with dimension 2N\n\n\u03ba since this is the spacing between operators from each k-\ndifferential. We also expect a second coordinate which allows us to go e.g. from the CB\noperator of largest dimension in \u03c6k to the one in \u03c6k\u22121. This has dimension 1 \u2212 N\n\n\u03ba . Finally,\nsince \u2206max (the highest dimension in the CB spectrum) after closure becomes 2N\u2212 2N2+2N\n\n\u03ba we\nconclude that the third coordinate has dimension N \u2212 N2+N\n\n\u03ba . Finally, using the normalization\ncondition D(\u21263) = 1 we find that the fourth coordinate has dimension N \u2212 N2+2N\n\n\u03ba . Using\nthese data we find as desired the IHS singularity\n\nu2 + x\u03ba\u2212N\u22121 + xy2 + yzN = 0. (6.14)\n\nModels with bt = 4N \u2212 2. The relevant SW geometry is\n\nuv + x2N + xz\u03ba+1/2 + subleading = 0. (6.15)\n\nThe spacing between operators from the same k-differential is always a multiple of 4N\u22122\n2\u03ba+1 and\n\nthis quantity will therefore become the dimension of one of the coordinates. Interpolating\nbetween differentials of degree k and k \u2212 1 requires instead a coordinate with dimension\n1\u2212 2N\u22121\n\n2\u03ba+1 . The coordinate u will have dimension \u2206max/2, which in the case at hand is equal\nto N \u2212 (2N\u22121)(N+1)\n\n2\u03ba+1 . Finally, the normalization condition D(\u21263) = 1 implies that the fourth\ncoordinate has dimension N \u2212 (2N\u22121)(N+2)\n\n2\u03ba+1 . From these results we find the IHS\n\nu2 + xy\u03ba\u2212N + yz2 + zxN = 0. (6.16)\n\n6.4.2 Twisted Aeven theories\n\nAlso in this case the outer-automorphism changes the sign of k-differentials with k odd. The\ncorresponding monomials will therefore involve half-integer powers of the coordinate z. Un-\nfortunately the detailed data of twisted Aeven punctures are not known at present, but we\nhave sufficient information to determine how the spectrum changes upon closure of the regu-\nlar puncture [106]. The change in pole orders and the implementation of c-type constraints15\n\ninstructs us to remove for each k-differential the\n\u230a\nk\n2\n\n\u230b\n\u2212 1 terms with largest dimension from\n\nthe spectrum of the theory with a full puncture. Furthermore, there is a constraint of a-type\nwhenever k is odd and therefore we should modify the spectrum accordingly.\n\n15It is not known at present how to disentangle these two pieces of information.\n\n62\n\n\n\nLet us give an example of this procedure since this is the first time we come across a-type\nconstraints. Let us consider the case k = 5 (and bt = 2N for definiteness). The corresponding\noperators in the theory with a full puncture have dimension\n\n\u2212 2N\n\u03ba\n, 5\u2212 4N\n\n\u03ba\n, 5\u2212 6N\n\n\u03ba\n, . . . (6.17)\n\nSince\n\u230a\nk\n2\n\n\u230b\n\u22121 is 1 for k = 5, in order to implement the closure we first remove the operator with\n\nlargest dimension, therefore the first in the sequence above and only afterwards we implement\nthe a-constraint and trade the second operator for another with the same dimension divided\nby two. We therefore get an operator with dimension 5\n\n2 \u2212\n2N\n\u03ba .\n\nModels with bt = 4N + 2. The relevant SW geometry is\n\nuv + x2N+1 + z\u03ba+1/2 + subleading = 0. (6.18)\n\nThe spacing between operators from the same k-differential is a multiple of 4N+2\n2\u03ba+1 which be-\n\ncomes the dimension of one of the coordinates. Moving between differentials with consecutive\ndegree (k and k \u2212 1) requires instead a coordinate with dimension 1 \u2212 2N+1\n\n2\u03ba+1 . The coordi-\nnate u has dimension \u2206max/2, namely N + 1\n\n2 \u2212\n(2N+1)2\n\n4\u03ba+2 . Finally, the normalization condition\nD(\u21263) = 1 implies that the fourth coordinate has dimension N + 1\n\n2 \u2212\n(2N+1)2\n\n4\u03ba+2 \u2212 2N+1\n2\u03ba+1 . From\n\nthese results we find the IHS\n\nu2 + x2N+1 + y\u03ba\u2212N + yz2 = 0. (6.19)\n\nModels with bt = 2N The relevant SW geometry is\n\nuv + x2N+1 + xz\u03ba + subleading = 0. (6.20)\n\nThe spacing between operators from the same k-differential is a multiple of 2N\n\u03ba which becomes\n\nthe dimension of one of the coordinates. Moving between differentials with consecutive degree\n(k and k \u2212 1) requires a coordinate with dimension 1 \u2212 N\n\n\u03ba . The coordinate u has dimension\n\u2206max/2, namely N + 1\n\n2 \u2212\n2N2+N\n\n2\u03ba . Finally, the normalization condition D(\u21263) = 1 implies that\nthe fourth coordinate has dimension N + 1\n\n2 \u2212\n2N2+3N\n\n2\u03ba . From these results we find the IHS\n\nu2 + x2N+1 + xy\u03ba\u2212N + yz2 = 0. (6.21)\n\n6.4.3 Twisted DN+1 theories\n\nThe class S description includes k-differentials with k even from 2 to 2N plus another dif-\nferential with k = N + 1 associated with the pfaffian of the Hitchin field. For this family\n\n63\n\n\n\nof theories the outer-automorphism acts nontrivially (changing the sign) of the pfaffian only.\nThe corresponding monomials will therefore involve half-integer powers of the coordinate z. In\nthis case both the full and minimal punctures do not exhibit any constraints [69] and therefore\nwe just need to know the pole orders. For the differentials (\u03c62, \u03c64, . . . , \u03c62N ;\u03c6N+1) the pole\norders for the full puncture are (1, 3, . . . , 2N \u2212 1; 2N+1\n\n2 ) whereas for the minimal puncture we\nhave (1, 1, . . . , 1; 1\n\n2). The number of operators we need to remove from each k-differential to\nimplement the closure is therefore (0, 2, 4, . . . , 2N \u2212 2;N). Let us now discuss the two cases\nseparately.\n\nModels with bt = 2N + 2. The relevant SW geometry is\n\nuv + xN + xy2 + yz\u03ba+1/2 + subleading = 0. (6.22)\n\nThe spacing between operators from the same k-differential is a multiple of 2N+2\n2\u03ba+1 which be-\n\ncomes the dimension of one of the coordinates. Moving between differentials with consecutive\ndegree (k and k\u22122) requires instead a coordinate with dimension 2\u2212 4N+4\n\n2\u03ba+1 . The coordinate u\nhas dimension \u2206max/2, namely N\u2212 2N2+N\u22121\n\n2\u03ba+1 . Finally, the normalization condition D(\u21263) = 1\nimplies that the fourth coordinate has dimension N\u22121\u2212 2N2+N\u22121\n\n2\u03ba+1 + 2N+2\n2\u03ba+1 . From these results\n\nwe find the IHS\nu2 + xy2 + yz\u03ba\u2212N + zxN = 0. (6.23)\n\nModels with bt = 2N . The relevant SW geometry is\n\nu2 + xN + xy2 + z\u03ba + subleading = 0. (6.24)\n\nThe spacing between operators from the same k-differential is a multiple of 2N\n\u03ba which becomes\n\nthe dimension of one of the coordinates. Moving between differentials with consecutive degree\n(k and k \u2212 2) requires a coordinate with dimension 2\u2212 4N\n\n\u03ba . The coordinate u has dimension\n\u2206max/2, namely N \u2212 2N2\u2212N\n\n\u03ba . Finally, the normalization condition D(\u21263) = 1 implies that\nthe fourth coordinate has dimension N \u2212 1\u2212 2N2\u22123N\n\n\u03ba . From these results we find the IHS\n\nu2 + x\u03ba+1\u22122N + xyN + yz2 = 0. (6.25)\n\n6.4.4 Z3-twisted D4 theories\n\nThis is the only case in which the outer-automorphism is not Z2. There are a quadratic and a\nsextic differentials which are invariant under outer-automorphisms and two quartic differentials\nwhich transform as \u03c64 \u2192 \u03c9\u03c64 and \u03c6\u03034 \u2192 \u03c9\u22121\u03c6\u03034 with \u03c93 = 1. This implies that all terms in\n\n64\n\n\n\n\u03c62 and \u03c66 contain integer powers of z, whereas \u03c64 contains terms of the form zn+1/3 and \u03c6\u03034\n\ncontains terms of the form zn+2/3. The pole orders (see [63]) for (\u03c62, \u03c64, \u03c6\u03034, \u03c66) at the full\npuncture are (1, 10/3, 11/3, 5) and at the minimal puncture are (1, 7/3, 8/3, 4). In the case of\nthe minimal puncture we have a constraint of a-type for \u03c64 and a c-constraint for \u03c6\u03034. There\nare instead two constraints of c-type for \u03c66.\n\nModels with bt = 12. The relevant SW geometry is\n\nu2 + x3 + xy2 + yz\u03ba\u00b11/3 + subleading = 0. (6.26)\n\nThe spacing between operators from the same k-differential is a multiple of 12\n3\u03ba\u00b11 , which\n\nbecomes the dimension of one of the coordinates. The new feature in this case is that the sign\nambiguity leads to two different families of singularities. Moving between the differentials \u03c66\n\nand \u03c64 requires a coordinate with dimension 2\u2212 20\n3\u03ba\u00b11 and going instead from \u03c66 to \u03c6\u03034 leads to\n\na coordinate with dimension 2\u2212 16\n3\u03ba\u00b11 . The coordinate u has as always dimension \u2206max/2, i.e.\n\n3\u2212 24\n3\u03ba\u00b11 . Notice that at this stage we have already determined the scaling dimensions of all\n\nthe coordinates and therefore the normalization condition D(\u21263) = 1 should be automatically\nsatisfied for the consistency of our picture. It is satisfactory to see this is indeed the case.\nFrom these assignments of dimensions we find the following two families of singularities:\n\nu2 + x3 + yz3 + zy\u03ba\u22122 = 0 (6.27)\n\nwhen we choose the + sign and\n\nu2 + x3 + yz3 + xy\u03ba\u22123 = 0 (6.28)\n\nwhen we choose the \u2212 sign.\n\nModels with bt = 6. The relevant SW geometry is\n\nu2 + x3 + xy2 + z\u03ba + subleading = 0. (6.29)\n\nWe have no sign ambiguity this time, but as in the bt = 12 case we will be able to identify\nthe scaling dimension of all the coordinates without exploiting the normalization condition.\nThe spacing between operators from the same k-differential is a multiple of 6\n\n\u03ba , which therefore\nbecomes the dimension of one of the coordinates. Moving between the differentials \u03c66 and\n\u03c64 requires a coordinate with dimension 2 \u2212 10\n\n\u03ba and going instead from \u03c66 to \u03c6\u03034 leads to a\ncoordinate with dimension 2 \u2212 8\n\n\u03ba . The dimension of u, which is always equal to \u2206max/2, in\nthis case reads 3\u2212 12\n\n\u03ba . Again the normalization condition D(\u21263) = 1 is automatically satisfied.\nFrom these assignments of dimensions we find the following family of singularities:\n\nu2 + x3 + yz3 + y\u03ba\u22124 = 0. (6.30)\n\n65\n\n\n\n6.4.5 Twisted E6 theories\n\nIn the E6 class S theory we have k-differentials with k = 2, 5, 6, 8, 9, 12 and only those with\nk = 5, 9 are odd under the action of the outer-automorphism. We therefore conclude that\nterms in \u03c65 and \u03c69 are proportional to half-integer powers of z whereas all the others are\nproportional to integer powers of z. Finally, let us consider the properties of the full and\nminimal punctures [66]. The pole orders for (\u03c62, \u03c65, \u03c66, \u03c68, \u03c69, \u03c612) are (1, 9/2, 5, 7, 17/2, 11)\nfor the full puncture and (1, 5/2, 3, 4, 9/2, 6) for the minimal. Moreover, the minimal puncture\nexhibits one constraint of a-type for \u03c66 and several c-type constraints: one for \u03c65, two for \u03c68\n\nand \u03c69 and three for \u03c612.\n\nModels with bt = 18. The relevant SW geometry is\n\nu2 + x3 + y4 + yz\u03ba+1/2 + subleading = 0. (6.31)\n\nThe spacing between operators from the same k-differential is a multiple of 18\n2\u03ba+1 , which\n\ntherefore becomes the dimension of one of the coordinates. Moving between the differentials\n\u03c612 and \u03c69 requires a coordinate with dimension 3\u2212 45\n\n2\u03ba+1\n16 and going instead from \u03c612 to \u03c68\n\nleads to a coordinate with dimension 4 \u2212 54\n2\u03ba+1 . Finally, in this case \u2206max = 12 \u2212 162\n\n2\u03ba+1 and\ntherefore the dimension of u is equal to 6\u2212 81\n\n2\u03ba+1 . Again the normalization condition D(\u21263) = 1\nis automatically satisfied. From these assignments of dimensions we find the singularity\n\nu2 + x3 + yz4 + zy\u03ba\u22126 = 0. (6.32)\n\nModels with bt = 12. The relevant SW geometry is\n\nu2 + x3 + y4 + z\u03ba + subleading = 0. (6.33)\n\nThe spacing between operators from the same k-differential is a multiple of 12\n\u03ba , which therefore\n\nbecomes the dimension of one of the coordinates. Moving between the differentials \u03c612 and\n\u03c69 requires a coordinate with dimension 3 \u2212 30\n\n\u03ba and going instead from \u03c612 to \u03c68 leads to\na coordinate with dimension 4 \u2212 36\n\n\u03ba . Finally, in this case \u2206max = 12 \u2212 108\n\u03ba and therefore\n\nthe dimension of u is equal to 6 \u2212 54\n\u03ba . Again the normalization condition D(\u21263) = 1 is\n\nautomatically satisfied. From these assignments of dimensions we find the singularity\n\nu2 + x3 + yz4 + y\u03ba\u22129 = 0. (6.34)\n16We can also notice, as a further check of our method, that this assignment of scaling dimension also allows\n\nus to recover from the term with highest dimension in \u03c66 the term generated by the a-type constraint.\n\n66\n\n\n\nModels with bt = 8. The relevant SW geometry is\n\nu2 + x3 + y4 + xz\u03ba + subleading = 0. (6.35)\n\nThe spacing between operators from the same k-differential is a multiple of 8\n\u03ba , which therefore\n\nbecomes the dimension of one of the coordinates. Moving between the differentials \u03c612 and\n\u03c69 requires a coordinate with dimension 3 \u2212 20\n\n\u03ba and going instead from \u03c612 to \u03c68 leads to a\ncoordinate with dimension 4 \u2212 24\n\n\u03ba . In this case \u2206max = 12 \u2212 72\n\u03ba and therefore the dimension\n\nof u is equal to 6 \u2212 36\n\u03ba . The normalization condition D(\u21263) = 1 is automatically satisfied as\n\nin the previous cases and from these assignments of dimensions we find the singularity\n\nu2 + x3 + yz4 + xy\u03ba\u22126 = 0. (6.36)\n\n6.5 IHS for Trinions\n\nAs is well known, the class S formalism does not allow to describe the gauging of more\nthan two matter sectors, in particular it does not provide a realization of unitary quivers\nwith exceptional shape. This is not a restriction for geometric engineering and indeed IHS\ndescriptions in Type IIB for quivers with exceptional shape are known [76]. This is just a\nspecial case of systems (which we call trinions) involving the gauging of three Db\n\np(G) theories\nthrough a G vector multiplet.\n\nA general procedure to construct IHS descriptions for trinions of Db\np(G) theories with G\n\nsimply-laced was proposed in [29], and we will now briefly review it. With this result at hand,\nwe can use the Type IIB description to determine the defect group of the trinion theory,\ntherefore providing a highly nontrivial check of our results. Notice that this computation is\nsensitive to the non trapped part of the defect group.\n\n6.5.1 Trinions of Db\np(G) Theories from Type IIB\n\nIn the general case of gaugings of three Db\np(G) theories, we just have a Landau-Ginzburg (LG)\n\ndescription instead of a threefold singularity. The LG superpotential reads\n\nW = w2 + f(t, x) +\n3\u2211\ni=1\n\nzpii fbi(x, t) , (6.37)\n\nwhere WG(w, x, t) \u2261 w2 +f(t, x) = 0 is the ADE singularity of type G and fbi(x, t)z\npi\ni denotes\n\nthe z-dependent part of the threefold singularity describing Dbi\npi(G), as in table 3. From a\n\nLG model point of view, w in (6.37) is a massive field and can be integrated out, leaving five\nfields. The conformality condition reads\n\nb1\np1\n\n+ b2\np2\n\n+ b3\np3\n\n= h\u2228(G) . (6.38)\n\n67\n\n\n\nImportantly, if the singularityW = 0 is non-isolated, one needs to add marginal terms to (6.37)\nin order to have an isolated singularity at the origin, so that the LG model is well-defined\n(see [29] for a detailed discussion on this point).\n\nWe will focus on the special case in which the LG model is equivalent to a system with\nat most four fields, since this is the class of theories for which the LG superpotential reduces\nto the defining equation of a IHS. This is always the case when G is special unitary since\nWG = w2 + t2 + xN and therefore also t is massive and can be integrated out, leaving us\nwith the four fields x, z1, z2, z3. We then conclude that a trinion involving the gauging of\nDbi\npi(SU(N)) for i = 1, 2, 3 is described by the IHS\n\nxN + xN\u2212b1zp1\n1 + xN\u2212b2zp2\n\n2 + xN\u2212b3zp3\n3 = 0 . (6.39)\n\nThe case in which G is special orthogonal or exceptional is more subtle since we cannot\nintegrate out either t or x. In order to reduce to a system with four fields, we should restrict\nto cases in which at least one of the fields zi is massive, so that it can be integrated out. This\nhappens whenever\n\nzpfb(x, t) = z2 or zpfb(x, t) = tz , xz , (6.40)\n\nfor p = 2 or p = 1 and an appropriate choice of b. Such massive fields can be integrated out.\nIf we choose p = 2 for one of the legs, we are considering a trinion of the form\n\nDb2\np2(G) G Db3\n\np3(G)\n\nDh\u2228\n2 (G)\n\n(6.41)\n\nThe constraint (6.38) now implies that the other two Db\np(G) sectors should satisfy the relation\n\nb2\np2\n\n+ b3\np3\n\n= h\u2228(G)\n2 . (6.42)\n\nSince we are now left with only four fields, the system can be understood as a threefold\ncompactification in Type IIB. The second option is p = 1, which gives a mass term (6.40) for\nb 6= h\u2228(G), since in that case the fb(x, t) function is always linear in either x or t, we can\nsimply choose the Db1\n\np1(G) theory to be Db\n1(G) with b 6= h\u2228(G) (we remind the reader that\n\nDb\n1(G) is trivial for b = h\u2228(G)) and, due to (6.38), we take the other two Db\n\np(G) models to\nsatisy the constraint\n\nb2\np2\n\n+ b3\np3\n\n= h\u2228(G)\u2212 b. (6.43)\n\nUnder these conditions, we can integrate out both z1 and either x or t (the variable appearing\nin fb1(x, t)). We can now simply introduce a new massive field y which enters quadratically\n\n68\n\n\n\nin the superpotential. The threefold singularity is now given by a hypersurface in the four\nvariables z2, z3, y, and x or t (the variable we have not integrated out). We can therefore also\nconsider the family of trinions\n\nDb2\np2(G) G Db3\n\np3(G)\n\nDb\n1(G)\n\n(6.44)\n\nsatisfying the condition (6.43).\n\n6.5.2 The Defect Group of Trinions from Punctures\n\nLet us consider general 4d N = 2 SCFTs of the form\n\ng\n\nT\u2217P1\n\nT\u2217P2\nT\u2217P3 (6.45)\n\nwhere Pi are untwisted conformal punctures, so that each T\u2217Pi is a matter SCFT [29]. Moreover,\nT\u2217Pi carries a g flavor symmetry associated to the untwisted maximal regular puncture used\nin the Class S construction of T\u2217Pi . In the trinion theory (6.45), this g flavor symmetry of all\nthree T\u2217Pi is gauged by a single gauge algebra g in the center of the trinion.\n\nWe can compute the defect group LP1,P2,P3 of the above trinion theory in terms of defect\ngroups LPi associated to the punctures Pi. This is easily found to be\n\nLP1,P2,P3 = HP1,P2,P3 \u00d7 H\u0302P1,P2,P3 (6.46)\n\nwith\n\nHP1,P2,P3 =\n{\n\n(\u03b1, \u03b2, \u03b3) \u2208 HP1 \u00d7HP2 \u00d7HP3\n\n\u2223\u2223\u2223\u03c0P1(\u03b1) = \u03c0P2(\u03b2) = \u03c0P3(\u03b3)\n}\n\n(6.47)\n\nand the pairing provided by the pairing of H\u0302P1,P2,P3 with HP1,P2,P3 . In fact, we find that\nfor all the trinions that can be realized by IHS, the short exact sequence (4.9) splits for each\nparticipating puncture Pi, which allows us to simplify HP1,P2,P3 as\n\nHP1,P2,P3 =\n3\u220f\ni=1\nHTPi \u00d7 ZP1,P2,P3 , (6.48)\n\nwhere\nZP1,P2,P3 = ZP1 \u2229 ZP2 \u2229 ZP3 . (6.49)\n\n69\n\n\n\n7 Untwisted A\n\nIn this section, we describe the first of our proposals for the defect groups associated to\npunctures. We discuss untwisted punctures of 6d A-type (2, 0) theories. The key information\nthat we use about these punctures is discussed in subsection 7.1. We not only consider\nconformal punctures of IHS type, but also numerous other classes of conformal punctures. We\nalso include numerous classes of non-conformal punctures.\n\nIn subsection 7.2, we make our proposal. For each puncture, we assign a 4d N = 2\nquiver gauge theory, and propose that the defect groups associated to the quiver gauge theory\ncapture the defect groups of the associated punctures. See section 5.2. Using this proposal,\nwe explicitly computed the defect groups associated to all punctures considered in subsection\n7.1. As a result of this proposal, untwisted punctures of A-type do not carry any trapped\n1-form symmetries (but can carry non-trapped parts).\n\nIn subsection 7.3, we expand on our motivation for making the proposal discussed in\nsubsection 7.2. We describe a large sub-class of punctures that admits constructions in terms\nof Hanany-Witten brane setups in IIA. The IIA construction implies that, for a puncture P\nin this subclass, the 4d N = 2 theory TP0\n\nP associated to P is precisely the quiver gauge theory\nassigned to P. Hence, the defect group LP of the puncture P must match the defect group of\nthe quiver theory.\n\nIn subsection 7.4, we provide a very strong check of our proposal. We compactify the 4d\nN = 2 theory TP0\n\nP for an arbitrary puncture P on a circle, which leads us to a quiver gauge\ntheory in 3d. The defect group of TP0\n\nP must now match the defect group of the 3d quiver\ntheory, and we show that the latter defect group matches the defect group of 4d quiver theory\nassociated to P.\n\nIn subsection 7.5, we use the IIB ALE fibration construction of an arbitrary puncture P\nto compute the genuine part L0\n\nP of the defect group LP associated to P. In subsection 7.6,\nwe use the IHS realization to compute the trapped defect groups of IHS punctures, and find\nthat there cannot be any trapped contribution, which is in line with our proposal. The 4d\nN = 2 theories constructed by the IHS include the well-studied (A,A) type Argyres-Douglas\ntheories, which are known to have trivial 1-form symmetry.\n\n7.1 Punctures\n\nIn this section, we discuss untwisted punctures of An\u22121 N = (2, 0) theory. For simplicity and\nuniformity of presentation, we will specify them using a u(n) valued Higgs field, from which\nthe su(n) Higgs field can be obtained by removing the center of mass. Place the puncture\n\n70\n\n\n\nat t = 0 on a complex plane C with coordinate t. Near the puncture, the Higgs field can be\ndecomposed into blocks, which we label as Bi. Each block Bi is singular at t = 0, with the\nleading singular piece being\n\nBi = 1\nt1+ri\n\nAi + \u00b7 \u00b7 \u00b7 (7.1)\n\nwhere Ai is a non-singular diagonal matrix and ri \u2265 0 is a rational number. We order the\nblocks such that ri \u2265 ri+1. Let s be biggest value of i for which ri > 0. For each i \u2264 s, we\nwrite\n\nri = pi\nqi\n\n(7.2)\n\nwhere 1 \u2264 qi \u2264 n and gcd(pi, qi) = 1. For such a block, the sheets comprising the block are\npermuted by a Zqi monodromy as one encircles the puncture.\n\nIt is known [88] that irregular punctures (which in our notation are characterized as the\npunctures having s > 0) lead to 4d N = 2 conformal theories only if the compactification\nmanifold is a sphere and if the sphere carries either a single puncture that is irregular or two\npunctures such that one is irregular and the other is regular. However, not every irregular\npuncture can be used in this way to obtain a superconformal theory in 4d. Let us call the\nirregular punctures that lead to superconformal theories as conformal punctures.\n\nExtending the arguments of [88], we propose that an untwisted A-type puncture P is\nconformal only if ri = rj for all i, j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , s}. These have 0 \u2264 ns \u2264 n/2. Out of these,\nthe IHS punctures discussed in [81,88] are the ones for which ns = 0, 1.\n\n7.2 1-Form Symmetry from Class GQ\n\nConsider such a puncture P. Define for it\n\nni := n\u2212\ni\u2211\n\nj=1\nqj (7.3)\n\nfor 1 \u2264 i \u2264 s. Then, we claim that P \u2208 F\u03c4 (see section 5.2) with\n\nsu(n) su(n1) su(n2) \u00b7 \u00b7 \u00b7 su(ns\u22121)=\u03c4 [u(ns)] (7.4)\n\nwhere each edge denotes a hyper in bifundamental between the adjacent (gauge or flavor)\nalgebras. From this we can compute\n\nLTP = 0 (7.5)\n\nand\nLP = Zg \u00d7 Zg if ns = 0\n\nLP = 0 if ns 6= 0\n(7.6)\n\n71\n\n\n\nwith\ng = gcd(n, n1, n2, \u00b7 \u00b7 \u00b7 , ns\u22121) (7.7)\n\nand the pairing on LP = Zg \u00d7 Zg is obtained by regarding the two Zg factors as Pontryagin\nduals of each other. Since HTP = 0, we find that\n\nZP = Zg \u2286 Zn = ZG (7.8)\n\nfor ns = 0, and\nZP = 0 (7.9)\n\nfor ns 6= 0.\n\n7.3 Class GQ\u2032 \u2013 Type IIA Punctures\n\nConsider a puncture P \u2032 having pi = 1 for all i having ri > 0. The 4d N = 2 Class S theory T\u2217P \u2032\n\nassociated to P \u2032 admits a Hanany-Witten type brane construction in Type IIA superstring\ntheory [39,90,93]\n\nNS51 NS52 NS53 NS5s\u22121 NS5s\n\nn\nn1\n\nn2 ns\u22121\nns\n\n(7.10)\n\nwhere the segment between NS5i and NS5i+1 carries ni D4 branes, and there are n semi-\ninfinite D4 branes on the left and ns semi-infinite D4 branes on the right. The n semi-infinite\nD4 branes on the left give rise to the untwisted maximal regular puncture in the Class S\nconstruction. All the NS5 branes bend to the right and (along with the other D4 branes) give\nrise to the irregular puncture P \u2032 in the Class S construction. The resulting 4d theory T\u2217P \u2032 can\nbe identified as the quiver\n\n[su(n)] su(n1) su(n2) \u00b7 \u00b7 \u00b7 su(ns\u22121)=T\u2217P \u2032 [u(ns)] (7.11)\n\nand the 4d theory TP0\nP \u2032 can be identified as the quiver\n\nsu(n) su(n1) su(n2) \u00b7 \u00b7 \u00b7 su(ns\u22121)=TP0\nP \u2032 [u(ns)] (7.12)\n\nThe Hanany-Witten brane construction associated to TP0\nP \u2032 is\n\n72\n\n\n\nNS51 NS52 NS53 NS5s\u22121 NS5s\n\nn\nn1\n\nn2 ns\u22121\nns\n\nNS50 (7.13)\n\nThe NS50 brane bends to the left and gives rise to the P0 puncture.\n\n7.4 Checks Via Circle Reduction \u2013 Electric Quiver EQ4\n\nFor a general puncture P, consider the 4d theory TP0\nP and compactify this theory on a circle.\n\nA particular zero radius limit of the 4d theory leads to the 3d theory EQ4(TP0\nP ) which is the\n\nquiver [29]\n\nsu(n) \u00b7 \u00b7 \u00b7 su(ni\u22121) u(ni,1) \u00b7 \u00b7 \u00b7 u(ni,pi\u22121) su(ni) \u00b7 \u00b7 \u00b7 [u(ns)]\n\n(7.14)\nwhich is constructed from (7.4) by inserting between su(ni\u22121) and su(ni) algebras, a pi \u2212 1\nnumber of unitary gauge algebras u(ni,j) with 1 \u2264 j \u2264 pi \u2212 1. We have\n\nni,j = bni\u22121 \u2212 j/ric (7.15)\n\nThe defect group LP = L\nT\nP0\nP\n\nof lines in the 4d theory TP0\nP should be identified with the defect\n\ngroup formed by lines and local operators in the 3d theory EQ4(TP0\nP ). The reader can easily\n\nverify from the above quiver description of EQ4(TP0\nP ), that the defect group of EQ4(TP0\n\nP )\nis given by (7.6). This provides a strong check for our proposal for computing defect group\nLP = L\n\nT\nP0\nP\n\nas the defect group L\u03c4 of the quiver \u03c4 shown in (7.4).\nSimilarly, the 3d theory EQ4(T\u2217P) is the quiver\n\n[su(n)] \u00b7 \u00b7 \u00b7 su(ni\u22121) u(ni,1) \u00b7 \u00b7 \u00b7 u(ni,pi\u22121) su(ni) \u00b7 \u00b7 \u00b7 [u(ns)]\n\n(7.16)\nwhich confirms that LTP = 0.\n\n7.5 Spectral Cover Monodromies\n\nIn this subsection, we derive the defect group (7.6) of an arbitrary untwisted A-type puncture\nusing the monodromy of the Higgs field near the puncture, under the assumption that the\npuncture does not carry any trapped part. As discussed earlier, the monodromy of the Higgs\nfield allows one to compute the part\n\nL0\nP = HTP \u00d7WP \u2286 LP (7.17)\n\n73\n\n\n\nof the defect group LP associated to a puncture P. If one knows via other methods that\nHTP = 0, then the whole defect group LP can be recovered from the knowledge of the piece\nL0\nP as then one has the relationship\n\nLP =\n(\nL0\nP\n\n)2\n(7.18)\n\nNotice that in this situation we also have L0\nP\n\u223c= Z\u0302P\n\nFor this computation, we only need the profile of the spectral curve near the puncture\nplaced at t = 0. We work in the frame where the differential associated to the curve is taken\nto be \u03bb = vdt/t. Then, the profile of the spectral curve very close to the puncture can be\ndescribed as\n\nvn +\ns\u2211\ni=1\n\nvni\n\ntPi\n= 0 (7.19)\n\nwhere\n\nPj :=\nj\u2211\ni=1\n\npi (7.20)\n\nThis is just the leading behavior of the spectral curve following from the Higgs field singularity\n(7.1) describing the puncture.\n\nThe sheets of the spectral cover form s number of orbits17 (under monodromy around the\npuncture) parametrized by the index i. The number of sheets in the orbit i are qi. This means\nthat the integers pi do not enter the monodromy, and hence the defect group associated to\nthe puncture. Indeed the result (7.6) depends only on qi but not on pi.\n\nLet ea with 1 \u2264 a \u2264 n denote various sheets. The first q1 sheets are cyclically permuted\namongst themselves, the next q2 sheets are cyclically permuted amongst themselves, and so\non. The roots can be expressed as\n\n\u03b1a = ea \u2212 ea+1 (7.21)\n\nfor 1 \u2264 a \u2264 n\u2212 1. The above monodromy action on the sheets ea descends to a monodromy\naction MP on the roots \u03b1a. We now compute and find if ns = 0\n\nTP = MP \u2212 1 , SNF (TP) = diag (g, 1, . . . , 1, 0, . . . , 0) (7.22)\n\nwhere g = gcd(n, n1, . . . , ns) and we have s\u2212 1 vanishing entries. With this we compute\n\nL0\nP = Tor\n\n(\nZn\u22121\n\nTPZn\u22121\n\n)\n= Zg . (7.23)\n\nWhen ns 6= 0, we instead find L0\nP = 0.\n\n17Here we regard all sheets having trivial monodromy to be in the same \u201corbit\u201d for uniformity of presentation.\n\n74\n\n\n\nExample: P0 puncture. Let us consider the example of P0 puncture, which has s =\n1, p1 = 1, q1 = n. There is a Zn monodromy around the P0 puncture. That is, all the n\nsheets are cyclically permuted amongst themselves. We label the sheets by weights wi of the\nn-dimensional fundamental representation such that these are permuted as wi \u2192 wi+1 with\nn + 1 \u2261 1. We have the roots \u03b1a = wa \u2212 wa+1 where a = 1, . . . , n \u2212 1. With respect to this\nlabelling the monodromy action on sheets leads to the following action on the roots\n\n\u03b1a \u2192 \u03b1a+1 \u2200 1 \u2264 a \u2264 n\u2212 2 , \u03b1n\u22121 \u2192 \u2212\nn\u22121\u2211\na=1\n\n\u03b1a (7.24)\n\nThe mondromy matrix is thus\n\nMP0 =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n\n0 0 \u00b7 \u00b7 \u00b7 0 0 0 \u22121\n1 0 \u00b7 \u00b7 \u00b7 0 0 0 \u22121\n\n0 1 . . . 0 0 0 \u22121\n... . . . . . . . . . ...\n\n...\n...\n\n0 0 . . . 1 0 0 \u22121\n0 0 . . . 0 1 0 \u22121\n0 0 . . . 0 0 1 \u22121\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\n\n(7.25)\n\nFrom here we define\nTP0 = MP0 \u2212 1 (7.26)\n\nand find\nSNF (TP0) = diag (n, 1, . . . , 1) (7.27)\n\nimplying that\nL0\nP0 = Zn (7.28)\n\n7.6 Trapped Defect Group from Type IIB on CY3\n\nAs we discussed earlier, for a puncture P of IHS type we have an alternate geometric method\nfor computing the trapped part of the defect group LTP based on the associated isolated\nhypersurface singularity XP . The 4d N = 2 SCFT TP associated to an untwisted A-type IHS\npuncture P is an AD theory of type A, with the following isolated hypersurface realization:\n\nAD[An, Ak] : x2\n1 + xn+1\n\n2 + x2\n3 + xk+1\n\n4 = 0 . (7.29)\n\nThe results in [17,30,55] show that for any k, n these have a trivial defect group\n\nLXAD[An,Ak] = 0 . (7.30)\n\n75\n\n\n\nSimilarly, for untwisted AN\u22121-type IHS punctures Pbk having b = N \u2212 1 and arbitrary k, one\nfinds using the IHS singularity, that the defect group LTPb\n\nk\n\nof the theory TPb\nk\nassociated to\n\nthe puncture Pbk is trivial. Thus we find that there is no trapped defect group for all IHS\npunctures of untwisted type A\n\nLTPb\nk\n\n= 0 . (7.31)\n\nThis is consistent with the result (7.5) stating that in fact no conformal (IHS or non-IHS) or\nnon-conformal puncture of untwisted A-type carries any trapped defect group.\n\n8 Untwisted D\n\nIn this section, we describe our proposal for computing the defect groups associated to un-\ntwisted punctures for 6d D-type (2, 0) theories. The key information that we use about these\npunctures is discussed in subsection 8.1. We not only consider conformal punctures of IHS\ntype, but also numerous other classes of conformal and non-conformal punctures.\n\nIn subsection 8.2, we make our proposal. For each puncture, we assign a 4d N = 2 gener-\nalized quiver gauge theory involving both perturbative and strongly coupled matter sectors,\nand propose that the defect groups associated to the generalized quiver gauge theory capture\nthe defect groups of the associated punctures.\n\nIn subsection 8.2.1, we expand on our motivation for making the proposal discussed in\nsubsection 8.2. We describe a large class of punctures P for which the 4d N = 2 theories TP0\n\nP\n\ncoincide with the proposed generalized quivers. A subclass of this class of punctures, whose\nassociated generalized quivers involve only perturbative matter content, can be realized in\nterms of Hanany-Witten brane setups in IIA involving O4 planes.\n\nBefore using the proposal of subsection 8.2 to compute defect groups associated to un-\ntwisted D-type punctures, one needs to understand some properties of the strongly coupled\nmatter sectors appearing in the generalized quivers associated to these punctures. These\nproperties are derived in subsection 8.3, and subsequently used in subsection8.4 to derive the\ndefect groups associated to untwisted D-type punctures. Unlike untwisted A-type punctures,\nwe find that untwisted D-type punctures can carry trapped 1-form symmetries.\n\nNon-trivial checks of this proposal are provided using the IIB ALE fibrations in subsection\n8.5. In subsection 8.6.1, we use the IHS realization to compute the trapped defect groups of\nIHS punctures, and find a perfect match with the trapped defect groups computed using our\nproposal. The 4d N = 2 theories constructed by the IHS include the well-studied (A,D) type\nArgyres-Douglas theories, which are known to have non-trivial 1-form symmetry in general. In\nsubsection 8.6.2, we study other IHS that construct trinion theories involving three untwisted\n\n76\n\n\n\nD-type punctures. In all such cases, we find that the defect group of the trinion theory as\ncomputed using IHS maps the defect group as computed using our proposal.\n\n8.1 Punctures\n\nNow we consider punctures for 6d Dn N = (2, 0) theory. These are described in terms of a\nHitchin field in vector representation of Dn.\n\nThe i-th block of the Hitchin field takes the form\n\nBi = 1\nt1+ri\n\nAi + \u00b7 \u00b7 \u00b7 (8.1)\n\nAgain we order the blocks such that ri \u2265 ri+1 and let s be biggest value of i for which ri > 0.\nFor each i \u2264 s, we write\n\nri = pi\nqi\n\n(8.2)\n\nwhere 1 \u2264 qi \u2264 2n and gcd(pi, qi) = 1.\nLet us again define\n\nni := 2n\u2212\ni\u2211\n\nj=1\nqj (8.3)\n\nWe impose extra conditions on the punctures that can be described in terms of ni as follows.\nIf ni is even (including n0 := 2n) and qi+1 is odd, then we require\n\nqi+2 = qi+1 (8.4)\n\nThis in particular ensures that ni\u22121 and ni+1 are even if ni is odd. Furthermore, we require\nthat ns is even. If s is odd then ns \u2265 2, and if s is even then ns \u2265 0.\n\nSimilar to the untwisted A-type punctures, an untwisted D-type puncture is conformal\nonly if ri = rj for all i, j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , s}. Out of these, the IHS punctures discussed in [81,88]\nare those for which ns = 0, 2.\n\nThe conformal untwisted-DN punctures Pbk of IHS type have b = 2N \u2212 2 or b = N . The\ntheories TPb\n\nk\nassociated to b = 2N \u2212 2 are the AD[A,D] theories. Again, there is a prediction\n\nfrom the hyper-surface realization for the defect group of the theories TPb\nk\n, which we discuss\n\nin section 8.6.\n\n8.2 Class GQ of Generalized Quivers\n\nConsider a puncture P of the above type. Then we conjecture that P \u2208 F\u03c4 where \u03c4 is a\ngeneralized quiver that can be constructed using the data of ni as follows. The quiver takes\nthe form\n\nso(2n) N1 N2 \u00b7 \u00b7 \u00b7 Ns\u22121 [gs] (8.5)\n\n77\n\n\n\nThe node Ni is either a gauge algebra or a matter SCFT, depending on whether ni is even or\nodd respectively. If ni is even, we write\n\nNi = gi (8.6)\n\nIf i is even, we have\ngi = so(ni) (8.7)\n\nand if i is odd, we have\ngi = usp(ni \u2212 2) (8.8)\n\nThe same applies to the flavor algebra gs. If s is even, we have\n\ngi = so(ns) (8.9)\n\nand if s is odd, we have\ngi = usp(ns \u2212 2) (8.10)\n\nIf ni is odd and i is odd, then we write\n\nNi = C(ni) (8.11)\n\nwhere C(ni) is a matter SCFT having flavor algebra\n\nfC(ni) = so(2ni)\u2295 u(1) (8.12)\n\nIf ni is odd and i is even, then we write\n\nNi = D(ni) (8.13)\n\nwhere D(ni) is a matter SCFT having flavor algebra\n\nfD(ni) = usp(2ni \u2212 4)\u2295 u(1) (8.14)\n\nLet us now describe the edges in the quiver \u03c4 . Consider the edge between Ni and Ni+1\n\nwhere both ni and ni+1 are even. If i is even, we have\n\nso(ni) usp(ni+1 \u2212 2) (8.15)\n\nIf i is odd, we have\nusp(ni \u2212 2) so(ni+1) (8.16)\n\n78\n\n\n\nIn both cases, the edge denotes a half-hyper in bifundamental representation of the two gauge\nalgebras. Now, consider the situation where i is odd and ni is odd. If i+ 1 < s, then locally\nthe quiver looks like\n\nso(ni\u22121) so(ni+1)C(ni) = so(ni + qi) so(ni \u2212 qi)C(ni) (8.17)\n\nwhere the edges denote that so(ni\u22121)\u2295 so(ni+1) = so(ni + qi)\u2295 so(ni \u2212 qi) \u2282 so(2ni) \u2282 fC(ni)\n\nsubalgebra of the flavor algebra fC(ni) of the matter SCFT C(ni) has been gauged. If i+1 = s,\nthen locally the quiver looks like\n\nso(ns\u22122) [so(ns)]C(ns\u22121) = so(ns + 2qs) [so(ns)]C(ns + qs) (8.18)\n\nwhere the edges denote that so(ns\u22122) = so(ns + 2qs) \u2282 so(2ns + 2qs) \u2282 fC(ns\u22121) subalgebra of\nthe flavor algebra fC(ns\u22121) of the matter SCFT C(ns\u22121) has been gauged. Now, consider the\nsituation where i is even and ni is odd. If i+ 1 < s, then locally the quiver looks like\n\nusp(ni\u22121 \u2212 2) usp(ni+1 \u2212 2)D(ni)\n\n= usp(ni + qi \u2212 2) usp(ni \u2212 qi \u2212 2)D(ni) (8.19)\n\nwhere the edges denote that usp(ni\u22121\u22122)\u2295usp(ni+1\u22122) = usp(ni+qi\u22122)\u2295usp(ni\u2212qi\u22122) \u2282\nusp(2ni \u2212 4) \u2282 fD(ni) subalgebra of the flavor algebra fD(ni) of the matter SCFT D(ni) has\nbeen gauged. If i+ 1 = s, then locally the quiver looks like\n\nusp(ns\u22122 \u2212 2) [usp(ns \u2212 2)]D(ns\u22121)\n\n= usp(ns + 2qs \u2212 2) [usp(ns \u2212 2)]D(ns + qs) (8.20)\n\nwhere the edges denote that usp(ns\u22122\u2212 2) = usp(ns + 2qs\u2212 2) \u2282 usp(2ns + 2qs\u2212 4) \u2282 fD(ns\u22121)\n\nsubalgebra of the flavor algebra fD(ns\u22121) of the matter SCFT D(ns\u22121) has been gauged.\n\n8.2.1 Class GQ\u2032 and Type IIA Punctures\n\nThe Class GQ\u2032 of punctures is given by punctures having pi = 1 for all 1 \u2264 i \u2264 s. The Type\nIIA punctures form a subclass of GQ\u2032 for which all qi and hence all ni are even. In such a\nsituation, every node Ni in (5.2) is a gauge algebra, which is so(ni) for i even and usp(ni\u2212 2)\n\n79\n\n\n\nfor i odd. The Type IIA brane construction corresponding to a Type IIA puncture P \u2032 is\n\nNS51 NS52 NS53 NS5s\u22121 NS5s\n\nn\nm1\n\nm2 ms\u22121\nms\n\nO4\u2212 O4+ O4\u2212\n\nO4\u2212\nor\n\nO4+ O4\u2212\n\nO4+\nor\n\n(8.21)\n\nwhere mi number of physical D4 branes have been placed in the ith interval, where mi = ni\n2\n\nfor i even and mi = ni\n2 \u2212 1 for i odd. Moreover, the ith interval carries an O4\u2212 plane if i is\n\neven and an O4+ plane if i is odd.\n\n8.3 The C(m) and D(m) SCFTs\n8.3.1 The C(m) SCFT\n\nThe theory C(m) is a 4d N = 2 SCFT which is better known as the D2m\u22124\n2\n\n(\nSO(2m \u2212 2)\n\n)\ntheory lying in the class Db\n\np(G) of 4d N = 2 SCFTs. This theory can be recognized as the\n4d N = 2 theory T\u2217P associated to an untwisted puncture P of 6d N = (2, 0) theory of type\nso(2m\u2212 2). The puncture P is characterized by\n\ns = 2, q1 = q2 = m\u2212 2, p1 = p2 = 1 (8.22)\n\nFor even m, it can also be recognized as a Lagrangian 4d N = 2 theory carrying usp(m\u2212 2)\ngauge algebra and m full hypermultiplets in the fundamental representation. On the other\nhand, for odd m, there is no such Lagrangian description available. This is the case that arises\nas matter SCFT in the generalized quivers discussed above.\n\nIn order to determine the defect group associated to the generalized quivers discussed\nabove, we need to determine the defect group of C(2m+ 1), and additionally also determine\nthe flavor center charges of the genuine local operators in the C(2m + 1) SCFT. For this\npurpose, we utilize another Class S construction of C(2m + 1) discussed in [62] (where this\nmodel was called R2,2m\u22121) that uses only regular punctures. This involves the compactification\nof 6d N = (2, 0) theory of type su(2m \u2212 1) on a sphere with three regular punctures. One\nof the punctures is maximal regular (whose associated partition is [12m\u22121]). The other two\npunctures are of the same type, described by partition [m\u2212 1,m\u2212 1, 1]. Since the Class S\ncompactification involves only regular punctures, the defect group of lines of C(2m+ 1) must\nbe trivial [31]. Thus there is no contribution to defect group from a node of the form (8.11)\nin the generalized quivers discussed above.\n\n80\n\n\n\nThe manifest flavor symmetry (visible from the regular punctures) is only\n\nfman = su(2m\u2212 1)\u2295 u(2)\u2295 u(2) (8.23)\n\nwith su(2m \u2212 1) subfactor arising from the maximal puncture, and the two u(2) subfactors\narising from the two other punctures. For our purposes, it would be sufficient to keep track\nof only the non-abelian part of the manifest flavor symmetry which is\n\nfna\nman = su(2m\u2212 1)\u2295 so(4) , (8.24)\n\nwhich embeds into so(4m\u2212 2)\u2295 so(4) and then further into so(4m+ 2) part of the full flavor\nsymmetry algebra\n\nfC(2m+1) = so(4m+ 2)\u2295 u(1) (8.25)\n\nWe can easily study representations of local operators under fman or fna\nman using the method\n\nof [104]. We find that there exist local operators charged in spinor and cospinor irreps of\nso(4), while being uncharged under su(2m\u2212 1). This implies that the theory C(2m+ 1) must\ncontain a local operator charged in spinor irrep S of so(4m+ 2).\n\nThis local operator is charged under\n\nSC\u2295 CS (8.26)\n\nrepresentation of so(2p)\u2295 so(4m+ 2\u2212 2p) subalgebra of so(4m+ 2). Thus, in the generalized\nquivers discussed above, we can replace a sub-quiver of the form\n\nso(ni\u22121) so(ni+1)C(ni) (8.27)\n\nwith\nso(ni\u22121) so(ni+1)S\n\nSC\nC\n\n(8.28)\n\nas far as computation of defect group is concerned. The peculiar double edge denotes that we\nhave matter content transforming as SC \u2295 CS under the gauge algebra so(ni\u22121) \u2295 so(ni+1).\nSimilarly, we can replace a sub-quiver of the form\n\nso(ns\u22122) [so(ns)]C(ns\u22121) (8.29)\n\nwith\nso(ns\u22122) [so(ns)]S\n\nSC\nC\n\n(8.30)\n\nas far as computation of defect group is concerned. The double edge denotes that we have\nmatter content transforming as SC\u2295CS under the algebra so(ns\u22122)\u2295 so(ns), where so(ns\u22122)\nis a gauge algebra while so(ns) is a flavor algebra.\n\n81\n\n\n\n8.3.2 The D(m) SCFT\n\nThe theory D(m) is a 4d N = 2 SCFT which is better known as the D2m\u22124\n2\n\n(\nSO(2m\u2212 2)/Z2\n\n)\ntheory lying in the class Db\n\np(G/Zi) of 4d N = 2 SCFTs. This theory can be recognized as\nthe 4d N = 2 theory T\u2217P associated to a twisted puncture P of 6d N = (2, 0) theory of type\nso(2m\u2212 2). The puncture P is characterized by\n\ns = 2, q1 = q2 = m\u2212 2, p1 = p2 = 1 , (8.31)\n\nwhere the data characterized twisted punctures of D type is discussed in section 9.1. For even\nm, it can also be recognized as a Lagrangian 4d N = 2 theory carrying so(m) gauge algebra\nand m\u2212 2 hypermultiplets in the fundamental representation. On the other hand, for odd m,\nthere is no such Lagrangian description available. This is the case that arises as matter SCFT\nin the generalized quivers discussed above.\n\nIn order to determine the defect group associated to the generalized quivers discussed\nabove, we need to determine the defect group of D(2m+ 1), and additionally also determine\nthe flavor center charges of the genuine local operators in the D(2m + 1) SCFT. For this\npurpose, we utilize another construction of the D(2m+1). We propose that D(2m+1) can be\nobtained as a circle reduction of the 5d SCFT that admits a relevant deformation to 5d N = 1\ngauge theory carrying su(2m) gauge algebra at CS level 0 and 4m \u2212 2 fundamental hypers.\nThe circle reduction involves a twist by charge conjugation symmetries associated to su(2m)\ngauge algebra and su(4m \u2212 2) flavor algebra. Our proposal is an extension of the proposal\nmade in [107] for the case of m = 2.\n\nSince the 5d theory has no line and surface defects modulo screening, we deduce that\nD(2m+ 1) has no defect group of lines. Thus there is no contribution to defect group from a\nnode of the form (8.13) in the generalized quivers discussed above.\n\nTo compute the flavor center charges of the genuine local operators in the D(2m + 1)\nSCFT, we look at the magnetic quiver of the 5d theory, which is [108]\n\nu(1) u(2) u(2m\u2212 1) u(2) u(1)\n\nu(1) u(1)\n\n\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7u(2m\u2212 2) u(2m\u2212 2)\n\n(8.32)\nwhere the balanced nodes and the edges connecting them are shown in blue. The balanced sub-\nquiver forms an su(4m\u22122) Dynkin diagram corresponding to the su(4m\u22122) flavor symmetry\nof the 5d theory. Following the proposal of [109], because the circle reduction involves the\n\n82\n\n\n\nouter automorphism of su(4m\u2212 2), the magnetic quiver for the 4d theory can be obtained by\nfolding the magnetic quiver of the 5d theory by the action of the outer-automorphism. Thus,\nthe magnetic quiver for the 4d D(2m+ 1) SCFT is\n\nu(2m\u2212 1) u(2) u(1)\n\nu(1) u(1)\n\n\u00b7 \u00b7 \u00b7u(2m\u2212 2) (8.33)\n\nNon simply-laced quivers like (8.33) were first introduced in [110], where a prescription for com-\nputing their Coulomb branch Hilbert seris was proposed. The Coulomb branch is essentially\nobtained from that of the underlying simply-laced quiver (8.32) by restricting to monopole\nconfigurations invariant under the outer-automorphism action (see also [111]). From the quiver\n(8.33) we manifestly see the usp(4m\u22122) flavor symmetry subalgebra of the D(2m+1) theory.\nThe fact that we have an unbalanced node attached to the (2m\u22121)th node of the usp(4m\u22122)\nalgebra implies that we have a genuine (Higgs branch) local operator in the D(2m+ 1) theory\nthat transforms in the representation \u039b2m\u22121 obtained by antisymmetrizing the (2m \u2212 1)th\npower of the fundamental irrep of usp(4m\u22122). The local operator carries a non-trivial charge\nunder the Z2 center of the simply connected group USp(4m\u2212 2) associated to the flavor alge-\nbra usp(4m\u22122). This implies that we must have another genuine local operator in the theory\ncarrying the fundamental irrep F of usp(4m\u2212 2).\n\nThis local operator is charged under\n\nF\u2295 F (8.34)\n\nrepresentation of usp(2p)\u2295usp(4m\u22122\u22122p) subalgebra of usp(4m\u22122). Thus, in the generalized\nquivers discussed above, we can replace a sub-quiver of the form\n\nusp(ni\u22121) usp(ni+1)D(ni) (8.35)\n\nwith\nusp(ni\u22121) usp(ni+1)F F (8.36)\n\nas far as computation of defect group is concerned, thus splitting the quiver into two pieces.\nAn edge joining F to usp(n) denotes matter transforming as F of usp(n). Similarly, we can\nreplace a sub-quiver of the form\n\nusp(ns\u22122) [usp(ns)]D(ns\u22121) (8.37)\n\n83\n\n\n\nwith\nusp(ns\u22122) F (8.38)\n\nas far as computation of defect group is concerned, where we have thrown away a piece that\ndoes not involve gauge algebras.\n\n8.4 1-Form Symmetries\n\nAs proposed above, we can compute the defect group associated to an untwisted puncture\nP by computing the defect group associated to a generalized quiver of the form (8.5). We\ncompute the defect group of the quiver in terms of its 1-form symmetry as explained in section\n5.2.\n\nBefore describing the result, we introduce some notation. Let us call an so gauge node to\nbe of Type I if exactly one of its neighbors is a C(odd) SCFT. Let \u00b51 be the number of so\ngauge nodes of Type I and let \u03bd1 =\n\n\u230a\u00b51\n2\n\u230b\n. Similarly, let us call an so gauge node to be of Type\n\nII if none of its neighbors is a C(odd) SCFT. Let \u00b52 be the number of so gauge nodes of Type\nII. Let us define \u03bd2 = 1 if \u03bd1 + \u00b52 > 0 and \u03bd2 = 0 if \u03bd1 = \u00b52 = 0. Moreover, let \u00b53 be the\nnumber of nodes carrying D(odd) SCFT. Finally, let us also define \u00b5s = ns if s is even, and\n\u00b5s = ns \u2212 2 if s is odd.\n\nThen we can divide the result into the following cases:\n\n\u2022 Consider the case when \u00b51 + \u00b53 + \u00b5s > 0. Then we have\nHTP = Z\u03bd1+\u00b52\u2212\u03bd2\n\n2\n\nZP = Z\u03bd2\n2\n\nHP = HTP \u00d7 ZP\n\n(8.39)\n\nwith iP mapping HTP identically to the HTP subfactor of HP .\n\n\u2022 Consider the case when \u00b51 = \u00b53 = \u00b5s = 0 and n = 2m+ 1. Then we have\nHTP = Z\u00b52\u22121\n\n2\n\nZP = Z4\n\nHP = HTP \u00d7 ZP\n\n(8.40)\n\nwith iP mapping HTP identically to the HTP subfactor of HP .\n\n\u2022 Consider the case when \u00b51 = \u00b53 = \u00b5s = 0, n = 2m and n2i = 4m2i for all integer\n0 < i < s/2. Then we have\n\nHTP = Z\u00b52\u22121\n2\n\nZP = Z2\n2\n\nHP = HTP \u00d7 ZP\n\n(8.41)\n\n84\n\n\n\nwith iP mapping HTP identically to the HTP subfactor of HP .\n\n\u2022 Consider the case when \u00b51 = \u00b53 = \u00b5s = 0, n = 2m and n2i = 4m2i + 2 for at least one\ninteger 0 < i < s/2. Then we have\n\nHTP = Z\u00b52\u22122\n2 \u00d7 Z2\n\nZP = Z2 \u00d7 Z2\n\nHP = Z\u00b52\u22122\n2 \u00d7 Z4 \u00d7 Z2\n\n(8.42)\n\nUnlike the above cases, in this case, the short exact sequence\n\n0\u2192 HTP \u2192 HP \u2192 ZP \u2192 0 (8.43)\n\ndoes not split. The map iP maps Z\u00b52\u22122\n2 subfactor of HTP identically to the Z\u00b52\u22122\n\n2 sub-\nfactor of HP , and the Z2 subfactor of HTP to the Z2 subgroup of the Z4 subfactor of\nHP . Correspondingly, the map \u03c0P maps the Z\u00b52\u22122\n\n2 subfactor of HP to zero in ZP , the\ngenerator of Z4 subfactor of HP to the generator of one of the Z2 subfactors of ZP , and\nthe final Z2 subfactor of HP identically to the other Z2 subfactor of ZP .\n\n8.5 Spectral Cover Monodromies\n\nThe behavior of the Higgs field near the puncture takes the form\n\nF (v, t) = v2n +\n\u2211\ni\u2208I\n\nvni\n\ntPi\n+ 1\ntk\n\n= 0 (8.44)\n\nwhere I is the set of 1 \u2264 i \u2264 s for which ni is even, k is an integer and\n\nPj :=\nj\u2211\ni=1\n\npi (8.45)\n\nThis is similar to the behavior for untwisted A-type punctures, along with an extra constant\nterm v0t0. If the term 1/tk is not added, then the v-values for two sheets coincide in the vicinity\nof the puncture. In such cases, the constant term provides a distance between the two sheets,\nallowing us to read the full monodromy. Different values of k lead to distinct monodromies\nand which value of k captures the generic monodromy depends on the (extended) Coulomb\nbranch of the set-up.\n\nFix a point t0 6= 0 in the vicinity of the puncture. There are only n independent values\nof v solving F (v, t0) = 0, as the other n values of v are fixed to be negatives of the former n\nvalues, due to the symmetry v \u2192 \u2212v of F (v, t) = 0. We can identify a set of n independent\nvalues of v solving F (v, t0) = 0 as n of the weights ea for 1 \u2264 a \u2264 n. The other n values of v\nsolving F (v, t0) = 0 are identified with the weights \u2212ea.\n\n85\n\n\n\nAs one goes around the puncture t0 \u2192 e2\u03c0it0, the 2n weights are permuted into each other.\nThis induces an action on the roots, which can be identified as\n\n\u03b1a = ea \u2212 ea+1 (8.46)\n\nfor 1 \u2264 a \u2264 n\u2212 1 and\n\u03b1n = en\u22121 + en (8.47)\n\nLet the action on the roots associated to a puncture P be denoted by an n\u00d7 n matrixMP .\nThen, as before, we have the identification\n\nL0\nP = Tor Zn\n\nTP \u00b7 Zn\n(8.48)\n\nwhere\nTP :=MP \u2212 1 (8.49)\n\nExample: P0 puncture. Let us consider the example of P0 puncture, which has s = 2, p1 =\n1, q1 = 2n\u2212 2, p2 = 0, q2 = 1. The curve is\n\nv2n + 1 + v2\n\nt\n= 0 , (8.50)\n\nwhere we have moved onto the Coulomb branch to resolve an order two degeneracy with v = 0.\nThere is a Z2n\u22122\u00d7Z2 monodromy around the P0 puncture. That is, 2n\u22122 sheets are cyclically\npermuted amongst themselves while a pair of sheets are interchanged along the same path.\nWe pick a set of n pairwise linearly independent sheets and label these by weights ea of the\n2n-dimensional vector representation such that these are permuted as\n\nea \u2192 ea+1 , en\u22121 \u2192 \u2212e1 , en \u2192 \u2212en (8.51)\n\nwhere a = 1, . . . , n\u2212 2. With respect to this labelling the monodromy action on sheets leads\nto the following action on the roots\n\n\u03b1b \u2192 \u03b1b+1 , \u03b1n\u22122 \u2192\nn\u2211\na=1\n\n\u03b1a , \u03b1n\u22121 \u2192 \u2212\nn\u22121\u2211\na=1\n\n\u03b1a , \u03b1n \u2192 \u2212\u03b1n \u2212\nn\u22122\u2211\na=1\n\n\u03b1a (8.52)\n\n86\n\n\n\nwhere b = 1, . . . , n\u2212 3. The mondromy matrix is thus\n\nMP0 =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n\n0 0 \u00b7 \u00b7 \u00b7 0 0 1 \u22121 \u22121\n1 0 \u00b7 \u00b7 \u00b7 0 0 1 \u22121 \u22121\n\n0 1 . . . 0 0 1 \u22121 \u22121\n... . . . . . . . . . ...\n\n...\n...\n\n...\n\n0 0 . . . 1 0 1 \u22121 \u22121\n0 0 . . . 0 1 1 \u22121 \u22121\n0 0 . . . 0 0 1 \u22121 0\n0 0 . . . 0 0 1 0 \u22121\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\n\n(8.53)\n\nFrom here we define\nTP0 = MP0 \u2212 1 , (8.54)\n\nand the reader can check that\n\nSNF (TP0) =\n{\n\ndiag (4, 1, 1, . . . , 1) g = D2n+1 ,\n\ndiag (2, 2, 1, . . . , 1) g = D2n\n(8.55)\n\nimplying that\n\nL0\nP0 =\n\n{\nZ4 g = D2n+1 ,\n\nZ2 \u00d7 Z2 g = D2n\n(8.56)\n\nExample: Puncture with trapped defects and non-trivial extension. Let us consider\nthe puncture P \u2032 engineering the GQ\u2032 quiver\n\n[so(12)] usp(8) so(6) (8.57)\n\nwhich has s = 3, pi = 1, q1 = 2, q2 = 4, q3 = 4 and the curve\n\nv12 + v10\n\nt\n+ v6 + 1\n\nt2\n+ v2\n\nt3\n= 0 (8.58)\n\nHere the term 1/t2 resolves a degeneracy at v = 0, it is the leading order contribution for\ngeneric Coulomb branch parameters. There is a Z2\n\n4\u00d7Z2\n2 monodromy around the P \u2032 puncture.\n\nWe pick a set of 6 pairwise linearly independent sheets and label these by weights ea of the\n2n-dimensional vector representation such that these are permuted as\n\ne1 \u2192 e2 \u2192 \u2212e1 \u2192 \u2212e2 , e3 \u2192 e4 \u2192 \u2212e3 \u2192 \u2212e4 , e5 \u2192 \u2212e5 , e6 \u2192 \u2212e6 (8.59)\n\n87\n\n\n\nWith respect to this labelling the monodromy action on sheets leads to the action on the roots\nsummarized by the monodromy matrix\n\nMP \u2032 =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n\n1 \u22121 0 0 0 0\n2 \u22121 0 0 0 0\n2 \u22121 1 \u22121 0 0\n2 \u22122 2 \u22121 0 0\n1 \u22121 1 0 \u22121 0\n1 \u22121 1 0 0 \u22121\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\n(8.60)\n\nFrom here we define\nTP \u2032 = MP \u2032 \u2212 1 , (8.61)\n\nand the reader can check that\n\nSNF (TP \u2032) = diag (4, 2, 2, 1, 1, 1) , (8.62)\n\nimplying that\nL0\nP \u2032 = Z2\n\n2 \u00d7 Z4 (8.63)\n\n8.6 Trapped Defect Group from Type IIB on CY3\n\nAgain, the trapped part of the defect group can be computed from the Type IIB realization\non IHS singularities.\n\n8.6.1 Trapped Parts of IHS Punctures\n\nFor a IHS-puncture P, we can compute the trapped defect group using their isolated hyper-\nsurface singularity XP realization.\n\nThe theories of with untwisted D type class S with irregular punctures can be realized\nusing the following hypersurface singularities: the AD[A,D], which have the hypersurface\nrealizations in type IIB as\n\nXAD[Al,Dn] : x2\n1 + xl+1\n\n2 + xn\u22121\n3 + x3x\n\n2\n4 = 0] . (8.64)\n\nThis singularity has associated to it b = 2n\u2212 2 and k = l+ 2n\u2212 1. And the second is of type\nVII ({7, 1}, {2, n\u2212 1, 2, l}) in the nomenclature of [55,79,85]\n\nX{7,1}(2,n\u22121,2,l) : x2\n1 + xn\u22121\n\n2 + x2x\n2\n3 + x3x\n\nl\n4 = 0 . (8.65)\n\nThis singularity has associated to it b = n and k = l + n.\n\n88\n\n\n\nTorH2(\u2202XAD[Al,Dn]) D4 D5 D6 D7 D8 D9 D10 D11 D12 D13 D14 D15\n\nA1 0 0 0 0 0 0 0 0 0 0 0 0\n\nA2 Z2\n2 0 0 Z2\n\n2 0 0 Z2\n2 0 0 Z2\n\n2 0 0\n\nA3 0 Z2\n2 0 0 0 Z2\n\n2 0 0 0 Z2\n2 0 0\n\nA4 0 0 Z4\n2 0 0 0 0 Z4\n\n2 0 0 0 0\n\nA5 0 0 0 Z4\n2 0 0 0 0 0 Z4\n\n2 0 0\n\nA6 0 0 0 0 Z6\n2 0 0 0 0 0 0 Z6\n\n2\n\nA7 0 0 0 0 0 Z6\n2 0 0 0 0 0 0\n\nA8 Z2\n2 0 0 Z2\n\n2 0 0 Z8\n2 0 0 Z2\n\n2 0 0\n\nTable 4: Defect groups for the AD[Al, Dn] theories.\n\nThe defect group of the AD[A, D] theories was computed in [17,30], shown for low values\nin table 4 and has as closed form\n\nLXAD[Al,Dn] =\n\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f3\nZgcd(l+1,n\u22121)\u22121\n\n2 if 2 6 |(l + 1)\n\nZgcd(l+1,n\u22121)\u22122\n2 if 2|(n\u2212 1) and gcd(l + 1, 2(n\u2212 1))|(n\u2212 1)\n\n0 else\n\n(8.66)\n\nFor the hypersurface X7,1(2,n\u22121,2,l) the result is shown for low values of l, n in table 5.\nBelow, we match these results with the trapped defect group of the IHS punctures com-\n\nputed using our proposal. An IHS puncture is characterized by two numbers b, k, where the\npossible values of b are n, 2n \u2212 2. These values of b correspond respectively to ns = 0, 2.\nThe number k is any positive integer. Since the IHS punctures are conformal, they have the\nproperty that all pi are equal and all qi are equal. Let r = ri, p = pi, q = qi. Then, we can\nwrite r as\n\nr = k\n\nb\n(8.67)\n\nfrom which we find\np = k\n\ngcd(k, b)\n\nq = b\n\ngcd(k, b)\n\n(8.68)\n\nWe also compute\ns = gcd(k, b) if b = 2n\u2212 2\n\ns = 2 \u00b7 gcd(k, b) if b = n\n(8.69)\n\nWe divide the further analysis into the following three cases:\n\n89\n\n\n\nTorH2(\u2202X) : l\\n 4 5 6 7 8 9 10 11 12\n\n4 0 0 0 0 0 0 0 0 0\n\n5 0 0 0 0 0 0 0 0 0\n\n6 Z2\n2 0 0 0 0 0 0 0 0\n\n7 0 0 0 0 0 0 0 0 0\n\n8 0 0 0 0 Z2\n2 0 0 0 0\n\n9 0 0 Z4\n2 0 0 0 0 0 0\n\n10 Z2\n2 0 0 0 0 0 0 0 0\n\n11 0 0 0 0 0 0 0 0 0\n\n12 0 0 0 0 Z6\n2 0 0 0 0\n\nTable 5: The 1-form symmetries for the hypersurfaces of type X{7,1}(2,n\u22121,2,l) : 0 = x2 +yn\u22121 +\nyu2 + uvl, l increases downwards, n increases to the right.\n\n\u2022 Assume q is odd. Then \u00b51 = 1 and hence \u03bd1 = 0. Also, \u00b52 = 0, so we find that\n\nLTP = 0 . (8.70)\n\n\u2022 Assume q is even and b = 2n \u2212 2. Then \u00b51 = 0 and \u00b52 = 1 +\n\u230a\n\ngcd(k,b)\u22121\n2\n\n\u230b\n. So, we find\n\nthat\nLTP = Z\n\n2\n\u230a gcd(k,b)\u22121\n\n2\n\n\u230b\n2 (8.71)\n\n\u2022 Assume q is even and b = n. Then \u00b51 = 0 and \u00b52 = 1 +\n\u230a\ngcd(k, b)\u2212 1\n\n2\n\n\u230b\n. So, we find\n\nthat\nLTP = Z2bgcd(k,b)\u2212 1\n\n2c\n2 . (8.72)\n\nOne can easily check that this matches (8.66) with the identification l = k \u2212 2n + 1 and\nb = 2n\u2212 2. It also matches with the results in table 5.\n\n8.6.2 Trinions\n\nUsing IHS, we can construct trinion theories of the form discussed in section 6.5.2, where each\npuncture Pi is an IHS puncture. Let ki, bi describe the data of these punctures. To compute\nthe defect group LP1,P2,P3 of the trinion theory, we need to first compute ZPi :\n\n\u2022 If qi is odd, then \u00b51 > 0 and \u03bd2 = 0, so we have\n\nZPi = 0 (8.73)\n\n90\n\n\n\n\u2022 If qi is even, then \u00b51 = \u03bd1 = \u00b53 = 0 and \u03bd2 = 1. If \u00b5s > 0, then\n\nZPi = Z2 (8.74)\n\n\u2022 If qi is even and \u00b5s = 0, then\nZPi = ZG (8.75)\n\nwhere ZG = Z2\n2 if n is even, and ZG = Z4 if n is odd.\n\nThus, if any of the qi is odd, then\nZP1,P2,P3 = 0 (8.76)\n\nand hence using (6.48), we find that\n\nLP1,P2,P3 =\n( 3\u220f\ni=1\nLTPi\n\n)2\n\n. (8.77)\n\nNow assume that all qi are even. If \u00b5s for any puncture i is non-zero, then we have\n\nZP1,P2,P3 = Z2 (8.78)\n\nand hence\n\nLP1,P2,P3 =\n( 3\u220f\ni=1\nLTPi \u00d7 Z2\n\n)2\n\n. (8.79)\n\nIf \u00b5s = 0 for all punctures, then we have\n\nZP1,P2,P3 = ZG (8.80)\n\nand hence\n\nLP1,P2,P3 =\n( 3\u220f\ni=1\nLTPi \u00d7 ZG\n\n)2\n\n. (8.81)\n\nThis can be matched with the defect group results obtained from the isolated hypersurface\nsingularities, appearing in Tables 15, 16 and 20 of [29].\n\n9 Twisted D\n\nIn this section, we describe our proposal for computing the defect groups associated to twisted\npunctures for 6d D-type (2, 0) theories. The analysis will largely be similar to that for un-\ntwisted D-type punctures, with only minor cosmetic differences. The key information that\nwe use about these twisted punctures is discussed in subsection 9.1. Again, we not only\nconsider conformal punctures of IHS type, but also numerous other classes of conformal and\nnon-conformal punctures.\n\n91\n\n\n\nIn subsection 9.2, we make our proposal. For each puncture, we assign a 4d N = 2 gener-\nalized quiver gauge theory involving both perturbative and strongly coupled matter sectors,\nand propose that the defect groups associated to the generalized quiver gauge theory capture\nthe defect groups of the associated punctures.\n\nIn subsection 9.2.1, we expand on our motivation for making the proposal discussed in\nsubsection 9.2. We describe a large class of punctures P for which the 4d N = 2 theories TP\n\no\n0\nP\n\ncoincide with the proposed generalized quivers. A subclass of this class of punctures, whose\nassociated generalized quivers involve only perturbative matter content, can be realized in\nterms of Hanany-Witten brane setups in IIA involving O4 planes.\n\nUsing the properties of the strongly coupled matter sectors derived in section 8.3, we derive\nin subsection 9.3 the defect groups associated to twisted D-type punctures. Like untwisted\nD-type punctures, we find that the twisted D-type punctures can also carry trapped 1-form\nsymmetries.\n\nNon-trivial checks of this proposal are provided using the IIB ALE fibrations in subsection\n9.4. In subsection 9.5, we use the IHS realization to compute the trapped defect groups of\nIHS punctures, and find a perfect match with the trapped defect groups computed using our\nproposal.\n\n9.1 Punctures\n\nLet us consider twisted punctures for 6d Dn N = (2, 0) theory. These are described in terms\nof a Hitchin field in vector representation of Dn. The i-th block of the Hitchin field takes the\nform\n\nBi = 1\nt1+ri\n\nAi + \u00b7 \u00b7 \u00b7 (9.1)\n\nAgain we order the blocks such that ri \u2265 ri+1 and let s be biggest value of i for which ri > 0.\nFor each i \u2264 s, we write\n\nri = pi\nqi\n\n(9.2)\n\nwhere 1 \u2264 qi \u2264 2n\u2212 2 and gcd(pi, qi) = 1.\nLet us again define\n\nni := 2n\u2212\ni\u2211\n\nj=1\nqj (9.3)\n\nWe impose extra conditions on the punctures that can be described in terms of ni as follows.\nIf ni is even (including n0 := 2n) and qi+1 is odd, then we require\n\nqi+2 = qi+1 (9.4)\n\n92\n\n\n\nThis in particular ensures that ni\u22121 and ni+1 are even if ni is odd. Furthermore, we require\nthat ns is even. If s is even then ns \u2265 2, and if s is odd then ns \u2265 0.\n\nAs for untwisted A and D type punctures, the twisted D type punctures are also conformal\nonly if ri = rj for all i, j \u2208 {1, 2, \u00b7 \u00b7 \u00b7 , s}. Out of these, the punctures of type IHS discussed\nin [89] are those for which ns = 0, 2.\n\n9.2 Class GQ of Generalized Quivers\n\nConsider a puncture P of the above type. Then we conjecture that P \u2208 F\u03c4 where \u03c4 is a\ngeneralized quiver that can be constructed using the data of ni as follows. The quiver takes\nthe form\n\nusp(2n\u2212 2) N1 N2 \u00b7 \u00b7 \u00b7 Ns\u22121 [gs] (9.5)\n\nThe node Ni is either a gauge algebra or a matter SCFT, depending on whether ni is even or\nodd respectively. If ni is even, we write\n\nNi = gi (9.6)\n\nIf i is odd, we have\ngi = so(ni) (9.7)\n\nand if i is even, we have\ngi = usp(ni \u2212 2) (9.8)\n\nThe same applies to the flavor algebra gs. If s is odd, we have\n\ngi = so(ns) (9.9)\n\nand if s is even, we have\ngi = usp(ns \u2212 2) (9.10)\n\nIf ni is odd and i is even, then\nNi = C(ni) (9.11)\n\nwhere C(ni) is a matter SCFT discussed in detail in the previous section. If ni is odd and i\nis odd, then\n\nNi = D(ni) (9.12)\n\nwhere D(ni) is another matter SCFT discussed in the previous section.\nThe edges have the same meaning as discussed in section 8.2.\n\n93\n\n\n\n9.2.1 Class GQ\u2032 and Type IIA Punctures\n\nThe Class GQ\u2032 of punctures is given by punctures having pi = 1 for all 1 \u2264 i \u2264 s. The Type\nIIA punctures form a subclass of GQ\u2032 for which all qi and hence all ni are even. In such a\nsituation, every node Ni in (5.2) is a gauge algebra, which is so(ni) for i odd and usp(ni \u2212 2)\nfor i even. The Type IIA brane construction corresponding to a Type IIA puncture P \u2032 is\n\nNS51 NS52 NS53 NS5s\u22121 NS5s\n\nn\u2212 1\nm1\n\nm2 ms\u22121\nms\n\nO4+ O4\u2212 O4+\n\nO4\u2212\nor\n\nO4+ O4\u2212\n\nO4+\nor\n\n(9.13)\n\nwhere mi number of physical D4 branes have been placed in the ith interval, where mi = ni\n2\n\nfor i odd and mi = ni\n2 \u2212 1 for i even. Moreover, the ith interval carries an O4\u2212 plane if i is\n\nodd and an O4+ plane if i is even.\n\n9.3 1-Form Symmetries\n\nAs proposed above, we can compute the defect group associated to a twisted puncture P by\ncomputing the defect group associated to a generalized quiver of the form (9.5). We describe\nthe result in terms of the quantities \u00b51, \u03bd1, \u00b52, \u00b53 introduced in section 8.4. We also define a\nnew quantity \u03bds defined as \u03bds := ns if s is odd, and \u03bds := ns \u2212 2 if s is even. Then, we can\ndivide the result into the following cases:\n\n\u2022 Consider the case when \u00b51 + \u00b53 + \u03bds > 0. Then we have\n\nHTP = Z\u03bd1+\u00b52\n2\n\nZP = 0\n\nHP = HTP \u00d7 ZP\n\n(9.14)\n\nwith iP mapping HTP identically to the HTP subfactor of HP .\n\n\u2022 Consider the case when \u00b51 = \u00b53 = \u03bds = 0, and n2i+1 = 4m2i+1 for all integers 0 < i <\n\ns\u22121\n2 . Then we have\n\nHTP = Z\u00b52\n2\n\nZP = Z2\n\nHP = HTP \u00d7 ZP\n\n(9.15)\n\nwith iP mapping HTP identically to the HTP subfactor of HP .\n\n94\n\n\n\n\u2022 Consider the case when \u00b51 = \u00b53 = \u03bds = 0, and n2i+1 = 4m2i+1 + 2 for at least one\ninteger i lying in the range 0 < i < s\u22121\n\n2 . Then we have\n\nHTP = Z\u00b52\u22121\n2 \u00d7 Z2\n\nZP = Z2\n\nHP = Z\u00b52\u22121\n2 \u00d7 Z4\n\n(9.16)\n\nUnlike the above cases, in this case, the short exact sequence\n\n0\u2192 HTP \u2192 HP \u2192 ZP \u2192 0 (9.17)\n\ndoes not split. The map iP maps Z\u00b52\u22121\n2 subfactor of HTP identically to the Z\u00b52\u22121\n\n2 sub-\nfactor of HP , and the Z2 subfactor of HTP to the Z2 subgroup of the Z4 subfactor of HP .\nCorrespondingly, the map \u03c0P maps the Z\u00b52\u22121\n\n2 subfactor of HP to zero in ZP , and the\ngenerator of the Z4 subfactor of HP to the generator of ZP = Z2.\n\n9.4 Spectral Cover Monodromies\n\nThe behavior of the Higgs field near the puncture takes the form\n\nF (v, t) = v2n +\n\u2211\ni\u2208I\n\nvni\n\ntPi\n+ 1\nt\n\n= 0 (9.18)\n\nwhere I is the set of 1 \u2264 i \u2264 s for which ni is even and\n\nPj :=\nj\u2211\ni=1\n\npi (9.19)\n\nThe extra constant term v0t\u22121 is added to resolve the distances between the sheets, which\nallows us to read the full monodromy.\n\nFix a point t0 6= 0 in the vicinity of the puncture. As discussed earlier, there are only n\nindependent values of v solving F (v, t0) = 0. We again identify a set of n independent values\nof v solving F (v, t0) = 0 as n of the weights ea for 1 \u2264 a \u2264 n. The other n values of v solving\nF (v, t0) = 0 are identified with the weights \u2212ea.\n\nAs one goes around the puncture t0 \u2192 e2\u03c0it0, the 2n weights are permuted into each other.\nThis induces an action on the roots, which can be identified as in (8.46) and (8.47). Let the\naction on the roots associated to a puncture P be denoted by an n\u00d7 n matrixMP . Then, as\nbefore, we have the identification\n\nL0\nP = Tor Zn\n\nTP \u00b7 Zn\n(9.20)\n\nwhere\nTP :=MP \u2212 1 (9.21)\n\n95\n\n\n\nExample: P0 puncture. Let us consider the example of P0 puncture, which has s = 1, p1 =\n1, q1 = 2n. The curve is\n\nv2n+2 + 1\nt\n\n= 0 , (9.22)\n\nThese are the same class of curves as for untwisted A-type gauge algebras in section 7.5.\nThere is a Z2n+2 monodromy around the P0 puncture which permutes sheets cyclically. We\npick a set of n + 1 pairwise linearly independent sheets and label these by weights ea of the\n2n+ 2-dimensional vector representation such that these are permuted as\n\nea \u2192 ea+1 , en+1 \u2192 \u2212e1 , (9.23)\n\nwhere a = 1, . . . , n. With respect to this labelling the monodromy action on sheets leads to\nthe following action on the roots represented by the monodromy matrix\n\nMP0 =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n\n0 0 \u00b7 \u00b7 \u00b7 0 0 0 1 \u22121\n1 0 \u00b7 \u00b7 \u00b7 0 0 0 1 \u22121\n\n0 1 . . . 0 0 0 1 \u22121\n... . . . . . . . . . ...\n\n...\n...\n\n...\n\n0 0 . . . 1 0 0 1 \u22121\n0 0 . . . 0 1 0 1 \u22121\n0 0 . . . 0 0 1 0 \u22121\n0 0 . . . 0 0 0 1 0\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\n\n(9.24)\n\nFrom here we define\nTP0 = MP0 \u2212 1 , (9.25)\n\nand the reader can check that\n\nSNF (TP0) = diag (2, 1, . . . , 1) (9.26)\n\nimplying that\nL0\nP0 = Z2 (9.27)\n\nExample: Puncture with trapped defects and non-trivial extension. Let us consider\nthe puncture P \u2032 engineering the GQ\u2032 quiver\n\n[usp(6)] so(6) (9.28)\n\nwhich has s = 2, pi = 1, q1 = 2, q2 = 4 and the curve\n\nv8 + v6 + 1\nt\n\n+ v2\n\nt2\n= 0 (9.29)\n\n96\n\n\n\nHere the term 1/t resolves a degeneracy at v = 0, it is the leading order contribution for\ngeneric Coulomb branch parameters. There is a Z4\u00d7Z2\n\n2 monodromy around the P \u2032 puncture.\nWe pick a set of 4 pairwise linearly independent sheets and label these by weights ea of the\n8-dimensional vector representation such that these are permuted as\n\ne1 \u2192 e2 \u2192 \u2212e1 \u2192 \u2212e2 , e3 \u2192 \u2212e3 , e4 \u2192 \u2212e4 (9.30)\n\nWith respect to this labelling the monodromy action on sheets leads to the action on the roots\nsummarized by the monodromy matrix\n\nMP \u2032 =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n1 \u22121 0 0\n2 \u22121 0 0\n1 0 \u22121 0\n1 0 0 \u22121\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8 (9.31)\n\nFrom here we define\nTP \u2032 = MP \u2032 \u2212 1 , (9.32)\n\nand the reader can check that\n\nSNF (TP \u2032) = diag (4, 2, 1, 1) , (9.33)\n\nimplying that\nL0\nP \u2032 = Z2 \u00d7 Z4 (9.34)\n\n9.5 Trapped Defect Group from Type IIB on CY3\n\nFor a puncture P of IHS type, we can compute its trapped defect group using an isolated\nhypersurface singularity XP providing a check for our above proposal.\n\nThere are again two types of IHS that are relevant for twisted D type theories: the first is\n\nX{7,1}(2,l+1,n\u22121,2) : x2\n1 + xl+1\n\n2 + x2x\nn\u22121\n3 + x3x\n\n2\n4 = 0 . (9.35)\n\nThis singularity has associated to it b = 2n\u2212 2 and k = l + 2n\u2212 2. And the second is\n\nX{10,1}(2,2,n\u22121,l+2) : x2\n1 + x2\n\n2x3 + xn\u22121\n3 x4 + xl+2\n\n4 x2 = 0 . (9.36)\n\nThis singularity has associated to it b = 2n and k = l + n + 1. The defect groups computed\nusing IHS techniques are presented in tables 6 and 7.\n\nLet us now find the trapped defect group for an IHS puncture according to our proposal\noutlined in the above subsections. An IHS puncture is characterized by two numbers b, k,\n\n97\n\n\n\nTorH2(\u2202X) : n\\l 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n\n3 0 Z2\n2 0 0 0 Z2\n\n2 0 0 0 Z2\n2 0 0 0 Z2\n\n2\n\n4 0 0 Z2\n2 0 0 0 0 0 Z2\n\n2 0 0 0 0 0\n\n5 0 Z2\n2 0 Z4\n\n2 0 Z2\n2 0 0 0 Z2\n\n2 0 Z4\n2 0 Z2\n\n2\n\n6 0 0 0 0 Z4\n2 0 0 0 0 0 0 0 0 0\n\n7 0 Z2\n2 Z2\n\n2 0 0 Z6\n2 0 0 Z2\n\n2 Z2\n2 0 0 0 Z2\n\n2\n\n8 0 0 0 0 0 0 Z6\n2 0 0 0 0 0 0 0\n\n9 0 Z2\n2 0 Z4\n\n2 0 Z2\n2 0 Z8\n\n2 0 Z2\n2 0 Z4\n\n2 0 Z2\n2\n\n10 0 0 Z2\n2 0 0 0 0 0 Z8\n\n2 0 0 0 0 0\n\nTable 6: Defect groups for the x2\n1 + xl+1\n\n2 + x2x\nn\u22121\n3 + x3x\n\n2\n4 = 0. k increase left to right, n\n\nincreases top to bottom.\n\nTorH2(\u2202X) : n\\l 1 2 3 4 5 6 7 8 9 10 11 12 13\n\n3 0 0 Z2\n2 0 0 Z2\n\n2 0 0 Z2\n2 0 0 Z2\n\n2 0\n\n4 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n5 Z4\n2 0 0 0 0 Z4\n\n2 0 0 0 0 Z4\n2 0 0\n\n6 0 0 Z2\n2 0 0 Z2\n\n2 0 0 Z2\n2 0 0 Z2\n\n2 0\n\n7 0 Z6\n2 0 0 0 0 0 0 Z6\n\n2 0 0 0 0\n\n8 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n9 0 0 Z8\n2 0 0 Z2\n\n2 0 0 Z2\n2 0 0 Z8\n\n2 0\n\n10 Z4\n2 0 0 0 0 Z4\n\n2 0 0 0 0 Z4\n2 0 0\n\nTable 7: Defect groups for the x2\n1 + x2\n\n2x3 + xn\u22121\n3 x4 + xl+2\n\n4 x2 = 0. k increase left to right, n\nincreases top to bottom.\n\n98\n\n\n\nwhere the possible values of b are 2n, 2n \u2212 2. These values of b correspond respectively to\nns = 0, 2. The number k is any positive integer. Since the IHS punctures are conformal, they\nhave the property that all pi are equal and all qi are equal. Let r = ri, p = pi, q = qi. Then,\nwe can write r as\n\nr = k\n\nb\n(9.37)\n\nfor b = 2n\u2212 2 and as\nr = 2k + 1\n\nb\n(9.38)\n\nfor b = 2n. From this we find\n\np = k\n\ngcd(k, b) if b = 2n\u2212 2\n\np = 2k + 1\ngcd(2k + 1, b) if b = 2n\n\n(9.39)\n\nand\nq = b\n\ngcd(k, b) if b = 2n\u2212 2\n\nq = b\n\ngcd(2k + 1, b) if b = 2n\n(9.40)\n\nWe also compute\ns = gcd(k, b) if b = 2n\u2212 2\n\ns = gcd(2k + 1, b) if b = 2n\n(9.41)\n\nWe divide the further analysis into the following three cases:\n\n\u2022 Assume q is odd. Then \u00b51 = \u00b52 = 0, so we find that\n\nLTP = 0 (9.42)\n\n\u2022 Assume q is even. Then \u00b51 = 0 and \u00b52 =\n\u230a\ns+1\n\n2\n\n\u230b\n. So, we find that\n\nLTP = Z2b s2c\n2 (9.43)\n\nThis can be verified with the results appearing in tables 6 and 7.\n\n10 Untwisted E\n\nIn this section, we derive the full defect groups associated to untwisted IHS punctures of E-\ntype 6d N = (2, 0) theories. This is achieved by combining the two different string-theoretic\nconstructions we have been using so far: namely the IHS construction, and the construction\n\n99\n\n\n\nas ALE fibration with monodromy. Using the IHS description, we read the trapped defect\ngroup LTP from which we deduce\n\nHTP =\n\u221a\nLTP . (10.1)\n\nOn the other hand, using the ALE fibration description, we read the genuine part L0\nP of the\n\ndefect group LP . Recall that L0\nP must admit a decomposition as\n\nL0\nP = HTP \u00d7WP . (10.2)\n\nCombining it with the knowledge of HTP from (10.1), we can read the group WP . Thus,\ncombining the two computations, we can deduce WP and WT\n\nP = H\u0302TP . The final data needed\nis the surjective map\n\nWP \u2192WT\nP , (10.3)\n\nwhich is apriori not determined even after combining the above two string-theoretic compu-\ntations. However, luckily, for untwisted E-type IHS punctures, we find that WP and WT\n\nP are\nsuch that there is a unique surjection (10.3). Moreover, this surjection is such that we can\ndecompose\n\nWP = Z\u0302P \u00d7WT\nP . (10.4)\n\nIn other words, the short exact sequence\n\n0\u2192 Z\u0302P \u2192WP \u2192WT\nP \u2192 0 (10.5)\n\nsplits, and hence the trapped and non-trapped parts do not mix with each other.\nNote that for E8, we do not need to perform the spectral cover computation because for\n\nany such puncture P, we must have Z\u0302P = 0 as ZE8 = 0. This implies that\n\nL0\nP = LTP , (10.6)\n\nwhich can be determined solely from the IHS computation.\nBelow, in subsection 10.1, we discuss how the weights and roots are encoded for E6,7\n\nspectral covers. Using this, we perform the computation of L0\nP in subsection 10.2 for E6,\n\nE7 punctures. The data of LTP , L0\nP , Z\u0302P , WP and WT\n\nP is given in tables 8, 9 and 10 for E6\n\npunctures; and in tables 11 and 12 for E7 punctures. The data of LTP is given in table13 for\nE8 punctures. The short exact sequence (10.5) is then the trivial split sequence derived using\nthis data.\n\n100\n\n\n\nE\n(8)\n6 [k] 1 2 3 4 5 6 7 8\n\nLTP 0 0 0 Z2\n2 0 0 0 0\n\nL0\nP 0 0 0 Z2\n\n2 0 0 0 0\n\nZ\u0302P 0 0 0 0 0 0 0 0\n\nWP 0 0 0 Z2 0 0 0 0\n\nWT\nP 0 0 0 Z2 0 0 0 0\n\nTable 8: Various contributions to the defect group for the untwisted punctures P(8)\n6 [k] of type\n\nE6 N = (2, 0) theory. The columns parametrize different values of k. The results can be\nextended beyond this table as they only depend on k (mod 8).\n\nE\n(9)\n6 [k] 1 2 3 4 5 6 7 8 9\n\nLTP 0 0 Z2\n3 0 0 Z2\n\n3 0 0 0\n\nL0\nP Z3 Z3 Z3\n\n3 Z3 Z3 Z3\n3 Z3 Z3 0\n\nZ\u0302P Z3 Z3 Z3 Z3 Z3 Z3 Z3 Z3 0\n\nWP Z3 Z3 Z2\n3 Z3 Z3 Z2\n\n3 Z3 Z3 0\n\nWT\nP 0 0 Z3 0 0 Z3 0 0 0\n\nTable 9: Various contributions to the defect group for the untwisted punctures P(9)\n6 [k] of type\n\nE6 N = (2, 0) theory. The columns parametrize different values of k. The results can be\nextended beyond this table as they only depend on k (mod 9).\n\nE\n(12)\n6 [k] 1 2 3 4 5 6 7 8 9 10 11 12\n\nLTP 0 0 0 Z2\n3 0 Z2\n\n2 0 Z2\n3 0 0 0 0\n\nL0\nP Z3 Z3 0 Z3\n\n3 Z3 Z2\n2 Z3 Z3\n\n3 0 Z3 Z3 0\n\nZ\u0302P Z3 Z3 0 Z3 Z3 0 Z3 Z3 0 Z3 Z3 0\n\nWP Z3 Z3 0 Z2\n3 Z3 Z2 Z3 Z2\n\n3 0 Z3 Z3 0\n\nWT\nP 0 0 0 Z3 0 Z2 0 Z3 0 0 0 0\n\nTable 10: Various contributions to the defect group for the untwisted punctures P(12)\n6 [k] of\n\ntype E6 N = (2, 0) theory. The columns parametrize different values of k. The results can be\nextended beyond this table as they only depend on k (mod 12).\n\n101\n\n\n\nE\n(14)\n7 [k] 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n\nLTP 0 0 0 0 0 0 Z6\n2 0 0 0 0 0 0 0\n\nL0\nP Z2 0 Z2 0 Z2 0 Z7\n\n2 0 Z2 0 Z2 0 Z2 0\n\nZ\u0302P Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0\n\nWP Z2 0 Z2 0 Z2 0 Z4\n2 0 Z2 0 Z2 0 Z2 0\n\nWT\nP 0 0 0 0 0 0 Z3\n\n2 0 0 0 0 0 0 0\n\nTable 11: Various contributions to the defect group for the untwisted punctures P(14)\n7 [k] of\n\ntype E7 N = (2, 0) theory. The columns parametrize different values of k. The results can be\nextended beyond this table as they only depend on k (mod 14).\n\nE\n(18)\n7 [k] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18\n\nLTP 0 0 0 0 0 Z2\n3 0 0 Z6\n\n2 0 0 Z2\n3 0 0 0 0 0 0\n\nL0\nP Z2 0 Z2 0 Z2 Z2\n\n3 Z2 0 Z7\n2 0 Z2 Z2\n\n3 Z2 0 Z2 0 Z2 0\n\nZ\u0302P Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0 Z2 0\n\nWP Z2 0 Z2 0 Z2 Z3 Z2 0 Z4\n2 0 Z2 Z3 Z2 0 Z2 0 Z2 0\n\nWT\nP 0 0 0 0 0 Z3 0 0 Z3\n\n2 0 0 Z3 0 0 0 0 0 0\n\nTable 12: Various contributions to the defect group for the untwisted punctures P(18)\n7 [k] of\n\ntype E7 N = (2, 0) theory. The columns parametrize different values of k. The results can be\nextended beyond this table as they only depend on k (mod 18).\n\nLT\nP(b)\n\n8 [k]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n\nb = 20 0 0 0 Z2\n5 Z4\n\n2 0 0 Z2\n5 0 Z8\n\n2 0 Z2\n5 0 0 Z4\n\n2\n\nb = 24 0 0 Z2\n2 0 0 Z4\n\n2 0 Z4\n3 Z2\n\n2 0 0 Z8\n2 0 0 Z2\n\n2\n\nb = 30 0 0 0 0 0 Z2\n5 0 0 0 Z4\n\n3 0 Z2\n5 0 0 Z8\n\n2\n\nContinued 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30\n\nb = 20 Z2\n5 0 0 0 0 0 0 0 Z2\n\n5 Z4\n2 0 0 Z2\n\n5 0 Z8\n2\n\nb = 24 Z4\n3 0 Z4\n\n2 0 0 Z2\n2 0 0 0 0 0 Z2\n\n2 0 0 Z4\n2\n\nb = 30 0 0 Z2\n5 0 Z4\n\n3 0 0 0 Z2\n5 0 0 0 0 0 0\n\nTable 13: Trapped defect groups for untwisted punctures P(b)\n8 [k] of type E8 N = (2, 0) theory.\n\nThe columns parametrize different values of k. The results can be extended beyond this table\nas they only depend on k (mod b).\n\n102\n\n\n\n10.1 Spectral Covers and Weights Systems\n\nE-type spectral curves are discussed in [112\u2013114]. The E6 spectral curve with respect to the\nrepresentation 27 has six Casimirs\n\nu2, u5, u6, u8, u9, u12 (10.7)\n\nand the equation\n\nFE6(v, t) = 1\n2v\n\n3u2\n12 \u2212Q(v)u12 + 1\n\n2v3\n\n[\nQ(v)2 \u2212 P1(v)2P2(v)\n\n]\n= 0 . (10.8)\n\nHere the polynomials P1, P2, Q are\n\nP1(v) = 78v10 + 60v8u2 + 14v6u2\n2 \u2212 33v5u5 + 2v4u12 \u2212 5v3u2u5 \u2212 v2u8 \u2212 vu9 \u2212 u2\n\n5\n\nP2(v) = 12v10 + 12v8u2 + 4v6u2\n2 \u2212 12v5u5 + v4u6 \u2212 4v3u2u5 \u2212 2v2u8 + 4vu9 + u2\n\n5\n\nQ(v) = 270v15 + 342v13u2 + 162v11u2\n2 \u2212 252v10u5 + v9\n\n(\n26u3\n\n2 + 18u6\n)\n\u2212 162v8u2u5\n\n+ v7(6u2u6 \u2212 27u8)\u2212 v6\n(\n30u2\n\n2u5 \u2212 36u9\n)\n\n+ v5\n(\n27u2\n\n5 \u2212 9u2u8\n)\n\n\u2212 v4(3u5u6 \u2212 6u2u9)\u2212 3v3u2u2\n5 \u2212 3vu5u9 \u2212 u3\n\n5 .\n\n(10.9)\n\nThe spectral curve has degFE6 = 27 sheets vi and for any value of the Casimirs the sheets\ngroup into 45 triplets [i, j, k] such that each sheet appears in 5 triplets with each triplet\nsatisfying\n\nvi + vj + vk = 0 . (10.10)\n\nThe weights wi of the representation 27 of E6 also group into 45 triplets [i, j, k] with each\nweight appearing in 5 triplets and each triplet satisfying\n\nwi + wj + wk = 0 . (10.11)\n\nSheets of the spectral curve are labelled by weights such that these structures match. The\nlabelling is unique up to Weyl transformations.\n\nThe E7 spectral curve with respect to the representation 56 has seven Casimirs\n\nu2, u6, u8, u10, u12, u14, u18 (10.12)\n\nand the equation\n\nFE7(v, t) = \u2212 1\n729v\n\n2\n[\nu3\n\n18 +A2(v)u2\n18 +A1(v)u18 +A0(v)\n\n]\n. (10.13)\n\n103\n\n\n\nThe polynomials A0, A1, A2 are\n\nA0(v) = \u2212\n( 9\n\n16v2\n\n)3 [\n4R(v)2P1(v)3 + 6Q(v)R(v)P1(v)2P2(v) + 9Q(v)2P1(v)2P3(v)\n\n\u2212 6R(v)P1(v)P2(v)P3(v)\u2212 6QP1(v)P3(v)2 + 2R(v)P2(v)3\n\n+ 3Q(v)P2(v)2P3 + P3(v)3\n]\n\nA1(v) =\n( 9\n\n16v2\n\n)2 [\n9Q(v)2P1(v)2 \u2212 6R(v)P1(v)P2(v)\u2212 12Q(v)P1(v)P3(v)\n\n+ 3Q(v)P2(v)2 + 3P3(v)2\n]\n\nA2(v) = 9\n16v2\n\n[\n6Q(v)P1(v)\u2212 3P3(v)\n\n]\n.\n\n(10.14)\n\nHere the polynomials P1, P2, P3, Q,R are\n\nP1(v) = \u2212u10 \u2212 2u8v\n2 + 7u6v\n\n4 + 88u2\n2v\n\n6 + 660u2v\n8 + 1596v10\n\nP2(v) =\n( 218\n\n8613u2u\n2\n6 \u2212\n\n4\n3u14\n\n)\nv +\n\n(2\n9u\n\n2\n6 \u2212\n\n4\n3u12\n\n)\nv3 +\n\n(\n68u10 \u2212\n\n68\n3 u2u8\n\n)\nv5\n\n(100\n3 u2u6 \u2212 100u8\n\n)\nv7 +\n\n(\n264u3\n\n2 + 176u6\n)\nv9\n\n+ 2952u2\n2v\n\n11 + 11368u2v\n13 + 16872v15\n\nP3(v) = u2\n10 + 4\n\n3u8u10v\n2 +\n\n(\n\u22122\n\n3u6u10 \u2212\n64\n3 u14u2 + 3488\n\n8613u\n2\n2u\n\n2\n6 + 4\n\n9u\n2\n8\n\n)\nv4\n\n+\n(\n\u221216u2\n\n2u10 \u2212\n32\n9 u2u12 \u2212\n\n416\n3 u14 + 27776\n\n8613 u2u\n2\n6 \u2212\n\n4\n9u6u8\n\n)\nv6\n\n+\n(\n\u221240u2u10 \u2212\n\n64\n3 u12 + 32u2\n\n2u6 + 11\n3 u\n\n2\n6\n\n)\nv8\n\n+\n(\n\n192u4\n2 + 312u2u6 \u2212\n\n1552\n3 u8\n\n)\nv12 +\n\n(\n2880u3\n\n2 + 2216\n3 u6\n\n)\nv14\n\n+ 16080u2\n2v\n\n16 + 41568u2v\n18 + 44560v20\n\nQ(v) = \u22121\n3u10 + 2\n\n9u8v\n2 \u2212 1\n\n3u6v\n4 \u2212 8\n\n3u\n2\n2v\n\n6 \u2212 44\n3 u2v\n\n8 \u2212 28v10\n\nR(v) =\n( 109\n\n8613u2u\n2\n6 \u2212\n\n2\n3u14\n\n)\nv +\n\n(\n2u10 \u2212\n\n2\n3u2u8\n\n)\nv5 +\n\n(\n4u3\n\n2 + 8\n3u6\n\n)\nv9\n\n+\n(2\n\n3u2u6 \u2212 2u8\n\n)\nv7 + 36u2\n\n2v\n11 +\n\n( 1\n81u\n\n2\n6 \u2212\n\n2\n27u12 + 116u2\n\n)\nv13 + 148v15\n\n(10.15)\n\nThe spectral curve has degFE7 = 56 sheets vi and for any value of the Casimirs the sheets\ngroup into 630 quadruplets [i, j, k, l] such that each sheet appears in 45 quadruplets with each\n\n104\n\n\n\nquadruplets satisfying\nvi + vj + vk + vl = 0 , (10.16)\n\nand no pair of sheets in the same quadruplet summing to zero. Further there are 28 pairs [i, j]\nsuch that\n\nvi + vj = 0 . (10.17)\n\nSimilarly the weights wi of the representation 56 of E7 group into 630 quadruplets and 28\npairs and permitted labelings of sheets by weights are such that these two structures match.\nSuch labelings are unique up to Weyl transformations. Further details are discussed in the\nappendices of [112].\n\n10.2 Spectral Cover Monodromies\n\nIn the spectral cover descriptions punctures are specified by boundary conditions on the\nCasimirs. We consider punctures localized at t = 0 and labelled by two integers (b, k) such\nthat\n\nub = 1\ntk\n\n(10.18)\n\nconstitutes the leading order behaviour in the limit t\u2192 0 among the Casimirs ui with all other\nCasimirs subleading. We denote these punctures by P(b)\n\nn [k] with n = 6, 7, 8 for E6, E7, E8\n\nrespectively.\nThe monodromy on weights informs the mondromy on simple roots, see section 5.3, and\n\nwe denote the associated monodromy matrix by MP(b)\nn [k]. From (10.18) it now follows that\n\nthe monodromy matrices of the different punctures are related as\n\nMP(b)\nn [k] = Mk\n\nP(b)\nn [1]\n\n(10.19)\n\nand with this we compute the group of genuine lines to be\n\nL0\nP(b)\nn [k]\n\n= Tor coker\n(\nMk\n\nP(b)\nn [1]\n\n\u2212 1\n)\n\n(10.20)\n\nand collect the results in tables 8\u201312.\n\nExample: P(12)\n6 [1] puncture. Compactification of 6d N = (2, 0) theory with g = e6 on\n\na sphere with two P(12)\n6 [1] punctures engineers 4d N = 2 SYM with g = e6. This puncture\n\ntherefore plays the same role as P0 punctures for classical bulk algebras of type A and D. To\nstudy the puncture P(12)\n\n6 [1] we set u12 = 1/t and u2,5,6,8 = 0 and u9 = 1 in the E6 spectral\ncurve (10.8) which then becomes\n\n0 = v27 + 28v18 + 5v15\n\nt\n\u2212 53v9\n\n3 + 2v6\n\n3t \u2212\nv3\n\n108t2 + 1\n27 (10.21)\n\n105\n\n\n\nwhere we have moved onto the Coulomb branch with u9 6= 0 to resolve a degree three degen-\neracy with v = 0. Next we label the sheets vi by weights wi. For this we compute the roots\nat t = 1, we depict these as crosses in\n\nw15\n\nw14\n\nw16 w23w5\n\nw7\n\nw9\n\nw13\n\nw18\n\nw22\n\nw21\n\nw17\n\nw12\n\nw8\n\nw6\nw1\n\nw2\n\nw4\n\nw11 w20\n\nw25\n\nw27\n\nw26\n\nw24\n\nw19w10\n\nw3\n\nRe v\n\nIm v\n\n(10.22)\n\nHere we have further displayed the monodromy action on sheets upon encircling the puncture\npositively and given a labelling consistent with (10.10) and (10.11). See appendix B for\nMathematica code used to study the monodromies of (10.21). The weights and their vanishing\ntriples are given explicitly in table 14. The monodromy on roots is computed with this labelling\nto\n\nMP(12)\n6 [1] =\n\n\uf8eb\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\n\n0 0 \u22121 1 0 0\n0 \u22121 0 1 0 0\n1 0 \u22121 1 0 0\n1 \u22121 \u22121 2 \u22121 1\n0 0 0 1 \u22121 1\n0 0 0 1 \u22121 0\n\n\uf8f6\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8\n(10.23)\n\nfrom which we compute\n\nL0\nP(12)\n\n6 [1]\n= Tor coker\n\n(\nMP(12)\n\n6 [1] \u2212 1\n)\n\u223c= Z3 (10.24)\n\n106\n\n\n\nwhich is the center of E6 matching the field theory expectation.\n\n10.3 Trapped Defect Group from Type IIB on CY3\n\nIn [81] the superconformal theories TP(b)\nn [k] engineered from the punctures P(b)\n\nn [k] were denoted\n\nby E(b)\nn [k]. These theories admit an IHS realization in IIB (see also table 2)\n\nE\n(8)\n6 [k] = X{2,1}(2,4,3,\u03ba) : 0 = u2 + x3 + y4 + xz\u03ba\n\nE\n(9)\n6 [k] = X{2,1}(2,3,4,\u03ba) : 0 = u2 + x3 + y4 + yz\u03ba\n\nE\n(12)\n6 [k] = X{1,1}(2,3,4,\u03ba) : 0 = u2 + x3 + y4 + z\u03ba\n\nE\n(14)\n7 [k] = X{7,1}(2,3,3,\u03ba) : 0 = u2 + x3 + xy3 + yz\u03ba\n\nE\n(18)\n7 [k] = X{2,1}(2,\u03ba,3,3) : 0 = u2 + x3 + xy3 + z\u03ba\n\nE\n(20)\n8 [k] = X{2,1}(2,5,3,\u03ba) : 0 = u2 + x3 + y5 + xz\u03ba\n\nE\n(24)\n8 [k] = X{2,1}(2,3,5,\u03ba) : 0 = u2 + x3 + y5 + yz\u03ba\n\nE\n(30)\n8 [k] = X{1,1}(2,3,5,\u03ba) : 0 = u2 + x3 + y5 + z\u03ba .\n\n(10.25)\n\nIn these equations\n\u03ba = k \u2212 b . (10.26)\n\nAgain the alternate nomenclature is the one used in [55]. From the hypersurface we compute\nthe trapped defect group via the boundary topology of the associated Calabi-Yau three-fold\nX\n\n(b)\nn [k] using the methods in [55]. These are in agreement (for low values of k) with the\n\ntrapped contributions in tables 8\u201313. Note, that the rows of the tables are periodic with\nk \u223c k + b.\n\n11 Conclusions and Outlook\n\nThe main goal of this work is to study the 1-form symmetry groups and line defect groups of\narbitrary 4d N = 2 Class S theories. This problem was recently tackled extensively for the\ncase of regular punctures in [31], and it was shown that these groups can be encoded in the\ntopological properties of 1-cycles on the Riemann surface used for Class S construction.\n\nIn the present work, we include irregular punctures into the analysis. Once irregular\npunctures are included, one quickly realizes, using alternative descriptions of the 4d theories\nas discussed in section 3, that there can be extra contributions to the 1-form symmetry and\nline defect groups of the Class S theory that are not accounted by 1-cycles on the Riemann\nsurface. These additional contributions have to be somehow trapped at the locations of the\n\n107\n\n\n\n27 Weights (Ambient Space) Vanishing Triples\n\nw1\n(\n0, 0, 0, 0, 0,\u2212 2\n\n3 ,\u2212\n2\n3 ,+\n\n2\n3\n)\n\n{[1, 13, 26], [1, 14, 27], [1, 17, 25], [1, 20, 24], [1, 22, 23]}\nw2\n\n(\n\u2212 1\n\n2 ,+\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 12, 27], [2, 15, 26], [2, 18, 24], [2, 19, 25], [2, 21, 23]}\nw3\n\n(\n+ 1\n\n2 ,\u2212\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[3, 9, 27], [3, 11, 26], [3, 16, 25], [3, 18, 22], [3, 20, 21]}\nw4\n\n(\n+ 1\n\n2 ,+\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[4, 8, 26], [4, 10, 27], [4, 16, 24], [4, 17, 21], [4, 19, 22]}\nw5\n\n(\n\u2212 1\n\n2 ,\u2212\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[5, 6, 27], [5, 7, 26], [5, 16, 23], [5, 17, 18], [5, 19, 20]}\nw6\n\n(\n+ 1\n\n2 ,+\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[5, 6, 27], [6, 8, 25], [6, 11, 24], [6, 13, 21], [6, 15, 22]}\nw7\n\n(\n+ 1\n\n2 ,+\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[5, 7, 26], [7, 9, 24], [7, 10, 25], [7, 12, 22], [7, 14, 21]}\nw8\n\n(\n\u2212 1\n\n2 ,\u2212\n1\n2 ,+\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[4, 8, 26], [6, 8, 25], [8, 9, 23], [8, 12, 20], [8, 14, 18]}\nw9\n\n(\n\u2212 1\n\n2 ,+\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[3, 9, 27], [7, 9, 24], [8, 9, 23], [9, 13, 19], [9, 15, 17]}\nw10\n\n(\n\u2212 1\n\n2 ,\u2212\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n{[4, 10, 27], [7, 10, 25], [10, 11, 23], [10, 13, 18], [10, 15, 20]}\n\nw11\n(\n\u2212 1\n\n2 ,+\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[3, 11, 26], [6, 11, 24], [10, 11, 23], [11, 12, 17], [11, 14, 19]}\nw12\n\n(\n+ 1\n\n2 ,\u2212\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 12, 27], [7, 12, 22], [8, 12, 20], [11, 12, 17], [12, 13, 16]}\nw13\n\n(\n0, 0, 0,+1, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 13, 26], [6, 13, 21], [9, 13, 19], [10, 13, 18], [12, 13, 16]}\nw14\n\n(\n0, 0, 0, 0,+1,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 14, 27], [7, 14, 21], [8, 14, 18], [11, 14, 19], [14, 15, 16]}\nw15\n\n(\n+ 1\n\n2 ,\u2212\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 15, 26], [6, 15, 22], [9, 15, 17], [10, 15, 20], [14, 15, 16]}\nw16\n\n(\n\u2212 1\n\n2 ,+\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[3, 16, 25], [4, 16, 24], [5, 16, 23], [12, 13, 16], [14, 15, 16]}\nw17\n\n(\n0, 0,+1, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 17, 25], [4, 17, 21], [5, 17, 18], [9, 15, 17], [11, 12, 17]}\nw18\n\n(\n+ 1\n\n2 ,+\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 18, 24], [3, 18, 22], [5, 17, 18], [8, 14, 18], [10, 13, 18]}\nw19\n\n(\n+ 1\n\n2 ,\u2212\n1\n2 ,+\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 19, 25], [4, 19, 22], [5, 19, 20], [9, 13, 19], [11, 14, 19]}\nw20\n\n(\n0,+1, 0, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 20, 24], [3, 20, 21], [5, 19, 20], [8, 12, 20], [10, 15, 20]}\nw21\n\n(\n\u2212 1\n\n2 ,\u2212\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n6 ,\u2212\n\n1\n6 ,+\n\n1\n6\n)\n\n{[2, 21, 23], [3, 20, 21], [4, 17, 21], [6, 13, 21], [7, 14, 21]}\nw22\n\n(\n\u22121, 0, 0, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 22, 23], [3, 18, 22], [4, 19, 22], [6, 15, 22], [7, 12, 22]}\nw23\n\n(\n+1, 0, 0, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 22, 23], [2, 21, 23], [5, 16, 23], [8, 9, 23], [10, 11, 23]}\nw24\n\n(\n0,\u22121, 0, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 20, 24], [2, 18, 24], [4, 16, 24], [6, 11, 24], [7, 9, 24]}\nw25\n\n(\n0, 0,\u22121, 0, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 17, 25], [2, 19, 25], [3, 16, 25], [6, 8, 25], [7, 10, 25]}\nw26\n\n(\n0, 0, 0,\u22121, 0,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 13, 26], [2, 15, 26], [3, 11, 26], [4, 8, 26], [5, 7, 26]}\nw27\n\n(\n0, 0, 0, 0,\u22121,+ 1\n\n3 ,+\n1\n3 ,\u2212\n\n1\n3\n)\n\n{[1, 14, 27], [3, 9, 27], [4, 10, 27], [5, 6, 27], [9, 15, 27]}\n\nSimple Roots Simple Roots from Weights\n\u03b11\n\n(\n+ 1\n\n2 ,\u2212\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,\u2212\n\n1\n2 ,+\n\n1\n2\n)\n\n\u22122w22 \u2212 3\n2w23 + 1\n\n2(w24 + w25 + w26 + w27)\n\u03b12 (+1,+1, 0, 0, 0, 0, 0, 0) w23 \u2212 w24\n\n\u03b13 (\u22121,+1, 0, 0, 0, 0, 0, 0) w22 \u2212 w24\n\n\u03b14 (0,\u22121,+1, 0, 0, 0, 0, 0) w24 \u2212 w25\n\n\u03b15 (0, 0,\u22121,+1, 0, 0, 0, 0) w25 \u2212 w26\n\n\u03b16 (0, 0, 0,\u22121,+1, 0, 0, 0) w26 \u2212 w27\n\nTable 14: Weights of the E6 representation 27 as given by SAGE. Weights are represented with\nrespect to their embedding into the weight lattice of E8 (Ambient Space). We also give the\npresentations of simple roots \u03b1i and their decomposition into weights.\n\n108\n\n\n\nirregular punctures. Indeed, as we show in this paper, there is a non-trivial line defect group\nassociated to irregular punctures that contributes to the line defect group of a Class S theory.\n\nThis insight from Class S implies a more general, conceptual point: the existence of relative\ndefects in relative theories.\n\nIt is well-known, and we review in sections 2.1 and 2.2, that a non-trivial defect group\nindicates that the theory under study is a relative theory attached to a TQFT in one higher\ndimension. In the same way, as explained in detail in section 2, the fact that a puncture\nof a 6d N = (2, 0) theory carries a defect group means that it is a relative codimension-\ntwo defect attached to a topological system in one higher dimension. Since 6d N = (2, 0)\ntheory is a relative theory, we learn that a general codimension-two defect of a 6d N = (2, 0)\ntheory is a relative defect inside a relative theory. This has the interesting consequence that\nthe topological system attached to the relative codimension-two defect is itself a topological\ndefect of the TQFT attached to the 6d N = (2, 0) theory.\n\nWe discuss the general formalism of relative defects in relative theories in section 2. The\nresults of this paper provide interesting and concrete examples of such relative defects in the\nform of codimension-two defects of 6d N = (2, 0) theories.\n\nThe full line defect group of a puncture can be divided into trapped and non-trapped\nparts. The non-trapped part is related to the surface defect group of the parent 6d N = (2, 0)\ntheory, while the trapped part is not related to the bulk surface defect group, but arises as a\ncontribution from the puncture (i.e. codimension two defect). It is important to know how\nthe trapped and non-trapped parts combine to form the full line defect group associated to a\npuncture. The combination is captured by a short exact sequence, which is non-split whenever\nthe trapped and non-trapped parts combine non-trivially. The details about the structure of\nline defect groups of punctures, and its usage in the computation of the line defect group of\nan arbitrary Class S theory, are discussed in section 4.\n\nWe obtain explicit expressions for the line defect groups of many classes of conformal and\nnon-conformal untwisted A- and D-types, and twisted D-type punctures. This is done by\nproposing that the line defect groups of punctures are the same as line defect groups of a class\nof 4d N = 2 generalized quiver gauge theories.\n\nMany of the classes of punctures that we discuss (even the conformal ones) have not\nappeared prior in the literature. A sub-class of these new punctures can be constructed using\nHanany-Witten brane setups in Type IIA string theory, and generalizations thereof.\n\nWe use two geometric constructions of punctures in Type IIB string theory to test the\nproposed defect groups. Using such geometric constructions, we can compute important pieces\nof the full defect groups of the punctures, which can then be matched with the proposals.\n\n109\n\n\n\nOne of these constructions employs the use of isolated hypersurface Calabi-Yau threefold\nsingularities in IIB, using which we can compute trapped parts of the defect groups associated\nto punctures. The other construction involves ALE fibrations over a punctured complex plane.\nThe monodromies of these ALE fibrations can be used to compute the genuine part of the\ndefect group associated to the punctures.\n\nCombining these two geometric constructions, we are able to also derive defect groups\nassociated to a class of well-known conformal untwisted E-type punctures.\n\nConceptually, we expect the ALE-fibration to contain the same information as the Class S\nconstruction. What we have shown in this paper, is how to geometrically extract the genuine\npart of the defect group associated to the punctures. However, as we explained in section 5.3,\nwe do not understand how to combine this and describe the full defect group of the puncture,\nwhich is locally modelled by the ALE-fibration. It would be very interesting to develop this\nline of reasoning further.\n\nIn this paper we focused on codimension 2 defects in Class S constructions. Naturally,\nthis should have extensions to N = 1 versions of Class S theories, and potentially interesting\nimplications for studies of confinement. More broadly, we expect relative defects in relative\ntheories to also play a role in other contexts of compactifications from higher-dimensional\nrelative theories, e.g. 6d to 3d and 2d.\n\nAcknowledgements\n\nWe thank Cyril Closset, I\u00f1aki Garc\u00eda Etxebarria, Dave Morrison and Yinan Wang for dis-\ncussions. This work is supported in part by the European Union\u2019s Horizon 2020 Framework\nthrough the ERC grants 682608 (LB, SG and SSN) and 787185 (LB). The work of SG is also\nsupported by the INFN grant \u201cPer attivit\u00e0 di formazione per sostenere progetti di ricerca\u201d\n(GRANT 73/STRONGQFT). MH is funded and SSN is supported in part by the \u201cSimons\nCollaboration on Special Holonomy in Geometry, Analysis and Physics\u201d.\n\nA Glossary\n\nA.1 Glossary for Sections 2.1 and 2.2\n\n\u2022 DP : A p-dimensional and generically non-topological defect.\n\n\u2022 Td: A d-dimensional relative theory.\n\n\u2022 Sd+1: A (d+1)-dimensional non-invertible TQFT associated to a d-dimensional relative\ntheory.\n\n110\n\n\n\n\u2022 Lp: The group formed by invertible p-dimensional topological defects in a TQFT Sd+1.\nAlso the group of (d\u2212 p)-form symmetries of Sd+1.\n\n\u2022 L: The defect group associated to Sd+1.\n\n\u2022 T\u039b\nd : An absolute d-dimensional theory associated to polarization \u039b obtained from a\n\nrelative theory Td.\n\n\u2022 B\u039b\nd : A topological boundary condition of a TQFT Sd+1 associated to polarization \u039b.\n\n\u2022 \u039bp: The subgroup of Lp characterizing the topological defects that can end on the\nboundary B\u039b\n\nd .\n\n\u2022 \u039b\u0302p+1: The p-form symmetry group of the absolute theory T\u039b\nd .\n\nA.2 Glossary for Section 2.4\n\n\u2022 TD: A D-dimensional relative theory.\n\n\u2022 Td: A d-dimensional relative defect in TD.\n\n\u2022 SD+1: The (D + 1)-dimensional non-invertible TQFT associated to TD.\n\n\u2022 Sd+1: The (d + 1)-dimensional non-invertible topological defect of SD+1 associated to\nTd.\n\n\u2022 LD,p: The group formed by invertible p-dimensional topological defects of SD+1. Also\nthe group of (D \u2212 p)-form symmetries of SD+1.\n\n\u2022 Ld,p: The group formed by invertible p-dimensional topological sub-defects of Sd+1.\nAlso the group of (d\u2212 p)-form symmetries localized along Sd+1.\n\n\u2022 L0\nd,p: The group formed by invertible p-dimensional topological sub-defects of Sd+1 that\n\nare genuine i.e. unattached to other topological defects of SD+1.\n\n\u2022 LD: The defect group associated to SD+1.\n\n\u2022 Ld: The defect group associated to Sd+1.\n\n\u2022 \u03c0p: The map from Ld,p to LD,p+1 describing the (p + 1)-dimensional topological defect\nof SD+1 attached to a p-dimensional topological sub-defect of Sd+1.\n\n\u2022 sd\u2212p: The map from LD,D\u2212p\u22121 to L0\nd,d\u2212p describing the genuine topological sub-defect\n\nof Sd+1 obtained by squeezing a topological defect of SD+1 onto Sd+1.\n\n111\n\n\n\n\u2022 LTd,p: The group formed by invertible p-dimensional topological sub-defects of Sd+1 that\nare trapped i.e. cannot be related to topological defects of SD+1.\n\n\u2022 T\u039bD\nD : An absolute D-dimensional theory associated to polarization \u039bD obtained from\n\nrelative theory TD.\n\n\u2022 T\u039bd\nd : An absolute d-dimensional defect associated to polarization \u039bd obtained from\n\nrelative defect Td.\n\n\u2022 B\u039bD\nD : A topological boundary condition of SD+1 associated to polarization \u039bD.\n\n\u2022 B\u039bd\nd : A topological sub-defect of B\u039bD\n\nD associated to polarization \u039bd.\n\n\u2022 \u039bD,p: The subgroup of LD,p characterizing the topological defects that can end on the\nboundary B\u039bD\n\nD .\n\n\u2022 \u039bd,p: The subgroup of Ld,p characterizing the topological defects that can end on the\nboundary B\u039bd\n\nd .\n\n\u2022 \u039b\u0302D,p+1: The p-form symmetry group of the absolute theory T\u039bD\nD .\n\n\u2022 \u039b\u0302d,p+1: The p-form symmetry group of the absolute defect T\u039bd\nd .\n\nA.3 Glossary for the Rest of the Paper\n\n\u2022 Z\u0302G: The Pontryagin dual of the center ZG of a Lie group G.\n\n\u2022 Og: The group of outer-automorphisms modulo inner automorphisms of a Lie algebra\ng. Also, the group of 0-form symmetries of a 6d N = (2, 0) theory of type g.\n\n\u2022 LX : The line defect group of the 4d N = 2 SCFT constructed by compactifying IIB on\nthe Calabi-Yau threefold X.\n\n\u2022 LT: The line defect group of a 4d N = 2 relative theory T.\n\n\u2022 OT\u039b : The 1-form symmetry group of a 4d N = 2 absolute theory T\u039b.\n\n\u2022 S6d: The surface defect group of a 6d N = (2, 0) theory.\n\n\u2022 So6d: The surface defect group of a 6d N = (2, 0) theory modded out by the action of an\nouter-automorphism 0-form symmetry o.\n\n\u2022 S6d,o: The surface defect group of a 6d N = (2, 0) theory left invariant by the action of\nan outer-automorphism 0-form symmetry o.\n\n112\n\n\n\n\u2022 P: A puncture of a 6d N = (2, 0) theory.\n\n\u2022 P0: A special untwisted puncture of a 6d N = (2, 0) theory, that is obtained by gauging\nthe flavor symmetry carried by an untwisted maximal regular puncture.\n\n\u2022 Po0 : A special o-twisted puncture of a 6d N = (2, 0) theory, that is obtained by gauging\nthe flavor symmetry carried by an o-twisted maximal regular puncture.\n\n\u2022 LP : The full line defect group of a puncture P.\n\n\u2022 LTP : The trapped part of the line defect group of a puncture P.\n\n\u2022 L0\nP : The genuine part of the line defect group of a puncture P.\n\n\u2022 HP : The magnetic part of the line defect group of a puncture P.\n\n\u2022 HTP : The trapped magnetic part of the line defect group of a puncture P.\n\n\u2022 iP : The injective map from HTP to HP describing the trapped part as a subgroup of the\nfull magnetic line defect group.\n\n\u2022 WP : The electric part of the line defect group of a puncture P.\n\n\u2022 WT\nP : The trapped electric part of the line defect group of a puncture P.\n\n\u2022 ZP : The subgroup of surface defects of a 6d N = (2, 0) theory that can end at a puncture\nP.\n\n\u2022 \u03c0P : The projection map from HP to ZP describing the bulk surface defect that a line\ndefect living on puncture P is attached to.\n\n\u2022 Z\u0302P : The subgroup of genuine line defects in WP that can be lifted to bulk surface\ndefects.\n\n\u2022 TP : A special 4d N = 2 theory obtained by compactifying a 6d N = (2, 0) theory\non a sphere with a puncture P. If P is an untwisted puncture, no other punctures\nare included. On the other hand, if P is a twisted puncture, then a minimal twisted\npuncture is also included.\n\n\u2022 T\u2217P : A special 4d N = 2 theory obtained by compactifying a 6d N = (2, 0) theory on a\nsphere with a puncture P. If P is an untwisted puncture, a maximal untwisted regular\npuncture is also included. On the other hand, if P is a twisted puncture, then a maximal\ntwisted regular puncture is included.\n\n113\n\n\n\n\u2022 TP0\nP : A special 4d N = 2 theory obtained by compactifying a 6d N = (2, 0) theory on a\n\nsphere with an untwisted puncture P and another puncture P0.\n\n\u2022 T\nPo0\nP : A special 4d N = 2 theory obtained by compactifying a 6d N = (2, 0) theory on a\n\nsphere with an o\u22121-twisted puncture P and another puncture Po0 .\n\n\u2022 \u03c6 or \u03a6: Higgs (Hitchin) field associated to Class S compactification.\n\n\u2022 SNF(M): Smith Normal Form of a matrix M .\n\nB Spectral Cover Monodromies\n\nConsider a puncture P in a theory of class S with bulk Lie algebra g. Let t be a local coordinate\nfor a patch of the UV curve centered on the puncture and v a coordinate on the cotangent\nfibers projecting to this patch. The differential is \u03bb = vdt/t and the spectral curve is locally\na polynomial\n\nF (v, t) = 0 . (B.1)\n\nFor further details on the set-up see the discussion in section 5.3. The curves for untwisted\nLie algebras g = An, Dn, E6 were discussed in sections 7.5, 8.5, 10 respectively.\n\nThe vanishing locus of the discriminant of F with respect to v determines the t coordinate\nof the branch points, these solve\n\n\u2206(F, v)(t) = 0 . (B.2)\n\nThe monodromy action on the sheets vi of the spectral curve F associated to the puncture\nP follows from considering a small loop linking P which does not enclose any of the branch\npoints solving (B.2).\n\nWe present a convenient numerical method for determining the monodromy action on\nsheets. This method employs Mathematica and is independent of the bulk Lie algebra g\n\nwhich determines the map from this monodromy action to the monodromy on roots after\nchoosing a labelling of sheets by weights. As an example let us consider the curve\n\nF (v, t) = Pn1(v)t2 + Pn2(v)t+ Pn3(v) = 0 (B.3)\n\nwith n2 \u2212 n3 > n1 \u2212 n2 > 0. Here Pni are polynomials of degree ni. We set all physical\nconstants to one as we are solely interested in ramification structure of the cover at t = 0.\nThe leading order terms of the curve in the limit t\u2192 0 are\n\nF0(v, t) = vn1t2 + vn2t+ vn3 = 0 . (B.4)\n\n114\n\n\n\nFigure 26: Example of the Mathematica out-put for (n1, n2, n3) = (20, 17, 5) and (c1, c2, c3) =\n(1, 1, 0) and k = 2. The t-plane and v-plane are plotted in the same plane. The black dot sets\nthe value of t and can be dragged. The green dot marks t = 0 while the purple dots mark a\nfixed reference frame in the t-plane. The roots vi(t) are displayed by red dots. Drag the black\ndot around the green dot to watch them permute. We clearly see three monodromy orbits of\ncardinality 3, 12, 5 permuted cyclically.\n\nThe roots of this equation are n3-fold degenerate for v = 0 and all t. This degeneracy needs\nto be lifted to study the monodromy at generic points of the extended Coulomb branch. We\ntherefore tune to a more generic part of the extended Coulomb branch by turning on the\nconstants ci as\n\nP0(v, t) = (vn1 + c1)t2 + (vn2 + c2)t+ vn3 + c3 = 0 . (B.5)\n\nThe physics of the set-up constrains which constants ci are permitted to be non-vanishing.\nThe constant ci with the smallest index then determines the generic monodromy behaviour of\nthe previously degenerate roots.\n\nThe roots of P0 organize into three monodromy orbits of order n1 \u2212 n2, n2 \u2212 n3, n3. The\norbits group roots by their scaling behavior in the limit t \u2192 0. Roots of the first two orbits\ndiverge upon approaching the puncture. Encircling the puncture counter-clockwise the orbits\nwith n1 \u2212 n2 and n2 \u2212 n3 roots experience a cyclic permutation clockwise. The orbit with n3\n\nroots is permuted 3\u2212 k times counter-clockwise where k is the largest index for which ci 6= 0.\n\n115\n\n\n\nAn explicit example can be viewed using the Mathematica code:\n\nManipulate[n=20;index=Table[i,{i,n}];\n\nPoly=v^5+(v^(17)+1)(t[[1]]+I t[[2]])+(v^(20)+1)(t[[1]]+I t[[2]])^2;\n\nscale=0.5;roots=NSolve[Poly==0,v];rts=v/.roots[[index]];\n\nGraphics[{Green,Disk[{0, 0},.03], Black,Disk[t,.03],Red,Table[Disk[{Re[rts[[i]]],\n\nIm[rts[[i]]]},.04],{i,n}],Purple,{Disk[{1,0},.03],Disk[{-1,0},.03],Disk[{0,1},.03],\n\nDisk[{0,-1},.03]}},PlotRange->5, ImageSize->1000],\n\n{{t,{1/20,0}}, {-5,-5},{5,5},Locator,Appearance->None},TrackedSymbols->True]\n\nwhich produces the out-put shown in figure 26. More general polynomials F (v, t) of arbitrary\norder in t are analyzed similarly. Once the monodromy on sheets is known, a labelling of\nsheets by weights is picked and from it the monodromy action on roots is inferred.\n\nAs a final example we include the Mathematica code used in the analysis of the E6 example\nof section 10.2.\n\nManipulate[n = 27; index = Table[i, {i, n}];\n\nPoly = 1/27 - (53 v^9)/3 + 28 v^18 + v^27 - v^3/( 108 (t[[1]] + I t[[2]])^2) +\n\n(2 v^6)/(3 (t[[1]] + I t[[2]])) + ( 5 v^15)/(t[[1]] + I t[[2]]);\n\nscale = 0.5; roots = NSolve[Poly == 0, v]; rts = v /. roots[[index]];\n\nGraphics[{Green, Disk[{0., 0}, .03], Black, Disk[t, .04], Red, Table[Disk[{Re[rts[[i]]],\n\nIm[rts[[i]]]}, .02], {i, 27}], Purple, {Disk[{1, 0}, .03], Disk[{-1, 0}, .03],\n\nDisk[{0, 1}, .03], Disk[{0, -1}, .03]}},\n\nPlotRange -> 5, ImageSize -> 1000], {{t, {1/2, 0}}, {-5, -5}, {5, 5}, Locator,\n\nAppearance -> None}, TrackedSymbols -> True]\n\nReferences\n\n[1] D. Gaiotto, G. W. Moore, and A. Neitzke, \u201cFramed BPS States,\u201d Adv. Theor. Math.\nPhys. 17 no. 2, (2013) 241\u2013397, arXiv:1006.0146 [hep-th].\n\n[2] O. Aharony, N. Seiberg, and Y. Tachikawa, \u201cReading between the lines of\nfour-dimensional gauge theories,\u201d JHEP 08 (2013) 115, arXiv:1305.0318 [hep-th].\n\n[3] D. Gaiotto, A. Kapustin, N. Seiberg, and B. Willett, \u201cGeneralized Global\nSymmetries,\u201d JHEP 02 (2015) 172, arXiv:1412.5148 [hep-th].\n\n116\n\nhttp://dx.doi.org/10.4310/ATMP.2013.v17.n2.a1\nhttp://dx.doi.org/10.4310/ATMP.2013.v17.n2.a1\nhttp://arxiv.org/abs/1006.0146\nhttp://dx.doi.org/10.1007/JHEP08(2013)115\nhttp://arxiv.org/abs/1305.0318\nhttp://dx.doi.org/10.1007/JHEP02(2015)172\nhttp://arxiv.org/abs/1412.5148\n\n\n[4] M. Del Zotto, J. J. Heckman, D. S. Park, and T. Rudelius, \u201cOn the Defect Group of a\n6D SCFT,\u201d Lett. Math. Phys. 106 no. 6, (2016) 765\u2013786, arXiv:1503.04806\n\n[hep-th].\n\n[5] E. Sharpe, \u201cNotes on generalized global symmetries in QFT,\u201d Fortsch. Phys. 63 (2015)\n659\u2013682, arXiv:1508.04770 [hep-th].\n\n[6] Y. Tachikawa, \u201cOn gauging finite subgroups,\u201d SciPost Phys. 8 no. 1, (2020) 015,\narXiv:1712.09542 [hep-th].\n\n[7] C. C\u00f3rdova, T. T. Dumitrescu, and K. Intriligator, \u201cExploring 2-Group Global\nSymmetries,\u201d JHEP 02 (2019) 184, arXiv:1802.04790 [hep-th].\n\n[8] F. Benini, C. C\u00f3rdova, and P.-S. Hsin, \u201cOn 2-Group Global Symmetries and their\nAnomalies,\u201d JHEP 03 (2019) 118, arXiv:1803.09336 [hep-th].\n\n[9] P.-S. Hsin, H. T. Lam, and N. Seiberg, \u201cComments on One-Form Global Symmetries\nand Their Gauging in 3d and 4d,\u201d SciPost Phys. 6 no. 3, (2019) 039,\narXiv:1812.04716 [hep-th].\n\n[10] I. n. Garc\u00eda Etxebarria, B. Heidenreich, and D. Regalado, \u201cIIB flux non-commutativity\nand the global structure of field theories,\u201d JHEP 10 (2019) 169, arXiv:1908.08027\n\n[hep-th].\n\n[11] J. Eckhard, H. Kim, S. Schafer-Nameki, and B. Willett, \u201cHigher-Form Symmetries,\nBethe Vacua, and the 3d-3d Correspondence,\u201d JHEP 01 (2020) 101,\narXiv:1910.14086 [hep-th].\n\n[12] O. Bergman, Y. Tachikawa, and G. Zafrir, \u201cGeneralized symmetries and holography in\nABJM-type theories,\u201d JHEP 07 (2020) 077, arXiv:2004.05350 [hep-th].\n\n[13] D. R. Morrison, S. Schafer-Nameki, and B. Willett, \u201cHigher-Form Symmetries in 5d,\u201d\nJHEP 09 (2020) 024, arXiv:2005.12296 [hep-th].\n\n[14] F. Albertini, M. Del Zotto, I. n. Garc\u00eda Etxebarria, and S. S. Hosseini, \u201cHigher Form\nSymmetries and M-theory,\u201d JHEP 12 (2020) 203, arXiv:2005.12831 [hep-th].\n\n[15] P.-S. Hsin and H. T. Lam, \u201cDiscrete theta angles, symmetries and anomalies,\u201d SciPost\nPhys. 10 no. 2, (2021) 032, arXiv:2007.05915 [hep-th].\n\n[16] I. Bah, F. Bonetti, and R. Minasian, \u201cDiscrete and higher-form symmetries in SCFTs\nfrom wrapped M5-branes,\u201d JHEP 03 (2021) 196, arXiv:2007.15003 [hep-th].\n\n117\n\nhttp://dx.doi.org/10.1007/s11005-016-0839-5\nhttp://arxiv.org/abs/1503.04806\nhttp://arxiv.org/abs/1503.04806\nhttp://dx.doi.org/10.1002/prop.201500048\nhttp://dx.doi.org/10.1002/prop.201500048\nhttp://arxiv.org/abs/1508.04770\nhttp://dx.doi.org/10.21468/SciPostPhys.8.1.015\nhttp://arxiv.org/abs/1712.09542\nhttp://dx.doi.org/10.1007/JHEP02(2019)184\nhttp://arxiv.org/abs/1802.04790\nhttp://dx.doi.org/10.1007/JHEP03(2019)118\nhttp://arxiv.org/abs/1803.09336\nhttp://dx.doi.org/10.21468/SciPostPhys.6.3.039\nhttp://arxiv.org/abs/1812.04716\nhttp://dx.doi.org/10.1007/JHEP10(2019)169\nhttp://arxiv.org/abs/1908.08027\nhttp://arxiv.org/abs/1908.08027\nhttp://dx.doi.org/10.1007/JHEP01(2020)101\nhttp://arxiv.org/abs/1910.14086\nhttp://dx.doi.org/10.1007/JHEP07(2020)077\nhttp://arxiv.org/abs/2004.05350\nhttp://dx.doi.org/10.1007/JHEP09(2020)024\nhttp://arxiv.org/abs/2005.12296\nhttp://dx.doi.org/10.1007/JHEP12(2020)203\nhttp://arxiv.org/abs/2005.12831\nhttp://dx.doi.org/10.21468/SciPostPhys.10.2.032\nhttp://dx.doi.org/10.21468/SciPostPhys.10.2.032\nhttp://arxiv.org/abs/2007.05915\nhttp://dx.doi.org/10.1007/JHEP03(2021)196\nhttp://arxiv.org/abs/2007.15003\n\n\n[17] M. Del Zotto, I. n. Garc\u00eda Etxebarria, and S. S. Hosseini, \u201cHigher form symmetries of\nArgyres-Douglas theories,\u201d JHEP 10 (2020) 056, arXiv:2007.15603 [hep-th].\n\n[18] L. Bhardwaj and S. Sch\u00e4fer-Nameki, \u201cHigher-form symmetries of 6d and 5d theories,\u201d\nJHEP 02 (2021) 159, arXiv:2008.09600 [hep-th].\n\n[19] F. Apruzzi, M. Dierigl, and L. Lin, \u201cThe Fate of Discrete 1-Form Symmetries in 6d,\u201d\narXiv:2008.09117 [hep-th].\n\n[20] C. Cordova, T. T. Dumitrescu, and K. Intriligator, \u201c2-Group Global Symmetries and\nAnomalies in Six-Dimensional Quantum Field Theories,\u201d JHEP 04 (2021) 252,\narXiv:2009.00138 [hep-th].\n\n[21] P. Benetti Genolini and L. Tizzano, \u201cInstantons, symmetries and anomalies in five\ndimensions,\u201d JHEP 04 (2021) 188, arXiv:2009.07873 [hep-th].\n\n[22] M. Yu, \u201cSymmetries and anomalies of (1+1)d theories: 2-groups and symmetry\nfractionalization,\u201d JHEP 08 (2021) 061, arXiv:2010.01136 [hep-th].\n\n[23] L. Bhardwaj, Y. Lee, and Y. Tachikawa, \u201cSL(2,Z) action on QFTs with Z2 symmetry\nand the Brown-Kervaire invariants,\u201d JHEP 11 (2020) 141, arXiv:2009.10099\n\n[hep-th].\n\n[24] O. DeWolfe and K. Higginbotham, \u201cGeneralized symmetries and 2-groups via\nelectromagnetic duality in AdS/CFT ,\u201d Phys. Rev. D 103 no. 2, (2021) 026011,\narXiv:2010.06594 [hep-th].\n\n[25] S. Gukov, P.-S. Hsin, and D. Pei, \u201cGeneralized global symmetries of T [M ] theories.\nPart I,\u201d JHEP 04 (2021) 232, arXiv:2010.15890 [hep-th].\n\n[26] N. Iqbal and N. Poovuttikul, \u201c2-group global symmetries, hydrodynamics and\nholography,\u201d arXiv:2010.00320 [hep-th].\n\n[27] Y. Hidaka, M. Nitta, and R. Yokokura, \u201cGlobal 3-group symmetry and \u2019t Hooft\nanomalies in axion electrodynamics,\u201d JHEP 01 (2021) 173, arXiv:2009.14368\n\n[hep-th].\n\n[28] T. D. Brennan and C. Cordova, \u201cAxions, Higher-Groups, and Emergent Symmetry,\u201d\narXiv:2011.09600 [hep-th].\n\n118\n\nhttp://dx.doi.org/10.1007/JHEP10(2020)056\nhttp://arxiv.org/abs/2007.15603\nhttp://dx.doi.org/10.1007/JHEP02(2021)159\nhttp://arxiv.org/abs/2008.09600\nhttp://arxiv.org/abs/2008.09117\nhttp://dx.doi.org/10.1007/JHEP04(2021)252\nhttp://arxiv.org/abs/2009.00138\nhttp://dx.doi.org/10.1007/JHEP04(2021)188\nhttp://arxiv.org/abs/2009.07873\nhttp://dx.doi.org/10.1007/JHEP08(2021)061\nhttp://arxiv.org/abs/2010.01136\nhttp://dx.doi.org/10.1007/JHEP11(2020)141\nhttp://arxiv.org/abs/2009.10099\nhttp://arxiv.org/abs/2009.10099\nhttp://dx.doi.org/10.1103/PhysRevD.103.026011\nhttp://arxiv.org/abs/2010.06594\nhttp://dx.doi.org/10.1007/JHEP04(2021)232\nhttp://arxiv.org/abs/2010.15890\nhttp://arxiv.org/abs/2010.00320\nhttp://dx.doi.org/10.1007/JHEP01(2021)173\nhttp://arxiv.org/abs/2009.14368\nhttp://arxiv.org/abs/2009.14368\nhttp://arxiv.org/abs/2011.09600\n\n\n[29] C. Closset, S. Giacomelli, S. Schafer-Nameki, and Y.-N. Wang, \u201c5d and 4d SCFTs:\nCanonical Singularities, Trinions and S-Dualities,\u201d JHEP 05 (2021) 274,\narXiv:2012.12827 [hep-th].\n\n[30] C. Closset, S. Schafer-Nameki, and Y.-N. Wang, \u201cCoulomb and Higgs Branches from\nCanonical Singularities: Part 0,\u201d JHEP 02 (2021) 003, arXiv:2007.15600 [hep-th].\n\n[31] L. Bhardwaj, M. Hubner, and S. Schafer-Nameki, \u201c1-form Symmetries of 4d N=2 Class\nS Theories,\u201d arXiv:2102.01693 [hep-th].\n\n[32] M. Nguyen, Y. Tanizaki, and M. \u00dcnsal, \u201cNoninvertible 1-form symmetry and Casimir\nscaling in 2D Yang-Mills theory,\u201d Phys. Rev. D 104 no. 6, (2021) 065003,\narXiv:2104.01824 [hep-th].\n\n[33] B. Heidenreich, J. McNamara, M. Montero, M. Reece, T. Rudelius, and I. Valenzuela,\n\u201cNon-Invertible Global Symmetries and Completeness of the Spectrum,\u201d JHEP 09\n(2021) 203, arXiv:2104.07036 [hep-th].\n\n[34] F. Apruzzi, M. van Beest, D. S. W. Gould, and S. Sch\u00e4fer-Nameki, \u201cHolography,\n1-form symmetries, and confinement,\u201d Phys. Rev. D 104 no. 6, (2021) 066005,\narXiv:2104.12764 [hep-th].\n\n[35] F. Apruzzi, L. Bhardwaj, J. Oh, and S. Schafer-Nameki, \u201cThe Global Form of Flavor\nSymmetries and 2-Group Symmetries in 5d SCFTs,\u201d arXiv:2105.08724 [hep-th].\n\n[36] S. S. Hosseini and R. Moscrop, \u201cMaruyoshi-Song flows and defect groups of Db\np(G)\n\ntheories,\u201d JHEP 10 (2021) 119, arXiv:2106.03878 [hep-th].\n\n[37] M. Cvetic, M. Dierigl, L. Lin, and H. Y. Zhang, \u201cHigher-Form Symmetries and Their\nAnomalies in M-/F-Theory Duality,\u201d arXiv:2106.07654 [hep-th].\n\n[38] M. Buican and H. Jiang, \u201c1-Form Symmetry, Isolated N=2 SCFTs, and Calabi-Yau\nThreefolds,\u201d arXiv:2106.09807 [hep-th].\n\n[39] L. Bhardwaj, M. Hubner, and S. Schafer-Nameki, \u201cLiberating Confinement from\nLagrangians: 1-form Symmetries and Lines in 4d N=1 from 6d N=(2,0),\u201d\narXiv:2106.10265 [hep-th].\n\n[40] N. Iqbal and J. McGreevy, \u201cMean string field theory: Landau-Ginzburg theory for\n1-form symmetries,\u201d arXiv:2106.12610 [hep-th].\n\n119\n\nhttp://dx.doi.org/10.1007/JHEP05(2021)274\nhttp://arxiv.org/abs/2012.12827\nhttp://dx.doi.org/10.1007/JHEP02(2021)003\nhttp://arxiv.org/abs/2007.15600\nhttp://arxiv.org/abs/2102.01693\nhttp://dx.doi.org/10.1103/PhysRevD.104.065003\nhttp://arxiv.org/abs/2104.01824\nhttp://dx.doi.org/10.1007/JHEP09(2021)203\nhttp://dx.doi.org/10.1007/JHEP09(2021)203\nhttp://arxiv.org/abs/2104.07036\nhttp://dx.doi.org/10.1103/PhysRevD.104.066005\nhttp://arxiv.org/abs/2104.12764\nhttp://arxiv.org/abs/2105.08724\nhttp://dx.doi.org/10.1007/JHEP10(2021)119\nhttp://arxiv.org/abs/2106.03878\nhttp://arxiv.org/abs/2106.07654\nhttp://arxiv.org/abs/2106.09807\nhttp://arxiv.org/abs/2106.10265\nhttp://arxiv.org/abs/2106.12610\n\n\n[41] A. P. Braun, M. Larfors, and P.-K. Oehlmann, \u201cGauged 2-form Symmetries in 6D\nSCFTs Coupled to Gravity,\u201d arXiv:2106.13198 [hep-th].\n\n[42] M. Cveti\u010d, J. J. Heckman, E. Torres, and G. Zoccarato, \u201cReflections on the Matter of\n3d N = 1 Vacua and Local Spin(7) Compactifications,\u201d arXiv:2107.00025 [hep-th].\n\n[43] C. Closset and H. Magureanu, \u201cThe U -plane of rank-one 4d N = 2 KK theories,\u201d\narXiv:2107.03509 [hep-th].\n\n[44] L. Bhardwaj, \u201c2-Group Symmetries in Class S,\u201d arXiv:2107.06816 [hep-th].\n\n[45] Y. Hidaka, M. Nitta, and R. Yokokura, \u201cTopological axion electrodynamics and\n4-group symmetry,\u201d Phys. Lett. B 823 (2021) 136762, arXiv:2107.08753 [hep-th].\n\n[46] Y. Lee and Y. Zheng, \u201cRemarks on compatibility between conformal symmetry and\ncontinuous higher-form symmetries,\u201d Phys. Rev. D 104 no. 8, (2021) 085005,\narXiv:2108.00732 [hep-th].\n\n[47] Y. Lee, K. Ohmori, and Y. Tachikawa, \u201cMatching higher symmetries across\nIntriligator-Seiberg duality,\u201d JHEP 10 (2021) 114, arXiv:2108.05369 [hep-th].\n\n[48] Y. Hidaka, M. Nitta, and R. Yokokura, \u201cGlobal 4-group symmetry and \u2019t Hooft\nanomalies in topological axion electrodynamics,\u201d arXiv:2108.12564 [hep-th].\n\n[49] M. Koide, Y. Nagoya, and S. Yamaguchi, \u201cNon-invertible topological defects in\n4-dimensional Z2 pure lattice gauge theory,\u201d arXiv:2109.05992 [hep-th].\n\n[50] F. Apruzzi, L. Bhardwaj, D. S. W. Gould, and S. Schafer-Nameki, \u201c2-Group\nSymmetries and their Classification in 6d,\u201d arXiv:2110.14647 [hep-th].\n\n[51] J. Kaidi, K. Ohmori, and Y. Zheng, \u201cKramers-Wannier-like duality defects in (3 + 1)d\ngauge theories,\u201d arXiv:2111.01141 [hep-th].\n\n[52] Y. Choi, C. Cordova, P.-S. Hsin, H. T. Lam, and S.-H. Shao, \u201cNon-Invertible Duality\nDefects in 3+1 Dimensions,\u201d arXiv:2111.01139 [hep-th].\n\n[53] I. Bah, F. Bonetti, E. Leung, and P. Weck, \u201cM5-branes Probing Flux Backgrounds,\u201d\narXiv:2111.01790 [hep-th].\n\n[54] S. Gukov, D. Pei, C. Reid, and A. Shehper, \u201cSymmetries of 2d TQFTs and\nEquivariant Verlinde Formulae for General Groups,\u201d arXiv:2111.08032 [hep-th].\n\n120\n\nhttp://arxiv.org/abs/2106.13198\nhttp://arxiv.org/abs/2107.00025\nhttp://arxiv.org/abs/2107.03509\nhttp://arxiv.org/abs/2107.06816\nhttp://dx.doi.org/10.1016/j.physletb.2021.136762\nhttp://arxiv.org/abs/2107.08753\nhttp://dx.doi.org/10.1103/PhysRevD.104.085005\nhttp://arxiv.org/abs/2108.00732\nhttp://dx.doi.org/10.1007/JHEP10(2021)114\nhttp://arxiv.org/abs/2108.05369\nhttp://arxiv.org/abs/2108.12564\nhttp://arxiv.org/abs/2109.05992\nhttp://arxiv.org/abs/2110.14647\nhttp://arxiv.org/abs/2111.01141\nhttp://arxiv.org/abs/2111.01139\nhttp://arxiv.org/abs/2111.01790\nhttp://arxiv.org/abs/2111.08032\n\n\n[55] C. Closset, S. Schafer-Nameki, and Y.-N. Wang, \u201cCoulomb and Higgs Branches from\nCanonical Singularities, Part 1: Hypersurfaces with Smooth Calabi-Yau Resolutions,\u201d\narXiv:2111.13564 [hep-th].\n\n[56] M. Yu, \u201cGauging Categorical Symmetries in 3d Topological Orders and Bulk\nReconstruction,\u201d arXiv:2111.13697 [hep-th].\n\n[57] F. Apruzzi, F. Bonetti, I. n. G. Etxebarria, S. S. Hosseini, and S. Schafer-Nameki,\n\u201cSymmetry TFTs from String Theory,\u201d arXiv:2112.02092 [hep-th].\n\n[58] E. Beratto, N. Mekareeya, and M. Sacchi, \u201cZero-form and one-form symmetries of the\nABJ and related theories,\u201d arXiv:2112.09531 [hep-th].\n\n[59] D. S. Freed and C. Teleman, \u201cRelative quantum field theory,\u201d Commun. Math. Phys.\n326 (2014) 459\u2013476, arXiv:1212.1692 [hep-th].\n\n[60] D. Gaiotto, \u201cN=2 dualities,\u201d JHEP 08 (2012) 034, arXiv:0904.2715 [hep-th].\n\n[61] Y. Tachikawa, \u201cSix-dimensional D(N) theory and four-dimensional SO-USp quivers,\u201d\nJHEP 07 (2009) 067, arXiv:0905.4074 [hep-th].\n\n[62] O. Chacaltana and J. Distler, \u201cTinkertoys for Gaiotto Duality,\u201d JHEP 11 (2010) 099,\narXiv:1008.5203 [hep-th].\n\n[63] O. Chacaltana, J. Distler, and A. Trimm, \u201cTinkertoys for the Z3-twisted D4 Theory,\u201d\narXiv:1601.02077 [hep-th].\n\n[64] O. Chacaltana, J. Distler, A. Trimm, and Y. Zhu, \u201cTinkertoys for the E8 Theory,\u201d\narXiv:1802.09626 [hep-th].\n\n[65] O. Chacaltana, J. Distler, A. Trimm, and Y. Zhu, \u201cTinkertoys for the E7 theory,\u201d\nJHEP 05 (2018) 031, arXiv:1704.07890 [hep-th].\n\n[66] O. Chacaltana, J. Distler, and A. Trimm, \u201cTinkertoys for the Twisted E6 Theory,\u201d\narXiv:1501.00357 [hep-th].\n\n[67] O. Chacaltana and J. Distler, \u201cTinkertoys for the DN series,\u201d JHEP 02 (2013) 110,\narXiv:1106.5410 [hep-th].\n\n[68] O. Chacaltana, J. Distler, and A. Trimm, \u201cTinkertoys for the E6 theory,\u201d JHEP 09\n(2015) 007, arXiv:1403.4604 [hep-th].\n\n121\n\nhttp://arxiv.org/abs/2111.13564\nhttp://arxiv.org/abs/2111.13697\nhttp://arxiv.org/abs/2112.02092\nhttp://arxiv.org/abs/2112.09531\nhttp://dx.doi.org/10.1007/s00220-013-1880-1\nhttp://dx.doi.org/10.1007/s00220-013-1880-1\nhttp://arxiv.org/abs/1212.1692\nhttp://dx.doi.org/10.1007/JHEP08(2012)034\nhttp://arxiv.org/abs/0904.2715\nhttp://dx.doi.org/10.1088/1126-6708/2009/07/067\nhttp://arxiv.org/abs/0905.4074\nhttp://dx.doi.org/10.1007/JHEP11(2010)099\nhttp://arxiv.org/abs/1008.5203\nhttp://arxiv.org/abs/1601.02077\nhttp://arxiv.org/abs/1802.09626\nhttp://dx.doi.org/10.1007/JHEP05(2018)031\nhttp://arxiv.org/abs/1704.07890\nhttp://arxiv.org/abs/1501.00357\nhttp://dx.doi.org/10.1007/JHEP02(2013)110\nhttp://arxiv.org/abs/1106.5410\nhttp://dx.doi.org/10.1007/JHEP09(2015)007\nhttp://dx.doi.org/10.1007/JHEP09(2015)007\nhttp://arxiv.org/abs/1403.4604\n\n\n[69] O. Chacaltana, J. Distler, and A. Trimm, \u201cTinkertoys for the Twisted D-Series,\u201d JHEP\n04 (2015) 173, arXiv:1309.2299 [hep-th].\n\n[70] O. Chacaltana, J. Distler, and Y. Tachikawa, \u201cNilpotent orbits and codimension-two\ndefects of 6d N=(2,0) theories,\u201d Int. J. Mod. Phys. A 28 (2013) 1340006,\narXiv:1203.2930 [hep-th].\n\n[71] O. Chacaltana, J. Distler, and Y. Tachikawa, \u201cGaiotto duality for the twisted A2N\u22121\n\nseries,\u201d JHEP 05 (2015) 075, arXiv:1212.3952 [hep-th].\n\n[72] C. Beem and W. Peelaers, \u201cArgyres-Douglas Theories in Class S Without\nIrregularity,\u201d arXiv:2005.12282 [hep-th].\n\n[73] N. Drukker, D. R. Morrison, and T. Okuda, \u201cLoop operators and S-duality from\ncurves on Riemann surfaces,\u201d JHEP 09 (2009) 031, arXiv:0907.2593 [hep-th].\n\n[74] Y. Tachikawa, \u201cOn the 6d origin of discrete additional data of 4d gauge theories,\u201d\nJHEP 05 (2014) 020, arXiv:1309.0697 [hep-th].\n\n[75] A. Klemm, W. Lerche, P. Mayr, C. Vafa, and N. P. Warner, \u201cSelfdual strings and N=2\nsupersymmetric field theory,\u201d Nucl. Phys. B 477 (1996) 746\u2013766,\narXiv:hep-th/9604034.\n\n[76] S. Katz, P. Mayr, and C. Vafa, \u201cMirror symmetry and exact solution of 4-D N=2 gauge\ntheories: 1.,\u201d Adv. Theor. Math. Phys. 1 (1998) 53\u2013114, arXiv:hep-th/9706110.\n\n[77] S. Gukov, C. Vafa, and E. Witten, \u201cCFT\u2019s from Calabi-Yau four folds,\u201d Nucl. Phys. B\n584 (2000) 69\u2013108, arXiv:hep-th/9906070. [Erratum: Nucl.Phys.B 608, 477\u2013478\n(2001)].\n\n[78] A. D. Shapere and C. Vafa, \u201cBPS structure of Argyres-Douglas superconformal\ntheories,\u201d arXiv:hep-th/9910182.\n\n[79] S. S.-T. Yau and Y. Yu, \u201cClassification of 3-dimensional isolated rational hypersurface\nsingularities with c*-action,\u201d The Rocky Mountain Journal of Mathematics 35 no. 5,\n(2005) 1795\u20131809.\n\n[80] S. Cecotti, A. Neitzke, and C. Vafa, \u201cR-Twisting and 4d/2d Correspondences,\u201d\narXiv:1006.3435 [hep-th].\n\n[81] Y. Wang and D. Xie, \u201cClassification of Argyres-Douglas theories from M5 branes,\u201d\nPhys. Rev. D 94 no. 6, (2016) 065012, arXiv:1509.00847 [hep-th].\n\n122\n\nhttp://dx.doi.org/10.1007/JHEP04(2015)173\nhttp://dx.doi.org/10.1007/JHEP04(2015)173\nhttp://arxiv.org/abs/1309.2299\nhttp://dx.doi.org/10.1142/S0217751X1340006X\nhttp://arxiv.org/abs/1203.2930\nhttp://dx.doi.org/10.1007/JHEP05(2015)075\nhttp://arxiv.org/abs/1212.3952\nhttp://arxiv.org/abs/2005.12282\nhttp://dx.doi.org/10.1088/1126-6708/2009/09/031\nhttp://arxiv.org/abs/0907.2593\nhttp://dx.doi.org/10.1007/JHEP05(2014)020\nhttp://arxiv.org/abs/1309.0697\nhttp://dx.doi.org/10.1016/0550-3213(96)00353-7\nhttp://arxiv.org/abs/hep-th/9604034\nhttp://dx.doi.org/10.4310/ATMP.1997.v1.n1.a2\nhttp://arxiv.org/abs/hep-th/9706110\nhttp://dx.doi.org/10.1016/S0550-3213(00)00373-4\nhttp://dx.doi.org/10.1016/S0550-3213(00)00373-4\nhttp://arxiv.org/abs/hep-th/9906070\nhttp://arxiv.org/abs/hep-th/9910182\nhttp://arxiv.org/abs/1006.3435\nhttp://dx.doi.org/10.1103/PhysRevD.94.065012\nhttp://arxiv.org/abs/1509.00847\n\n\n[82] D. Xie and S.-T. Yau, \u201c4d N=2 SCFT and singularity theory Part I: Classification,\u201d\narXiv:1510.01324 [hep-th].\n\n[83] B. Chen, D. Xie, S.-T. Yau, S. S. T. Yau, and H. Zuo, \u201c4D N = 2 SCFT and\nsingularity theory. Part II: complete intersection,\u201d Adv. Theor. Math. Phys. 21 (2017)\n121\u2013145, arXiv:1604.07843 [hep-th].\n\n[84] Y. Wang, D. Xie, S. S. T. Yau, and S.-T. Yau, \u201c4d N = 2 SCFT from complete\nintersection singularity,\u201d Adv. Theor. Math. Phys. 21 (2017) 801\u2013855,\narXiv:1606.06306 [hep-th].\n\n[85] I. C. Davenport and I. V. Melnikov, \u201cLandau-Ginzburg skeletons,\u201d JHEP 05 (2017)\n050, arXiv:1608.04259 [hep-th].\n\n[86] B. Chen, D. Xie, S. S. T. Yau, S.-T. Yau, and H. Zuo, \u201c4d N = 2 SCFT and\nsingularity theory Part III: Rigid singularity,\u201d Adv. Theor. Math. Phys. 22 (2018)\n1885\u20131905, arXiv:1712.00464 [hep-th].\n\n[87] M. Akhond, G. Arias-Tamargo, A. Mininno, H.-Y. Sun, Z. Sun, Y. Wang, and F. Xu,\n\u201cThe Hitchhiker\u2019s Guide to 4d N = 2 Superconformal Field Theories,\u201d 12, 2021.\narXiv:2112.14764 [hep-th].\n\n[88] D. Xie, \u201cGeneral Argyres-Douglas Theory,\u201d JHEP 01 (2013) 100, arXiv:1204.2270\n\n[hep-th].\n\n[89] Y. Wang and D. Xie, \u201cCodimension-two defects and Argyres-Douglas theories from\nouter-automorphism twist in 6d (2, 0) theories,\u201d Phys. Rev. D 100 no. 2, (2019)\n025001, arXiv:1805.08839 [hep-th].\n\n[90] D. Gaiotto, G. W. Moore, and A. Neitzke, \u201cWall-crossing, Hitchin Systems, and the\nWKB Approximation,\u201d arXiv:0907.3987 [hep-th].\n\n[91] A. Hanany and E. Witten, \u201cType IIB superstrings, BPS monopoles, and\nthree-dimensional gauge dynamics,\u201d Nucl. Phys. B 492 (1997) 152\u2013190,\narXiv:hep-th/9611230.\n\n[92] E. Witten, \u201cSolutions of four-dimensional field theories via M theory,\u201d Nucl. Phys. B\n500 (1997) 3\u201342, arXiv:hep-th/9703166.\n\n[93] D. Nanopoulos and D. Xie, \u201cHitchin Equation, Irregular Singularity, and N = 2\nAsymptotical Free Theories,\u201d arXiv:1005.1350 [hep-th].\n\n123\n\nhttp://arxiv.org/abs/1510.01324\nhttp://dx.doi.org/10.4310/ATMP.2017.v21.n1.a2\nhttp://dx.doi.org/10.4310/ATMP.2017.v21.n1.a2\nhttp://arxiv.org/abs/1604.07843\nhttp://dx.doi.org/10.4310/ATMP.2017.v21.n3.a6\nhttp://arxiv.org/abs/1606.06306\nhttp://dx.doi.org/10.1007/JHEP05(2017)050\nhttp://dx.doi.org/10.1007/JHEP05(2017)050\nhttp://arxiv.org/abs/1608.04259\nhttp://dx.doi.org/10.4310/ATMP.2018.v22.n8.a2\nhttp://dx.doi.org/10.4310/ATMP.2018.v22.n8.a2\nhttp://arxiv.org/abs/1712.00464\nhttp://arxiv.org/abs/2112.14764\nhttp://dx.doi.org/10.1007/JHEP01(2013)100\nhttp://arxiv.org/abs/1204.2270\nhttp://arxiv.org/abs/1204.2270\nhttp://dx.doi.org/10.1103/PhysRevD.100.025001\nhttp://dx.doi.org/10.1103/PhysRevD.100.025001\nhttp://arxiv.org/abs/1805.08839\nhttp://arxiv.org/abs/0907.3987\nhttp://dx.doi.org/10.1016/S0550-3213(97)00157-0\nhttp://arxiv.org/abs/hep-th/9611230\nhttp://dx.doi.org/10.1016/S0550-3213(97)00416-1\nhttp://dx.doi.org/10.1016/S0550-3213(97)00416-1\nhttp://arxiv.org/abs/hep-th/9703166\nhttp://arxiv.org/abs/1005.1350\n\n\n[94] E. Witten, \u201cAdS / CFT correspondence and topological field theory,\u201d JHEP 12 (1998)\n012, arXiv:hep-th/9812012.\n\n[95] N. Seiberg and W. Taylor, \u201cCharge Lattices and Consistency of 6D Supergravity,\u201d\nJHEP 06 (2011) 001, arXiv:1103.0019 [hep-th].\n\n[96] E. Witten, \u201cGeometric Langlands From Six Dimensions,\u201d arXiv:0905.2720\n\n[hep-th].\n\n[97] G. W. Moore and N. Seiberg, \u201cPolynomial Equations for Rational Conformal Field\nTheories,\u201d Phys. Lett. B 212 (1988) 451\u2013460.\n\n[98] G. W. Moore and N. Seiberg, \u201cNaturality in Conformal Field Theory,\u201d Nucl. Phys. B\n313 (1989) 16\u201340.\n\n[99] G. W. Moore and N. Seiberg, \u201cClassical and Quantum Conformal Field Theory,\u201d\nCommun. Math. Phys. 123 (1989) 177.\n\n[100] G. W. Moore and N. Seiberg, \u201cTaming the Conformal Zoo,\u201d Phys. Lett. B 220 (1989)\n422\u2013430.\n\n[101] S. Elitzur, G. W. Moore, A. Schwimmer, and N. Seiberg, \u201cRemarks on the Canonical\nQuantization of the Chern-Simons-Witten Theory,\u201d Nucl. Phys. B 326 (1989) 108\u2013134.\n\n[102] G. W. Moore and N. Seiberg, \u201cLECTURES ON RCFT,\u201d in 1989 Banff NATO ASI:\nPhysics, Geometry and Topology. 9, 1989.\n\n[103] S. Cecotti, M. Del Zotto, and S. Giacomelli, \u201cMore on the N=2 superconformal\nsystems of type Dp(G),\u201d JHEP 04 (2013) 153, arXiv:1303.3149 [hep-th].\n\n[104] L. Bhardwaj, \u201cGlobal Form of Flavor Symmetry Groups in 4d N=2 Theories of Class\nS,\u201d arXiv:2105.08730 [hep-th].\n\n[105] S. Giacomelli, \u201cRG flows with supersymmetry enhancement and geometric\nengineering,\u201d JHEP 06 (2018) 156, arXiv:1710.06469 [hep-th].\n\n[106] F. Carta, S. Giacomelli, N. Mekareeya, and A. Mininno, \u201cConformal manifolds and 3d\nmirrors of Argyres-Douglas theories,\u201d JHEP 08 (2021) 015, arXiv:2105.08064\n\n[hep-th].\n\n[107] M. Martone and G. Zafrir, \u201cOn the compactification of 5d theories to 4d,\u201d JHEP 08\n(2021) 017, arXiv:2106.00686 [hep-th].\n\n124\n\nhttp://dx.doi.org/10.1088/1126-6708/1998/12/012\nhttp://dx.doi.org/10.1088/1126-6708/1998/12/012\nhttp://arxiv.org/abs/hep-th/9812012\nhttp://dx.doi.org/10.1007/JHEP06(2011)001\nhttp://arxiv.org/abs/1103.0019\nhttp://arxiv.org/abs/0905.2720\nhttp://arxiv.org/abs/0905.2720\nhttp://dx.doi.org/10.1016/0370-2693(88)91796-0\nhttp://dx.doi.org/10.1016/0550-3213(89)90511-7\nhttp://dx.doi.org/10.1016/0550-3213(89)90511-7\nhttp://dx.doi.org/10.1007/BF01238857\nhttp://dx.doi.org/10.1016/0370-2693(89)90897-6\nhttp://dx.doi.org/10.1016/0370-2693(89)90897-6\nhttp://dx.doi.org/10.1016/0550-3213(89)90436-7\nhttp://dx.doi.org/10.1007/JHEP04(2013)153\nhttp://arxiv.org/abs/1303.3149\nhttp://arxiv.org/abs/2105.08730\nhttp://dx.doi.org/10.1007/JHEP06(2018)156\nhttp://arxiv.org/abs/1710.06469\nhttp://dx.doi.org/10.1007/JHEP08(2021)015\nhttp://arxiv.org/abs/2105.08064\nhttp://arxiv.org/abs/2105.08064\nhttp://dx.doi.org/10.1007/JHEP08(2021)017\nhttp://dx.doi.org/10.1007/JHEP08(2021)017\nhttp://arxiv.org/abs/2106.00686\n\n\n[108] S. Cabrera, A. Hanany, and F. Yagi, \u201cTropical Geometry and Five Dimensional Higgs\nBranches at Infinite Coupling,\u201d JHEP 01 (2019) 068, arXiv:1810.01379 [hep-th].\n\n[109] A. Bourget, J. F. Grimminger, A. Hanany, M. Sperling, G. Zafrir, and Z. Zhong,\n\u201cMagnetic quivers for rank 1 theories,\u201d JHEP 09 (2020) 189, arXiv:2006.16994\n\n[hep-th].\n\n[110] S. Cremonesi, G. Ferlito, A. Hanany, and N. Mekareeya, \u201cCoulomb Branch and The\nModuli Space of Instantons,\u201d JHEP 12 (2014) 103, arXiv:1408.6835 [hep-th].\n\n[111] A. Dey, A. Hanany, P. Koroteev, and N. Mekareeya, \u201cOn Three-Dimensional Quiver\nGauge Theories of Type B,\u201d JHEP 09 (2017) 067, arXiv:1612.00810 [hep-th].\n\n[112] P. Longhi and C. Y. Park, \u201cADE Spectral Networks,\u201d JHEP 08 (2016) 087,\narXiv:1601.02633 [hep-th].\n\n[113] W. Lerche and N. P. Warner, \u201cExceptional SW geometry from ALE fibrations,\u201d Phys.\nLett. B 423 (1998) 79\u201386, arXiv:hep-th/9608183.\n\n[114] T. Eguchi, N. P. Warner, and S.-K. Yang, \u201cADE singularities and coset models,\u201d Nucl.\nPhys. B 607 (2001) 3\u201337, arXiv:hep-th/0105194.\n\n125\n\nhttp://dx.doi.org/10.1007/JHEP01(2019)068\nhttp://arxiv.org/abs/1810.01379\nhttp://dx.doi.org/10.1007/JHEP09(2020)189\nhttp://arxiv.org/abs/2006.16994\nhttp://arxiv.org/abs/2006.16994\nhttp://dx.doi.org/10.1007/JHEP12(2014)103\nhttp://arxiv.org/abs/1408.6835\nhttp://dx.doi.org/10.1007/JHEP09(2017)067\nhttp://arxiv.org/abs/1612.00810\nhttp://dx.doi.org/10.1007/JHEP08(2016)087\nhttp://arxiv.org/abs/1601.02633\nhttp://dx.doi.org/10.1016/S0370-2693(98)00106-3\nhttp://dx.doi.org/10.1016/S0370-2693(98)00106-3\nhttp://arxiv.org/abs/hep-th/9608183\nhttp://dx.doi.org/10.1016/S0550-3213(01)00263-2\nhttp://dx.doi.org/10.1016/S0550-3213(01)00263-2\nhttp://arxiv.org/abs/hep-th/0105194\n\n\t1 Introduction\n\t2 Relative Defects and Relative Theories\n\t2.1 Relative Theories\n\t2.2 Absolute Theories from Relative Theories\n\t2.3 Relative Defects in Absolute Theories\n\t2.4 Relative Defects in Relative Theories\n\t2.5 Relative Defects in 6d (2,0) Theories\n\t2.6 Compactification: Relative Theories from Relative Defects\n\n\t3 Evidence for Trapped 1-Form Symmetries\n\t3.1 The Defect Group of Type IIB on IHS\n\t3.2 Collisions of Regular Punctures\n\n\t4 1-Form Symmetries of Arbitrary Class S Theories\n\t4.1 The Defect Group of a Puncture\n\t4.2 Defect Groups of Special Punctures\n\t4.3 Defect Groups of Class S Theories from Defect Groups of Punctures\n\n\t5 Computing Defect Groups of Punctures\n\t5.1 Special Class S Theories Associated to a Puncture\n\t5.2 Generalized Quivers: Classes GQ and GQ'\n\t5.3 Spectral Cover Monodromies and ALE Fibrations in IIB\n\n\t6 Type IIB on Canonical Singularities and Irregular Punctures\n\t6.1 Untwisted Punctures\n\t6.2 Twisted Punctures\n\t6.3 Extracting the IHS for twisted A3\n\t6.4 IHS for twisted irregular punctures\n\t6.4.1 Twisted Aodd theories\n\t6.4.2 Twisted Aeven theories\n\t6.4.3 Twisted DN+1 theories\n\t6.4.4 Z3-twisted D4 theories\n\t6.4.5 Twisted E6 theories\n\n\t6.5 IHS for Trinions\n\t6.5.1 Trinions of Dpb(G) Theories from Type IIB\n\t6.5.2 The Defect Group of Trinions from Punctures\n\n\n\t7 Untwisted A\n\t7.1 Punctures\n\t7.2 1-Form Symmetry from Class GQ\n\t7.3 Class GQ' \u2013 Type IIA Punctures\n\t7.4 Checks Via Circle Reduction \u2013 Electric Quiver EQ4\n\t7.5 Spectral Cover Monodromies\n\t7.6 Trapped Defect Group from Type IIB on CY3\n\n\t8 Untwisted D\n\t8.1 Punctures\n\t8.2 Class GQ of Generalized Quivers\n\t8.2.1 Class GQ' and Type IIA Punctures\n\n\t8.3 The C(m) and D(m) SCFTs\n\t8.3.1 The C(m) SCFT\n\t8.3.2 The D(m) SCFT\n\n\t8.4 1-Form Symmetries\n\t8.5 Spectral Cover Monodromies\n\t8.6 Trapped Defect Group from Type IIB on CY3\n\t8.6.1 Trapped Parts of IHS Punctures\n\t8.6.2 Trinions\n\n\n\t9 Twisted D\n\t9.1 Punctures\n\t9.2 Class GQ of Generalized Quivers\n\t9.2.1 Class GQ' and Type IIA Punctures\n\n\t9.3 1-Form Symmetries\n\t9.4 Spectral Cover Monodromies\n\t9.5 Trapped Defect Group from Type IIB on CY3\n\n\t10 Untwisted E\n\t10.1 Spectral Covers and Weights Systems\n\t10.2 Spectral Cover Monodromies\n\t10.3 Trapped Defect Group from Type IIB on CY3\n\n\t11 Conclusions and Outlook\n\tA Glossary\n\tA.1 Glossary for Sections 2.1 and 2.2\n\tA.2 Glossary for Section 2.4\n\tA.3 Glossary for the Rest of the Paper\n\n\tB Spectral Cover Monodromies\n\n"}
{"Title": "FACET: A new long-lived particle detector in the very forward region of the CMS experiment", "Authors": "S. Cerci, D. Sunar Cerci (1 and 2), D. Lazic (3), G. Landsberg (4), F. Cerutti, M. Sabate-Gilarte (5), M.G. Albrow, J. Berryhill, D.R. Green, J. Hirschauer (6), S. Kulkarni (7), J.E. Brucken (8), L. Emediato, A. Mestvirishvili, J. Nachtman, Y. Onel, A. Penzo (9), O. Aydilek, B. Hacisahinoglu, S. Ozkorucuklu, H. Sert, C. Simsek, C. Zorbilmez (2), I. Hos (10 and 2), N. Hadley, A. Skuja (11), M. Du, R. Fang, Z. Liu (12), B. Isildak (13 and 2), V.Q. Tran (14) ((1) Adiyaman Univ., (2) Istanbul Univ., (3) Boston Univ., (4) Brown Univ., (5) CERN, (6) Fermilab, (7) Univ. Graz, (8) Helsinki Inst. Phys., (9) Univ. Iowa, (10) Istanbul Univ.-Cerrahpasa, (11) Univ. Maryland, (12) Univ. Nanjing, (13) Ozyegin Univ., (14) Tsung-Dao Lee Inst., Shanghai)", "Abstract": "  We describe a proposal to add a set of very forward detectors to CMS for the high-luminosity era of the Large Hadron Collider to search for beyond the standard model long-lived particles, such as dark photons, heavy neutral leptons, axion-like particles, and dark Higgs bosons. The proposed subsystem is called FACET for Forward-Aperture CMS ExTension, and will be sensitive to any particles that can penetrate at least 50 m of magnetized iron and decay in an 18 m long, 1 m diameter vacuum pipe. The decay products will be measured in detectors using identical technology to the planned CMS Phase-2 upgrade.      ", "Subject": "High Energy Physics - Experiment (hep-ex)", "ID": "arXiv:2201.00019", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFACET: A new long-lived particle detector\n\nin the very forward region of the CMS experiment\n\nS. Cerci\u2020, D. Sunar Cerci\u2020 (Adiyaman Univ.), D. Lazic (Boston Univ.),\nG. Landsberg\u2217 (Brown Univ.), F. Cerutti, M. Sabate\u0301-Gilarte (CERN),\n\nM.G. Albrow\u2217, J. Berryhill, D.R. Green, J. Hirschauer (Fermilab),\nS. Kulkarni (Univ. Graz), J.E. Bru\u0308cken (Helsinki Inst. Phys.),\n\nL. Emediato, A. Mestvirishvili, J. Nachtman, Y. Onel, A. Penzo (Univ. Iowa),\nO. Aydilek, B. Hacisahinoglu, S. Ozkorucuklu\u2217, H. Sert, C. Simsek,\nC. Zorbilmez (Istanbul Univ.), I. Hos\u2020 (Istanbul Univ.-Cerrahpasa),\n\nN. Hadley, A. Skuja (Univ. Maryland), M. Du, R. Fang, Z. Liu (Univ. Nanjing),\nB. Isildak\u2020 (Ozyegin Univ.), V.Q. Tran (Tsung-Dao Lee Inst., Shanghai)\n\n\u2020Also at Istanbul Univ.\n\n\u2217Contacts: albrow@fnal.gov, greg.landsberg@cern.ch, suat.ozkorucuklu@cern.ch\n\nJanuary 4, 2022\n\nAbstract\n\nWe describe a proposal to add a set of very forward detectors to CMS for the high-luminosity\nera of the Large Hadron Collider to search for beyond the standard model long-lived particles,\nsuch as dark photons, heavy neutral leptons, axion-like particles, and dark Higgs bosons. The\nproposed subsystem is called FACET for Forward-Aperture CMS ExTension, and will be\nsensitive to any particles that can penetrate at least 50 m of magnetized iron and decay in an\n18 m long, 1 m diameter vacuum pipe. The decay products will be measured in detectors using\nidentical technology to the planned CMS Phase-2 upgrade.\n\n1 Introduction\n\nThe existence of dark matter (DM) is well established from astronomical observations and cosmol-\nogy. Dark matter is generally assumed to consist of particles beyond the standard model (BSM).\nWhile searches for such particles in the TeV region continue at the CERN Large Hadron Collider\n(LHC), the possibility that new particles may be relatively light (.50 GeV), and yet have escaped\ndetection so far because of very weak coupling to standard model (SM) particles, is receiving con-\nsiderable attention, as discussed in, e.g., Refs. [1\u20133]. There are many possible so-called portals;\nthese are neutral particles that couple weakly to the SM and also to DM particles (but being un-\nstable are not themselves DM candidates), such as dark photons [4\u20136], heavy neutral leptons [7,8],\naxion-like particles [9\u201311], and scalars or dark Higgs particles [12,13]. The proposed new CMS sub-\nsystem, FACET (Forward-Aperture CMS ExTension), can search for many such portals (called\nhere X0) depending only on their forward production cross section, momentum, mass mX0 , and\nproper lifetime c\u03c4 . We will show that FACET covers a region of parameter space not accessible to\nother experiments, neither existing nor proposed.\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n01\n\n9v\n1 \n\n [\nhe\n\np-\nex\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\n\n\nLow-mass particles typically imply production peaking in the forward direction. However, even\ndecay products of a 125 GeV Higgs boson (H(125)) can have small enough polar angle \u03b8 to reach\nFACET [14]. Small couplings often imply long lifetimes, hence the focus on searches for long-lived\nparticles (LLPs) that can manifest as displaced vertices, e.g., in the large central detectors at the\nLHC.\n\nLonger lifetimes can be probed in the LHC experiment FASER (Run 3) [15, 16] in the beam\ndirection (\u03b8 = 0\u25e6) at a distance z = 480 m from the collision point, and proposed experiments for\nthe high-luminosity LHC era, such as MATHUSLA [17, 18], CODEX-b [19] and FASER-2 [20, 21].\nFixed-target experiments, such as NA62 [22, 23] at the CERN SPS, have sensitivity especially for\ndark photons with mass less than 1 GeV from \u03c00, \u03b7, and \u03b7\u2032 meson decays.\n\nFACET is not proposed to be a new experiment, but a new subsystem of the CMS experiment\nthat, while overlapping in the parameter space with other searches, will cover an extended and\nunique region. FACET will be sensitive to particles produced with polar angle 1 < \u03b8 < 4 mrad\n(equivalently 7.6 > \u03b7 > 6.2). It is closer to the interaction region (IP5) than FASER-2 (at IP1),\nwith four times the solid angle. FACET has an 18 m long decay volume from z = 101 to 119 m,\nfollowed by an 8 m long region instrumented with various particle detectors. FACET covers a range\nof proper lifetimes c\u03c4 of \u223c0.1\u2013100 m. We note that the Lorentz factor \u03b3 is typically high in the\nforward direction. A unique feature among the LHC experiments is that the decay volume is at\nhigh vacuum (LHC quality, as it is part of the LHC beam pipe), eliminating any background from\nparticle interactions inside a \u223c14 m3 fiducial region.\n\nSmall couplings also imply the ability of an LLP to penetrate a large amount of absorbing\nmaterial. Between IP5 and the decay volume LLPs have to penetrate 35\u201350 m (200\u2013300 \u03bbint)\nof magnetized iron in the LHC quadrupole magnets Q1\u2013Q3 and the new (for Run 4) 35 T\u00b7m\nsuperconducting dipole D1. Since neutrinos are the only SM particles that can penetrate that\nmuch absorber, essentially all the SM backgrounds having direct paths from the IP are eliminated.\nNevertheless, the detectors are in a region with high radiation levels and particle showers from\nupstream interactions in the beam pipe and surrounding material. The design of FACET takes\nthese challenges into account.\n\n2 FACET as a new Subsystem of CMS\n\nA schematic view of the detector is shown in Fig. 1. The project requires that an 18 m long section\nof the LHC beam pipe, between z = 101 and 119 m on one side of the IP5 collision region be replaced\nwith a circular pipe of a 50 cm radius1. The transition from R = 10.6 to 50 cm is a \u223c45\u25e6 cone to\nmitigate the beam impedance mismatch. This section is downstream of the focusing quadrupole\nmagnets and beam separation dipole magnet D1. Additional shielding will be placed upstream of\nthe first detector, which is a multilayer counter hodoscope, made of radiation-hard scintillator or\nquartz bars and/or pads. The hodoscope must have very high efficiency to tag charged particles\nfrom interactions in the upstream shielding, most of which have large enough polar angles to miss\nthe tracker.\n\nDedicated fluka [24, 25] simulation predicts that with the present design there will be \u223c30\ncharged particles in the tracker per bunch crossing, most of which have large enough polar angles\nto miss the tracker. These are all background tracks, which are ignored in the subsequent analysis.\nThe fluka simulation also predicts that there will be, on average, one neutral hadron (mostly\nK0 or \u039b) decaying inside the decay volume. All bunch crossings will be examined for candidate\ndecays inside the vacuum volume, giving a sensitivity to an integrated luminosity of \u223c3 ab\u22121 in\n\n1A large beam pipe with a similar radius already exists downstream of the ALICE experiment.\n\n2\n\n\n\nthe high-luminosity LHC era. The highly segmented upstream hodoscope, precision tracking, and\nimaging calorimetry will reduce these backgrounds to very low levels, even eliminating them in some\nchannels, as discussed below. In addition, we are investigating the possibility to further mitigate\nthese backgrounds by installing additional shielding closer to the D1 dipole and possibly shortening\nthe vacuum decay volume by 1\u20132 m to make space for more shielding, including a magnetized iron\ntoroid, in front of the hodoscope.\n\nFigure 1: Schematic layout of the proposed FACET spectrometer. Side view and top view are\nessentially the same since it is azimuthally symmetric. Upstream (to the left) is the IP5 collision\nregion followed by the machine elements Q1\u2013Q3 and D1 comprising 35\u201350 m of iron shielding. The\nTAXN limits the extension in the z direction; it provides shielding for the superconducting LHC\nelements downstream. The superimposed red dashed line shows schematically an LLP from the\nIP5 decaying into two charged tracks shown in blue.\n\nThe back end of the enlarged beam pipe, where it transitions from R = 50 to 18 cm, is a thin\n(\u223c0.5 mm) beryllium window to minimize multiple scattering of the charged particles. Strengthen-\ning ribs can cover .2% of the area. An internal wire cone mitigates impedance mismatch. Behind\nthat window (in air) precision tracking, high-granularity electromagnetic and hadron calorimetry,\nand a toroidal magnet interspersed with tracking detectors measure charged-particle tracks and\nidentify and measure the energies of photons, electrons, hadrons, and muons. There is no mag-\nnetic field between the X0 decay and the precision tracker, making accurate reconstruction of\ndecay vertices simple. A layer of fast timing with Low-Gain Avalanche Detectors, LGADs, will be\nincluded. This high-resolution timing, with \u03c3t \u223c 30 ps, will be used to reduce backgrounds from\ninteractions in upstream material, providing vertex positioning in 4D (x, y, z, t), and a time-of-flight\nmeasurement for candidates.\n\nThe tracking is followed by electromagnetic and hadron calorimetry, using identical technology\nto the CMS HGCAL (High-Granularity Calorimeter) [26] planned for the forward direction in the\n\n3\n\n\n\nCMS Phase-2 upgrade. Copper or tungsten plates interspersed with silicon pads provide imaging in\n4D. The high granularity is important to measure individual showers above a threshold energy (e.g.,\n10 GeV, but tunable) and their directions in the presence of many low-energy showers. Behind\nthe calorimeter, an iron toroid with magnetic field of B \u223c 1.75 T instrumented with additional\nsilicon tracking measures the charge of muons and allows an approximate measurement of the muon\nmomentum and the dimuon mass for any muon pairs. Muons are also detected through the active\nlayers of the calorimeter.\n\nThe approximate number of channels in the FACET detector amounts to about 5% of that\nfor the CMS Phase-2 upgrade, making the detector relatively inexpensive, as most of it could be\nbuilt using the same modules as are going to be used for the central CMS detector upgrade, thus\nminimizing the R&D and engineering needs.\n\n3 Sensitivity to Long-Lived Particles\n\nThe reach in LLP parameter space has been calculated for dark photons, heavy neutral leptons,\naxion-like particles, and dark Higgs bosons in several benchmark scenarios. Predictions are generally\nmodel dependent and some also depend on the nature of other BSM particles, e.g., a heavy Z \u2032\n\nboson and its mass. We base these studies on a total integrated luminosity of 3 ab\u22121 of proton-\nproton collisions at a center-of-mass energy\n\n\u221a\ns = 14 TeV, with either 3 or 5 candidate events,\n\nassuming no background and that FACET can detect all penetrating neutral particle decays to \u2265 2\ncharged particles or photons occurring between 101 < z < 119 m with the decay products within\n18 < R < 50 cm at z = 120 m.\n\n3.1 Dark Photons\n\nMassive dark photons A\u2032 are neutral gauge bosons, which are not directly charged under SM gauge\ngroups. However, they can interact with SM particles via mixing with photons. A recent review\ncan be found in Ref. [5]. A massive virtual photon produced by any process in a hadron-hadron\ncollision has some probability of conversion to an A\u2032, governeed by the kinetic mixing parameter\n\u03b5. If mA\u2032 . 1 GeV, the most prolific source will be decays of \u03c00, \u03b7, and \u03b7\u2032 mesons. The fluxes of\nthese particles are highest at small polar angles.\n\nFig. 2 shows limits calculated using foresee [27] without assuming any other BSM sources of\ndark photons, such as a heavy Z \u2032 bosons, which can extend the mass range and require the energy\nof the LHC.\n\nFor mA\u2032 > 1 GeV the main production mechanisms are: q+ q\u0304 \u2192 A\u2032+X; Drell\u2013Yan: q+ q\u0304 \u2192 A\u2032;\nbremsstrahlung: p \u2192 A\u2032 + p and q \u2192 A\u2032 + q; and heavy-quark decays: c \u2192 A\u2032 + X, b \u2192 A\u2032 + X.\nThe decay modes to SM particles of a minimal dark photon are the same as the final states in\ne+e\u2212 \u2192 \u03b3\u2217 at\n\n\u221a\ns = mA\u2032 .\n\nA comparison of the FACET and other experiments dark photon reach for all final states in the\nmodel of Ref. [43] is given in Fig. 3 (left). In this model, the main production mechanism of dark\nphotons is via radiation in a rather rich hidden sector, which contains a Dirac fermion \u03c8 and two\ngauge bosons, which mix with the SM weak hypercharge field B\u00b5. FACET covers a unique region\nof the mixing parameter \u03b51 vs. mass (or alternatively lifetime vs. mass) phase space. Figure 3\n(right) shows the number of events as a function of lifetime c\u03c4 for three A\u2032 masses for the model\nparameters corresponding to the reach shown in Fig. 3 (left).\n\n4\n\n\n\n10 2 10 1 100\n\nDark Photon Mass mA \u2032 [GeV]\n10 8\n\n10 7\n\n10 6\n\n10 5\n\n10 4\n\n10 3\n\nKi\nne\n\ntic\n M\n\nix\nin\n\ng \n\nSeaQuest\nNA62\n\nSHiP\n\nHPS Belle II\n\nLHCb LHCb\n\nE137 CHARM\n\nNuCal\n\nE141\n\nNA64\n\nBaBarNA48\n\nFASER-2\n\nFACET\n\nDark Photons\n\nFigure 2: FACET reach for dark photons in a generic model with no BSM sources, as calculated\nwith Foresee [27]. Existing bounds (gray shaded regions) are taken from CHARM (following\nRef. [28]), BaBar [28], E137 [29], E141 [30], LHCb [31], NA48/2 [32], NA64 [33], and NuCal [34],\nalong with the prospective limits taken from studies performed for Belle II [35], HPS [36, 37],\nLHCb [38,39], NA62 [40], SeaQuest [41], FASER-2 [27], and SHiP [42].\n\n10\u22122 10\u22121 100 101 102\n\nc\u03c4 (m)\n\n10\u22122\n\n10\u22121\n\n100\n\n101\n\n102\n\nN FACET\n\nN=5\n\nm\u03c8 = 15GeV, \u03b52 = 0.01,L = 3ab\u22121\n\nmA\u2032 =2 GeV\n\nmA\u2032 =4 GeV\n\nmA\u2032 =10 GeV\n\nFigure 3: Left: FACET reach for dark photons (5 event contours) in the parameter space of coupling\n\u03b51 and mass mA\u2032 in the model of Ref. [43]. Of the other projects shown, only FASER and MTD,\nthe CMS Phase-2 MIP Timing Detector, are currently approved. Right: Number of dark photon\nevents as a function of c\u03c4 for mA\u2032 = 2, 4, and 10 GeV in this model.\n\n5\n\n\n\n3.2 Heavy Neutral Leptons\n\nMany extensions of the SM involve heavy right-handed neutrinos or heavy neutral leptons Ni (where\nthe subscript i indicates flavor), which may explain the light neutrino masses through the seesaw\nmechanism [8,44,45]. They may be produced in any kinematically allowed SM weak leptonic decay,\ne.g., of s, c, b, t quarks, or W or Z bosons. We consider a specific extension of the SM model [46],\nwith a Z \u2032 boson (which can be light and yet have escaped detection due to the small coupling\nto SM particles) and three heavy right-handed Majorana neutrinos Ni. In this model, the decay\nZ \u2032 \u2192 NiNi is allowed, and the Ni can be long-lived and decay to SM particles, e.g., a lepton of\nthe same flavor and a virtual W \u2217 or Z\u2217 boson. For the Z \u2032 masses in the 10\u2013100 GeV range, most\ninteresting in this model, the branching fraction of the Z \u2032 \u2192 NiNi decays amounts to about 20%,\ni.e., rather large and similar to that for the Z boson decays into SM neutrinos.\n\nFigure 5: FACET reach in the coupling-mass plane for heavy neutral leptons [22]. Only LHCb is\nan approved experiment.\n\n5 Backgrounds190\n\nFACET is unique among all LHC LLP searches in having a very large volume of LHC-quality191\n\nvacuum for decays. Vertices with two or more associated tracks from well inside a fiducial volume192\n\n(with R > 15 cm) cannot have come from interactions; they must be due to decays1. Our goal is193\n\nto have no background events even with 3 ab\ufffd1 of integrated luminosity in many decay channels;194\n\nin which case even a few events can constitute a discovery.195\n\nThe direct path from the collision region to the decay volume has more than 200 \ufffdint of magnetised196\n\niron, e\u21b5ectively eliminating all SM particles, except neutrinos. Therefore the only SM particles197\n\nentering the decay volume are indirect, from interactions in the beam pipe and LHC components198\n\n(mainly protons, neutrons and muons). The fluka code, the standard for LHC background199\n\ncalculations, predicts that there will be about one neutral hadron and \u21e0 1.9 \u00b5\u00b1 entering the200\n\nvacuum decay volume at R > 12.5 cm per bunch crossing.201\n\nNeutral hadrons of concern are K0\nS , K0\n\nL, \u21e40 and \u23050. Their decay tracks can be well measured202\n\nand their energies determined in the calorimeter. A Monte Carlo simulation shows that the parent203\n\nmass and direction can be reconstructed with this information. Requiring the parent to point204\n\nback to the interaction region, and using decay position information (flat in z for an LLP) will205\n\nreduce this neutral hadron background, that may still be overwhelming for X0 ! h+h\ufffd with206\n\nM(X0) . 0.8 GeV.207\n\nThe situation is much better for lepton pairs. Only K0 decays can contribute, either through both208\n\ncharged pions being misidentified as electrons or as muons, or by genuine dilepton decays, all of209\n\nwhich have very small branching fractions B < 10\ufffd8. The K0\nL has common semileptonic decays210\n\nto \u21e1\u00b1e\u2325\u232be and \u21e1\u00b1\u00b5\u2325\u232be, so only one \u21e1\u00b1 has to be misidentified as a lepton. The missing neutrino211\n\nsmears the pointing from the IR, the reconstructed mass is a continuum with M(X0) < 500 MeV,212\n\nand the z distribution of the vertex is not flat as it would be for an LLP.213\n\nIn 2\u21e51015 bunch crossings (3 ab\ufffd1) we expect several thousand true K0\nL ! \u00b5+\u00b5\ufffd decays in the214\n\n1Interactions of beam bunches with residual gas molecules in the LHC during the HL-LHC are actively being\nstudied [29].\n\n7\n\n10-2\n,._.....-,---,-\ufffd...,........,----.-----,-\ufffd----.-\ufffd\ufffd--,---.-...,........,----.-----,-\ufffd\ufffd....--,\n\nPessimistic CMSJl'. HCb background \ngB-L=lO- , mz=3XmN\n\nMATHUSLA \n\n1 o-7 L_L......,_\ufffd-'------'-\ufffd\ufffd-'-------'--\ufffd\ufffd:::::::\ufffdc:D.o.\ufffd_._J \n\n5 10 15 20 25 30 \n\nm  [GeV] N\n\nFigure 4: FACET reach in the mixing parameter vs. mass plane for a heavy neutral lepton, along\nwith projections for other proposed experiments, as well as for MAPP and the upgraded LHCb\ndetectors [46].\n\nFig. 4 shows the coverage in the mixing parameter |V\u00b5N | vs. mN plane in the case of a single\nMajorana neutrino N mixed with a muon neutrino. In this case, FACET has a unique sensitivity\nat high masses, above \u223c15 GeV for lifetimes c\u03c4 between \u223c0.1 and \u223c100 m.\n\n3.3 Axion-Like Particles\n\nPseudoscalar particles, such as extremely light axions, were initially proposed to solve the strong\nCP -problem of QCD. More massive axion-like particles (ALPs, a) may exist, and if produced at\nthe LHC [11,47], they may decay with long lifetimes into photon pairs (or \u03b3e+e\u2212) or lepton pairs,\nafter penetrating thick absorbers. FACET will be well-placed to discover such ALPs in certain\nregions of their mass and the coupling to SM gauge bosons. An overview of the FACET reach for\nALPs is given in Fig. 5 in a specific W -dominance ALP model [48, 49], as a function of the ALP\nmass and the coupling to W bosons, gaWW .\n\n6\n\n\n\n10 1 100\n\nALP ma [GeV]\n\n10 7\n\n10 6\n\n10 5\n\n10 4\n\n10 3\n\ng a\nW\n\nW\n [G\n\neV\n1 ]\n\nBelle2 3KOTO 2\nKOTO 4\n\nNA62 0\n\nNA62 2\n\nLHC Z 3\n\nSN1987\n\nE137\n\nBaBar\n\nLEP\n\nE949\n\nNA\n62\n\n+\n\nNA62\n\nKOTO\n\nKT\nEV\n\nNA\n48\n\n/2\n\nE949\n\nCDF\n\n           ALPs (W dominance)\n\nFACET\nFASER-2\n\nFigure 5: FACET sensitivity to ALPs in the W -dominance model, as a function of mass and\ncoupling, as calculated with Foresee [27]. The gray-shaded regions are excluded by current\nbounds, while dashed lines correspond to projected sensitivity of various experiments, as calculated\nin Refs. [48, 49]. The BaBar limits are from Ref. [50]. More details can be found in Refs. [51, 52]\nand references therein.\n\n3.4 Dark Higgs Bosons\n\nThe possible existence of a dark sector partner \u03c6 of the 125 GeV Higgs boson has attracted attention,\nas discussed, e.g., in Refs. [12,13,63]. A dark Higgs field provides a simple mechanism to give mass\nto the dark photon A\u2032. The corresponding dark Higgs boson \u03c6 may be the lightest dark sector\nstate and can decay into SM particles via mixing with the Higgs boson, governed by the mixing\nangle \u03b8. Unitarity and perturbativity suggest that the dark Higgs boson cannot be much heavier\nthan the dark gauge boson A\u2032, while it can be significantly lighter. The dark Higgs boson can be\nvery long-lived due to its suppressed couplings to the accessible light SM states.\n\nFor mass ranges below \u223c5 GeV the dominant production mechanism is through B meson decays,\ne.g., B \u2192 K + \u03c6, with \u03c6 decaying to pairs of most massive SM fermions accessible kinematically,\ne.g., to a pair of muons for light \u03c6, or to a pair of \u03c4 leptons or charm quarks for a heavier \u03c6. A\nheavier \u03c6 may also decay to another pair of new scalars, s, which may in turn be LLPs.\n\nThe reach of FACET for a dark Higgs boson decaying to a detectable final state is given in\nFig. 6. In addition to the production via B meson decays (left plot), we also consider the case of\na small, non-zero trilinear coupling \u03c6\u03c6H between the SM Higgs and dark Higgs bosons, resulting\nin a 2.5% branching fraction of the H(125) \u2192 \u03c6\u03c6 decay (right plot). This value is lower than the\nprojected limits on the BSM Higgs boson decay branching fraction at the high-luminosity LHC [64].\nIn this case, the low-mass reach is slightly improved compared to the case with no trilinear coupling,\nas a new decay mode b\u2192 s\u03c6\u03c6, where b and s is are the bottom and strange quarks, respectively, is\npresent due to a virtual Higgs boson exchange [13]. However, the most striking feature in this model\n\n7\n\n\n\n10 1 100\n\nDark Higgs Mass m  [GeV]\n\n10 6\n\n10 5\n\n10 4\n\n10 3\n\n10 2\nM\n\nix\nin\n\ng \n\nSHiP\n\nMATHUSLA\n\nCodexB\n\nLHCb\n\nLH\nCb\n\n B\n0\n\nLH\nCb\n\n B\n+\n\nLH\nCb\n\n B\n+\n\nLS\nND\n\nCH\nAR\n\nM\n\nBo\noN\n\nE\n\nE9\n49\n\nNA\n62\n\n K\n+\n\nNA\n62\n\n \n+\n\nDark Higgs\n\nFACET\nFASER-2\n\n10 1 100 101\n\nDark Higgs Mass m  [GeV]\n\n10 8\n\n10 7\n\n10 6\n\n10 5\n\n10 4\n\n10 3\n\n10 2\n\nM\nix\n\nin\ng \n\nSHiP\n\nMATHUSLA\n\nCodexB\n\nLHCb\n\nLH\nCb\n\n B\n0\n\nLH\nCb\n\n B\n+\n\nLH\nCb\n\n B\n+\n\nLS\nND\n\nCH\nAR\n\nM\n\nBo\noN\n\nE\nE9\n\n49\n\nNA\n62\n\n K\n+\n\nNA\n62\n\n \n+\n\nDark Higgs\n\nFASER-2, (H )=2.5%\nFACET, (H )=2.5%\n\nFigure 6: Reach of FACET and other existing and proposed experiments for a dark Higgs boson\n\u03c6 with the assumption of either 0% (left) or 2.5% (right) branching fraction for the H(125)\u2192 \u03c6\u03c6\ndecays. In the second scenario, FACET offers a unique coverage all the way to half mH for a\nrange of mixing angles. FACET and FASER-2 contours are calculated with Foresee [27]. Current\nexclusions from NA62 [53], BNL-E949 [54], LHCb [55,56], CHARM [57], LSND [58], MicroBooNE\n[59] are shown as gray shaded regions. Also, sensitivity from studies for MATHUSLA [60], CODEX-\nb [61], LHCb upgrade [61], and SHiP [62] are shown.\n\nis that FACET offers a unique sensitivity for the dark Higgs boson masses up to the kinematic limit\nof mH/2 due to a large number of Higgs bosons that are produced at the high-luminosity LHC with\na significant longitudinal boost, resulting in at least one of the two dark Higgs bosons decaying\nwithin the FACET detector acceptance [14].\n\n4 Triggers\n\nAs a part of the CMS Phase-2 Upgrade at the high-luminosity LHC, the Level-1 (L1) trigger system\nwill be upgraded, with a latency increased to 12.5 \u00b5s and output rate to the High-Level Trigger\n(HLT) increased to 750 kHz. The HLT will analyse the data with close to off-line performance,\nsending data to long-term storage at a rate of about 7.5 kHz. FACET will provide an additional\nexternal trigger to the CMS L1 Global Trigger, built from the hodoscope, tracking, calorimeter,\nand muon detector information, and using the same hardware and code to be used in the upgraded\nCMS detectors.\n\nThe L1 triggers will be formed from, among others:\n\n1. \u2265 2 tracks with a small distance of closest approach inside a decay volume;\n\n2. \u2265 2 muon tracks through the toroidal spectrometer;\n\n3. \u2265 1 cluster of energy in the electromagnetic calorimeter above some threshold and with a\ndirection requirement based on the tracker and/or the calorimeter;\n\n4. \u2265 1 cluster of energy in the hadron calorimeter above some threshold and with a direction\nrequirement based on the tracker.\n\n8\n\n\n\nTo achieve maximum sensitivity for the LLP search, FACET will be exposed to all bunch\ncrossings. The goal of the trigger is to select all candidates for X0 \u2192 \u2265 2 charged tracks or two\nphotons (even if merged), while excluding decays of the SM particles, such as K0 and \u039b.\n\nThe fluka [24, 25] code, regularly used for LHC background calculations, predicts that there\nwill be about 30 charged particles with the momentum above 1 GeV (mostly protons, \u03c0\u00b1, and e\u00b1,\nwith \u223c1.9 \u00b5\u00b1) entering the tracker at R > 18 cm per bunch crossing (with a pileup of 140). These\nare all background tracks, and will be tagged as such by the front hodoscope and ignored. The L1\ntrack trigger will form tracks (at 119 < z < 121 m) and calculate the position of candidate vertices\ninside the decay volume, as well as confirm that the decay signature is consistent with an LLP\noriginating at IP5.\n\nSince the planned rate of L1 triggers for CMS is 750 kHz, FACET triggers at a L1 rate of a\nfew kHz is a goal, which should be achievable by tuning thresholds. The HLT can apply selections\nclose to the offline analysis to reduce the rate to long-term storage to .100 Hz out of 7.5 KHz total\nrate-to-tape for CMS. The FACET-triggered events will include the full CMS data, and the FACET\ninformation will be included in all CMS triggered events. The FACET data will be \ufffd 1% of the\nfull CMS data. The FACET trigger could also be run in a standalone mode, with only FACET\ninformation saved, and without correlating with the central CMS detector.\n\nFor charged particles with \u03b8 < 1 mrad that come through the dipole D1 aperture, the rates will\nbe high, but some SM channels, e.g., e+e\u2212 and \u00b5+\u00b5\u2212, are interesting and special triggers for those\ncan be included. Such triggers will be prescaled, but the data will be useful for checks throughout\nthe LHC running.\n\nFor any low-pileup LHC runs, with proton, as well as with ion beams, a different set of triggers\nwill be prepared. Since many bunch crossings will then have only a single interaction, correlations\nbetween leading charged hadrons and the central event can be studied.\n\n5 Backgrounds\n\nFACET is unique among all LHC LLP search proposals in having a very large volume of LHC-\nquality vacuum for decays. Vertices with R > 15 cm inside a fiducial volume with two or more\nassociated tracks cannot have come from interactions; they must be due to decays2. Our goal is to\nhave no background events even with 3 ab\u22121 of integrated luminosity in many decay channels; in\nwhich case even a few signal candidate events can mark a discovery.\n\nThe direct path from the collision region to the decay volume has 200\u2013300 \u03bbint (depending on\n\u03b8) of magnetized iron, effectively eliminating all SM particles, except neutrinos. Therefore the only\nSM particles entering the decay volume are indirect, from interactions in the beam pipe and LHC\ncomponents. Most are at large enough polar angle \u03b8 to miss the tracker, nevertheless the fluka\ncode predicts that there will be about \u223c30 charged particles with the momentum above 1 GeV\nentering the tracker at R > 18 cm per bunch crossing. There is a significantly larger flux of lower\nmomentum charged particles entering the hodoscope, most of which have large enough polar angles\nto miss the downstream tracker. This drives the need for at least one layer of \u223c1 cm2 pads in the\nhodoscope.\n\nNeutral hadrons of concern are K0\nS , K0\n\nL, \u039b, and \u039e0, with about one entering the decay volume\nper bunch crossing. Their decay tracks will be well measured and their energies determined in\nthe calorimeter. A Monte Carlo simulation shows that the parent mass and the direction can be\nreconstructed with this information. Requiring the parent track to point back to the IP5 interaction\n\n2Interactions of beam bunches with residual gas molecules in the LHC during the high-luminosity LHC operations\nare actively being studied [65], but such vertices would be close to the outgoing beams with R < 10 cm.\n\n9\n\n\n\nregion and using the decay position information (flat in z for an LLP) will reduce this neutral hadron\nbackground, that may still be overwhelming for X0 \u2192 h+h\u2212 with mX0 . 0.8 GeV.\n\nThe situation is much better for lepton pairs. Only K0 decays can contribute; for K0\nS either\n\nthrough both charged pions being misidentified as electrons or as muons, or by genuine dilepton\ndecays, all of which have very small branching fractions < 10\u22128. The K0\n\nL meson has common\nsemileptonic decays to \u03c0\u00b1e\u2213\u03bde and \u03c0\u00b1\u00b5\u2213\u03bde, so only one \u03c0\u00b1 has to be misidentified as a lepton.\nThe missing neutrino smears the pointing from the IP5, the reconstructed mass is a continuum\nwith mX0 < 500 MeV, and the z distribution of the vertex is not nearly uniform as it would be for\nan LLP.\n\nIn 2\u00d71015 bunch crossings (3 ab\u22121) we expect several thousand true K0\nL \u2192 \u00b5+\u00b5\u2212 decays in the\n\nvacuum volume given the branching fraction of 7 \u00d7 10\u22129. The \u00b5+\u00b5\u2212 mass is reconstructed and,\nif compatible with mK0 , the momentum, the decay time c\u03c4 and the total momentum are known.\nWhile it would be interesting (and an excellent control measurement) to observe these rare K0\n\ndilepton decays, they will not be a background to X0 \u2192 l+l\u2212 decays for mX0 & 0.6 GeV.\nA potential background in the X0 \u2192 l+l\u2212 channel is from pileup, with two muons or electrons\n\nfrom different collisions in the same bunch crossing appearing to come from a common vertex in\nthe decay volume. Studies done with fluka show that the transverse distribution of muons is\napproximately proportional to 1/R, the density ranging from 2 \u00d7 10\u22124 to 8 \u00d7 10\u22125 cm\u22122. The\ntotal is an average of 1.9 muons (both charges) per bunch crossing within 18 < R < 50 cm.\nThis background will be eliminated by charged-particle tagging in the upstream hodoscope, and\nprecision vertexing. If the inefficiency of the hodoscope is 10\u22124 (10\u22125) there will be \u223c107 (\u223c105)\nbunch crossings in 3 ab\u22121 with two or more untagged muons entering the decay volume. A Monte\nCarlo study of pairs of uncorrelated muons was used to determine the probability that any pair\nhas a distance of closest approach < 60 \u00b5m; the prediction is 150 (1.5) two-track vertices from\npileup, which is further reduced by a factor of two by the opposite-sign track requirement. Further\nrequiring the vector sum of the muon momenta to point back to the IP5 collision region eliminates\nthis background.\n\nA search for X0 \u2192 \u03b3\u03b3, e.g., for an axion-like particle, having no charged tracks and less precise\nvertex location, will be challenging, with a large background from photons from \u03c00, \u03b7, and \u03b7\u2032 meson\ndecays, as well as from K0\n\nS \u2192 \u03c00\u03c00 decays. The electromagnetic section of the calorimeter measures\nboth the shower directions and the distance of closest approach of the two photons, albeit without\nthe high precision which is achieved for tracks. Requiring matching in x,y,z,t using position and\ntiming information and that the momentum of the diphoton pair points back to IP5 will suppress\nthese backgrounds, especially for m\u03b3\u03b3 & 1 GeV. Studies based on full detector simulation are under\nway to determine whether this background could be controlled.\n\nMany BSM particles with masses above about 1 GeV have decay modes to more than two\ncharged particles. The only SM hadrons that can decay to four charged particles inside the FACET\ndecay volume are K0, via the following decays: K0\n\nS \u2192 e+e\u2212\u03c0+\u03c0\u2212 ,K0\nL \u2192 e+e\u2212\u03c0+\u03c0\u2212 ,K0\n\nL \u2192\ne+e\u2212e+e\u2212, and K0\n\nL \u2192 \u00b5+\u00b5\u2212e+e\u2212. With the expected K0 fluxes FACET will detect such decays,\nbut they will not constitute a background for 4-body decays with mX0 & 0.6 GeV.\n\nWe have also considered pileup of two unrelated neutral-hadron (e.g., K0\nS , \u039b) decays, but to\n\nbe a background to X0 \u2192 4 hadrons these decays must be superimposed in x,y,z, consistent in\ntime, and the apparent \u201cparent\u201d must point back to IP5. In addition, for some of the signals we\nmay veto pair masses compatible with that of a neutral K0 or \u039b. These requirements eliminate\nthe background from pileup.\n\nTo summarize, while decays of neutral hadrons inside the vacuum volume will be a major\nsource of background for hadronic decays of LLPs with mX0 . 0.8 GeV, decays to leptons and\nmultihadrons at higher masses should have vanishing backgrounds even in 3 ab\u22121, thanks to 200\u2013\n\n10\n\n\n\n300 \u03bbint of the iron absorber, the vacuum decay volume, high precision tracking, a high-granularity\ncalorimeter, and muon momentum measurement in the toroidal spectrometer.\n\n6 Summary\n\nFACET is proposed as a new subsystem for CMS in the high-luminosity LHC era. The primary\nobjective is to search for beyond the standard model long-lived particles decaying in a large vacuum\nvolume, during the high-luminosity LHC phase, corresponding to an integrated luminosity of about\n3 ab\u22121 of proton-proton collisions at\n\n\u221a\ns = 14 TeV. The FACET detector requires an enlarged\n\nbeam pipe section between z = 101 and 119 m, followed by high-precision tracking and calorimeter\nmodules using identical technology to the CMS Phase-2 upgrade. These are designed for the high\nradiation environment expected in the high-lminosity LHC era. The searches can be background-\nfree in many channels, especially for neutral long-lived particles with masses &1 GeV. FACET will\nmake an inclusive search for dark photons, heavy neutral leptons, axion-like particles, and dark\nHiggs bosons with a sensitivity defined by their masses and couplings to standard model particles.\nThe couplings must be large enough to give a detectable production cross section in the forward\ndirection, and for the particles to decay to visible states, while small enough for the particles to\ntraverse 35\u201350 m of iron upstream of the decay volume. FACET will explore a unique area in\nthe parameter space of mass and couplings, largely complementary to other exsiting and proposed\nsearches, yet with some overlap ensuring seamless coverage.\n\n7 Acknowledgments\n\nWe thank V. Kashikhin (Fermilab) for the preliminary toroid design, P. Fessia (CERN ATS-DO)\nand V. Baglin (CERN TE-VSC) for information on the LHC and beam pipe, respectively. The\nwork of G. Landsberg is partially supported by the DOE Award No. DE-SC0010010. S. Kulkarni\nis supported by the Austrian Science Fund Elise-Richter grant project number V592-N27. M. Du,\nR. Fang, and Z. Liu are supported in part by the National Natural Science Foundation of China\nunder Grant No. 11775109. V.Q. Tran is supported in part by the National Natural Science\nFoundation of China under Grant No. 19Z103010239. Istanbul University group work is supported\nby FUA-2018-32919 from the Scientific Research Projects Coordination Unit of Istanbul University.\nThe University of Iowa group work is supported by the DOE Award No. DE-SC0010113. The\nUniversity of Maryland group effort is supported by the DOE Award No. DE-SC0010072. We\nacknowledge support provided by the following funding agencies: Academy of Finland and HIP\n(Finland), TUBITAK and TENMAK (Turkey), DOE and NSF (USA).\n\nReferences\n\n[1] R. Essig et al., \u201cWorking Group Report: New Light Weakly Coupled Particles\u201d, in\nCommunity Summer Study 2013: Snowmass on the Mississippi. 2013. arXiv:1311.0029.\n\n[2] J. Alimena et al., \u201cSearching for long-lived particles beyond the Standard Model at the Large\nHadron Collider\u201d, J. Phys. G 47 (2020) 090501, arXiv:1903.04497.\ndoi:10.1088/1361-6471/ab4574.\n\n[3] P. Agrawal et al., \u201cFeebly-interacting particles: FIPs 2020 workshop report\u201d, Eur. Phys. J.\nC 81 (2021) 1015, arXiv:2102.12143. doi:10.1140/epjc/s10052-021-09703-7.\n\n11\n\nhttp://www.arXiv.org/abs/1311.0029\nhttp://www.arXiv.org/abs/1903.04497\nhttp://dx.doi.org/10.1088/1361-6471/ab4574\nhttp://dx.doi.org/10.1088/1361-6471/ab4574\nhttp://www.arXiv.org/abs/2102.12143\nhttp://dx.doi.org/10.1140/epjc/s10052-021-09703-7\n\n\n[4] L. B. Okun, \u201cLimits of electrodynamics: paraphotons?\u201d, Sov. Phys. JETP 56 (1982) 502.\n\n[5] A. Caputo, A. J. Millar, C. A. J. O\u2019Hare et al., \u201cDark photon limits: A handbook\u201d, Phys.\nRev. D 104 (2021) 095029, arXiv:2105.04565. doi:10.1103/PhysRevD.104.095029.\n\n[6] T. Araki, K. Asai, H. Otono et al., \u201cDark photon from light scalar boson decays at FASER\u201d,\nJHEP 03 (2021) 072, arXiv:2008.12765. [Erratum: JHEP 06 (2021) 087].\ndoi:10.1007/JHEP03(2021)072.\n\n[7] G. Cottin, \u201cSearches for long-lived particles and Heavy Neutral Leptons: Theory\nperspective\u201d, PoS LHCP2021 (2021) 003. doi:10.22323/1.397.0003.\n\n[8] SHiP Collaboration, \u201cSensitivity of the SHiP experiment to Heavy Neutral Leptons\u201d, JHEP\n04 (2019) 077, arXiv:1811.00930. doi:10.1007/JHEP04(2019)077.\n\n[9] J. L. Feng, I. Galon, F. Kling et al., \u201cAxionlike particles at FASER: The LHC as a photon\nbeam dump\u201d, Phys. Rev. D 98 (2018) 055021, arXiv:1806.02348.\ndoi:10.1103/PhysRevD.98.055021.\n\n[10] M. Bauer, M. Heiles, M. Neubert et al., \u201cAxion-Like Particles at Future Colliders\u201d, Eur.\nPhys. J. C 79 (2019) 74, arXiv:1808.10323. doi:10.1140/epjc/s10052-019-6587-9.\n\n[11] D. d\u2019Enterria, \u201cCollider constraints on axion-like particles\u201d, in Workshop on Feebly\nInteracting Particles. 2021. arXiv:2102.08971.\n\n[12] M. Duerr, A. Grohsjean, F. Kahlhoefer et al., \u201cHunting the dark Higgs\u201d, JHEP 04 (2017)\n143, arXiv:1701.08780. doi:10.1007/JHEP04(2017)143.\n\n[13] J. L. Feng, I. Galon, F. Kling et al., \u201cDark Higgs bosons at the ForwArd Search\nExpeRiment\u201d, Phys. Rev. D 97 (2018) 055034, arXiv:1710.09387.\ndoi:10.1103/PhysRevD.97.055034.\n\n[14] I. Boiarska, K. Bondarenko, A. Boyarsky et al., \u201cLight scalar production from Higgs bosons\nand FASER 2\u201d, JHEP 05 (2020) 049, arXiv:1908.04635.\ndoi:10.1007/JHEP05(2020)049.\n\n[15] J. L. Feng, I. Galon, F. Kling et al., \u201cForwArd Search ExpeRiment at the LHC\u201d, Phys. Rev.\nD 97 (2018) 035001, arXiv:1708.09389. doi:10.1103/PhysRevD.97.035001.\n\n[16] FASER Collaboration, \u201cTechnical Proposal for FASER: ForwArd Search ExpeRiment at the\nLHC\u201d, arXiv:1812.09139.\n\n[17] MATHUSLA Collaboration, \u201cA Letter of Intent for MATHUSLA: A Dedicated Displaced\nVertex Detector above ATLAS or CMS.\u201d, arXiv:1811.00927.\n\n[18] D. Curtin et al., \u201cLong-Lived Particles at the Energy Frontier: The MATHUSLA Physics\nCase\u201d, Rept. Prog. Phys. 82 (2019) 116201, arXiv:1806.07396.\ndoi:10.1088/1361-6633/ab28d6.\n\n[19] G. Aielli et al., \u201cExpression of interest for the CODEX-b detector\u201d, Eur. Phys. J. C 80\n(2020) 1177, arXiv:1911.00481. doi:10.1140/epjc/s10052-020-08711-3.\n\n[20] FASER Collaboration, \u201cFASER\u2019s physics reach for long-lived particles\u201d, Phys. Rev. D 99\n(2019) 095011, arXiv:1811.12522. doi:10.1103/PhysRevD.99.095011.\n\n12\n\nhttp://www.arXiv.org/abs/2105.04565\nhttp://dx.doi.org/10.1103/PhysRevD.104.095029\nhttp://www.arXiv.org/abs/2008.12765\nhttp://dx.doi.org/10.1007/JHEP03(2021)072\nhttp://dx.doi.org/10.1007/JHEP03(2021)072\nhttp://dx.doi.org/10.22323/1.397.0003\nhttp://www.arXiv.org/abs/1811.00930\nhttp://dx.doi.org/10.1007/JHEP04(2019)077\nhttp://www.arXiv.org/abs/1806.02348\nhttp://dx.doi.org/10.1103/PhysRevD.98.055021\nhttp://dx.doi.org/10.1103/PhysRevD.98.055021\nhttp://www.arXiv.org/abs/1808.10323\nhttp://dx.doi.org/10.1140/epjc/s10052-019-6587-9\nhttp://www.arXiv.org/abs/2102.08971\nhttp://www.arXiv.org/abs/1701.08780\nhttp://dx.doi.org/10.1007/JHEP04(2017)143\nhttp://www.arXiv.org/abs/1710.09387\nhttp://dx.doi.org/10.1103/PhysRevD.97.055034\nhttp://dx.doi.org/10.1103/PhysRevD.97.055034\nhttp://www.arXiv.org/abs/1908.04635\nhttp://dx.doi.org/10.1007/JHEP05(2020)049\nhttp://dx.doi.org/10.1007/JHEP05(2020)049\nhttp://www.arXiv.org/abs/1708.09389\nhttp://dx.doi.org/10.1103/PhysRevD.97.035001\nhttp://www.arXiv.org/abs/1812.09139\nhttp://www.arXiv.org/abs/1811.00927\nhttp://www.arXiv.org/abs/1806.07396\nhttp://dx.doi.org/10.1088/1361-6633/ab28d6\nhttp://dx.doi.org/10.1088/1361-6633/ab28d6\nhttp://www.arXiv.org/abs/1911.00481\nhttp://dx.doi.org/10.1140/epjc/s10052-020-08711-3\nhttp://www.arXiv.org/abs/1811.12522\nhttp://dx.doi.org/10.1103/PhysRevD.99.095011\n\n\n[21] FASER Collaboration, \u201cFASER: ForwArd Search ExpeRiment at the LHC\u201d,\narXiv:1901.04468.\n\n[22] NA62 Collaboration, \u201cThe Beam and detector of the NA62 experiment at CERN\u201d, JINST\n12 (2017) P05025, arXiv:1703.08501. doi:10.1088/1748-0221/12/05/P05025.\n\n[23] M. Drewes, J. Hajer, J. Klaric et al., \u201cNA62 sensitivity to heavy neutral leptons in the low\nscale seesaw model\u201d, JHEP 07 (2018) 105, arXiv:1801.04207.\ndoi:10.1007/JHEP07(2018)105.\n\n[24] FLUKA Collaboration. https://fluka.cern\".\n\n[25] G. Battistoni et al., \u201cOverview of the FLUKA code\u201d, Annals Nucl. Energy 82 (2015) 10.\ndoi:10.1016/j.anucene.2014.11.007.\n\n[26] CMS Collaboration, \u201cThe Phase-2 Upgrade of the CMS Endcap Calorimeter\u201d.\nCERN-LHCC-2017-023, CMS-TDR-019, 2017.\n\n[27] F. Kling and S. Trojanowski, \u201cForward experiment sensitivity estimator for the LHC and\nfuture hadron colliders\u201d, Phys. Rev. D 104 (2021) 035012, arXiv:2105.07077.\ndoi:10.1103/PhysRevD.104.035012.\n\n[28] BaBar Collaboration, \u201cSearch for a Dark Photon in e+e\u2212 Collisions at BaBar\u201d, Phys. Rev.\nLett. 113 (2014) 201801, arXiv:1406.2980. doi:10.1103/PhysRevLett.113.201801.\n\n[29] J. D. Bjorken, S. Ecklund, W. R. Nelson et al., \u201cSearch for Neutral Metastable Penetrating\nParticles Produced in the SLAC Beam Dump\u201d, Phys. Rev. D 38 (1988) 3375.\ndoi:10.1103/PhysRevD.38.3375.\n\n[30] E. Riordan et al., \u201cA Search for Short Lived Axions in an Electron Beam Dump\nExperiment\u201d, Phys. Rev. Lett. 59 (1987) 755. doi:10.1103/PhysRevLett.59.755.\n\n[31] LHCb Collaboration, \u201cSearch for A\u2032 \u2192 \u00b5+\u00b5\u2212 Decays\u201d, Phys. Rev. Lett. 124 (2020) 041801,\narXiv:1910.06926. doi:10.1103/PhysRevLett.124.041801.\n\n[32] NA48/2 Collaboration, \u201cSearch for the dark photon in \u03c00 decays\u201d, Phys. Lett. B 746\n(2015) 178, arXiv:1504.00607. doi:10.1016/j.physletb.2015.04.068.\n\n[33] NA64 Collaboration, \u201cSearch for a Hypothetical 16.7 MeV Gauge Boson and Dark Photons\nin the NA64 Experiment at CERN\u201d, Phys. Rev. Lett. 120 (2018) 231802,\narXiv:1803.07748. doi:10.1103/PhysRevLett.120.231802.\n\n[34] J. Blumlein et al., \u201cLimits on neutral light scalar and pseudoscalar particles in a proton\nbeam dump experiment\u201d, Z. Phys. C 51 (1991) 341. doi:10.1007/BF01548556.\n\n[35] Belle Collaboration, \u201cSearch for the dark photon in B0 \u2192 A\u2032A\u2032, A\u2032 \u2192 e+e\u2212, \u00b5+\u00b5\u2212, and\n\u03c0+\u03c0\u2212 decays at Belle\u201d, JHEP 04 (2021) 191, arXiv:2012.02538.\ndoi:10.1007/JHEP04(2021)191.\n\n[36] M. R. Solt, \u201cSearching for long-lived dark photons with the heavy photon search\nexperiment\u201d, Ph.D. Thesis, Stanford U. (2020).\n\n[37] M. Battaglieri et al., \u201cUS Cosmic Visions: New Ideas in Dark Matter 2017: Community\nReport\u201d, in U.S. Cosmic Visions: New Ideas in Dark Matter. 2017. arXiv:1707.04591.\n\n13\n\nhttp://www.arXiv.org/abs/1901.04468\nhttp://www.arXiv.org/abs/1901.04468\nhttp://www.arXiv.org/abs/1703.08501\nhttp://dx.doi.org/10.1088/1748-0221/12/05/P05025\nhttp://www.arXiv.org/abs/1801.04207\nhttp://dx.doi.org/10.1007/JHEP07(2018)105\nhttp://dx.doi.org/10.1007/JHEP07(2018)105\nhttps://fluka.cern\"\nhttp://dx.doi.org/10.1016/j.anucene.2014.11.007\nhttp://dx.doi.org/10.1016/j.anucene.2014.11.007\nhttp://www.arXiv.org/abs/2105.07077\nhttp://dx.doi.org/10.1103/PhysRevD.104.035012\nhttp://dx.doi.org/10.1103/PhysRevD.104.035012\nhttp://www.arXiv.org/abs/1406.2980\nhttp://dx.doi.org/10.1103/PhysRevLett.113.201801\nhttp://dx.doi.org/10.1103/PhysRevD.38.3375\nhttp://dx.doi.org/10.1103/PhysRevD.38.3375\nhttp://dx.doi.org/10.1103/PhysRevLett.59.755\nhttp://www.arXiv.org/abs/1910.06926\nhttp://dx.doi.org/10.1103/PhysRevLett.124.041801\nhttp://www.arXiv.org/abs/1504.00607\nhttp://dx.doi.org/10.1016/j.physletb.2015.04.068\nhttp://www.arXiv.org/abs/1803.07748\nhttp://www.arXiv.org/abs/1803.07748\nhttp://dx.doi.org/10.1103/PhysRevLett.120.231802\nhttp://dx.doi.org/10.1007/BF01548556\nhttp://www.arXiv.org/abs/2012.02538\nhttp://dx.doi.org/10.1007/JHEP04(2021)191\nhttp://dx.doi.org/10.1007/JHEP04(2021)191\nhttp://www.arXiv.org/abs/1707.04591\n\n\n[38] P. Ilten, J. Thaler, M. Williams et al., \u201cDark photons from charm mesons at LHCb\u201d, Phys.\nRev. D 92 (2015) 115017, arXiv:1509.06765. doi:10.1103/PhysRevD.92.115017.\n\n[39] P. Ilten, Y. Soreq, J. Thaler et al., \u201cProposed Inclusive Dark Photon Search at LHCb\u201d,\nPhys. Rev. Lett. 116 (2016) 251803, arXiv:1603.08926.\ndoi:10.1103/PhysRevLett.116.251803.\n\n[40] NA62 Collaboration, \u201cDark Sectors at fixed targets: The example of NA62\u201d, Frascati Phys.\nSer. 66 (2018) 312, arXiv:1807.10170.\n\n[41] A. Berlin, S. Gori, P. Schuster et al., \u201cDark Sectors at the Fermilab SeaQuest Experiment\u201d,\nPhys. Rev. D 98 (2018) 035011, arXiv:1804.00661. doi:10.1103/PhysRevD.98.035011.\n\n[42] SHiP Collaboration, \u201cSensitivity of the SHiP experiment to dark photons decaying to a pair\nof charged particles\u201d, Eur. Phys. J. C 81 (2021) 451, arXiv:2011.05115.\ndoi:10.1140/epjc/s10052-021-09224-3.\n\n[43] M. Du, R. Fang, Z. Liu et al., \u201cEnhanced long-lived dark photon signals at lifetime frontier\ndetectors\u201d. 2021. arXiv:2111.15503.\n\n[44] P. Minkowski, \u201c\u00b5\u2192 e\u03b3 at a Rate of One Out of 109 Muon Decays?\u201d, Phys. Lett. B 67\n(1977) 421. doi:10.1016/0370-2693(77)90435-X.\n\n[45] D. Chang, R. N. Mohapatra, J. Gipson et al., \u201cExperimental Tests of New SO(10) Grand\nUnification\u201d, Phys. Rev. D 31 (1985) 1718. doi:10.1103/PhysRevD.31.1718.\n\n[46] F. Deppisch, S. Kulkarni, and W. Liu, \u201cHeavy neutrino production via Z \u2032 at the lifetime\nfrontier\u201d, Phys. Rev. D 100 (2019) 035005, arXiv:1905.11889.\ndoi:10.1103/PhysRevD.100.035005.\n\n[47] K. Mimasu and V. Sanz, \u201cALPs at Colliders\u201d, JHEP 06 (2015) 173, arXiv:1409.4792.\ndoi:10.1007/JHEP06(2015)173.\n\n[48] S. Gori, G. Perez, and K. Tobioka, \u201cKOTO vs. NA62 Dark Scalar Searches\u201d, JHEP 08\n(2020) 110, arXiv:2005.05170. doi:10.1007/JHEP08(2020)110.\n\n[49] F. Kling and S. Trojanowski, \u201cLooking forward to test the KOTO anomaly with FASER\u201d,\nPhys. Rev. D 102 (2020) 015032, arXiv:2006.10630.\ndoi:10.1103/PhysRevD.102.015032.\n\n[50] BaBar Collaboration, \u201cSearch for an Axion-Like Particle in B Meson Decays\u201d,\narXiv:2111.01800.\n\n[51] J. Beacham et al., \u201cPhysics Beyond Colliders at CERN: Beyond the Standard Model\nWorking Group Report\u201d, J. Phys. G 47 (2020) 010501, arXiv:1901.09966.\ndoi:10.1088/1361-6471/ab4cd2.\n\n[52] M. J. Dolan, T. Ferber, C. Hearty et al., \u201cRevised constraints and Belle II sensitivity for\nvisible and invisible axion-like particles\u201d, JHEP 12 (2017) 094, arXiv:1709.00009.\n[Erratum: JHEP 03 (2021) 190]. doi:10.1007/JHEP12(2017)094.\n\n[53] G. Ruggiero, \u201cNew Result on K+ \u2192 \u03c0+\u03bd\u03bd from the NA62 Experiment\u201d, J. Phys. Conf. Ser.\n1526 (2020) 012003. doi:10.1088/1742-6596/1526/1/012003.\n\n14\n\nhttp://www.arXiv.org/abs/1509.06765\nhttp://dx.doi.org/10.1103/PhysRevD.92.115017\nhttp://www.arXiv.org/abs/1603.08926\nhttp://dx.doi.org/10.1103/PhysRevLett.116.251803\nhttp://dx.doi.org/10.1103/PhysRevLett.116.251803\nhttp://www.arXiv.org/abs/1807.10170\nhttp://www.arXiv.org/abs/1804.00661\nhttp://dx.doi.org/10.1103/PhysRevD.98.035011\nhttp://www.arXiv.org/abs/2011.05115\nhttp://dx.doi.org/10.1140/epjc/s10052-021-09224-3\nhttp://dx.doi.org/10.1140/epjc/s10052-021-09224-3\nhttp://www.arXiv.org/abs/2111.15503\nhttp://dx.doi.org/10.1016/0370-2693(77)90435-X\nhttp://dx.doi.org/10.1103/PhysRevD.31.1718\nhttp://www.arXiv.org/abs/1905.11889\nhttp://dx.doi.org/10.1103/PhysRevD.100.035005\nhttp://dx.doi.org/10.1103/PhysRevD.100.035005\nhttp://www.arXiv.org/abs/1409.4792\nhttp://dx.doi.org/10.1007/JHEP06(2015)173\nhttp://dx.doi.org/10.1007/JHEP06(2015)173\nhttp://www.arXiv.org/abs/2005.05170\nhttp://dx.doi.org/10.1007/JHEP08(2020)110\nhttp://www.arXiv.org/abs/2006.10630\nhttp://dx.doi.org/10.1103/PhysRevD.102.015032\nhttp://dx.doi.org/10.1103/PhysRevD.102.015032\nhttp://www.arXiv.org/abs/2111.01800\nhttp://www.arXiv.org/abs/2111.01800\nhttp://www.arXiv.org/abs/1901.09966\nhttp://dx.doi.org/10.1088/1361-6471/ab4cd2\nhttp://dx.doi.org/10.1088/1361-6471/ab4cd2\nhttp://www.arXiv.org/abs/1709.00009\nhttp://dx.doi.org/10.1007/JHEP12(2017)094\nhttp://dx.doi.org/10.1088/1742-6596/1526/1/012003\n\n\n[54] BNL-E949 Collaboration, \u201cStudy of the decay K+ \u2192 \u03c0+\u03bd\u03bd\u0304 in the momentum region\n140 < P\u03c0 < 199 MeV/c\u201d, Phys. Rev. D 79 (2009) 092004, arXiv:0903.0030.\ndoi:10.1103/PhysRevD.79.092004.\n\n[55] LHCb Collaboration, \u201cSearch for hidden-sector bosons in B0\u2192 K\u22170\u00b5+\u00b5\u2212 decays\u201d, Phys.\nRev. Lett. 115 (2015) 161802, arXiv:1508.04094.\ndoi:10.1103/PhysRevLett.115.161802.\n\n[56] LHCb Collaboration, \u201cSearch for long-lived scalar particles in B+ \u2192 K+\u03c7(\u00b5+\u00b5\u2212) decays\u201d,\nPhys. Rev. D 95 (2017) 071101, arXiv:1612.07818. doi:10.1103/PhysRevD.95.071101.\n\n[57] M. W. Winkler, \u201cDecay and detection of a light scalar boson mixing with the Higgs boson\u201d,\nPhys. Rev. D 99 (2019) 015018, arXiv:1809.01876. doi:10.1103/PhysRevD.99.015018.\n\n[58] S. Foroughi-Abari and A. Ritz, \u201cLSND Constraints on the Higgs Portal\u201d, Phys. Rev. D\n102 (2020) 035015, arXiv:2004.14515. doi:10.1103/PhysRevD.102.035015.\n\n[59] MicroBooNE Collaboration, \u201cSearch for a Higgs Portal Scalar Decaying to Electron-Positron\nPairs in the MicroBooNE Detector\u201d, Phys. Rev. Lett. 127 (2021) 151803,\narXiv:2106.00568. doi:10.1103/PhysRevLett.127.151803.\n\n[60] J. P. Chou, D. Curtin, and H. J. Lubatti, \u201cNew Detectors to Explore the Lifetime Frontier\u201d,\nPhys. Lett. B 767 (2017) 29, arXiv:1606.06298.\ndoi:10.1016/j.physletb.2017.01.043.\n\n[61] V. V. Gligorov, S. Knapen, M. Papucci et al., \u201cSearching for Long-lived Particles: A\nCompact Detector for Exotics at LHCb\u201d, Phys. Rev. D 97 (2018) 015023,\narXiv:1708.09395. doi:10.1103/PhysRevD.97.015023.\n\n[62] S. Alekhin et al., \u201cA facility to Search for Hidden Particles at the CERN SPS: the SHiP\nphysics case\u201d, Rept. Prog. Phys. 79 (2016) 124201, arXiv:1504.04855.\ndoi:10.1088/0034-4885/79/12/124201.\n\n[63] E. Bertuzzo and M. Taoso, \u201cProbing light dark scalars with future experiments\u201d, JHEP 03\n(2021) 272, arXiv:2011.04735. doi:10.1007/JHEP03(2021)272.\n\n[64] A. Dainese, M. Mangano, A. B. Meyer et al., eds., \u201cReport on the Physics at the\nHL-LHC,and Perspectives for the HE-LHC\u201d, volume 7/2019 of CERN Yellow Reports:\nMonographs. CERN, Geneva, Switzerland, 2019.\n\n[65] R. Bruce et al., \u201cCollimation-induced experimental background studies at the CERN Large\nHadron Collider\u201d, Phys. Rev. Accel. Beams 22 (2019) 021004.\ndoi:10.1103/PhysRevAccelBeams.22.021004.\n\n15\n\nhttp://www.arXiv.org/abs/0903.0030\nhttp://dx.doi.org/10.1103/PhysRevD.79.092004\nhttp://dx.doi.org/10.1103/PhysRevD.79.092004\nhttp://www.arXiv.org/abs/1508.04094\nhttp://dx.doi.org/10.1103/PhysRevLett.115.161802\nhttp://dx.doi.org/10.1103/PhysRevLett.115.161802\nhttp://www.arXiv.org/abs/1612.07818\nhttp://dx.doi.org/10.1103/PhysRevD.95.071101\nhttp://www.arXiv.org/abs/1809.01876\nhttp://dx.doi.org/10.1103/PhysRevD.99.015018\nhttp://www.arXiv.org/abs/2004.14515\nhttp://dx.doi.org/10.1103/PhysRevD.102.035015\nhttp://www.arXiv.org/abs/2106.00568\nhttp://www.arXiv.org/abs/2106.00568\nhttp://dx.doi.org/10.1103/PhysRevLett.127.151803\nhttp://www.arXiv.org/abs/1606.06298\nhttp://dx.doi.org/10.1016/j.physletb.2017.01.043\nhttp://dx.doi.org/10.1016/j.physletb.2017.01.043\nhttp://www.arXiv.org/abs/1708.09395\nhttp://www.arXiv.org/abs/1708.09395\nhttp://dx.doi.org/10.1103/PhysRevD.97.015023\nhttp://www.arXiv.org/abs/1504.04855\nhttp://dx.doi.org/10.1088/0034-4885/79/12/124201\nhttp://dx.doi.org/10.1088/0034-4885/79/12/124201\nhttp://www.arXiv.org/abs/2011.04735\nhttp://dx.doi.org/10.1007/JHEP03(2021)272\nhttp://dx.doi.org/10.1103/PhysRevAccelBeams.22.021004\nhttp://dx.doi.org/10.1103/PhysRevAccelBeams.22.021004\n\n\t1 Introduction\n\t2 FACET as a new Subsystem of CMS\n\t3 Sensitivity to Long-Lived Particles\n\t3.1 Dark Photons\n\t3.2 Heavy Neutral Leptons\n\t3.3 Axion-Like Particles\n\t3.4 Dark Higgs Bosons\n\n\t4 Triggers\n\t5 Backgrounds\n\t6 Summary\n\t7 Acknowledgments\n\n"}
{"Title": "Geometric Fluctuation of Conformal Hilbert Spaces and Multiple Graviton Modes in Fractional Quantum Hall Effect", "Authors": "Yuzhu Wang, Bo Yang", "Abstract": "  We develop the microscopic theory for the emergence of multiple graviton modes (GMs) in fractional quantum Hall (FQH) fluids, and show explicitly these modes are associated with the geometric fluctuation of well-defined conformal Hilbert spaces (CHS). These Hilbert spaces are hierarchical subspaces within a single Landau level, each with emergent conformal symmetry and continuously parameterized by a unimodular metric. We show explicitly the multiple GMs originate from the spectral weights of the long wavelength GMP modes in each of the CHSs, corresponding to the quantum fluctuation of each of its metric. For different FQH phases, whether or not the spectral weight in a certain CHS is zero can be analytically derived. This leads to a number of statements about the number of GMs as well as merging and splitting of those modes, which we verified numerically. We also discuss how the microscopic theory can serve as the basis for the additional Haldane modes in the effective field theory description, and their experimental relevance to realistic electron-electron interaction.      ", "Subject": "Strongly Correlated Electrons (cond-mat.str-el)", "ID": "arXiv:2201.00020", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeometric Fluctuation of Conformal Hilbert Spaces and Multiple Graviton Modes in\nFractional Quantum Hall Effect\n\nWang Yuzhu1 and Yang Bo1, 2, \u2217\n\n1School of Physical and Mathematical Sciences, Nanyang Technological University, 639798 Singapore\n2Institute of High Performance Computing, A*STAR, 138632 Singapore\n\n(Dated: January 10, 2022)\n\nWe develop the microscopic theory for the emergence of multiple graviton modes (GMs) in frac-\ntional quantum Hall (FQH) fluids, and show explicitly these modes are associated with the geometric\nfluctuation of well-defined conformal Hilbert spaces (CHS). These Hilbert spaces are hierarchical\nsubspaces within a single Landau level, each with emergent conformal symmetry and continuously\nparameterized by a unimodular metric. We show explicitly the multiple GMs originate from the\nspectral weights of the long wavelength GMP modes in each of the CHSs, corresponding to the quan-\ntum fluctuation of each of its metric. For different FQH phases, whether or not the spectral weight\nin a certain CHS is zero can be analytically derived. This leads to a number of statements about the\nnumber of GMs as well as merging and splitting of those modes, which we verified numerically. We\nalso discuss how the microscopic theory can serve as the basis for the additional Haldane modes in\nthe effective field theory description, and their experimental relevance to realistic electron-electron\ninteraction.\n\nGravitons are hypothetical spin-2 bosons from the\nquantization of gravitational field, the existence of which\nhas not been confirmed by experiments and remained one\nof the most interesting unsolved mysteries in physics[1,\n2]. There also exist the analogous \u201cgraviton modes\u201d\nin the fractional quantum Hall (FQH) droplet, which\nis a two-dimensional quantum fluid of electrons subject\nto a strong magnetic field at low temperature. As a\ntypical manifestation of the interplay between topology\nand geometry, the graviton modes are collective neu-\ntral excitations with spin-2, originating from the metric\nfluctuations emerging from the strong interactions be-\ntween electrons[3\u20135]. While Lorentz invariance is ab-\nsent in this (2 + 1)-dimensional space-time, these 2D\ngraviton modes encode topological information about\ntheir respective FQH phases, and their dynamics lead\nto rich physics ranging from ground state incompressibil-\nity to the dynamical phase transitions of the low-lying\nexcitations[6, 7].\n\nThe effective field theory studying these modes has\nbeen proposed by using the Newton-Carton metric, and\nvarious experimental proposals for the observation of\nthese modes have been put forward[8\u201317]. The standard\ntechnique in probing neutral excitations is to use inelas-\ntic photon scattering[18\u201322]. The coupling between the\ngraviton modes and the acoustic waves can also be used\nto simulate the behaviour of gravitons interacting with\nthe gravitational waves[23]. Meanwhile, the microscopic\ntheory of the graviton modes with model Hamiltonians\nhas also been established to provide insights for the ex-\nperiments, where model Hamiltonians for the graviton\nmodes have been constructed for FQH fluids at different\nfilling factors[7, 24]. Recently numerical results have im-\nplied the signature of multiple graviton modes in FQH\n\n\u2217 yang.bo@ntu.edu.sg\n\nstates, the microscopic understanding of which is un-\nder development[25, 26]. Given that most of the re-\nsearch so far on graviton modes are based on effective\nfield-theoretical descriptions and numerical analysis with\nmodel wavefunctions[26], a detailed microscopic theory is\nneeded for a more complete characterisation of the emer-\ngence and interaction between different graviton modes.\n\nIn this article, we show analytically that multiple gravi-\nton modes (GM) is a generic feature for FQH fluids,\nfrom the splitting of the long wavelength limit of the\nGMP mode[3] in different subspaces in a single LL. Us-\ning the analytic tools we developed earlier[7], we demon-\nstrate that the number of GMs is dynamical in nature,\nand is only meaningful when referring to specific in-\nteraction Hamiltonians. Each GM can be interpreted\nas the metric fluctuation of a conformal Hilbert space\n(or the null spaces of model Hamiltonians, as explained\nlater) within a single LL. For short-range two-body in-\nteractions, we show all non-Laughlin FQH states around\n\u03bd = 1/(2n) with n > 1 (e.g. within the null space of\n\nV\u03022bdy\nn =\n\n\u2211n\nk=1 V\u0302\n\n2bdy\n2k\u22121 Haldane pseudopotential interac-\n\ntion), including the interacting composite fermion (CF)\nstates, have at least two GMs. In particular, the Jain\nstates at \u03bd = N/ (2nN \u00b1 1) and the Pfaffian states at\n\u03bd = 1/(2n) all have two GMs if n,N > 1. The Laughlin\nstates (N = 1) and the Jain states with n = 1 all have\na single GM. This agrees with the special cases studied\nnumerically in both[25, 26] at \u03bd = 2/7, 2/9, 1/4, at the\nsame time providing an analytic explanation and geomet-\nric interpretation to their numerical observations. The\nmicroscopic theory can easily predict the chirality of the\ngravitons[17] without numerical computations. It also\nserves as the basis for the effective field theory, where\nwe show the necessity of additional Haldane modes de-\npends on the proper identification of the base space of\nsuch theories.\n\nThe cyclotron and guiding center metric\u2013 It is useful\nto first consider the simple case of the integer quantum\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n0v\n2 \n\n [\nco\n\nnd\n-m\n\nat\n.s\n\ntr\n-e\n\nl]\n  7\n\n J\nan\n\n 2\n02\n\n2\n\nmailto:yang.bo@ntu.edu.sg\n\n\n2\n\nR\u0302ai Guiding center operator\n\n\u03c1\u0302q Guiding center density operator\n\n\u03b4\u03c1\u0304q Regularized guiding center density operator\n\n\u03c0\u0302ia Dynamical momentum operator\n\ng\u0304ab Guiding center metric\n\ng\u0303ab Cyclotron metric\n\ngab\u03b1 Guiding center metric of CHS H\u03b1\nSq Regularised guiding center structure factor\n\nV\u0302 kbdy\n\u03b1 k-body pseudopotential\n\nV\u0302kbdy\n\u03b1 Model Hamiltonian defined by\n\n\u2211\u03b1\ni=1 \u03bbiV\u0302\n\nkbdy\ni\n\nHkbdy\n\u03b1 CHS determined by V\u0302kbdy\n\n\u03b1\n\nTABLE I. Definition of various symbols used in the\ntext. Note that due to fermionic statistics, the constant co-\nefficients \u03bbi in V\u0302kbdy\n\n\u03b1 might vanish. For example, V\u03022bdy\n3 =\n\n\u03bb1V\u0302\nkbdy\n1 + \u03bb3V\u0302\n\nkbdy\n3 with \u03bb2 = 0.\n\nHall effect (IQHE), which are topological phases coming\nfrom fully filled Landau levels (LL). We are dealing with\nthe following full Hamiltonian:\n\nH\u0302 =\n\nNe\u2211\ni=1\n\n1\n\n2m\ng\u0303ab\u03c0\u0302ia\u03c0\u0302ib + V\u0302int (1)\n\nHere \u03c0\u0302ia = p\u0302ia + eA\u0302ia denotes the dynamical momen-\ntum operator of the i-th electron (p\u0302i is the canonical mo-\n\nmentum and A\u0302i is the external vector potential), with\nthe commutation rules [\u03c0\u0302ia, \u03c0\u0302jb] = i\u03b4ij\u03b5ab/`\n\n2\nB . The mag-\n\nnetic field is B = \u03b5ab\u2202aA\u0302ib and the magnetic length is\n`B =\n\n\u221a\n1/eB. We assume the cyclotron energy is the\n\ndominant energy scale, so any LL mixing induced by\nelectron-electron interaction can be perturbatively cap-\ntured by few-body interaction of the second term V\u0302int,\nwhich now describes the dynamics only within a single\nLL[27\u201331]. The important note here is that the Hilbert\nspace of a single LL, which we will refer to as the lowest\nLL (LLL) without loss of generality, is parametrized by\nthe unimodular metric g\u0303ab in Eq.(1), which is physically\nthe effective mass tensor. Quantum fluctuations around\nthis metric thus lead to density modes in higher LLs,\nwhich we can term as \u201ccyclotron gravitons\u201d. The energy\nof this GM is very high with large magnetic field. It is\nthe only GM for the IQHE, since the LLL is fully filled.\n\nFor FQHE in a partially filled LL, the dynamics is de-\ntermined entirely by the guiding center coordinates R\u0304a =\n\nr\u0302a \u2212 \u03b5ab\u03c0\u0302b`\n2\nB with the commutation rules\n\n[\nR\u0303a, R\u0303b\n\n]\n=\n\ni`2B\u03b5\nab,\n[\nR\u0304a, R\u0304b\n\n]\n= \u2212i`2B\u03b5ab,\n\n[\nR\u0303a, R\u0304b\n\n]\n= 0, where we de-\n\nfine R\u0303a = `2B\u03b5\nab\u03c0\u0302b. This implies the interaction energy\n\nV\u0302int is a functional of R\u0304i only and commutes with the\n\n1LL\n\n2LL\n\nHLLL\n\nLLL\n\nLL\nMIXING\n\n...\n\nHFibonacci\n\nHMR\n\nHGaffnian\n\nHHaffnian\n\nHLaughlin-1/3\n\nHLaughlin-1/5\n\nFIG. 1. Intrinsic metrics in FQH states. The left panel\nshows that the fluctuations of the cyclotron metric g\u0303ab origi-\nnate from the LL mixing. The right panel shows the hierarchi-\ncal structure of the CHSs (null spaces) of the corresponding\nmodel Hamiltonians (more details can be found in Table.II)\nin the lowest Landau level. Each of these spaces can have its\nown metric gabi , the fluctuation around which can potentially\nlead to multiple graviton modes in a single Landau level.\n\nkinetic energy. It can be explicitly expressed as:\n\nV\u0302int =\n\n\u222b\nd2qV|q|\u03c1\u0304q\u03c1\u0304\u2212q (2)\n\nwhere \u03c1\u0304q =\n\u2211\ni e\niq\u00b7R\u0304i is the guiding center density op-\n\nerator. For rotationally invariant systems we have a\nnew unimodular metric g\u0304ab defining distance in the mo-\n\nmentum space |q| =\n\u221a\ng\u0304abqaqb, which is physically in-\n\ndependent from g\u0303ab. We illustrate a complete analogy\nto the \u201ccyclotron graviton\u201d in the IQHE by using the\n\nsimple example of V\u0302int = V\u0302 2bdy\n1 , or the model Hamilto-\n\nnian for the Laughlin \u03bd = 1/3 state. Just like the LLL,\nwhich is the null space of the kinetic energy parame-\n\nterized by g\u0303ab, the null space of V\u0302 2bdy\n1 (spanned by the\n\nLaughlin ground state and quasiholes) is parametrized\nby g\u0304ab. The quantum fluctuation around g\u0303ab gives the\n\u201ccyclotron graviton\u201d outside of LLL, while that of g\u0304ab\n\ngives the well-known graviton or quadrupole mode (the\nlong wavelength limit of the GMP mode) outside of the\n\nV\u0302 2bdy\n1 null space[5].\nWe would like to emphasize the arguments above ap-\n\nplies to any V\u0302int with an incompressible ground state.\nThus generally speaking all FQH states have at least two\nGMs due to the structure of the full Hamiltonian: the\ncyclotron GM residing in higher LLs which is at very\nhigh energy due to the large magnetic field, and at least\none guiding center GM within the LLL. For the rest of\nthis work we will ignore the cyclotron GM and focus on\nthe dynamics within the LLL, though we will borrow the\nsame concept when understanding the emergence of mul-\ntiple guiding center GMs from V\u0302int.\n\nThe hierarchy of conformal Hilbert spaces\u2013 Given the\nrich algebraic structure of the Hilbert spaces like the\n\nLLL and the V\u0302 2bdy\n1 null space, we term them as con-\n\nformal Hilbert spaces (CHSs), because they are believed\nto be generated by the conformal operators (i.e. the\n\n\n\n3\n\nCHS Model Hamiltonian\n\nHFibonacci V\u0302 4bdy\n6\n\nHMR V\u0302 3bdy\n3\n\nHGaffnian \u03bb1V\u0302\n3bdy\n3 + \u03bb2V\u0302\n\n3bdy\n5\n\nHHaffnian \u03bb1V\u0302\n3bdy\n3 + \u03bb2V\u0302\n\n3bdy\n5 + \u03bb3V\u0302\n\n3bdy\n6\n\nHLaughlin-1/3 V\u0302 2bdy\n1\n\nHLaughlin-1/5 \u03bb1V\u0302\n2bdy\n1 + \u03bb2V\u0302\n\n2bdy\n3\n\nTABLE II. The CHSs are defined as the null spaces of the cor-\nresponding model Hamiltonians. Here \u03bbi can be any constant\ncoefficient.\n\nVirasoro algebra)[32, 33]. In many cases such Hilbert\nspaces are spanned by degenerate (zero energy) many-\nbody states of special local Hamiltonians, including the\nwell-known generalised pseudopotentials, that physically\nproject into the angular momentum sectors of a cluster of\nelectrons[34, 35]. The null spaces of these Hamiltonians\nhave conformal symmetry in the thermodynamic limit,\nand those zero energy states are the ground states and\nquasiholes of a particular FQH phase (though some are\nbelieved to be gapless phases)[36, 37]. More importantly\nlike the Hilbert space of the LLL (or any other single\nLL), such CHSs are built up with quasiparticles, which\nare emergent particles from LL projection and strong in-\nteraction. In the LLL, the quasiparticles are simply elec-\ntrons projected into a single LL, while in other CHSs,\nthey can be abelian or non-abelian anyons[38\u201344].\n\nLet H\u03b1 be one of these CHSs, and the null space of\nthe corresponding model Hamiltonian V\u0302\u03b1. Just like in\nEq.(2), V\u0302\u03b1 contains a guiding center metric gab\u03b1 , and H\u03b1\ncontinuously depends on it. This is the geometric as-\npect we would like to introduce to the CHSs, and each\nof them can be completely characterised by a triplet of\n{H\u03b1, V\u0302\u03b1, gab\u03b1 }. For the special case where H\u03b1 = HLLL,\n\nthe entire Hilbert space of the LLL, V\u0302\u03b1 is the kinetic en-\nergy Hamiltonian and gab\u03b1 = g\u0303ab is the cyclotron metric or\nthe effective mass tensor. All other CHSs are subspaces\nof HLLL.\n\nIn Fig. (1) we illustrate a hierarchical structure of\ndifferent H\u03b1 in the LLL[7]. For a given H\u03b1, it is possible\nto find another H\u03b2 \u2282 H\u03b1. If we fix gab\u03b1 , we can still\ndefine a H\u03b2 freely parametrized by gab\u03b2 that is completely\nwithin H\u03b1. This is straightforward for H\u03b1 = HLLL, since\nthe cyclotron coordinates and guiding center coordinates\ncommute. For other pairs of CHSs, such geometric tuning\ncan only be realised with the following Hamiltonian:\n\nV\u0302int = \u03bb\u03b1V\u0302\u03b1 + \u03bb\u03b2V\u0302\u03b2 (3)\n\nwith \u03bb\u03b1 \ufffd \u03bb\u03b2 > 0 (the metric dependence of V\u0302\u03b1,\u03b2 is\nimplicit). For any ground state |\u03c8\u3009 \u2282 H\u03b2 of Eq.(3) we\n\ncan thus define two types of area-preserving deformation:\n\n|\u03c8\u03c71 \u3009 \u223c lim\n|\u03c7|\u21920\n\nP\u0302\u03b1U\u0302 (\u03c7) |\u03c8\u3009 \u223c lim\n|q|\u21920\n\nP\u0302\u03b1\u03b4\u03c1\u0304q|\u03c8\u3009 (4)\n\n|\u03c8\u03c72 \u3009 =\n(\nI\u0302\u2212 P\u0302\u03b1U\u0302 (\u03c7)\n\n)\n|\u03c8\u3009 (5)\n\nwhere U\u0302 (\u03c7) = ei\u03c7ab\u039b\u0302ab\n\nis the unitary operator in-\nducing the squeezing and rotation of the guiding cen-\nter metric[5, 45], with \u039b\u0302ab = 1\n\n4l2B\n\n\u2211\ni{R\u0304ai , R\u0304bi}, and |\u03c7|\n\nparamertrize the squeezing; \u03b4\u03c1\u0304q = \u03c1\u0304q \u2212 \u3008\u03c80|\u03c1\u0304q|\u03c80\u3009 is the\nregularised guiding center density operator, and Eq.(4)\n\nhas been established in[4]. Here P\u0302\u03b1 is the projection into\n\nH\u03b1 so that V\u0302\u03b1|\u03c8\u03c71 \u3009 = 0, and |\u03c8\u03c71 \u3009 is associated with the\ngeometric deformation ofH\u03b2 . Eq.(5) is entirely outside of\nH\u03b1 and in some cases it will vanish, as we will see later.\nIf it is non-vanishing, then |\u03c8\u03c72 \u3009 is associated with the\ngeometric deformation of H\u03b1. This geometric descrip-\ntion forms the basis of possible multiple GMs in different\nFQH phases, dictated by \u201cmodel Hamiltonians\u201d in the\nform of Eq.(3), and can be resolved by realistic Hamilto-\nnians close to those model Hamiltonians.\n\nEmergence of multiple GMs\u2013 Within this framework,\nlet us start with a collection of CHSs {Hk, V\u0302k, gabk }. We\nwill ignore the cyclotron GM so all these are subspaces of\nthe LLL, and also with a hierarchical structure Hk+1 \u2282\nHk. The model Hamiltonian for understanding the GMs\nis given by:\n\nV\u0302int =\n\nm\u2211\nk=1\n\n\u03bbkV\u0302k, \u03bbk \ufffd \u03bbk+1 (6)\n\nAll metrics gabk in the Hamiltonian is arbitrary and with-\nout loss of generality we can set them as gabk = I2, since\nthe GMs are quantum fluctuations around these fixed\nmetrics. Let the ground state of Eq.(6) be |\u03c80\u3009 \u2208 Hm,\nso the quadrupole excitation is obtained from the long\nwavelength limit of the GMP mode or single mode ap-\nproximation defined as follows[3, 4]:\n\n|\u03c8g\u3009 = lim\nq\u21920\n\n1\u221a\nSq\n\n\u03b4\u03c1\u0304q|\u03c80\u3009 (7)\n\nNote that |\u03c8g\u3009 and |\u03c80\u3009 are orthogonal, and Sq is the reg-\nularised guiding center structure factor with limq\u21920 Sq \u223c\n\u03b7|q|4. The Haldane bound dictates that the value of \u03b7\ngives the upper bound to the topological shift of |\u03c80\u3009[45].\n\nThe important question to ask here, is in which CHS\ndoes |\u03c8g\u3009 reside in. If |\u03c8g\u3009 \u2208 Hk and |\u03c8g\u3009 /\u2208 Hk+1, then\nobviously there is no GM associated with the quantum\nfluctuation around gabk , since such fluctuation will bring\nus out of Hk. However, |\u03c8g\u3009 can be decomposed into\nmultiple modes, each within Hk\u2032>k but outside of the\nHk\u2032+1, associated with the quantum fluctuation around\ngabk\u2032+1, as long as |\u03c80\u3009 \u2208 Hk\u2032+1. This is most easily seen\nfrom computing the spectral function defined below:\n\nI(E) =\n\u2211\nn\n\n|\u3008\u03c8n|\u03c8g\u3009|2 \u03b4 (E \u2212 En) (8)\n\n\n\n4\n\nGI\n\nGII\n\nGIII\n\n(a) (b)\n\nFQH at 1/7FQH at 6/7 FQH at 4/13\n\ne-e-e-e- e- e- e-\n\ncf1/3\n4cf2/3\n\n4cf2/3\n4\n\nFQH at 2/11\n\ncf1/5\n2\n\nC3\n\nC1\n\nC\n\nC\n\nC\n\ne-e- e- e-\n\ne- e-\n\n= =\n\n==\n\n2bdyH12bdyH5HLLL\n\n2bdyH3\n\ncf4/5\n2 cf4/5\n\n2 cf4/5\n2 cf4/5\n\n2\n\nFIG. 2. (a) An illustration of the hierarchical structure of three CHSs and the ground state |\u03c80\u3009 within HIII (red\nsphere) in the Hilbert space. The corresponding GMP mode |\u03c8g\u3009 is outside HI so one can imagine the regularised guiding\ncenter density operator acting on the ground state goes through three CHSs, leading to three emergent GMs because of the\nfluctuation around the metric of each of the CHSs. (b) PH conjugate of Laughlin states within different CHSs. Here\n\nCi denotes the PH conjugate within H2bdy\ni and C denotes the PH conjugate within a single LL or a single CF level. Magnetic\n\nfluxes are represented by arrows, and the CFs denoted by cfn\u03bd\u2217 , consisted of one electron and n fluxes, form a CF FQH state at\n\u03bd\u2217. Note that the red (cf24/5) and the yellow (cf42/3) CFs are anti-CFs with the fluxes opposite to the external field.\n\nwhere |\u03c8n\u3009, En are eigenstates and eigenenergies of\nEq.(6). Given that \u03bbk \ufffd \u03bbk+1, we will see m \u2212 k dis-\ntinct peaks well separated in energy, corresponding to\nm\u2212 k GMs each with transparent geometric interpreta-\ntion as illustrated in Fig.2(a). The spectral sum rule for\nthe guiding center structure factor will clearly be satis-\nfied from all the contributions of these GMs, as long as\n|\u03c8g\u3009 lives completely within Hk.\n\nShort-range two-body interaction\u2013 A number of ana-\nlytical results have been derived in our previous works,\nwhich are rigorous in the thermodynamic limit and use-\nful in determining which CHS |\u03c8g\u3009 resides in[7]. Let us\n\nfirst take V\u0302int in Eq.(6) as a sum of short-range two-body\ninteractions as follows:\n\nV\u0302int =\n\nn\u2211\ni=1\n\n\u03bbiV\u0302\n2bdy\n2i\u22121 (9)\n\nwith V\u0302 2bdy\n2i\u22121 as the (2i\u22121)th Haldane PP, where fermionic\n\nstatistics has been considered. Thus the corresponding\nnull spaces H2bdy\n\nn is spanned by the Laughlin ground\nstate and quasiholes at \u03bd = 1/ (2n+ 1). Here we can\nprove analytically[7] that |\u03c8g\u3009 of the Laughlin phase at\n\n\u03bd = 1/(2n + 1) resides within H2bdy\nn\u22121 but completely\n\noutside of H2bdy\nn (we take H2bdy\n\n0 = HLLL), which is\nsaturated by the ground state and quasiholes. Thus\nthere can only be one GM and one peak in the spec-\ntral function, associated with the metric fluctuation of\ngabn . There are, however, many other FQH states that\nare incompressible with Eq.(6) but not in H2bdy\n\nn . These\ninclude the Jain states at \u03bd = N/(2nN + 1), N > 1 and\n\ntheir particle-hole (PH) conjugate states (within H2bdy\nn\u22121 )\n\nat \u03bd = N/(2nN \u2212 1), N > 1. Note that all these\n\nstates still resides within H2bdy\nn\u22121 , though the ground state\n\nand quasiholes do not saturate H2bdy\nn\u22121 . One can prove\n\nanalytically that their corresponding |\u03c8g\u3009 all satisfies\n\n|\u03c8g\u3009 \u2208 H2bdy\nn\u22122 . While they are again completely outside\n\nof H2bdy\nn , now they have spectral weights within H2bdy\n\nn\u22121 .\nThus each of those states will have two GMs with re-\nspect to Eq.(6), a generic result agreeing some special\ncases studied before[25, 26]. These two GMs are asso-\nciated with the fluctuation of the metric gabn , g\n\nab\nn\u22121, and\n\nthey can also be understood via clustering properties in\nparton constructions[26].\n\nNon-abelian FQH states are particularly interesting in\nstrongly correlated topological systems, and their GMs\ncan also be predicted in a similar fashion, assuming that\nthey can be stabilised by realistic interactions adiabati-\ncally connected to Eq.(6). For example the Pfaffian state\nat \u03bd = 1/(2n) can be understood as a condensate of\npaired composite fermions, each with one electron at-\ntached to 2n magnetic fluxes[46, 47]. The model states\n\nof these FQH phases all live within H2bdy\nn\u22121 . For short-\n\nrange two-body interactions they will also all have two\n\nGMs, one within H2bdy\nn\u22121 , and the other within H2bdy\n\nn\u22122 .\nIt is also interesting to note with short-range two-body\n\ninteraction, all FQH states related to the Laughlin states\nby particle-hole (PH) conjugation will have at most two\nGMs. There can be multiple well-defined PH conjuga-\ntions for each Laughlin state in different Laughlin CHSs,\nnot just within LLL (where PH conjugation relates the\nstate at \u03bd to 1 \u2212 \u03bd). This is because for the Laughlin\nstate at \u03bd = 1/(2n + 1), it can also be reinterpreted as\na Laughlin state of composite fermions (CF) with each\nelectron attached to 2k magnetic fluxes (k < n), at the\nCF fractional filling factor \u03bd\u2217 = 1/(2(n\u2212 k) + 1)[48, 49]\nas Fig.2(b) shows. We can thus rigorously define the\n\nPH conjugate of CFs within H2bdy\nk , at the CF filling\n\nfactor of \u03bd\u2217 = 2(n \u2212 k)/(2(n \u2212 k) + 1), correspond-\ning to the interacting CF states at electron filling fac-\n\n\n\n5\n\n0 10\nE\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n|\nn|\n\ng\n|2\n\n10 V2bdy\n1 + V2bdy\n\n3\n\n(a1) 2/7-Graviton (8e27o)\n\n0.0 0.1 0.2\nE\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4 Coulomb\n interaction\n\n(a2) 2/7-Graviton (8e27o)\n\n0100 101 102 103 104\n\nE\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n|\nn|\n\ng\n|2\n\n104 V2bdy\n1 + V2bdy\n\n3\n+V2bdy\n\n5\n\n(b1) 4/13-Graviton (8e25o)\n\n0.0 0.1 0.2\nE\n\n0.0\n\n0.2\n\n0.4\n\n0.6\nCoulomb interaction\n\n+0.01 V2bdy\n5\n\n(b2) 4/13-Graviton (8e25o)\n\n0 50 100\nE\n\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n|\nn|\n\ng\n|2\n\n102 V2bdy\n1 + 10 V2bdy\n\n3\n+V2bdy\n\n5\n\n(c1) 2/11-Graviton (6e30o)\n\n0.0 0.1 0.2\nE\n\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\nCoulomb\n\n interaction\n\n(c2) 2/11-Graviton (6e30o)\n\nFIG. 3. Spectral functions of the FQH states with the\nfilling factor \u03bd = 2/7, 4/13 and 2/11. The graviton mode\nof the FQH state with filling factor \u03bd is called \u03bd-graviton for\nsimplicity. The blue, the turquoise and the red region de-\nnote H2bdy\n\n3 , H2bdy\n1 and its complement correspondingly, from\n\nwhich one can clearly see the gaps between different sectors.\nFor the FQH states with \u03bd = 2/7 and 4/13, model Hamil-\ntonians show similar signatures of two peaks in the spectral\nfunctions as coulomb interactions (a small V\u0302 2bdy\n\n5 is added in\n(b2) for stabilizing the proper ground state, which now has\nan overlap of 0.99 with the model state in (b1)).\n\ntor \u03bd = 2(n \u2212 k)/(2(n \u2212 k)(2k + 1) + 1). Each Laugh-\nlin state at \u03bd = 1/(2n + 1) thus have n PH conju-\ngate state with k = 0, 2, \u00b7 \u00b7 \u00b7n \u2212 1, with k = 0 the\nusual PH conjugate state in LLL at \u03bd = 2n/(2n + 1).\nSince the \u03bd = 2(n \u2212 k)/(2(n \u2212 k)(2k + 1) + 1) state\n\nlives entirely within H2bdy\nk and entirely outside of H2bdy\n\nk+1 ,\none can rigorously show[7] its graviton mode lives en-\n\ntirely within H2bdy\nk\u22121 for k > 0, leading to two GMs.\n\nThese two GMs come from the fluctuation of gabk , as\nwell as the fluctuation of the metric defining the CHS of\n\u03bd = 2(n\u2212 k)/(2(n\u2212 k)(2k+ 1) + 1). Since we are taking\n\nthe PH conjugate within H2bdy\nk , the GM within H2bdy\n\nk\nwill also have the opposite chirality as the one outside of\n\nit. For k = 0, the anti-Laughlin state at \u03bd = 2n/(2n+ 1)\nonly has one GM, since there is no additional CHS de-\nfined by the two-body interaction within LLL that also\ncontains the CHS of \u03bd = 2n/(2n + 1). An example of\nthe PH conjugate state with n = 3, k = 1 (e.g. the PH\n\nconjugate state of \u03bd = 1/7 within H2bdy\n1 , at \u03bd = 4/13)\n\nwill be discussed in details later.\nFew-body non-Abelian interactions\u2013 We now illustrate\n\nthat the number of GMs is a dynamical property strongly\ndependent on the interaction. Let us first look at the\nJain state at \u03bd = 2/9, corresponding to the \u03bd\u2217 = 2 state\nof the CFs with each electron bound to four magnetic\nfluxes, or the \u03bd\u2217 = 2/5 state of the CFs with each electron\nbound to two magnetic fluxes. We have argued before\nthat with short-range two-body interactions, this FQH\nstate has two GMs. It is important to note, however,\nwhile the CHS of this FQH state is well-defined from\nthe CF construction, such construction does not allow an\nexact model Hamiltonian within the LLL. The two-body\ninteraction only defines its CHS approximately, though\nto a very good level of accuracy. A better microscopic\nHamiltonian is given as follows:\n\nV\u0302int = V\u03023bdy\nn =\n\nn\u2211\ni=3\n\nV\u0302 3bdy\ni (10)\n\nwhere V\u0302 3bdy\ni are the three-body PPs[35]. Note there is no\n\nV\u0302 3bdy\n4 due to fermionic statistics, and V\u0302 2bdy\n\n9 , V\u0302 3bdy\n11 are\n\ndoubly degenerate, so here we take them as an arbitrary\nlinear combination (the CHS is invariant). The unique\nhighest density ground state of Eq.(10) with n = 11 has\nvery high overlap with the Jain \u03bd = 2/9 state (\u223c 0.99\nfor eight electrons). While its quasihole counting is non-\nAbelian, one could conjecture that the ground state is\ntopologically equivalent to the Jain state, in analogy to\nthe Gaffnian state and the Jain \u03bd = 2/5 state that has\nbeen studied before[33, 50].\n\nSuch subtleties, while important by themselves, do\nnot really affect our discussions about GMs, which are\ngapped excitations. The main message here is that\nthe null spaces of V\u03023bdy\n\nn give a family of CHSs beyond\nthe Laughlin CHSs discussed before. The Moore-Read,\nGaffnian and Haffnian CHSs are illustrated in Fig.1, cor-\nresponding to the case of n = 3, 5, 6 respectively. Let the\nnull space of V\u03023bdy\n\nn be H3bdy\nn , and it is easy to check that\n\nH3bdy\n11 \u2282 H3bdy\n\n9 \u2282 H2bdy\n1 . Note that the ground state of\n\n\u03bd = 2/9 resides in H3bdy\n11 , and it has very high overlap\n\nwith the ground state of V\u0302 2bdy\n3 . We can thus construct\n\nthe following Hamiltonian:\n\nV\u0302int = \u03bb1V\u0302\n2bdy\n1 + \u03bb2V\u0302\n\n3bdy\n9 + V\u0302 2bdy\n\n3 (11)\n\nwith \u03bb1 \ufffd \u03bb2 \ufffd 1. In addition to the original two GMs\n\n(one from the metric fluctuation of H3bdy\n11 , or the CHS of\n\nthe \u03bd = 2/9 phase, and the other from the metric fluctu-\n\nation of H2bdy\n1 ), there will be a third GM from the metric\n\nfluctuation of H3bdy\n9 , easily observable from the spectral\n\nfunction. If we tune \u03bb2 to zero, then the two GMs of the\n\n\n\n6\n\n0 100 101 102 103 104\n\nE\n\n0\n\n10 4\n\n10 3\n\n10 2\n\n10 1\n\n100\n\n|\nn|\n\ng\n|2\n\n(a) 104 V2bdy\n1 + 102 V3bdy\n\n9 + V2bdy\n3\n\n0 100 101 102 103 104\n\nE\n\n(b) 104 V2bdy\n1 + V2bdy\n\n3\n\n0.00 0.05 0.10 0.15 0.20\nE\n\n(c) Coulomb interaction\n\nFIG. 4. Spectral functions of FQH states at \u03bd = 2/9 with 8 electrons. (a) shows two peaks within H2bdy\n1 in the spectral\n\nfunction with respect to the model Hamiltonian, where the green sector denotes the null space of V\u0302 3bdy\n9 . These peaks will merge\n\nafter V\u0302 3bdy\n9 is removed from the Hamiltonian as (b) shows. A slightly exaggerating ratio between different PPs is adopted to\n\nshow the signature of different CHSs clearly.\n\nlower energies will gradually merge, to become a single\n\nGM within H2bdy\n1 , accounting only for the metric fluctu-\n\nation of the CHS of the \u03bd = 2/9 as shown in Fig.4. The\nmerging and splitting of GMs can also be expected for\nthe non-Abelian Pfaffian state at \u03bd = 1/4, which simi-\nlarly has an exact three-body model Hamiltonian[51\u201353].\nWe will discuss in more details next with numerical com-\nputations.\n\nNumerical results and GM interactions\u2013 While the\nmain concepts and predictions of the GMs have been\nformulated analytically above, it is also useful to fur-\nther illustrate the formalism with examples of numerical\ncalculations. The spectral functions for the Jain states\nat \u03bd = 2/7, 2/9, 1/4 with Coulomb interaction has been\ncomputed[25, 26]. Here we compute the spectral func-\ntions of these and additional FQH states with model\nHamiltonians, to show that two or even more peaks can\nbe unambiguously resolved and far separated as com-\npared to the realistic interactions.\n\nThe first two examples are the Jain state at \u03bd = 2/7\n(the PH conjugate of the Laughlin \u03bd = 1/5 state within\n\nH2bdy\n1 ) and the interacting CF state at \u03bd = 4/13 (the PH\n\nconjugate of the Laughlin \u03bd = 1/7 state within H2bdy\n1 ,\n\nwith some experimental evidence[54]). In both cases the\nPH conjugate is defined for CFs, each with one electron\nattached to two fluxes. The CHS of both phases are\n\nproper subspaces of H2bdy\n1 , but outside of H2bdy\n\n3 . Thus\nthere will be a non-zero component of the graviton out-\n\nside of H2bdy\n1 . A short-range two-body interaction with\n\na very dominant V\u0302 2bdy\n1 can thus easily resolve the two\n\nGMs as previously predicted (see Fig.(3a,b)). The two\n\nGMs can also be clearly resolved with V\u0302LLL since it is\n\ndominated by V\u0302 2bdy\n1 .\n\nThe Jain state at \u03bd = 2/11 offers an interesting con-\ntrast, which is the PH conjugate of the Laughlin \u03bd = 1/7\n\nstate within the H2bdy\n3 , defined for CFs with one electron\n\nattached to four fluxes. The two GMs are within and out-\nside of H2bdy\n\n3 , so it can be clearly resolved with a model\n\nHamiltonian with a dominant V\u0302 2bdy\n3 (and a dominant\n\nV\u0302 2bdy\n1 to maintain the ground state gap). However with\n\nV\u0302LLL the strength of V\u0302 2bdy\n3 is only slightly larger than\n\nthat of V\u0302 2bdy\n5 , and it cannot clearly resolve the two GMs\n\n(see Fig.(3c)). This is an example when reducing the\n\nV\u0302 2bdy\n3 of the interaction leads to the mixing and merging\n\nof the two GMs into a single GM, while the ground state\n\nis not affected at all, since it is in the null space of V\u0302 2bdy\n3 .\n\nNote that the energies of the GMs for this FQH phase\n\nare not affected by the V\u0302 2bdy\n1 component of the two-body\n\ninteraction.\n\nFor the Jain state at \u03bd = 2/9, any V\u0302 2bdy\n1 dominated\n\ninteraction (e.g. V\u0302LLL) will give two GMs, as can be\nanalytically proven. From numerical studies with eight\n\nelectrons, the spectral weight of the GM outside H2bdy\n1 is\n\nsmall as compared to other Jain states. It is also another\n\nexample where a single GM (here within H2bdy\n1 ) can be\n\nsplit into two GMs, this time with the introduction of the\nthree-body interactions. We can analytically show that\n\nwithin H2bdy\n1 , there is non-zero graviton spectral weight\n\nboth within and outside of H3bdy\n9 . Thus an introduc-\n\ntion of V\u0302 3bdy\n9 to the microscopic Hamiltonian can lead to\n\nthe splitting of the two GMs in total to three GMs, as\nshown in Fig.4. It is worth noting that the GM within\n\nH3bdy\n9 dominates, and both the second and the third GM\n\nhave the spectral weights that are more than one order\nof magnitude smaller. This could be a finite size effect,\nsince we can analytically show that the spectral weights\nof all three GMs are non-zero for any finite systems. It is\nstill possible, however, that in the thermodynamic limit\nthe weights of the second and/or third GM vanish. We\nare unable to numerically access system sizes with more\nthan eight electrons, and will leave more detailed discus-\n\n\n\n7\n\nsions to future works.\n\nThe non-Abelian Pfaffian state at \u03bd = 1/4 is the ex-\n\nact ground state of V\u03023bdy\n10 . Just like the Pfaffian state at\n\n\u03bd = 1/2 (believed to be stabilised by second LL Coulomb\ninteraction)[32, 55], this state can also be stabilised by a\n\nslightly modified V\u0302LLL, with an overlap of 0.91 for eight\nelectrons. While this small perturbation may not be\neasily realised in experiments, with this Hamiltonian we\nhave the clear understanding that there will be two GMs\n\n(one inside, and the other outside of H2bdy\n1 ). It is inter-\n\nesting to note that we have the hierarchical relationship\n\nthat H3bdy\n9 \u2282 H2bdy\n\n1 \u2282 H3bdy\n8 , and both GMs are within\n\nH3bdy\n8 and at the same time outside of H3bdy\n\n9 . Thus\nwith the model Hamiltonian consisting of only three-\nbody PPs, the two GMs will again merge to become\n\na single GM, in the absence of V\u0302 2bdy\n1 , as reflected in\n\nFig.5. For non-Abelian states there are additional neu-\ntral modes, e.g. the \u201cgravitino\u201d modes at spin s = 3/2 for\nPfaffian[4, 56], that can be considered as super-partners\nof the gravitons. We expect multiple GMs will also lead\nto multiple gravitino modes, and will leave detailed dis-\ncussions elsewhere.\n\nThe experimental relevance\u2013 The experimental detec-\ntion of the multiple GMs in FQH systems and the inter-\naction among them is particularly interesting, because of\nboth the topological and geometric aspects of such neu-\ntral excitations. Seeing clean signals of different GMs\nin experiments could be difficult. This is both because\nthe GMs are buried in the energy continuum and thus\nare easily scattered by disorders, and also because with\nrealistic interactions different GMs can interact and mix\nstrongly. The microscopic picture we developed points to\nthe crucial role of the hierarchy of energy scales associ-\nated with different CHSs, that realistic interaction needs\nto imitate to resolve multiple GMs. Thus the realisation\nof robust Hall plateau may not be enough for the detec-\ntion of GMs. The experimental system may need to be\nflexible enough in tuning the effective electron-electron\ninteractions, so as to control the dynamics of low-lying\ngapped excitations.\n\nFor systems when the LL mixing is negligible (e.g. with\nstrong magnetic field), our calculation shows that short-\nrange interaction (e.g. the Coulomb interaction in the\nLLL) can at most resolve two GMs both for abelian and\nnon-Abelian FQH phases, and we have not found any ex-\nceptions. The universality of such results is due to the\nalgebraic structure of the Laughlin CHSs, and to clearly\nresolve the two GMs, we prefer to have the effective in-\nteraction to be as short-range as possible. Formally if we\nexpand the realistic two-body interaction in the Haldane\nPP basis, we should aim to have the ratio consecutive\n\nPP coefficients (i.e. the ratio of the coefficient of V\u0302 2bdy\ni\n\nover that of V\u0302 2bdy\ni+1 ) to be large. This can be achieved by\n\nscreening of electron-electron interaction, or by increas-\ning the sample thickness in experiments. In particular,\nJain states at \u03bd = N/(2nN + 1) with N > 1, as well as\nPH conjugate states at \u03bd = 2(n\u2212k)/(2(n\u2212k)(2k+1)+1)\n\nwith k > 0, will all have two GMs. Numerical calcula-\ntions also show such short range interactions favour the\nincompressibility of these FQH states, as compared to\nthe bare Coulomb interaction.\n\nThe most easily observed second GM in experiments\nwould be the one outside of the V\u03021 null space (i.e. H1),\n\nwhich requires a dominant V\u03021 interaction and can be\nrealised with the Coulomb interaction within the LLL\nfor FQH states around \u03bd = 1/4 as discussed in previous\nworks[7]. For FQH states in the SLL, however, the GM\noutside of H1 will mix strongly with the ones inside H1,\nbecause of the significantly stronger V\u03023 as compared to\nLLL Coulomb interaction. It is also important to note\nwhile the FQH states around \u03bd = 1/6 (e.g. the \u03bd = 2/11\nstate) all in principle have at least two GMs (except for\nthe Laughlin state at \u03bd = 1/7), they will be hard to\nobserve even with LLL Coulomb interaction. This is be-\ncause such GMs have to be resolved by a dominant V\u0302 2bdy\n\n3\n\n(as compared to V\u0302 2bdy\nk>3 ), which is not the case for LLL\n\nCoulomb interaction. Thus in general, the observation of\nmultiple GMs even for simple two-body interactions will\nnecessarily require careful tuning of experimental param-\neters with Coulomb based interaction.\n\nThe short-range two-body interactions do not favour\nnon-Abelian FQH states, as the compressible composite\nFermi liquid (CFL) states are generally more competi-\ntive, for example at \u03bd = 1/(2n)[27, 57\u201362]. For non-\nAbelian FQH states we generally require longer-range\ninteractions (e.g. Coulomb interaction in the second\nLL), or few-body interactions from LL mixing[27, 33, 53].\nWhile it is hard to predict from finite size numerical cal-\nculations how these exotic states can be stabilised by\nthe realistic interactions, these additional ingredients are\nnecessary if we would like to observe more than two GMs.\nA possible candidate for three GMs seems to be the Jain\nstate at \u03bd = 2/9, where we have shown that the proper\nintroduction of three-body interactions can lead to three\npeaks in the spectral function. We expect one of the\npeaks resolved by the three-body interaction to be rather\nweak, and the dominant peak resides at low energies. For\nthis state our numerical results so far are also inconclu-\nsive due to the small system sizes accessible, and more\nwork is needed to establish its behaviour from finite size\nscaling.\n\nMicroscopic basis for the effective field theory\u2013 For the\neffective field theory construction, the number of grav-\nitational fields needed (i.e. the Haldane modes) for a\ncomplete description of the response to the metric fluc-\ntuation should be determined by the underlying micro-\nscopic theory. It is important to first identify the physical\nHilbert space on which the effective field theory is based.\nFor example, for the Jain states near \u03bd = 1/(2n), the\nelementary particles are CFs with each electron bound\nto 2n magnetic fluxes (and their PH conjugates, or CF\nholes). The Hilbert space is thus spanned by CF levels\n(the fully filled ones gives the Jain \u03bd = N/(2nN + 1)\nstates) and their PH conjugates (giving Jain states with\n\u03bd = N/(2nN \u2212 1)). We can denote it as the base space\n\n\n\n8\n\n0100 101 102 103 104 105 106\n\nE\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n|\n\nn|\ng\n\n|2\n(a) 106 3bdy\n\n8 + 104 V2bdy\n1 + 102 V3bdy\n\n9 + V3bdy\n10\n\n0100 101 102 103 104 105 106\n\nE\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n(b) 106 3bdy\n8 + 102 V3bdy\n\n9 + V3bdy\n10\n\n0.00 0.05 0.10 0.15\nE\n\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n(c) Coulomb interaction+0.02 V2bdy\n5\n\nFIG. 5. Spectral functions of the Pfaffian state at \u03bd = 1/4 with 8 electrons. The turquoise, the orange and the\n\npink region denote H2bdy\n1 , the null space of V\u03023bdy\n\n8 and its complement correspondingly. When there is no two-body PP V\u0302 2bdy\n1\n\nin the Hamiltonian, one can clearly observe the merging of peaks from (a) to (b). Considering the coulomb interaction is\n\nV\u0302 2bdy\n1 -dominated, we can also observe two peaks in (c). A slightly exaggerating ratio between different PPs is adopted to show\n\nthe signature of different CHSs clearly. A small V\u0302 2bdy\n5 is added in (c) for stabilizing the non-Abelian Pfaffian state.\n\n(a) (b)\n\n(c) (d)\n\n*\n\n* '\n\n'\n\n0 Haldane Mode\n1 Peak in I(E)\n\nn=1 n>1\n\n2 Haldane Mode\n3 Peak in I(E)\n\n1 Haldane Mode\n3 Peak in I(E)\n\n1 Haldane Mode\n2 Peaks in I(E)\n\nPH\nConjugate\n\nPeaks\n\nFIG. 6. Number of Haldane modes with different\nstructure of CHSs. Laughlin states (N = 1, \u03b7 = 1)\nare denoted by the white point in the corresponding CHS\n(blue circle). For the Jain states at N/(2nN + \u03b7), (a) with\nn = 1, N > 1, \u03b7 = \u00b11, (e.g. the FQH state at 2/3 and 2/5,\netc.), because \u03b4\u03c1\u0302q = \u03b4\u03c1\u0302\u2217q, these states will show the same be-\nhaviour as the Laughlin state at 1/3, i.e. one peak with no\nHaldane mode required. When n > 1, (b) shows that a single\nHaldane mode is needed in the effective field theory despite\ntwo peaks observed in the spectral function, among which\ngiven n, the states with N = 2, \u03b7 = \u22121 can be regarded\nas the particle-hole conjugate partner of the corresponding\nLaughlin state within some specific CHS, and the states with\nN > 1, \u03b7 = 1 are the states in higher CF levels as shown in\nFig.2(b). (c) and (d) show more possibilities and lead to the\nconclusion that the number of Haldane modes added to the\neffective theory cannot be easily reckoned from the number of\npeaks in the spectral function I(E), which is closely related\nto the microscopic Hamiltonian used.\n\nof the effective field theory. In particular, it is the full\nHilbert space of LLL for n = 1. For n > 1, the base space\n\nis H2bdy\nn\u22121 .\n\nTo determine if and how many Haldane modes need\nto be added to effective field theory, it all depends on\nif the long wavelength limit of the GMP mode lives en-\ntirely within the base space. For n = 1 this is definitely\nthe case, since the GMP mode lives entirely within the\nLLL as illustrated in Fig.6(a). In particular, the regu-\nlarised density operator \u03b4\u03c1\u0304q is PH symmetric. For n > 1,\nthe GMP modes for all the Laughlin states live entirely\nwithin the base space, but \u03b4\u03c1\u0304q is no longer PH symmet-\nric within the base space. One can also show rigorously\nfrom the microscopic point of view that all Jain states at\n\u03bd = N/(2nN\u00b11) with N > 1 have GMP modes partially\noutside of the base space, thus requiring at least one ad-\nditional Haldane mode to be added to the effective field\ntheory as illustrated in Fig.6(b).\n\nIn principle we can have multiple CHSs containing\nthe base space with the hierarchical structure Hbase \u2282\nH1 \u00b7 \u00b7 \u00b7 \u2282 Hk with k > 1, and the GMP mode resides in\nHk having non-zero weights in all Hk\u2032<k. We have not\nfound such cases for Jain states with CHSs defined by\ntwo-body and three-body PPs, but it may be possible for\nother FQH states, or for CHSs defined by few-body PPs\ninvolving clusters of more than three electrons. These\ncases are illustrated by Fig.6(c), where more than one\nHaldane modes are needed for the effective field theory,\nfor it to agree with microscopic Hamiltonians that can\nresolve those CHSs in terms of energy.\n\nNumerical calculations are essential in verifying the ef-\nfective field theory predictions, but it is important to\nnote that the number of Haldane modes needed for the\neffective field theory does not necessarily correspond to\nthe number of peaks in the graviton spectral function,\nsince the latter depends on the microscopic details of\n\n\n\n9\n\nthe Hamiltonian. Fig.6(d) is another example that even\nwithin the base space there can be multiple CHSs, which\ncan be resolved by proper model Hamiltonians. With\nsuch interactions the GM within the base space (which is\nthe conventional graviton, not the Haldane modes) can\nlead to multiple spectral weight peaks well separated in\nenergy, though the total weight is captured by the cou-\npling of the composite particles with the Hall manifold\nmetric in the effective theory.\n\nIn fact, from an effective theory point of view, we\ncan always use a single Haldane mode to capture all the\nGM weights outside of the base space, while all the GM\nweights within the base space can be captured by the\nusual composite particle action. While the known Dirac\nCF description for the Haldane mode strictly speaking\nonly applies to the FQH states very close to \u03bd = 1/(2n)\n\n(i.e. for Jain states \u03bd = N/(2nN \u00b1 1) with N \u2192\u221e, and\ndefinitely does not apply for Laughlin states at N = 1),\nthe general arguments here with the relationship between\nthe GMP modes and the base space should apply to all ef-\nfective field theory description, with or without particle-\nhole symmetry.\n\nACKNOWLEDGMENTS\n\nWe are grateful to A. Balram and Dung X. Nguyen\nfor helpful discussions. This work is supported by the\nSingapore National Research Foundation (NRF) under\nNRF fellowship award NRF-NRFF12-2020-0005, and a\nNanyang Technological University start-up grant (NTU-\nSUG).\n\n[1] F. Dyson. Is a graviton detectable? In XVIIth Interna-\ntional Congress on Mathematical Physics, pages 670\u2013682.\nWorld Scientific, 2014.\n\n[2] T. Rothman and S. Boughn. Can gravitons be detected?\nFoundations of Physics, 36(12):1801\u20131825, 2006.\n\n[3] S. M. Girvin, A. H. MacDonald, and P. M. Platz-\nman. Magneto-roton theory of collective excitations in\nthe fractional quantum hall effect. Physical Review B,\n33(4):2481, 1986.\n\n[4] B. Yang, Z.-X. Hu, Z. Papic\u0301, and F. D. M. Haldane.\nModel wave functions for the collective modes and the\nmagnetoroton theory of the fractional quantum hall ef-\nfect. Phys. Rev. Lett., 108:256807, Jun 2012.\n\n[5] F. D. M. Haldane. Geometrical description of the frac-\ntional quantum hall effect. Physical Review Letters, 107,\n9 2011.\n\n[6] Q. T. Ha and B. Yang. Fractionalization and dynamics\nof anyons and their experimental signatures in the \u03bd =\nn + 1/3 fractional quantum hall state. Phys. Rev. Lett.,\n127:046402, Jul 2021.\n\n[7] Y. Wang and B. Yang. Analytic exposition of the gravi-\nton modes in fractional quantum hall effects and its phys-\nical implications. arXiv preprint arXiv:2109.08816, 2021.\n\n[8] Dam T. Son. Newton-cartan geometry and the quantum\nhall effect. arXiv preprint arXiv:1306.0638, 6 2013.\n\n[9] Luo X., Y. S. Wu, and Yu Y. Noncommutative chern-\nsimons theory and exotic geometry emerging from the\nlowest landau level. Physical Review D, 93, 6 2016.\n\n[10] S. Golkar, Dung X. Nguyen, and Dam T. Son. Spectral\nsum rules and magneto-roton as emergent graviton in\nfractional quantum hall effect. Journal of High Energy\nPhysics, 2016:1\u201315, 1 2016.\n\n[11] A. Gromov and Dam T. Son. Bimetric theory of frac-\ntional quantum hall states. Physical Review X, 7, 11\n2017.\n\n[12] S. F. Liou, F. D. M. Haldane, Yang K., and E. H. Rezayi.\nChiral gravitons in fractional quantum hall liquids. Phys-\nical Review Letters, 123, 9 2019.\n\n[13] F. D. M. Haldane, E. H. Rezayi, and Kun Yang. Graviton\nchirality and topological order in the half-filled landau\nlevel. Phys. Rev. B, 104:L121106, Sep 2021.\n\n[14] Z. Liu, A. C. Balram, Z. Papic\u0301, and A. Gromov. Quench\n\ndynamics of collective modes in fractional quantum hall\nbilayers. Phys. Rev. Lett., 126:076604, Feb 2021.\n\n[15] A.r Kirmani, K. Bull, C.-Y. Hou, Z. Papic\u0301, A. Rah-\nmani, and P. Ghaemi. Realizing fractional-quantum-\nhall gravitons on quantum computers. arXiv preprint\narXiv:2107.10267, 2021.\n\n[16] Dung X. Nguyen and Dam T. Son. Probing the spin\nstructure of the fractional quantum hall magnetoroton\nwith polarized raman scattering. Phys. Rev. Research,\n3:023040, Apr 2021.\n\n[17] Dung X. Nguyen and Dam T. Son. Dirac composite\nfermion theory of general jain sequences. Phys. Rev. Re-\nsearch, 3:033217, Sep 2021.\n\n[18] U. Wurstbauer, K. W. West, L. N. Pfeiffer, and\nA. Pinczuk. Resonant inelastic light scattering investi-\ngation of low-lying gapped excitations in the quantum\nfluid at \u03bd= 5/2. Physical review letters, 110(2):026801,\n2013.\n\n[19] A. Pinczuk, B. S. Dennis, L. N. Pfeiffer, and K. W.\nWest. Light scattering by collective excitations in the\nfractional quantum hall regime. Physica B: Condensed\nMatter, 249:40\u201343, 1998.\n\n[20] A. Pinczuk, B. S. Dennis, L. N. Pfeiffer, and K. West. Ob-\nservation of collective excitations in the fractional quan-\ntum hall effect. Physical review letters, 70(25):3983, 1993.\n\n[21] U. Wurstbauer, A. L. Levy, A. Pinczuk, K. W. West,\nL. N. Pfeiffer, M. J. Manfra, G. C. Gardner, and J. D.\nWatson. Gapped excitations of unconventional fractional\nquantum hall effect states in the second landau level.\nPhysical Review B, 92(24):241407, 2015.\n\n[22] A. Pinczuk, B. S. Dennis, L. N. Pfeiffer, and K. W. West.\nInelastic light scattering in the regimes of the integer and\nfractional quantum hall effects. Semiconductor science\nand technology, 9(11S):1865, 1994.\n\n[23] K. Yang. Acoustic wave absorption as a probe of dy-\nnamical geometrical response of fractional quantum hall\nliquids. Physical Review B, 93, 4 2016.\n\n[24] B. Yang. Microscopic theory for nematic fractional quan-\ntum hall effect. Phys. Rev. Research, 2:033362, Sep 2020.\n\n[25] Dung X. Nguyen, F. D. M. Haldane, E. H. Rezayi,\nDam T. Son, and K. Yang. Multiple magnetorotons and\nspectral sum rules in fractional quantum hall systems.\n\n\n\n10\n\narXiv preprint arXiv:2111.10593, 2021.\n[26] A. C. Balram, Z. Liu, A. Gromov, and Z. Papic\u0301. Very\n\nhigh-energy collective states of partons in fractional\nquantum hall liquids. arXiv preprint arXiv:2111.10395,\n2021.\n\n[27] B. Yang. Three-body interactions in generic fractional\nquantum hall systems and impact of galilean invariance\nbreaking. Phys. Rev. B, 98:201101, Nov 2018.\n\n[28] F. D. M. Haldane and K. Yang. Landau level mixing and\nlevitation of extended states in two dimensions. Physical\nreview letters, 78(2):298, 1997.\n\n[29] I. Sodemann and A. H. MacDonald. Landau level mixing\nand the fractional quantum hall effect. Physical Review\nB, 87(24):245425, 2013.\n\n[30] S. H. Simon and E. H. Rezayi. Landau level mixing in\nthe perturbative limit. Physical Review B, 87(15):155426,\n2013.\n\n[31] M. R. Peterson and C. Nayak. More realistic hamiltoni-\nans for the fractional quantum hall regime in gaas and\ngraphene. Phys. Rev. B, 87:245129, Jun 2013.\n\n[32] G. Moore and N. Read. Nonabelions in the fractional\nquantum hall effect. Nuclear Physics B, 360(2-3):362\u2013\n396, 1991.\n\n[33] B. Yang. Gaffnian and haffnian: Physical relevance of\nnonunitary conformal field theory for the incompress-\nible fractional quantum hall effect. Physical Review B,\n103(11):115102, 2021.\n\n[34] F. D. M. Haldane. Fractional quantization of the hall ef-\nfect: A hierarchy of incompressible quantum fluid states.\nPhys. Rev. Lett., 51:605\u2013608, Aug 1983.\n\n[35] S. H. Simon, E. H. Rezayi, and N. R. Cooper. General-\nized quantum hall projection hamiltonians. Phys. Rev.\nB, 75:075318, Feb 2007.\n\n[36] G. Cristofano, G. Maiella, R. Musto, and F. Nicodemi.\nTopological order in quantum hall effect and two-\ndimensional conformal field theory. Nuclear Physics B-\nProceedings Supplements, 33(3):119\u2013133, 1993.\n\n[37] S. H. Simon, E. H. Rezayi, N. R. Cooper, and I. Berd-\nnikov. Construction of a paired wave function for spin-\nless electrons at filling fraction \u03bd = 2/5. Phys. Rev. B,\n75:075317, Feb 2007.\n\n[38] D. Arovas, J. R. Schrieffer, and F. Wilczek. Fractional\nstatistics and the quantum hall effect. Physical review\nletters, 53(7):722, 1984.\n\n[39] N. Read and E. Rezayi. Quasiholes and fermionic zero\nmodes of paired fractional quantum hall states: The\nmechanism for non-abelian statistics. Physical Review\nB, 54(23):16864, 1996.\n\n[40] R. L. Willett, L. N. Pfeiffer, and K. W. West. Alterna-\ntion and interchange of e/4 and e/2 period interference\noscillations consistent with filling factor 5/2 non-abelian\nquasiparticles. Physical Review B, 82(20):205301, 2010.\n\n[41] K. T. Law. Probing non-abelian statistics in \u03bd = 12/5\nquantum hall state. Phys. Rev. B, 77:205310, May 2008.\n\n[42] B. Parsa, V. Gurarie, and C. Nayak. Plasma analogy and\nnon-abelian statistics for ising-type quantum hall states.\nPhys. Rev. B, 83:075303, Feb 2011.\n\n[43] B. A. Bernevig and F. D. M. Haldane. Properties of non-\nabelian fractional quantum hall states at filling \u03bd = k/r.\nPhys. Rev. Lett., 101:246806, Dec 2008.\n\n[44] B. A. Bernevig and F. D. M. Haldane. Clustering prop-\nerties and model wave functions for non-abelian frac-\n\ntional quantum hall quasielectrons. Phys. Rev. Lett.,\n102:066802, Feb 2009.\n\n[45] F. D. M. Haldane. \u201dhall viscosity\u201d and intrinsic metric\nof incompressible fractional hall fluids. arXiv preprint\narXiv:0906.1854, 2009.\n\n[46] B. I. Halperin, Patrick A. Lee, and Nicholas Read. The-\nory of the half-filled landau level. Phys. Rev. B, 47:7312\u2013\n7343, Mar 1993.\n\n[47] G. Mo\u0308ller and S. H. Simon. Paired composite-fermion\nwave functions. Phys. Rev. B, 77:075319, Feb 2008.\n\n[48] J. K. Jain and V. J. Goldman. Hierarchy of states in\nthe fractional quantum hall effect. Physical Review B,\n45(3):1255, 1992.\n\n[49] J. K. Jain. Composite fermions. Cambridge University\nPress, 2007.\n\n[50] B. Yang, Y.-H. Wu, and Z. Papic\u0301. Effective abelian\ntheory from a non-abelian topological order in the \u03bd=\n2/5 fractional quantum hall effect. Physical Review B,\n100(24):245303, 2019.\n\n[51] E. Fradkin, C. Nayak, A. Tsvelik, and F. Wilczek. A\nchern-simons effective field theory for the pfaffian quan-\ntum hall state. Nuclear Physics B, 516(3):704\u2013718, 1998.\n\n[52] N. Read and E. Rezayi. Beyond paired quantum hall\nstates: Parafermions and incompressible states in the\nfirst excited landau level. Physical Review B, 59(12):8084,\n1999.\n\n[53] B. Yang. Fractional quantum hall effect from frustration-\nfree hamiltonians. Phys. Rev. Lett., 125:176402, Oct\n2020.\n\n[54] W. Pan, H. L. Stormer, D. C. Tsui, L. N. Pfeiffer, K. W.\nBaldwin, and K. W. West. Fractional quantum hall effect\nof composite fermions. Phys. Rev. Lett., 90:016801, Jan\n2003.\n\n[55] R. H. Morf. Transition from quantum hall to compress-\nible states in the second landau level: New light on the\n\u03bd = 5/2 enigma. Phys. Rev. Lett., 80:1505\u20131508, Feb\n1998.\n\n[56] A. Gromov, E. J. Martinec, and S. Ryu. Collective exci-\ntations at filling factor 5/2: The view from superspace.\nPhys. Rev. Lett., 125:077601, Aug 2020.\n\n[57] M. Levin, B. I. Halperin, and B. Rosenow. Particle-hole\nsymmetry and the pfaffian state. Physical review letters,\n99(23):236806, 2007.\n\n[58] S.-S. Lee, S. Ryu, C. Nayak, and M. P.A. Fisher. Particle-\nhole symmetry and the \u03bd = 5/2 quantum hall state.\nPhysical review letters, 99(23):236807, 2007.\n\n[59] E. H. Rezayi. Landau level mixing and the ground state\nof the \u03bd = 5/2 quantum hall effect. Phys. Rev. Lett.,\n119:026801, Jul 2017.\n\n[60] Ajit C. Balram, Csaba To\u030bke, A. Wo\u0301js, and J. K. Jain.\nSpontaneous polarization of composite fermions in the\nn = 1 landau level of graphene. Phys. Rev. B, 92:205120,\nNov 2015.\n\n[61] W. N. Faugno, Ajit C. Balram, Maissam Barkeshli, and\nJ. K. Jain. Prediction of a non-abelian fractional quan-\ntum hall state with f -wave pairing of composite fermions\nin wide quantum wells. Phys. Rev. Lett., 123:016802, Jul\n2019.\n\n[62] B. Yang and A. C. Balram. Elementary excitations in\nfractional quantum hall effect from classical constraints.\nNew Journal of Physics, 23(1):013001, 2021.\n\n\n\tGeometric Fluctuation of Conformal Hilbert Spaces and Multiple Graviton Modes in Fractional Quantum Hall Effect\n\tAbstract\n\t Acknowledgments\n\t References\n\n\n"}
{"Title": "Discovery of ammonia (9,6) masers in two high-mass star-forming regions", "Authors": "Y. T. Yan, C. Henkel, K. M. Menten, Y. Gong, J. Ott, T. L. Wilson, A. Wootten, A. Brunthaler, J. S. Zhang, J. L. Chen, K. Yang", "Abstract": "  Molecular maser lines are signposts of high-mass star formation, probing excitation and kinematics of very compact regions in the close environment of young stellar objects and providing useful targets for trigonometric parallax measurements. Only a few NH$_{3}$ (9,6) masers were known so far, and their origin is still poorly understood. Here we aim to find new NH$_{3}$ (9,6) masers to provide a better observational basis to study their role in high-mass star-forming regions. We carried out NH$_{3}$ (9,6) observations toward Cepheus A and G34.26$+$0.15 with the Effelsberg-100 m telescope and the Karl G. Janksy Very Large Array. We discovered new NH$_{3}$ (9,6) masers in Cep A and G34.26$+$0.25, which increases the number of high-mass star-forming regions hosting NH$_{3}$ (9,6) masers from five to seven. Long term monitoring (20 months) at Effelsberg shows that the intensity of the (9,6) maser in G34.26$+$0.25 is decreasing, while the Cep A maser remains stable. Compared to the Effelsberg data and assuming linear variations between the epochs of observation, the JVLA data indicate no missing flux. This suggests that the NH$_3$ (9,6) emission arises from single compact emission regions that are not resolved by the interferometric measurements. As JVLA imaging shows, the NH$_{3}$ (9,6) emission in Cep A originates from a sub-arcsecond sized region, slightly to the west of the peak position of the 1.36\\,cm continuum object, HW2. In G34.26$+$0.25, three NH$_{3}$ (9,6) maser spots are observed: one is close to the head of the cometary ultracompact \\h2 region C and the other two are emitted from a compact region to the west of the hypercompact \\h2 region A. The newly found (9,6) masers appear to be related to outflows. Higher angular resolution of JVLA and VLBI observations are needed to provide more accurate positions and constraints for pumping scenarios.      ", "Subject": "Astrophysics of Galaxies (astro-ph.GA)", "ID": "arXiv:2201.00021", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstronomy & Astrophysics manuscript no. mainArxiv \u00a9ESO 2022\nJanuary 19, 2022\n\nDiscovery of ammonia (9,6) masers in two high-mass star-forming\nregions\n\nY. T. Yan (\u95eb\u8000\u5ead)1,?, C. Henkel1, 2, 3, K. M. Menten1, Y. Gong (\u9f9a\u9f91)1, J. Ott4, T. L. Wilson1, A. Wootten4, A.\nBrunthaler1, J. S. Zhang (\u5f20\u6c5f\u6c34)5, J. L. Chen (\u9648\u5bb6\u6881)5, and K. Yang (\u6768\u6977)6, 7\n\n1 Max-Planck-Institut f\u00fcr Radioastronomie, Auf dem H\u00fcgel 69, 53121 Bonn, Germany\ne-mail: yyan@mpifr-bonn.mpg.de\n\n2 Astronomy Department, Faculty of Science, King Abdulaziz University, P. O. Box 80203, Jeddah 21589, Saudi Arabia\n3 Xinjiang Astronomical Observatory, Chinese Academy of Sciences, 830011 Urumqi, PR China\n4 National Radio Astronomy Observatory, 520 Edgemont Road, Charlottesville, VA 22903-2475, USA\n5 Center for Astrophysics, Guangzhou University, 510006 Guangzhou, People\u2019s Republic of China\n6 School of Astronomy and Space Science, Nanjing University, 163 Xianlin Avenue, Nanjing 210023, People\u2019s Republic of China\n7 Key Laboratory of Modern Astronomy and Astrophysics (Nanjing University), Ministry of Education, Nanjing 210023, People\u2019s\n\nRepublic of China\n\nReceived XXX; accepted YYY\n\nABSTRACT\n\nContext. Molecular maser lines are signposts of high-mass star formation, probing the excitation and kinematics of very compact\nregions in the close environment of young stellar objects and providing useful targets for trigonometric parallax measurements.\nAims. Only a few NH3 (9,6) masers are known so far, and their origin is still poorly understood. Here we aim to find new NH3 (9,6)\nmasers to provide a better observational basis for studying their role in high-mass star-forming regions.\nMethods. We carried out NH3 (9,6) observations toward Cepheus A and G34.26+0.15 with the Effelsberg 100-meter telescope (beam\nsize 49\u2032\u2032) and the Karl G. Jansky Very Large Array (JVLA; beam size about 1\u2032\u2032.2).\nResults. We discovered new NH3 (9,6) masers in Cep A and G34.26+0.25, which increases the number of known high-mass star-\nforming regions hosting NH3 (9,6) masers from five to seven. Long-term monitoring (20 months) at Effelsberg shows that the intensity\nof the (9,6) maser in G34.26+0.25 is decreasing, while the Cep A maser remains stable. Compared to the Effelsberg data and assuming\nlinear variations between the epochs of observation, the JVLA data indicate no missing flux. This suggests that the NH3 (9,6) emission\narises from single compact emission regions that are not resolved by the interferometric measurements. As JVLA imaging shows, the\nNH3 (9,6) emission in Cep A originates from a sub-arcsecond-sized region, slightly to the west (0\u2032\u2032.28 \u00b1 0\u2032\u2032.10) of the peak position\nof the 1.36 cm continuum object, HW2. In G34.26+0.25, three NH3 (9,6) maser spots are observed: one is close to the head of the\ncometary ultracompact H ii region C, and the other two are emitted from a compact region to the west of the hypercompact H ii region\nA.\nConclusions. The newly found (9,6) masers appear to be related to outflows. The higher angular resolution of JVLA and very long\nbaseline interferometry observations are needed to provide more accurate positions and constraints for pumping scenarios.\n\nKey words. Masers \u2013 ISM: clouds \u2013 ISM: individual objects: Cep A, G34.26+0.15 \u2013 ISM: H ii regions \u2013 Radio lines: ISM\n\n1. Introduction\n\nSince its discovery more than five decades ago (Cheung et al.\n1968), ammonia (NH3) has been a most valuable molecule for\ninvestigating the physical properties of molecular clouds (e.g.,\nHo & Townes 1983). While thermally excited transitions in\nthe centimeter-wavelength inversion transitions of ammonia are\nregarded as a reliable thermometer of molecular clouds (e.g.,\nWalmsley & Ungerechts 1983; Danby et al. 1988), ammonia\nmasers have attracted attention since the first detection of maser\naction in the (J,K) = (3,3) metastable (J = K) line toward the\nmassive star-forming region W33 (Wilson et al. 1982). Subse-\nquent observations have led to the detection of new metastable\nammonia masers, including 15NH3 (3,3) (Mauersberger et al.\n1986), NH3 (1,1) (Gaume et al. 1996), NH3 (2,2) (Mills et al.\n2018), NH3 (5,5) (Cesaroni et al. 1992), NH3 (6,6) (Beuther\n? Member of the International Max Planck Research School (IM-\n\nPRS) for Astronomy and Astrophysics at the universities of Bonn and\nCologne.\n\net al. 2007), NH3 (7,7), NH3 (9,9), and NH3 (12,12) (Henkel\net al. 2013). These have led to the discovery of metastable maser\nlines in 22 different regions (Mauersberger et al. 1986, 1987;\nWilson & Henkel 1988; Wilson et al. 1990; Pratap et al. 1991;\nCesaroni et al. 1992; Wilson & Schilke 1993; Mangum & Woot-\nten 1994; Kraemer & Jackson 1995; Zhang & Ho 1995; Zhang\net al. 1999; Walsh et al. 2007; Hunter et al. 2008; Galv\u00e1n-Madrid\net al. 2009; Brogan et al. 2011; Urquhart et al. 2011; Walsh\net al. 2011; Wang et al. 2012; Henkel et al. 2013; Hoffman &\nJoyce 2014; McEwen et al. 2016; Mills et al. 2018; Hogge et al.\n2019; Mei et al. 2020; Towner et al. 2021). Compared with the\nmetastable ammonia masers, detected non-metastable (J > K)\nammonia maser transitions are more numerous. The first highly\nexcited non-metastable ammonia maser was detected by Mad-\nden et al. (1986) in the (J,K) = (9,6) and (6,3) lines. Thereafter,\nmany other NH3 non-metastable inversion transition lines have\nbeen identified as masers, including the (5,3), (5,4), (6,1), (6,2),\n(6,4), (6,5), (7,3), (7,4), (7,5) (7,6), (8,3), (8,4), (8,5), (8,6), (9,3),\n(9,4), (9,5), (9,7), (9,8), (10,7), (10,8), (10,9), and (11,9) transi-\n\nArticle number, page 1 of 10\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n1v\n2 \n\n [\nas\n\ntr\no-\n\nph\n.G\n\nA\n] \n\n 1\n7 \n\nJa\nn \n\n20\n22\n\n\n\nA&A proofs: manuscript no. mainArxiv\n\ntions (e.g., Mauersberger et al. 1987, 1988; Walsh et al. 2007;\nHenkel et al. 2013; Mei et al. 2020). Except for the NH3 (3,3)\nmasers proposed to be associated with four supernova remnants\n(McEwen et al. 2016), almost all the other ammonia masers are\ndetected in high-mass star-forming regions (HMSFRs). How-\never, while many HMSFRs host water (H2O), hydroxyl (OH),\nor methanol (CH3OH) masers, ammonia masers are quite rare\nin these sources, and the role that the environment of a young\nhigh-mass star plays in their excitation remains unclear. There-\nfore, dedicated searches for ammonia masers in HMSFRs are\nindispensable in regard to their overall incidence and associa-\ntion with different environments, which can provide additional\nconstraints on the pumping mechanism of ammonia masers.\n\nSo far, a total of 32 NH3 inversion transitions (\u2206K = 0\nand \u2206J = 0) have been identified as masers. Among these, and\ndespite arising from energy levels as high as 1090 K above\nthe ground state, the NH3 (9,6) maser stands out as being the\nstrongest and most variable one in W51-IRS2 (e.g., Henkel et al.\n2013). Maser emission in this line has only been detected in five\nHMSFRs, W51, NGC7538, W49, DR21 (OH) (Madden et al.\n1986), and Sgr B2(N) (Mei et al. 2020). The NH3 (3,3) masers\nare thought to be collisionally excited (e.g., Flower et al. 1990;\nMangum & Wootten 1994); in contrast, the pumping mecha-\nnism of NH3 (9,6) masers is less well constrained (Madden et al.\n1986). Brown & Cragg (1991) have studied ortho-ammonia and\nfound that it could possibly pump the (6,3) inversion line, but\nthey did not extend their model to the (9,6) transition due to the\nfact that collision rates are only known for inversion levels up to\nJ = 6 (e.g., Danby et al. 1988).\n\nNH3 (9,6) masers are found to be strongly variable, similar to\nH2O masers (Madden et al. 1986; Pratap et al. 1991; Henkel et al.\n2013). In W51-IRS2, Henkel et al. (2013) found that the (9,6)\nline showed significant variation in line shape within a time in-\nterval of only two days. Mapping of the (9,6) maser toward W51\nwith very long baseline interferometry (VLBI) suggests that the\nmasers are closer to the H2O masers than to the OH masers or\nto ultracompact (UC) H ii regions (Pratap et al. 1991). While\nHenkel et al. (2013) and Goddi et al. (2015) showed that the SiO\nand NH3 masers in W51-IRS2 are very close to each other, their\npositions, differing by 0\u2032\u2032.065 (\u223c0.015 pc), do not fully coincide.\n\nIn this paper we report the discovery of NH3 (9,6) masers\nin two HMSFRs, Cepheus A and G34.26+0.15. This increases\nthe number of (9,6) maser detections in our Galaxy from five\nto seven. In Sect. 2 observations with the Effelsberg 100-meter\ntelescope and the Karl G. Jansky Very Large Array (JVLA) are\ndescribed. Results are presented in Sect. 3. The morphology of\nCep A and G34.26+0.15 as well as a comparison of the emission\ndistributions of different tracers with the NH3 (9,6) masers are\npresented in Sect. 4. Our main results are summarized in Sect. 5.\n\n2. Observations and data reduction\n\n2.1. Effelsberg observations and data reduction\n\nThe NH3 (9,6) line was observed toward Cep A and\nG34.26+0.15 with the 100-meter Effelsberg telescope1 in 2020\nJanuary and 2021 February, July, and August. The S14mm dou-\nble beam secondary focus receiver was employed. The full width\nat half maximum (FWHM) beam size is 49\u2032\u2032 at 18.5 GHz, the\nfrequency of the target line. The observations were performed in\nposition switching mode, and the off position was 10\u2032 in azimuth\n\n1 Based on observations with the 100-meter telescope of the MPIfR\n(Max-Planck-Institut f\u00fcr Radioastronomie) at Effelsberg.\n\naway from the source. For observations made before 2021 Au-\ngust, we used a spectrometer that covered 2 GHz wide backends\nwith a channel width of 38.1 kHz, corresponding to \u223c0.62 km s\u22121\n\nat the line\u2019s rest frequency, 18.49939 GHz (Poynter & Kakar\n1975). A high spectral resolution backend with 65536 channels\nand a bandwidth of 300 MHz was employed in 2021 August,\nproviding a channel width of 0.07 km s\u22121 at 18.5 GHz. Point-\ning was checked every 2 hours using 3C 286 or NGC 7027.\nFocus calibrations were done at the beginning of the observa-\ntions and during sunset and sunrise toward the abovementioned\npointing sources. The system temperatures were 100\u2013130 K on\na main-beam brightness temperature, TMB, scale. This flux den-\nsity was calibrated assuming a TMB/S ratio of 1.95 K/Jy, derived\nfrom continuum cross scans of NGC 7027 (the flux density was\nadopted from Ott et al. 1994). Calibration uncertainties are esti-\nmated to be \u223c 10%.\n\nWe used the GILDAS/CLASS2 package (Pety 2005) to re-\nduce the spectral line data. A first-order polynomial was sub-\ntracted from each spectrum for baseline removal.\n\n2.2. JVLA observations and data reduction\n\nObservations of the NH3 (9,6) line toward Cep A and\nG34.26+0.15 were obtained on 2021 July 13 with the JVLA\nof the National Radio Astronomy Observatory3 (NRAO) in the\nC configuration (project ID: 21A-157, PI: Yaoting Yan). We\nemployed 27 antennas for the observations. The primary beam\nof the JVLA antennas is 150\u2032\u2032 (FWHM) at 18.5 GHz. A mix-\nture of mixed three-bit and eight-bit samplers were used to per-\nform the observations. For the NH3 (9,6) line observations, we\nused one subband with the eight-bit sampler covering a band-\nwidth of 16 MHz with full polarization, eight recirculations, and\nfour baseline board pairs (BIBPs) to provide a velocity range\nof 260 km s\u22121 with a channel spacing of 0.13 km s\u22121. Two\nadditional subbands of bandwidth 16 MHz were used to cover\nthe NH3 (8,5) and (10,7) lines. The three-bit sampler with 32\nsubbands, each with a bandwidth of 128 MHz to cover a to-\ntal range of 4 GHz between 20\u201324 GHz, was used to mea-\nsure the continuum emission. 3C 286 with a flux density of\n2.89 Jy at 18.5 GHz (Perley & Butler 2013) was used as a\ncalibrator for pointing, flux density, bandpass, and polarization.\nJ2230+6946 and J1851+0035 served as gain calibrators for Cep\nA and G34.26+0.15, respectively. The on-source times were\n4m30s and 4m50s toward Cep A and G34.26+0.15, respectively.\n\nData from two antennas were lost due to technical is-\nsues. The data from the remaining 25 antennas were reduced\nthrough the Common Astronomy Software Applications pack-\nage (CASA4; McMullin et al. 2007). We calibrated the data with\nthe JVLA CASA calibration pipeline using CASA 6.1.2. The\nresults were obtained after flagging data that contain artifacts.\nWe inspected the phase, amplitude, and bandpass variations of\nthe calibrated visibility data to search for additional artifacts be-\nfore imaging. Then, the uvcontsub task in CASA was used to\nseparate the calibrated visibilities into two parts, one with line-\nonly data and the other with the continuum data. The tclean task\nwith a cell size of 0\u2032\u2032.2 and Briggs weighting with robust=0 was\nused to produce the images of spectral line and continuum emis-\nsion. The synthesized beams for NH3 (9,6) are 1\u2032\u2032.47 \u00d7 0\u2032\u2032.99 at\n\n2 https://www.iram.fr/IRAMFR/GILDAS/\n3 The National Radio Astronomy Observatory is a facility of the Na-\ntional Science Foundation operated under cooperative agreement by As-\nsociated Universities, Inc.\n4 https://casa.nrao.edu/\n\nArticle number, page 2 of 10\n\n\n\nY. T. Yan (\u95eb\u8000\u5ead) et al.: Discovery of ammonia (9,6) masers in two high-mass star-forming regions\n\nP.A. = 58\u25e6.79 and 1\u2032\u2032.33 \u00d7 1\u2032\u2032.06 at P.A. = 5\u25e6.36 toward Cep A\nand G34.26+0.15, respectively. For the 1.36 cm (20\u201324 GHz)\ncontinuum emission, the synthesized beams are 1\u2032\u2032.08 \u00d7 0\u2032\u2032.67 at\nP.A. = 60\u25e6.64 and 0\u2032\u2032.95 \u00d7 0\u2032\u2032.71 at P.A. = 5\u25e6.91 toward Cep A and\nG34.26+0.15. The typical absolute astrometric accuracy of the\nJVLA is \u223c10% of the synthesized beam5. The flux density scale\ncalibration accuracy is estimated to be within 15%.\n\nFig. 1. Spectra from NH3 (9,6) transition lines. Left: Top to bottom:\nTime sequence of NH3 (9,6) profiles observed toward Cep A with the\nEffelsberg 100-meter telescope (after subtracting a first-order polyno-\nmial baseline). A JVLA spectrum is interspersed. The systemic veloc-\nity from CO and HCO+ lines is indicated by a dashed blue line. The\ntwo dashed red lines at LSR velocities, VLSR, of \u22120.90 km s\u22121 and\n\u22120.28 km s\u22121 indicate the central velocities of the two major compo-\nnents. Right: NH3 (9,6) spectra from G34.26+0.15. The systemic ve-\nlocity from C17O is indicated by a dashed blue line. The three dashed\nred lines at VLSR = 54.1 km s\u22121, 55.8 km s\u22121, and 62.5 km s\u22121 show the\ncentral velocities of the main ammonia emission components.\n\n3. Results\n\nThe spectra from different epochs are shown in Figs. 1 and 2.\nToward Cep A, the NH3 (9,6) line profile from the JVLA is ex-\ntracted from an Effelsberg-beam-sized region (FWHM, 49\u2032\u2032). In\nthe case of G34.26+0.15, the NH3 spectrum is below the noise\nlevel if a similarly large beam size is used. Therefore, we de-\nrived the JVLA NH3 (9,6) spectrum from a smaller region, with\nradius 3\u2032\u2032.5, that contains all the detected NH3 (9,6) emission. In\nTable A.1, the observed NH3 (9,6) line parameters obtained by\nGaussian fits are listed. NH3 (8,5) and (10,7) emission is not de-\ntected by our JVLA observations. The 3\u03c3 upper limits for the\nNH3 (8,5) and (10,7) lines toward Cep A are 23.2 mJy beam\u22121\n\n5 https://science.nrao.edu/facilities/vla/docs/manuals/oss/performance-\n/positional-accuracy\n\nFig. 2. NH3 (9,6) line profiles emphasizing, in contrast to the spectra\nin Fig. 1, weaker features. Cep A spectra are presented on the left,\nG34.26+0.15 spectra on the right. The two dashed red lines in the left\npanels indicate VLSR = 1.48 km s\u22121 and 2.89 km s\u22121. In the right panels,\nthe two dashed red lines refer to 54.1 km s\u22121 and 55.8 km s\u22121.\n\nand 27.2 mJy beam\u22121, respectively. In G34.26+0.15, the corre-\nsponding 3\u03c3 upper limits for the NH3 (8,5) and (10,7) lines are\n22.1 mJy beam\u22121 and 30.4 mJy beam\u22121. For both sources, sen-\nsitivity levels refer to emission from a single channel of width\n0.13 km s\u22121. Taking the larger measured line widths of the (9,6)\nmaser features (see Table A.1), these limits could be further low-\nered by factors of two to four.\n\n3.1. Centimeter-continuum emission\n\nThe 1.36 cm continuum, derived from our JVLA observations,\ntoward Cep A is presented in Fig. 3. Six published compact\nsources, HW2, HW3a, HW3b, HW3c, HW3d, and HW9, are de-\ntected in our observations. Figure 4 shows the 1.36 cm contin-\nuum in G34.26+0.15. Three main continuum objects, A, B, and\nC, are detected. By using the imfit task in CASA, we measured\nthe continuum flux at 1.36 cm toward individual compact source\ncomponents in Cep A and G34.26+0.15. Details are given in Ta-\nble A.2.\n\n3.2. NH3 (9,6) emission in Cep A\n\nIn 2020 January, NH3 (9,6) emission with a peak flux density of\n0.67 \u00b1 0.07 Jy was first detected with the Effelsberg 100-meter\ntelescope in Cep A. Emission with similar strength was also de-\ntected in 2021 February and August with the same telescope.\nHigher velocity resolution data, which were obtained in 2021\nAugust, again with the Effelsberg 100-meter telescope, show\nthat the (9,6) emission contains two main velocity components.\nOverall, the flux densities of the NH3 (9,6) emission line mea-\nsured with the Effelsberg 100-meter telescope are, within the cal-\nibration uncertainties, unchanged. This is valid for the time inter-\nval between 2020 January and August 2021, when we smoothed\nthe obtained spectra to the same velocity resolution. We also\nsee another two weaker components. Figure 2 emphasizes these\nweak components with an expanded flux density scale.\n\nHigher angular resolution data from the JVLA pinpoint the\nposition of the NH3 (9,6) emission with an offset of (\u22120\u2032\u2032.28,\n0\u2032\u2032.02) relative to the 1.36 cm continuum peak of Cep A HW2\n(Fig. 3). The deconvolved NH3 (9,6) component size is (0\u2032\u2032.29 \u00b1\n0\u2032\u2032.15)\u00d7 (0\u2032\u2032.19\u00b1 0\u2032\u2032.14) at P.A. = 174\u25e6, derived with the imfit task\nin CASA, and can thus be considered, accounting for the uncer-\ntainties, as unresolved.\n\nArticle number, page 3 of 10\n\n\n\nA&A proofs: manuscript no. mainArxiv\n\nFig. 3. Cepheus A. White contours mark the 1.36 cm JVLA continuum map of Cep A; levels are \u22125, 5, 10, 20, 30, 40, 50, 70, 90,\nand 110 \u00d7 0.125 mJy beam\u22121. The background image is the Spitzer 4.5 \u00b5m emission, taken from the Galactic Legacy Infrared Mid-Plane\nSurvey Extraordinaire (GLIMPSE; Benjamin et al. 2003; Churchwell et al. 2009). The reference position is \u03b1J2000 = 22h56m17s.972, and\n\u03b4J2000 = 62\u25e601\u203249\u2032\u2032.587, the peak position of the continuum map, is marked with a black cross. Slightly to the west of the cross is the black\nellipse denoting the position of the NH3 (9,6) emission with a purple star at its center. OH (Bartkiewicz et al. 2005), H2O (Sobolev et al. 2018),\nand CH3OH (Sanna et al. 2017) masers are presented as diamonds, circles, and squares, respectively. The color bar on the right-hand side indicates\nthe LSR velocity range of the maser spots.\n\nFig. 4. 1.36 cm JVLA continuum map of G34.26+0.15 presented as white contours with levels of \u22125, 5, 10, 20, 30, 40, 50, 70, 90, 110, 130,\n150, 180, and 200 \u00d7 5.0 mJy beam\u22121. The background image is the Spitzer 4.5 \u00b5m emission, taken from GLIMPSE. The reference position is\n\u03b1J2000 = 18h53m18s.560, and \u03b4J2000 = 01\u25e614\u203258\u2032\u2032.201, the peak position, is marked by a black cross. The black ellipses show the positions of NH3\n(9,6) emissions with stars at their center (i.e., M1, M2, and M3). OH (Zheng et al. 2000), H2O (Imai et al. 2011), and CH3OH (Bartkiewicz et al.\n2016) masers are presented as diamonds, circles, and squares, respectively. The color bar indicates the velocity range (VLSR) of maser spots.\n\nIn view of the constancy of the flux densities obtained at Ef-\nfelsberg and the similar JVLA flux density, measured in 2021\nJuly, there is no missing interferometric flux density in the JVLA\ndata.\n\n3.3. NH3 (9,6) emission in G34.26+0.15\n\nThe NH3 (9,6) emission was first detected toward G34.26+0.15\nin 2020 January with the Effelsberg 100-meter telescope. Higher\n\nvelocity resolution data from 2021 August show the NH3 (9,6)\nemission to be composed of two different components. The spec-\ntra of weak components on a smaller flux density scale are pre-\nsented in Fig. 2.\n\nThree different locations showing NH3 (9,6) emission are\nfound toward G34.26+0.15 (Fig. 4). The deconvolved NH3 (9,6)\ncomponent sizes are (1\u2032\u2032.42\u00b10\u2032\u2032.43)\u00d7 (0\u2032\u2032.54\u00b10\u2032\u2032.62) at P.A. = 97\u25e6\n(M1), (0\u2032\u2032.42 \u00b1 0\u2032\u2032.27) \u00d7 (0\u2032\u2032.15 \u00b1 0\u2032\u2032.27) at P.A. = 150\u25e6 (M2), and\n\nArticle number, page 4 of 10\n\n\n\nY. T. Yan (\u95eb\u8000\u5ead) et al.: Discovery of ammonia (9,6) masers in two high-mass star-forming regions\n\n(1\u2032\u2032.17 \u00b1 0\u2032\u2032.34) \u00d7 (0\u2032\u2032.27 \u00b1 0\u2032\u2032.46) at P.A. = 53\u25e6 (M3) and are thus\ncomparable to or smaller than the beam size.\n\nOverall, the NH3 (9,6) line from G34.26+0.15 weakened\nduring the time interval from 2020 January to 2021 August by\nabout 70%. A comparison between the JVLA spectrum and the\nEffelsberg data, assuming a linear decrease in the integrated in-\ntensity as a function of time between different epochs of the\n100-meter observations, suggests there is no missing flux in the\nJVLA data. This is similar to the situation in Cep A.\n\n4. Discussion\n\n4.1. Morphology of Cep A and G34.26+0.15\n\nCep A, at a trigonometric parallax distance of 0.70\u00b10.04 kpc\n(Moscadelli et al. 2009; Dzib et al. 2011), is the second closest\nHMSFR (after Orion) and by far the closest NH3 (9,6) maser\nknown. About 16 compact (\u223c1\u2032\u2032) radio sources (e.g., Hughes &\nWouterloot 1984; Hughes 1991; Garay et al. 1996) have been\nidentified in Cep A. Hughes & Wouterloot (1984) discovered\nthese targets at radio wavelengths, which are UC and hypercom-\npact (HC) H ii regions and/or stellar wind sources, subsequently\nnamed as HW sources. The HW2 object is one of the best known\nexamples of a protostellar jet or disk system driving a powerful\noutflow (e.g., Rodriguez et al. 1980; G\u00fcsten et al. 1984; Torrelles\net al. 1986; Curiel et al. 2006; Carrasco-Gonz\u00e1lez et al. 2021).\nThe observed NH3 (9,6) emission is slightly offset (\u22120\u2032\u2032.28, 0\u2032\u2032.02)\nfrom the center of HW2 (see Fig. 3).\n\nG34.26+0.15 is an HMSFR located at a distance of 3.3 kpc\n(Kuchar & Bania 1994). It hosts four radio continuum compo-\nnents named A, B, C, and D. Component C is a prototypical\ncometary UC H ii region containing a compact head and a diffuse\ntail that extends from east to west (e.g., Reid & Ho 1985; Garay\net al. 1986; Sewilo et al. 2004; Sewi\u0142o et al. 2011). Components\nA and B are HC H ii regions, located to the east of component\nC. An extended ring-like H ii region, called component D, is lo-\ncated southeast of components A-C. One of the three observed\nNH3 (9,6) emission line sources, M1, is close to the head of com-\nponent C, whereas M2 and M3 originate from another compact\nregion in the west of the HC H ii component A (see Fig. 4).\n\n4.2. NH3 (9,6) emission possibly caused by maser action\n\nAs shown in Fig. 1, the NH3 (9,6) profiles in Cep A and\nG34.26+0.15 are narrow (\u2206V1/2 \u22642.0 km s\u22121), much narrower\nthan the expected line widths (&4 km s\u22121) of thermal lines ob-\nserved at a similar angular resolution (e.g., Torrelles et al. 1985,\n1986, 1993, 1999; Henkel et al. 1987; Comito et al. 2007; Mook-\nerjea et al. 2007; Wyrowski et al. 2012; Beuther et al. 2018). Ve-\nlocity shifts with respect to the systemic velocities of the two\nsources are both observed, that is, V \u223c10 km s\u22121 in Cep A and\nV \u223c4 km s\u22121 in G34.26+0.15 (see details in Sect. 4.3). Further-\nmore, time variability is observed in the case of G34.26+0.15,\nwhich is also a characteristic feature of maser emission.\n\nAdditional evidence of their maser nature is the high bright-\nness temperatures of the (9,6) emission spots toward Cep A and\nG34.26+0.15. The spectral parameters are listed in Table A.3.\nBecause at least a significant part of the NH3 (9,6) emission\nis not resolved by our JVLA observations, the derived bright-\nness temperatures are only lower limits. Nevertheless, the lower\nlimits on the brightness temperature are >800 K in Cep A (see\nTable A.3), which is much higher than the expected thermal\ngas temperature of \u223c250 K (e.g., Patel et al. 2005; Comito\net al. 2007; Beuther et al. 2018). This strongly suggests that\n\nthe NH3 (9,6) emission in Cep A is due to maser action. Be-\ncause G34.26+0.15 is located at about five times the distance to\nCep A, beam dilution effects reduce the lower main beam bright-\nness temperature limit to 400 K in G34.26+0.15 (M2) (see Ta-\nble A.3). We also note that the luminosity of the NH3 (9,6) emis-\nsion in G34.26+0.15 is higher than or comparable to that in Cep\nA, depending on the epoch of our observations.\n\nFinally, the non-detections of the (8,5) and (10,7) lines also\nindicate that the (9,6) line is special. This allows us to derive\nlower 3\u03c3 limits of the (9,6)/(8,5) and (9,6)/(10,7) line intensity\nratios. The (9,6) line arises from ortho-NH3 (K = 3n), whereas\nthe NH3 (8,5) and (10,7) lines are para-NH3 (K , 3n) lines.\nThe minimum ortho-to-para ratios are in the range 12\u201342 and 1\u2013\n8 toward Cep A and G34.26+0.15, respectively. The statistical\nweights for the ortho states are twice as large as those for the\npara states (e.g., Umemoto et al. 1999; Goddi et al. 2011; Henkel\net al. 2013). In Cep A, the line intensity ratios are far higher than\nthis factor of two. Thus, at least in Cep A the higher main beam\nbrightness peak temperature of the (9,6) emission is caused by\nmaser action, perhaps involving exponential amplification, and\nthe case of G34.26+0.15 is likely similar.\n\n4.3. Comparison of NH3 (9,6) masers with previously\npublished (quasi-)thermal NH3 emission\n\nThe metastable (1,1), (2,2), (3,3), and (4,4) ammonia lines\nshow thermal emission toward Cep A over a velocity range of\n\u221213 km s\u22121 \u2264 VLSR \u2264 \u22124 km s\u22121 (Brown et al. 1981; G\u00fcsten\net al. 1984; Torrelles et al. 1985, 1986, 1993, 1999). An average\nNH3 column density of \u223c5\u00d71015 cm\u22122 was estimated for a region\nof 3\u2032\u2032 around HW2 (Torrelles et al. 1999). This high NH3 abun-\ndance could provide a suitable environment for maser species.\nLarge line widths (\u2206V1/2 '7.0 km s\u22121) with VLSR \u223c \u221210 km s\u22121\n\nin both (1,1) and (2,2) lines were found toward HW2 (Torrelles\net al. 1993). The velocity is similar to the cloud\u2019s systemic lo-\ncal standard of rest (LSR) velocity of \u221211.2 km s\u22121, which\nis based on CO (Narayanan & Walker 1996) and HCO+ ob-\nservations (G\u00f3mez et al. 1999). Our (9,6) maser is redshifted\n(\u22120.9 km s\u22121 \u2264 VLSR \u22642.9 km s\u22121) and shares positions with\nthe outflowing gas seen in CO and HCO+ with similarly red-\nshifted velocities. Therefore, we argue that the (9,6) masers are\nrelated to outflowing gas.\n\nIn G34.26+0.15, a large NH3 column density,\n1018.5\u00b10.2 cm\u22122, and a kinetic temperature of 225\u00b175 K\nwere derived by Henkel et al. (1987) based on measurements\nof 15 NH3 inversion transitions in the frequency range of\n22.0\u201326.0 GHz. These did not include the (9,6) transition.\nWhile these lines were measured with a beam size of about\n40\u2032\u2032, a comparison of the peak intensities of the optically thick\nlines with the kinetic temperature reveals the size of the hot,\nammonia-emitting core to be only \u223c2.5\u2032\u2032. All those measured\nNH3 lines were quasi-thermal and had LSR velocities of\n\u223c 58.5 km s\u22121, close to the systemic velocity of \u223c 58.1 km s\u22121\n\nobtained from C17O observations (Wyrowski et al. 2012).\nTheir line widths (\u2206V1/2 \u22653.6 km s\u22121) are larger than what\nwe find (0.35 km s\u22121 \u2264 \u2206V1/2 \u2264 0.94 km s\u22121) for each (9,6)\nmaser component (see details in Table A.3). In all, we may\nhave observed four different (9,6) velocity features. Three\nare blueshifted at VLSR \u223c 53.8 km s\u22121, 55.8 km s\u22121, and\n56.8 km s\u22121, and a fourth, tentatively detected, at 62.5 km s\u22121.\nThis tentative redshifted feature was only potentially detected\nwith Effelsberg in 2020 January. The velocity is similar to that\nof the JVLA measurements on the NH3 (1,1) absorption line\nagainst continuum source C (\u223c 7\u2032\u2032 resolution; Keto et al. 1987)\n\nArticle number, page 5 of 10\n\n\n\nA&A proofs: manuscript no. mainArxiv\n\nand the NH3 (3,3) emission surrounding continuum source B as\nwell as the head of C (1\u2032\u2032.4\u00d71\u2032\u2032.2 resolution; Heaton et al. 1989).\nHowever, we did not find this redshifted component in our\nJVLA observations. Therefore, its position within G34.26+0.15\ncannot be determined. The blueshifted (9,6) masers with a\nvelocity range of 53.8\u201356.8 km s\u22121 (M1, M2, and M3) show\nvelocities compatible with those of the NH3 (3,3) emission at\nthe proper positions (Heaton et al. 1989), which might be a\nsuitable environment for maser species.\n\n4.4. Comparison of NH3 (9,6) masers with other maser lines\n\nTo characterize the environment of NH3 (9,6) masers, we can\ncompare their positions with respect to those of other maser\nspecies (i.e., OH, H2O, and CH3OH). Toward Cep A HW2,\nmany CH3OH (e.g., Menten 1991; Sugiyama et al. 2008; Sanna\net al. 2017) and H2O maser spots (e.g., Torrelles et al. 1998,\n2011; Sobolev et al. 2018) are detected and are associated with\nits disk. Sobolev et al. (2018) also found that most of the H2O\nmaser flux is associated with the compact H ii region HW3d. OH\nmaser features close to the H ii regions are also seen in HW2\n(e.g., Cohen & Brebner 1985; Bartkiewicz et al. 2005). These\nthree kinds of masers in Cep A have a large velocity range of\n\u221225 km s\u22121 \u2264 VLSR \u2264 \u22122 km s\u22121 and are widespread around\nHW2 and HW3, while NH3 (9,6) emission is only detected at\n\u22120.9 km s\u22121 \u2264 VLSR \u22642.9 km s\u22121 toward a sub-arcsecond-\nsized region to the west of the peak continuum position of HW2\n(see Fig. 3). This suggests that the NH3 (9,6) maser in Cep A\nis unique and not related to maser spots seen in other molecular\nspecies.\n\nIn G34.26+0.15, OH (Zheng et al. 2000), H2O (Imai et al.\n2011), and CH3OH (Bartkiewicz et al. 2016) masers have been\ndetected east of source C (Fig. 4), and none of them coincides\nwith the head of C. The NH3 (9,6) maser M1 is also found\nslightly off the head of source C. This could suggest that M1\nis powered by continuum source C or by an outflow. Near com-\nponent B, there are some OH and CH3OH masers but no H2O\nor NH3 masers. A group of H2O masers, well-known tracers\nof outflows, with a large velocity distribution of 43 km s\u22121 \u2264\n\nVLSR \u226454 km s\u22121, was found to the west of the centimeter-\ncontinuum source A and close to the peak of the millimeter-\ncontinuum emission (see details in our Fig. A.2 and also in Fig. 5\nof Imai et al. 2011). The closeness of NH3 (9,6) maser spots M2\nand M3 to this group of water masers and their similar velocities\nagain suggest an association of NH3 (9,6) masers with outflow\nactivity.\n\n4.5. Constraints on pumping scenarios\n\nOur observations have resulted in the detection of NH3 (9,6)\nmasers in Cep A and G34.26+0.15. The new detections could\nprovide additional constraints on the maser line\u2019s pumping\nmechanism. As mentioned in Sect. 1, the pumping mechanism\nof the (9,6) maser is unclear (Madden et al. 1986; Brown &\nCragg 1991). Previous studies have suggested that there are three\nmain pumping scenarios to explain the observed NH3 maser\nlines (Madden et al. 1986; Henkel et al. 2013): (1) infrared ra-\ndiation from the dust continuum emission, (2) line overlap, and\n(3) collisional pumping.\n\nFor the first mechanism, infrared photons near 10 \u00b5m are\nneeded for vibrational excitation. The high dust temperature\n(\u223c300 K) of W51-IRS2 can provide substantial infrared pho-\ntons near 10 \u00b5m, which is used for radiative pumping (Henkel\n\net al. 2013). Both Cep A and G34.26+0.15 have similar kinetic\ntemperatures of &200 K (Henkel et al. 1987; Patel et al. 2005;\nComito et al. 2007; Beuther et al. 2018). This suggests that\nhigh kinetic temperatures are needed to excite NH3 (9,6) masers.\nHowever, it should be noted that the silicate dust absorption fea-\nture might dominate at 10 \u00b5m (see the spectral energy distribu-\ntion of Cep A in De Buizer et al. 2017). Additionally, there is\nno bright infrared emission around the two (9,6) masers, M2 and\nM3, in G34.26+0.15 (see Fig. 4; see also Fig. 11 in De Buizer\net al. 2003 for a 10.5 \u00b5m map). This indicates that the pumping\nmechanism via infrared photons near 10 \u00b5m may not be viable\nto explain the (9,6) masers in Cep A and G34.26+0.15. Further-\nmore, Wilson & Schilke (1993) argued that radiative pumping by\ndust emission tends to excite multiple adjacent ammonia maser\ntransitions, which appears to contradict our failure to detect the\nadjacent (8,5) and (10,7) lines (with respect to quantum numbers\nand frequency) and to only measure the (9,6) transitions in Cep\nA and G34.26+0.15. Therefore, we suggest that infrared radia-\ntion from dust is not the main pumping source.\n\nMadden et al. (1986) suggested that there might be some\nline overlaps between the rotational NH3 transitions in the far-\ninfrared band. However, this would be unlikely to affect only the\n(9,6) line. Nevertheless, far-infrared spectral observations will\nbe needed to clarify this scenario.\n\nBased on our observations, the (9,6) maser spots are close\nto, but not coincident with, the peaks of the radio continuum\nemission in Cep A and G34.26+0.25. Furthermore, the (9,6)\nmasers show velocity offsets with respect to their systemic ve-\nlocities. This indicates that the (9,6) masers are located at the\nbase of outflows, similar to the H2O masers. This is supported\nby VLBI observations that show that (9,6) masers tend to be\nclosely associated with H2O masers (Pratap et al. 1991). The ob-\nserved time variability in G34.26+0.25 and W51-IRS2 can also\nbe attributed to episodic molecular outflows. This indicates that\ncollisional pumping could be the driver of the (9,6) maser. On\nthe other hand, collisional pumping has been successfully used\nto explain the NH3 (3,3) maser (Walmsley & Ungerechts 1983;\nFlower et al. 1990; Mangum & Wootten 1994). Collisions tend to\npump from the K=0 level to the K=3 level with parity changes,\nthat is, the upper level of the (3,3) metastable transition will be\noverpopulated. NH3 (9,6) arises from the ortho species, so a sim-\nilar mechanism might also occur in the case of the (9,6) transi-\ntion. Further measurements of collisional rates of ammonia will\nallow us to test this scenario.\n\n5. Summary\n\nWe report the discovery of NH3 (9,6) masers in two HMSFRs,\nCep A and G34.26+0.15. The narrow line width of the emis-\nsion features (\u2206V1/2 \u22642.0 km s\u22121) and their high brightness tem-\nperatures (> 400 K) indicate the maser nature of the lines.\nThe intensity of the (9,6) maser in G34.26+0.25 is decreasing\nwith time, while toward Cep A the maser is stable based on 20\nmonths of monitoring at Effelsberg. Linearly interpolating the\nintegrated intensities obtained at Effelsberg as a function of time,\nthe JVLA measurements show that there is no missing flux den-\nsity on scales on the order of 1.2 arcsec (4 \u00d710\u22123 and 2 \u00d710\u22122 pc)\nto the total single-dish flux. The JVLA-detected emission in-\ndicates that the NH3 (9,6) maser in Cep A originates from a\nsub-arcsecond-sized region slightly (0\u2032\u2032.28 \u00b1 0\u2032\u2032.10) to the west\nof the peak position of the 1.36 cm continuum object, HW2. In\nG34.26+0.25, three NH3 (9,6) maser spots are observed: one is\nclose to the head of the cometary UC H ii region C, and the other\ntwo are emitted from a compact region to the west of the HC H ii\n\nArticle number, page 6 of 10\n\n\n\nY. T. Yan (\u95eb\u8000\u5ead) et al.: Discovery of ammonia (9,6) masers in two high-mass star-forming regions\n\nregion A. We suggest that the (9,6) masers may be connected to\noutflowing gas. Higher angular resolution JVLA and VLBI ob-\nservations are planned to provide more accurate positions and\nconstraints on pumping scenarios.\nAcknowledgements. We would like to thank the anonymous referee for the use-\nful comments that improve the manuscript. Y.T.Y. is a member of the Interna-\ntional Max Planck Research School (IMPRS) for Astronomy and Astrophysics\nat the Universities of Bonn and Cologne. Y.T.Y. would like to thank the China\nScholarship Council (CSC) for its support. We would like to thank the staff at\nthe Effelsberg for their help provided during the observations. We thank the staff\nof the JVLA, especially Tony Perreault and Edward Starr, for their assistance\nwith the observations and data reduction. This research has made use of the\nNASA/IPAC Infrared Science Archive, which is funded by the National Aero-\nnautics and Space Administration and operated by the California Institute of\nTechnology.\n\nReferences\nBartkiewicz, A., Szymczak, M., Cohen, R. J., & Richards, A. M. S. 2005, MN-\n\nRAS, 361, 623\nBartkiewicz, A., Szymczak, M., & van Langevelde, H. J. 2016, A&A, 587, A104\nBenjamin, R. A., Churchwell, E., Babler, B. L., et al. 2003, PASP, 115, 953\nBeuther, H., Mottram, J. C., Ahmadi, A., et al. 2018, A&A, 617, A100\nBeuther, H., Walsh, A. J., Thorwirth, S., et al. 2007, A&A, 466, 989\nBrogan, C. L., Hunter, T. R., Cyganowski, C. J., et al. 2011, ApJ, 739, L16\nBrown, A. T., Little, L. T., MacDonald, G. H., Riley, P. W., & Matheson, D. N.\n\n1981, MNRAS, 195, 607\nBrown, R. D. & Cragg, D. M. 1991, ApJ, 378, 445\nCarrasco-Gonz\u00e1lez, C., Sanna, A., Rodr\u00edguez-Kamenetzky, A., et al. 2021, ApJ,\n\n914, L1\nCesaroni, R., Walmsley, C. M., & Churchwell, E. 1992, A&A, 256, 618\nCheung, A. C., Rank, D. M., Townes, C. H., Thornton, D. D., & Welch, W. J.\n\n1968, Phys. Rev. Lett., 21, 1701\nChurchwell, E., Babler, B. L., Meade, M. R., et al. 2009, PASP, 121, 213\nCohen, R. J. & Brebner, G. C. 1985, MNRAS, 216, 51P\nComito, C., Schilke, P., Endesfelder, U., Jim\u00e9nez-Serra, I., & Mart\u00edn-Pintado, J.\n\n2007, A&A, 469, 207\nCuriel, S., Ho, P. T. P., Patel, N. A., et al. 2006, ApJ, 638, 878\nDanby, G., Flower, D. R., Valiron, P., Schilke, P., & Walmsley, C. M. 1988,\n\nMNRAS, 235, 229\nDe Buizer, J. M., Liu, M., Tan, J. C., et al. 2017, ApJ, 843, 33\nDe Buizer, J. M., Radomski, J. T., Telesco, C. M., & Pi\u00f1a, R. K. 2003, ApJ, 598,\n\n1127\nDzib, S., Loinard, L., Rodr\u00edguez, L. F., Mioduszewski, A. J., & Torres, R. M.\n\n2011, ApJ, 733, 71\nFlower, D. R., Offer, A., & Schilke, P. 1990, MNRAS, 244, 4P\nGalv\u00e1n-Madrid, R., Keto, E., Zhang, Q., et al. 2009, ApJ, 706, 1036\nGaray, G., Ramirez, S., Rodriguez, L. F., Curiel, S., & Torrelles, J. M. 1996, ApJ,\n\n459, 193\nGaray, G., Rodriguez, L. F., & van Gorkom, J. H. 1986, ApJ, 309, 553\nGaume, R. A., Wilson, T. L., & Johnston, K. J. 1996, ApJ, 457, L47\nGoddi, C., Greenhill, L. J., Humphreys, E. M. L., Chandler, C. J., & Matthews,\n\nL. D. 2011, ApJ, 739, L13\nGoddi, C., Henkel, C., Zhang, Q., Zapata, L., & Wilson, T. L. 2015, A&A, 573,\n\nA109\nG\u00f3mez, J. F., Sargent, A. I., Torrelles, J. M., et al. 1999, ApJ, 514, 287\nG\u00fcsten, R., Chini, R., & Neckel, T. 1984, A&A, 138, 205\nHeaton, B. D., Little, L. T., & Bishop, I. S. 1989, A&A, 213, 148\nHenkel, C., Wilson, T. L., Asiri, H., & Mauersberger, R. 2013, A&A, 549, A90\nHenkel, C., Wilson, T. L., & Mauersberger, R. 1987, A&A, 182, 137\nHo, P. T. P. & Townes, C. H. 1983, ARA&A, 21, 239\nHoffman, I. M. & Joyce, S. A. 2014, ApJ, 782, 83\nHogge, T. G., Jackson, J. M., Allingham, D., et al. 2019, ApJ, 887, 79\nHughes, V. A. 1991, ApJ, 383, 280\nHughes, V. A. & Wouterloot, J. G. A. 1984, ApJ, 276, 204\nHunter, T. R., Brogan, C. L., Indebetouw, R., & Cyganowski, C. J. 2008, ApJ,\n\n680, 1271\nImai, H., Omi, R., Kurayama, T., et al. 2011, PASJ, 63, 1293\nKeto, E. R., Ho, P. T. P., & Reid, M. J. 1987, ApJ, 323, L117\nKraemer, K. E. & Jackson, J. M. 1995, ApJ, 439, L9\nKuchar, T. A. & Bania, T. M. 1994, ApJ, 436, 117\nMadden, S. C., Irvine, W. M., Matthews, H. E., Brown, R. D., & Godfrey, P. D.\n\n1986, ApJ, 300, L79\nMangum, J. G. & Wootten, A. 1994, ApJ, 428, L33\nMauersberger, R., Henkel, C., & Wilson, T. L. 1987, A&A, 173, 352\nMauersberger, R., Wilson, T. L., & Henkel, C. 1986, A&A, 160, L13\n\nMauersberger, R., Wilson, T. L., & Henkel, C. 1988, A&A, 201, 123\nMcEwen, B. C., Pihlstr\u00f6m, Y. M., & Sjouwerman, L. O. 2016, ApJ, 826, 189\nMcMullin, J. P., Waters, B., Schiebel, D., Young, W., & Golap, K. 2007, in As-\n\ntronomical Society of the Pacific Conference Series, Vol. 376, Astronomical\nData Analysis Software and Systems XVI, ed. R. A. Shaw, F. Hill, & D. J.\nBell, 127\n\nMei, Y., Chen, X., Shen, Z.-Q., & Li, B. 2020, ApJ, 898, 157\nMenten, K. M. 1991, ApJ, 380, L75\nMills, E. A. C., Ginsburg, A., Clements, A. R., et al. 2018, ApJ, 869, L14\nMookerjea, B., Casper, E., Mundy, L. G., & Looney, L. W. 2007, ApJ, 659, 447\nMoscadelli, L., Reid, M. J., Menten, K. M., et al. 2009, ApJ, 693, 406\nNarayanan, G. & Walker, C. K. 1996, ApJ, 466, 844\nOtt, M., Witzel, A., Quirrenbach, A., et al. 1994, A&A, 284, 331\nPatel, N. A., Curiel, S., Sridharan, T. K., et al. 2005, Nature, 437, 109\nPerley, R. A. & Butler, B. J. 2013, ApJS, 204, 19\nPety, J. 2005, in SF2A-2005: Semaine de l\u2019Astrophysique Francaise, ed. F. Ca-\n\nsoli, T. Contini, J. M. Hameury, & L. Pagani, 721\nPoynter, R. L. & Kakar, R. K. 1975, ApJS, 29, 87\nPratap, P., Menten, K. M., Reid, M. J., Moran, J. M., & Walmsley, C. M. 1991,\n\nApJ, 373, L13\nReid, M. J. & Ho, P. T. P. 1985, ApJ, 288, L17\nRodriguez, L. F., Ho, P. T. P., & Moran, J. M. 1980, ApJ, 240, L149\nSanna, A., Moscadelli, L., Surcis, G., et al. 2017, A&A, 603, A94\nSewilo, M., Churchwell, E., Kurtz, S., Goss, W. M., & Hofner, P. 2004, ApJ,\n\n605, 285\nSewi\u0142o, M., Churchwell, E., Kurtz, S., Goss, W. M., & Hofner, P. 2011, ApJS,\n\n194, 44\nSobolev, A. M., Moran, J. M., Gray, M. D., et al. 2018, ApJ, 856, 60\nSugiyama, K., Fujisawa, K., Doi, A., et al. 2008, PASJ, 60, 1001\nTorrelles, J. M., G\u00f3mez, J. F., Garay, G., et al. 1998, ApJ, 509, 262\nTorrelles, J. M., G\u00f3mez, J. F., Garay, G., et al. 1999, MNRAS, 307, 58\nTorrelles, J. M., Ho, P. T. P., Rodriguez, L. F., & Canto, J. 1985, ApJ, 288, 595\nTorrelles, J. M., Ho, P. T. P., Rodriguez, L. F., & Canto, J. 1986, ApJ, 305, 721\nTorrelles, J. M., Patel, N. A., Curiel, S., et al. 2011, MNRAS, 410, 627\nTorrelles, J. M., Verdes-Montenegro, L., Ho, P. T. P., Rodriguez, L. F., & Canto,\n\nJ. 1993, ApJ, 410, 202\nTowner, A. P. M., Brogan, C. L., Hunter, T. R., & Cyganowski, C. J. 2021, ApJ,\n\n923, 263\nUmemoto, T., Mikami, H., Yamamoto, S., & Hirano, N. 1999, ApJ, 525, L105\nUrquhart, J. S., Morgan, L. K., Figura, C. C., et al. 2011, MNRAS, 418, 1689\nWalmsley, C. M. & Ungerechts, H. 1983, A&A, 122, 164\nWalsh, A. J., Breen, S. L., Britton, T., et al. 2011, MNRAS, 416, 1764\nWalsh, A. J., Longmore, S. N., Thorwirth, S., Urquhart, J. S., & Purcell, C. R.\n\n2007, MNRAS, 382, L35\nWang, K., Zhang, Q., Wu, Y., Li, H.-b., & Zhang, H. 2012, ApJ, 745, L30\nWilson, T. L., Batrla, W., & Pauls, T. A. 1982, A&A, 110, L20\nWilson, T. L. & Henkel, C. 1988, A&A, 206, L26\nWilson, T. L., Johnston, K. J., & Henkel, C. 1990, A&A, 229, L1\nWilson, T. L. & Schilke, P. 1993, in Lecture Notes in Physics, Astrophysical\n\nMasers, ed. A. W. Clegg & G. E. Nedoluha, Vol. 412, 123\u2013126\nWyrowski, F., G\u00fcsten, R., Menten, K. M., Wiesemeyer, H., & Klein, B. 2012,\n\nA&A, 542, L15\nZhang, Q. & Ho, P. T. P. 1995, ApJ, 450, L63\nZhang, Q., Hunter, T. R., Sridharan, T. K., & Cesaroni, R. 1999, ApJ, 527, L117\nZheng, X. W., Moran, J. M., & Reid, M. J. 2000, MNRAS, 317, 192\n\nArticle number, page 7 of 10\n\n\n\nA&A proofs: manuscript no. mainArxiv\n\nAppendix A:\n\nTable A.1. Summary of NH3 (9, 6) maser observations.\n\nSource Telescope Beam Epoch Channel S \u03bd rms\n\u222b\n\nS \u03bddv VLSR \u2206V1/2\nsize spacing\n\n(km s\u22121) (Jy) (mJy) (Jy km s\u22121) (km s\u22121)\nCep A Effelsberg 49\u2032\u2032 2020, Jan. 04 0.62 0.67 3.41 1.19 \u00b1 0.02 -1.11 \u00b1 0.02 1.67 \u00b1 0.04\n\nEffelsberg 49\u2032\u2032 2021, Feb. 11 0.62 0.59 5.97 1.08 \u00b1 0.02 -0.74 \u00b1 0.02 1.70 \u00b1 0.04\nEffelsberg 49\u2032\u2032 2021, Feb. 15 0.62 0.65 10.98 1.11 \u00b1 0.03 -0.75 \u00b1 0.02 1.60 \u00b1 0.05\n\nJVLAa 1\u2032\u2032.47 \u00d7 0\u2032\u2032.99 2021, Jul. 13 0.13 1.13 144 0.89 \u00b1 0.09 -0.86 \u00b1 0.03 0.74 \u00b1 0.12\nEffelsberg 49\u2032\u2032 2021, Aug. 11 0.07 0.98 13.36 0.49 \u00b1 0.02 -0.90 \u00b1 0.01 0.47 \u00b1 0.01\n\n0.35 0.26 \u00b1 0.02 -0.28 \u00b1 0.02 0.69 \u00b1 0.05\nEffelsberg 49\u2032\u2032 2021, Aug. 12 0.07 0.98 13.35 0.50 \u00b1 0.01 -0.89 \u00b1 0.07 0.48 \u00b1 0.07\n\n0.35 0.20 \u00b1 0.01 -0.29 \u00b1 0.07 0.54 \u00b1 0.07\n0.06 0.07 \u00b1 0.01 0.51 \u00b1 0.07 1.09 \u00b1 0.07\n0.02 0.02 \u00b1 0.01 2.15 \u00b1 0.07 0.80 \u00b1 0.07\n0.07 0.06 \u00b1 0.01 2.89 \u00b1 0.07 0.92 \u00b1 0.07\n\nG34.26+0.15 Effelsberg 49\u2032\u2032 2020, Jan. 03 0.62 0.30 1.26 0.65 \u00b1 0.03 62.50 \u00b1 0.05 2.05 \u00b1 0.13\nEffelsberg 49\u2032\u2032 2021, Feb. 11 0.62 0.24 2.42 0.40 \u00b1 0.02 55.76 \u00b1 0.04 1.60 \u00b1 0.12\nEffelsberg 49\u2032\u2032 2021, Feb. 15 0.62 0.20 4.86 0.38 \u00b1 0.02 55.71 \u00b1 0.05 1.80 \u00b1 0.14\n\nJVLAb 1\u2032\u2032.33 \u00d7 1\u2032\u2032.06 2021, Jul. 13 0.13 0.23 37.1 0.09 \u00b1 0.02 54.41 \u00b1 0.03 0.38 \u00b1 0.09\n0.22 0.22 \u00b1 0.02 55.82 \u00b1 0.05 0.95 \u00b1 0.12\n0.15 0.06 \u00b1 0.01 57.21 \u00b1 0.04 0.35 \u00b1 0.08\n\nEffelsberg 49\u2032\u2032 2021, Aug. 11 0.07 0.08 13.92 0.06 \u00b1 0.007 54.10 \u00b1 0.05 0.68 \u00b1 0.12\n0.07 0.02 \u00b1 0.006 54.82 \u00b1 0.03 0.31 \u00b1 0.09\n0.12 0.10 \u00b1 0.006 55.85 \u00b1 0.02 0.75 \u00b1 0.06\n\nEffelsberg 49\u2032\u2032 2021, Aug. 12 0.07 0.16 27.40 0.09 \u00b1 0.008 55.83 \u00b1 0.02 0.56 \u00b1 0.05\n\nNotes. The spectral parameters are obtained from Gaussian fitting. (a) The JVLA spectrum toward Cep A is extracted from the Effelsberg-beam-\nsized region (FWHM 49\u2032\u2032). (b) For G34.26+0.15, the JVLA beam samples the NH3 (9,6) spectrum over a region of radius 3\u2032\u2032.5, which contains all\ndetected NH3 (9,6) emissions.\n\nTable A.2. 1.36 cm JVLA flux densities of individual continuum sources.\n\nSource R.A. Dec. Size P.A. S \u03bd\n\n(h m s) (\u25e6 \u2032 \u2032\u2032) (arcsec) (deg) (mJy)\nCep A HW2 22 56 17.972 \u00b1 0.003 +62 01 49.587 \u00b1 0.015 (0.45 \u00b1 0.19) \u00d7 (0.22 \u00b1 0.10) 50.0 20.2 \u00b1 1.4\n\nHW3a 22 56 17.420 \u00b1 0.022 +62 01 44.576 \u00b1 0.076 (2.35 \u00b1 0.45) \u00d7 (0.55 \u00b1 0.14) 66.6 4.75 \u00b1 0.74\nHW3b 22 56 17.578 \u00b1 0.009 +62 01 45.041 \u00b1 0.043 (1.43 \u00b1 0.24) \u00d7 (0.45 \u00b1 0.10) 59.9 3.19 \u00b1 0.36\nHW3c 22 56 17.956 \u00b1 0.016 +62 01 46.224 \u00b1 0.038 (1.44 \u00b1 0.37) \u00d7 (0.36 \u00b1 0.19) 86.0 9.90 \u00b1 1.7\nHW3d 22 56 18.195 \u00b1 0.005 +62 01 46.325 \u00b1 0.014 (1.26 \u00b1 0.12) \u00d7 (0.30 \u00b1 0.19) 102.5 13.75 \u00b1 0.92\nHW9 22 56 18.626 \u00b1 0.014 +62 01 47.851 \u00b1 0.137 (1.53 \u00b1 0.51) \u00d7 (0.29 \u00b1 0.30) 28.0 3.26 \u00b1 0.78\n\nG34.26+0.15 A 18 53 18.774 \u00b1 0.005 +01 14 56.208 \u00b1 0.125 (0.66 \u00b1 0.49) \u00d7 (0.50 \u00b1 0.33) 10.0 94 \u00b1 33\nB 18 53 18.649 \u00b1 0.005 +01 15 00.071 \u00b1 0.180 (2.31 \u00b1 0.49) \u00d7 (0.85 \u00b1 0.21) 17.4 597 \u00b1 110\nC 18 53 18.560 \u00b1 0.004 +01 14 58.201 \u00b1 0.112 (2.03 \u00b1 0.30) \u00d7 (1.34 \u00b1 0.20) 178.0 5070 \u00b1 660\n\nArticle number, page 8 of 10\n\n\n\nY. T. Yan (\u95eb\u8000\u5ead) et al.: Discovery of ammonia (9,6) masers in two high-mass star-forming regions\n\nTable A.3. NH3 (9,6) maser positions derived from the JVLA observations.\n\nSource R.A. Dec. S \u03bd TMB VLSR \u2206V1/2\n\n(h m s) (\u25e6 \u2032 \u2032\u2032) (mJy beam\u22121) (K) (km s\u22121)\nCep A M 22 56 17.933 \u00b1 0.002 +62 01 49.608 \u00b1 0.011 985.2 2464.8 -0.88 \u00b1 0.01 0.51 \u00b1 0.02\n\n343.2 829.5 -0.24 \u00b1 0.03 0.63 \u00b1 0.05\nG34.26+0.15 M1 18 53 18.569 \u00b1 0.007 +01 14 57.997 \u00b1 0.056 37.1 94.5 56.82 \u00b1 0.06 0.68 \u00b1 0.14\n\nM2 18 53 18.696 \u00b1 0.002 +01 14 55.807 \u00b1 0.034 48.4 122.4 53.77 \u00b1 0.05 0.35 \u00b1 0.08\n57.8 146.2 54.35 \u00b1 0.07 0.83 \u00b1 0.14\n\n180.8 457.6 55.83 \u00b1 0.01 0.59 \u00b1 0.03\nM3 18 53 18.667 \u00b1 0.005 +01 14 55.348 \u00b1 0.066 78.1 197.2 54.22 \u00b1 0.04 0.94 \u00b1 0.08\n\n73.7 186.3 55.78 \u00b1 0.04 0.79 \u00b1 0.08\n\nFig. A.1. Cepheus A. The grey shaded areas mark the 1.36 cm JVLA continuum map of Cep A. The reference position is \u03b1J2000 = 22h56m17s.972,\nand \u03b4J2000 = 62\u25e601\u203249\u2032\u2032.587, the peak position of the continuum map, is marked by a red cross. Slightly to the west of the cross is the white ellipse\ndenoting the position of the NH3 (9,6) emission with a purple star at its center. The red contours show the NOrthern Extended Millimeter Array\n(NOEMA) 1.37 mm continuum, taken from Beuther et al. (2018). Contour levels are -5, 5, 10, 20, 40, 80, 100, 150, and 200 \u00d7 2.43 mJy beam\u22121.\nOH (Bartkiewicz et al. 2005), H2O (Sobolev et al. 2018), and CH3OH (Sanna et al. 2017) masers are presented as diamonds, circles, and squares,\nrespectively. The color bar on the right-hand side indicates the velocity range (VLSR) of maser spots.\n\nArticle number, page 9 of 10\n\n\n\nA&A proofs: manuscript no. mainArxiv\n\nFig. A.2. 1.36 cm JVLA continuum map of G34.26+0.15 presented as gray shaded areas. The reference position is \u03b1J2000 = 18h53m18s.560, and\n\u03b4J2000 = 01\u25e614\u203258\u2032\u2032.201, the peak position, is marked by a red cross. The red ellipses show the positions of NH3 (9,6) emission with stars at their\ncenter (i.e., M1, M2, and M3). The blue contours show the Berkeley-Illinois-Maryland Association (BIMA) array 2.8 mm continuum, taken from\nMookerjea et al. (2007). Contour levels are -3, 3, 10, 20, 30, 40, 50, 70, 90, 100, 120, and 140 \u00d7 20 mJy beam\u22121. OH (Zheng et al. 2000), H2O (Imai\net al. 2011), and CH3OH (Bartkiewicz et al. 2016) masers are presented as diamonds, circles, and squares, respectively. The color bar indicates\nthe velocity range (VLSR) of maser spots.\n\nArticle number, page 10 of 10\n\n\n\t1 Introduction\n\t2 Observations and data reduction\n\t2.1 Effelsberg observations and data reduction\n\t2.2 JVLA observations and data reduction\n\n\t3 Results\n\t3.1 Centimeter-continuum emission\n\t3.2 NH3 (9,6) emission in Cep A\n\t3.3 NH3 (9,6) emission in G34.26+0.15\n\n\t4 Discussion\n\t4.1 Morphology of Cep A and G34.26+0.15\n\t4.2 NH3 (9,6) emission possibly caused by maser action\n\t4.3 Comparison of NH3 (9,6) masers with previously published (quasi-)thermal NH3 emission\n\t4.4 Comparison of NH3 (9,6) masers with other maser lines\n\t4.5 Constraints on pumping scenarios\n\n\t5 Summary\n\tA \n\n"}
{"Title": "The Formation of Intermediate Mass Black Holes in Galactic Nuclei", "Authors": "Sanaea C. Rose, Smadar Naoz, Re'em Sari, Itai Linial", "Abstract": "  Most stellar evolution models predict that black holes (BHs) should not exist above approximately $50-70$ M$_\\odot$. However, recent LIGO/Virgo detections indicate the existence of BHs with masses at and above this threshold. We suggest that massive BHs, including intermediate mass black holes (IMBHs), can form in galactic nuclei through collisions between stellar-mass black holes and the surrounding main-sequence stars. Considering dynamical processes such as collisions, mass segregation, and relaxation, we find that this channel can be quite efficient, forming IMBHs as massive as $10^4$ M$_\\odot$. Our results suggest that massive black holes and IMBHs may be ubiquitous in galactic centres. This formation channel also has implications for observations. Collisions between stars and BHs can produce electromagnetic signatures, for example, from x-ray binaries and tidal disruption events. Additionally, formed through this channel, both black holes in the mass gap and IMBHs can merge with the supermassive black hole at the center of a galactic nucleus through gravitational waves. These gravitational wave events are extreme and intermediate mass ratio inspirals (EMRIs and IMRIs, respectively).      ", "Subject": "Astrophysics of Galaxies (astro-ph.GA)", "ID": "arXiv:2201.00022", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDraft version January 4, 2022\nTypeset using LATEX twocolumn style in AASTeX631\n\nThe Formation of Intermediate Mass Black Holes in Galactic Nuclei\n\nSanaea C. Rose,1, 2 Smadar Naoz,1, 2 Re\u2019em Sari,3 and Itai Linial3\n\n1Department of Physics and Astronomy, University of California, Los Angeles, CA 90095, USA\n2Mani L. Bhaumik Institute for Theoretical Physics, University of California, Los Angeles, CA 90095, USA\n\n3Racah Institute for Physics, The Hebrew University, Jerusalem 91904, Israel\n\nABSTRACT\n\nMost stellar evolution models predict that black holes (BHs) should not exist above approximately\n\n50\u221270 M\ufffd. However, recent LIGO/Virgo detections indicate the existence of BHs with masses at and\n\nabove this threshold. We suggest that massive BHs, including intermediate mass black holes (IMBHs),\n\ncan form in galactic nuclei through collisions between stellar-mass black holes and the surrounding\n\nmain-sequence stars. Considering dynamical processes such as collisions, mass segregation, and relax-\n\nation, we find that this channel can be quite efficient, forming IMBHs as massive as 104 M\ufffd. Our\n\nresults suggest that massive black holes and IMBHs may be ubiquitous in galactic centres. This for-\n\nmation channel also has implications for observations. Collisions between stars and BHs can produce\n\nelectromagnetic signatures, for example, from x-ray binaries and tidal disruption events. Additionally,\n\nformed through this channel, both black holes in the mass gap and IMBHs can merge with the super-\n\nmassive black hole at the center of a galactic nucleus through gravitational waves. These gravitational\n\nwave events are extreme and intermediate mass ratio inspirals (EMRIs and IMRIs, respectively).\n\n1. INTRODUCTION\n\nThe recently detected gravitational wave source\n\nGW190521 (The LIGO Scientific Collaboration et al.\n\n2020a,b) produced an intermediate mass black hole of\n\napproximately 142 M\ufffd. This event may have also had a\n\n85 M\ufffd progenitor, which falls within the pair-instability\n\nmass gap that limits stellar black holes (BHs) to no\n\nmore than \u223c< 50 M\ufffd (e.g., Heger et al. 2003; Woosley\n\n2017)1. Similarly, the merger products of GW150914,\n\nGW170104, and GW170814 fall within the mass gap\n(e.g., Abbott et al. 2016, 2017a,b). BH mergers that\n\nform second generation BHs and, in some cases, inter-\n\nmediate mass BHs (IMBHs), these gravitational wave\n\n(GW) events can occur in globular clusters, young stel-\n\nlar clusters, or the field (e.g., Rodriguez et al. 2018; Ro-\n\ndriguez et al. 2019; Fishbach et al. 2020; Mapelli et al.\n\n2021b,a; Di Carlo et al. 2019, 2021; Dall\u2019Amico et al.\n\n2021; Arca Sedda et al. 2021). However, IMBHs are\n\nnot limited to these locations and may reside in galac-\n\nCorresponding author: Sanaea C. Rose\n\nsrose@astro.ucla.edu\n\n1 Note that the exact lower and upper limits may be sensitive to\nmetallicity of the progenitor (e.g., Woosley 2017; Spera & Mapelli\n2017a; Limongi & Chieffi 2018a; Sakstein et al. 2020; Belczynski\net al. 2020a; Renzo et al. 2020; Vink et al. 2021).\n\ntic nuclei as well. Several studies propose that our\n\nown galactic center may host an IMBH in the inner pc\n\n(e.g., Hansen & Milosavljevic\u0301 2003; Maillard et al. 2004;\n\nGu\u0308rkan & Rasio 2005; Gualandris & Merritt 2009; Chen\n\n& Liu 2013; Generozov & Madigan 2020; Fragione et al.\n\n2020a; Zheng et al. 2020; Naoz et al. 2020; GRAVITY\n\nCollaboration et al. 2020).\n\nSeveral IMBH formation channels have been suggested\n\nin the literature. For example, IMBHs may have a cos-\n\nmological origin, forming in the early universe either\n\nas a result of the very first stars (e.g., Madau & Rees\n\n2001; Schneider et al. 2002; Johnson & Bromm 2007;\n\nValiante et al. 2016) or from direct collapse of accumu-\n\nlated gas (e.g., Begelman et al. 2006; Yue et al. 2014;\n\nFerrara et al. 2014; Choi et al. 2015; Shlosman et al.\n\n2016). These high redshift IMBHs would need to sur-\n\nvive galaxy evolution and mergers to present day (e.g.,\n\nRashkov & Madau 2014), with significant effects on their\n\nstellar and even dark matter surroundings (e.g., Bertone\n\net al. 2009; Chen & Liu 2013; Bringmann et al. 2012; Eda\n\net al. 2013; Naoz & Silk 2014; Naoz et al. 2019). Another\n\npopular formation channel relies on the coalescence of\n\nmany stellar-mass black holes. For example, IMBHs\n\nmay form in the centers of globular clusters, where few-\n\nbody interactions lead to the merger of stellar-mass BHs\n\n(e.g., O\u2019Leary et al. 2006; Gu\u0308rkan et al. 2006; Blecha\n\net al. 2006; Freitag et al. 2006; Umbreit et al. 2012; Ro-\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n2v\n1 \n\n [\nas\n\ntr\no-\n\nph\n.G\n\nA\n] \n\n 3\n1 \n\nD\nec\n\n 2\n02\n\n1\n\nmailto: srose@astro.ucla.edu\n\n\n2 Rose et al.\n\ndriguez et al. 2018; Rodriguez et al. 2019; Fragione et al.\n\n2020b). Other formation mechanisms invoke successive\n\ncollisions and mergers of massive stars (e.g., Portegies\n\nZwart & McMillan 2002; Portegies Zwart et al. 2004;\n\nFreitag et al. 2006; Kremer et al. 2020; Gonza\u0301lez et al.\n\n2021; Di Carlo et al. 2021).\n\nThe main obstacle to sequential BH mergers in clus-\n\nters is that the merger recoil velocity kick often exceeds\n\nthe escape velocity from the cluster (e.g., Schnittman\n\n& Buonanno 2007; Centrella et al. 2010; O\u2019Leary et al.\n\n2006; Baibhav et al. 2020, Rom & Sari, in prep.). How-\n\never, nuclear star clusters at the centers of galaxies do\n\nnot encounter this problem. For example, Fragione et al.\n\n(2021) explore repeated BH-BH mergers in nuclear star\n\nclusters without a SMBH. They considered BH binary-\n\nsingle interactions, binary BH GW merger, and GW\n\nmerger recoil kicks. The post-kick merger product sinks\n\nback towards the cluster center over a dynamical fric-\n\ntion timescale. Using this approach, they showed that\n\n103 \u2212 104 M\ufffd IMBHs can form efficiently over the life-\n\ntime of a cluster.\n\nHowever, as discussed in Section 2.2, direct star-BH\n\ncollisions are much more frequent than BH-BH collision\n\nin galactic nuclei, making the former a promising chan-\n\nnel for BH growth. We propose that IMBHs can form\n\nnaturally within the central pc of a SMBH in a galactic\n\ncenter. Specifically, these IMBHs form through repeated\n\ncollisions with main sequence stars, accreting some or\n\nall of the star\u2019s mass depending on the details of the\n\ncollision. We demonstrate that this channel can create\n\nIMBHs with masses as large as 104 M\ufffd, depending on\n\nthe density profile of the surrounding stars.\n\nThe paper is structured as follows: we describe rele-\n\nvant physical processes and our approach in Section 2.\n\nIn particular, we provide an overview of collisions in\n\nSection 2.2 and present our statistical approach in Sec-\n\ntion 2.3. Section 2.4 discusses our treatment of the\n\nmass growth with each collision and presents analytic\n\nsolutions to our equations in two different regimes, ef-\n\nficient collisions and inefficient collisions We compare\n\nthese solutions to our statistical results. Sections 2.5\n\nand 2.7 discuss implications for GW merger events be-\n\ntween IMBHs and the SMBH. We then incorporate re-\n\nlaxation processes and discuss the subsequent results in\n\nSection 2.8. Finally, we discuss and summarize our find-\n\nings in Section 3.\n\n2. METHODOLOGY\n\nWe consider a population of stellar mass BHs embed-\n\nded in a cluster of 1 M\ufffd stars. When stars and BHs\n\ncollide, the BHs can accrete mass. The growth rate de-\n\npends on the physical processes outlined below. We use\n\na statistical approach to estimate the stellar encounters\n\nand final IMBH masses.\n\n2.1. Physical Picture\n\nWe consider a population of BHs within the inner few\n\nparsecs of the SMBH in a galactic nucleus (GN). We as-\n\nsume that the BH mass distribution follows that of the\n\nstars from which they originate, a Kroupa initial mass\n\nfunction dN/dm \u221d m\u22122.35. While this choice represents\n\na gross oversimplification, it has very little bearing on\n\nour final results. Future work may address the particu-\n\nlars of the BH mass distribution, but we do not expect\n\nthat it will significantly alter the outcome. The upper\n\nand lower limits of the BH mass distribution are 5 and\n\n50M\ufffd, respectively. We select the upper limit to en-\n\ncompass the range of upper bounds predicted by stellar\n\nevolution models, which vary between 40 and 125M\ufffd\ndepending on the metallicity (Heger et al. 2003; Woosley\n\n2017; Spera & Mapelli 2017b; Limongi & Chieffi 2018b;\n\nBelczynski et al. 2020b; Renzo et al. 2020). We assume\n\nthat the orbits of the BHs follow a thermal eccentricity\n\ndistribution. We draw their semimajor axes, a\u2022, from a\n\nuniform distribution in log distance, dN/d(log r) being\n\nconstant. While this distribution is not necessarily rep-\n\nresentative of actual conditions in the GN, we use it to\n\nbuild a comprehensive physical picture of BH growth at\n\nall distances from the SMBH, including within 0.01 pc.\n\nOtherwise, the innermost region of the GN would be\n\npoorly represented in our sample. We consider other\n\nobservationally motivated distributions in Section 2.8,\n\nbut reserve a more detailed examination of the distribu-\n\ntion\u2019s impact for future work.\n\n2.2. Direct Collisions\n\nBHs in the GN can undergo direct collisions with other\n\nobjects. The timescale for this process, tcoll, can be es-\n\ntimated using a simple rate calculation: t\u22121\ncoll = n\u03c3A,\n\nwhere n is the number density of objects, \u03c3 is the ve-\n\nlocity dispersion, and A is the cross-section. We use the\n\ncollision timescale from Rose et al. (2020):\n\nt\u22121\ncoll =\u03c0n(a\u2022)\u03c3(a\u2022)\n\n\u00d7\n(\nf1(e\u2022)r2\n\nc + f2(e\u2022)rc\n2G(mBH +m?)\n\n\u03c3(a\u2022)2\n\n)\n. (1)\n\nwhere G is the gravitational constant and rc is the sum\n\nof the radii of the interacting objects, a black hole with\n\nmass mBH and a star with mass m?. Detailed in Rose\n\net al. (2020), f1(e\u2022) and f2(e\u2022) account for the effect of\n\nthe eccentricity of the BH\u2019s orbit about the SMBH on\n\nthe collision rate, while n and \u03c3 are simply evaluated\n\nat the semimajor axis of the orbit (see below). Note\n\n\n\nIMBH Formation in Galactic Nuclei 3\n\nFigure 1. We plot the relevant timescales, including col-\nlision (green), relaxation (gold), and BH-BH GW capture\n(purple), for a single BH in the GN as a function of distance\nfrom the SMBH. For the collision timescale, we assume the\nBH is on a circular orbit. The timescales depend on the\ndensity, so we adopt a range of density profiles, bounded by\n\u03b1 = 1 (dashed curve) to \u03b1 = 2 (dark, solid curve). The dark\nblue line represents the time for a 105 M\ufffd BH to merge with\nthe SMBH through GW emission.\n\nthat this timescale equation includes the effects of grav-\n\nitational focusing, which enhances the cross-section of\n\ninteraction.\n\nAssuming a circular orbit for simplicity, we plot the\n\ntimescale for a BH orbiting in the GN to collide with\n\na 1M\ufffd star as a function of distance from the SMBH\n\nin Figure 1.2 As this timescale depends on the density\n\nof surrounding stars, we adopt a density profile of the\n\nform:\n\n\u03c1(r\u2022) = \u03c10\n\n(\nr\u2022\nr0\n\n)\u2212\u03b1\n\n, (2)\n\nwhere r\u2022 denotes the distance from the SMBH. We adopt\n\na SMBH mass of 4\u00d7 106 M\ufffd such that our fiducial GN\n\nmatches our own galactic center (e.g., Ghez et al. 2005;\n\nGenzel et al. 2003). In this case, the normalization in\n\nEq. (2) is \u03c10 = 1.35\u00d7 106M\ufffd/pc3 at r0 = 0.25 pc (Gen-\n\nzel et al. 2010). Additionally, in Eq. (2), \u03b1 gives the\n\nslope of the power law. We assume that a uniform pop-\n\nulation of solar mass stars account for most of the mass\n\nin the GN, making the stellar number density:\n\nn(r\u2022) =\n\u03c1(r\u2022)\n\n1M\ufffd\n. (3)\n\n2 We note that the eccentricity has a very minor effect on the\ncollision timescale (Rose et al. 2020).\n\nThe collision timescale also depends on the velocity dis-\n\npersion, which we express as:\n\n\u03c3(r\u2022) =\n\n\u221a\nGM\u2022\n\nr\u2022(1 + \u03b1)\n, (4)\n\nwhere \u03b1 is the slope of the density profile and M\u2022 de-\n\nnotes the mass of the SMBH (Alexander 1999; Alexan-\n\nder & Pfuhl 2014). As mentioned above, Eq. (1) depends\n\non the sum of the radii of the colliding objects, rc. We\n\ntake rc = 1R\ufffd because these interactions involve a BH\n\nand a star, and the former has a much smaller physi-\n\ncal cross-section. For example, the Schwarzschild radius\n\nof a 10M\ufffd BH is only 30 km, or 4.31 \u00d7 10\u22125R\ufffd. For\n\nthis reason, direct collisions between compact objects\n\nare very rare and not included in our model.\n\nWe note that direct collisions between BHs, via GW\n\nemission, were shown to be efficient in nuclear star clus-\n\nters without SMBHs (e.g., Portegies Zwart & McMil-\n\nlan 2000; O\u2019Leary et al. 2006; Rodriguez et al. 2016).\n\nHowever, in the GN, star-BH collisions are much more\n\nfrequent than direct BH-BH collisions. As depicted in\n\nFigure 1, the star-BH collision timescale for a range\n\nof density profiles is many orders of magnitude shorter\n\nthan the BH-BH GW collision timescale (for the rele-\n\nvant equations, see O\u2019Leary et al. 2009; Gonda\u0301n et al.\n\n2018, for example). Thus, we expect that star-BH col-\n\nlisions will be the main driver of IMBH growth in the\n\nGN.\n\n2.3. Statistical Approach to Collisions\n\nWe simulate the mass growth of a population of BHs\n\nwith initial conditions detailed in Section 2.1. Over an\n\nincrement \u2206t of 106 yr, we calculate the probability of\n\na collision occurring, given by \u2206t/tcoll. This choice of\n\n\u2206t is motivated by our galactic center\u2019s star formation\n\ntimescale (e.g., Lu et al. 2009), allowing for regular re-\n\nplenishment of the stellar population in the GN. We have\n\nchecked that the results are not sensitive to this choice\n\nof \u2206t, omitted here to avoid clutter. We draw a number\n\nbetween 0 and 1 using a random number generator. If\n\nthat number is less than or equal to the probability, we\n\nincrease the BH\u2019s mass by \u2206m, the mass that the BH is\n\nexpected to accrete in a single collision (see Section 2.4\n\nfor details). We recalculate the collision timescale using\n\nthe updated BH mass and repeat this process until the\n\ntime elapsed equals the simulation time of 10 Gyr3.\n\n3 Closer to the SMBH, \u2206t may exceed the collision timescale by\na factor of a few for steep density profiles. We include a safe-\nguard in our code which takes the ratio tcoll/\u2206t and rounds it\nto the nearest integer. We take this integer to be the number of\ncollisions and increase the BH mass accordingly.\n\n\n\n4 Rose et al.\n\n2.4. Mass Growth\n\nWhen a BH collides with a star, it may accrete ma-\n\nterial and grow in mass. The details of the accretion\n\ndepend on the relative velocity between the BH and\n\nstar. For simplicity, this calculation assumes that the\n\ntwo objects experience a head on collision, with the BH\n\npassing through the star\u2019s center. We begin by con-\n\nsidering the escape velocity from the BH at the star\u2019s\n\noutermost point, its surface, which corresponds to the\n\nmaximum impact parameter 1 R\ufffd. Qualitatively, one\n\nmight expect that the BH could accrete the entire star\n\n(i.e., \u2206m \u223c 1 M\ufffd) if the relative velocity is smaller than\n\nthe escape velocity from the BH at this point. However,\n\nin the vicinity of the SMBH, the dispersion velocity of\n\nthe stars may be much larger than the escape velocity\n\nfrom the BH at the star\u2019s surface. In this case, the BH\n\naccretes a \u201ctunnel\u201d of material through the star. This\n\ntunnel has radius equal to the Bondi radius and length\n\napproximately 1R\ufffd.\n\nTo estimate \u2206m, we begin with the Bondi-Hoyle ac-\n\ncretion rate, m\u0307, given by:\n\nm\u0307 =\n4\u03c0G2m2\n\nBH\u03c1star\n\n(c2s + \u03c32)\n3/2\n\n, (5)\n\nwhere cs is the speed of sound in the star and \u03c1star is its\n\ndensity (e.g., Bondi 1952; Bondi & Hoyle 1944; Shima\n\net al. 1985; Edgar 2004, see latter for a review). We\n\napproximate the density as 1M\ufffd/(4\u03c0R\n3\n\ufffd/3) and take\n\nthe conservative value of cs = 500 km s\u22121, which is\n\nconsistent with the sound speed inside a 1 M\ufffd star\n\n(Christensen-Dalsgaard et al. 1996) and allows us to set\n\na lower limit on \u2206m. To find \u2206m, at each collision, we\n\nhave:\n\n\u2206m = min(m\u0307\u00d7 t?,cross, 1 M\ufffd) , (6)\n\nwhere t?,cross \u223c R\ufffd/\u03c3 is the crossing time of the BH in\n\nthe star. We take the minimum between m\u0307\u00d7 t?,cross and\n\n1 M\ufffd because the BH cannot accrete more mass than\n\none star at each collision.\n\nFigure 2 juxtaposes the expected growth using Bondi-\n\nHoyle-Lyttleton accretion (blue small points) with a\n\nmuch simpler model in which the BH accretes the star\u2019s\n\nentire mass, 1M\ufffd (red large points). Both examples\n\nstart with identical populations of 10M\ufffd BHs (grey)\n\nand simulate growth through collisions using a statisti-\n\ncal approach. As the BHs grow, the collision timescale,\n\nwhich depends on mBH , decreases. Simultaneously,\n\n\u2206m, which also depends on mBH , increases. The re-\n\nsult is exponential growth (see discussion and details\n\nsurrounding Eq. (8)). In Figure 2, however, the simula-\n\ntions assume \u03b1 = 1 for the stellar density profile, ensur-\n\ning the collision timescale is long compared to the sim-\n\nulation time, 10 Gyr. Therefore, the BHs grow slowly,\n\nFigure 2. We consider an example that highlights the mass\ngrowth as a function of distance from the SMBH. Grey dots\nrepresent the initial masses and distances from the SMBH\nof the BHs involved in the simulation. For simplicity, we set\nthe inital mass equal to 10M\ufffd for all of the BHs. Assuming\nthe density profile of stars has \u03b1 = 1, we consider two cases:\nBHs accrete all of the star\u2019s mass during a collision (red) and\nonly a portion of the star\u2019s mass is accreted during a collision\ngiven by Eq. 6 (blue). The latter case results in less growth\ncloser to the SMBH where the velocity dispersion becomes\nhigh. The shaded regions and dashed lines represent the\nanalytical predictions detailed in Section 2.4.\n\nand their final masses can be approximated using the\n\nfollowing equation:\n\nmfinal(tcoll \u2192 const.) =minitial + \u2206m\nT\n\ntcoll\n, (7)\n\nin which T represents the simulation time and \u2206m and\n\ntcoll remain constant, approximated as their initial val-\n\nues.\n\nThis equation is plotted in Figure 2 for both cases,\n\n\u2206m = 1M\ufffd (red) and \u2206m from Bondi-Hoyle-Lyttleton\n\naccretion (blue), and the curves coincide with the cor-\n\nresponding simulated results. The shaded regions rep-\n\nresent one standard deviation from Eq. (7), calculated\n\nusing the square root of the number of collisions, T/tcoll.\n\nAs indicated by the results in red, in the absence of\n\nBondi-Hoyle-Lyttleton accretion, the BHs closest to the\n\nSMBH experience the most growth because they have\n\nshorter collision timescales. However, Bondi-Hoyle-\n\nLyttleton accretion becomes important closer to the\n\nSMBH, where the velocity dispersion is large compared\n\nwith the stars\u2019 escape velocity, and curtails the mass\n\ngrowth for BHs in this region. Outside of 10\u22122 pc, a BH\n\nconsumes the star\u2019s entire mass: the accretion-limited\n\n\u2206m governed by Eq. (7) is greater than or equal to the\n\nstar\u2019s mass.\n\nEq. 7 does not apply for other values of \u03b1. When the\n\ncollision timescale is shorter, corresponding to a larger\n\nindex \u03b1 in the density profile (see Figure 1), the growth\n\n\n\nIMBH Formation in Galactic Nuclei 5\n\nis very efficient and \u2206m quickly approaches 1 M\ufffd. Con-\n\nsequently, while we can now assume \u2206m = 1 M\ufffd, we\n\ncan no longer assume the collision timescale is constant.\n\nThe final mass grows exponentially as a result. For\n\n\u2206m = 1M\ufffd, the general solution is reached by solving\n\nthe differential equation dm/dt = 1M\ufffd/tcoll(m), which\n\ngives:\n\nmfinal(\u2206m\u2192 1 M\ufffd) =\u2212A+ (minitial +A) eCT (8)\n\nwhere A = \u03c32Rstar/G and C = 2\u03c0GnstarRstar/\u03c3. As an\n\nexample, we plot this curve in purple for the \u03b1 = 2 case,\n\nin Figure 3, which agrees with the simulated masses.\n\n2.5. GW Inspiral\n\nWhen a BH is close to the SMBH, GW emission can\n\ncircularize and shrink its orbit. We implement the ef-\n\nfects of GW emission on the BH\u2019s semimajor axis and\n\neccentricity following Peters & Mathews (1963a). The\n\ncharacteristic timescale to merge a BH with an SMBH\n\nis given by:\n\ntGW \u22482.9\u00d7 1012 yr\n\n(\nM\u2022\n\n106 M\ufffd\n\n)\u22121(\nmBH\n\n106 M\ufffd\n\n)\u22121\n\n\u00d7\n(\nM\u2022 +mBH\n\n2\u00d7 106 M\ufffd\n\n)\u22121(\na\u2022\n\n10\u22124 pc\n\n)4\n\n\u00d7 f(e\u2022)(1\u2212 e2\n\u2022)7/2 , (9)\n\nwhere f(e\u2022) is a function of e\u2022. For all values of e\u2022,\n\nf(e\u2022) is between 0.979 and 1.81 (Blaes et al. 2002). We\n\nplot this timescale for a 1 \u00d7 105M\ufffd BH in Figure 1 in\n\nblue.\n\nIn our simulations, we assume a BH has merged with\n\nthe SMBH when the condition tGW < telapsed is met.\n\nWhen this condition is satisfied, we terminate mass\n\ngrowth through collisions for that BH.4\n\n2.6. IMBH growth\n\nAs detailed above, BH-stellar collisions can increase\n\nthe BH masses as a function of time. Here, we examine\n\nthe sensitivity of the BH growth to the density power\n\nlaw. From Eq. (1), it is clear that the growth rate de-\n\npends on the stellar density profile, governed by the in-\n\ndex \u03b1. We expect that higher values of \u03b1, or steeper\n\nprofiles, will result in more efficient mass growth. In\n\nFigure 1, larger values of \u03b1 lead to collision timescales\n\nin the GN\u2019s inner region, inwards of 0.25 pc, that are\n\n4 For comparison, we also incrementally changed the semimajor\naxis and eccentricity from GW emission following the equations\nin Peters & Mathews (1963b). This method leads to a slight\nincrease in the final IMBH masses because it accounts for the\ncollisions that take place while the orbit is gradually shrinking.\n\nmuch smaller that the 10 Gyr simulation time. Figure 3\n\nconfirms this expectation. It depicts the mass growth of\n\na uniform distribution of BHs with initial conditions de-\n\ntailed in Section 2.1 for five \u03b1 values, spanning 1 (green)\n\nto 2 (purple). The most massive IMBHs form inwards\n\nof 0.25 pc for the \u03b1 = 2 case.\n\n2.7. Gravitational Wave Mergers and Intermediate\n\nand Extreme Mass Ratio Inspiral Candidates\n\nTowards the SMBH, efficient collisions can create BHs\n\nmassive enough to merge with the SMBH through GWs.\n\nFollowing the method detailed in Section 2.5, when a\n\ngiven BH meets the criterion tGW < telapsed, we mark\n\nit as merged with the SMBH. We assume that at this\n\npoint the dynamics of the BH will be determined by GW\n\nemission, shrinking and circularizing the BHs orbit un-\n\ntil it undergoes an extreme or intermediate mass ratio\n\ninspiral (EMRI and IMRI, respectively). The righthand\n\nplot in Figure 3 shows the BH masses versus time of\n\nmerger. It is interesting to note that even in the ab-\n\nsence of relaxation processes, which are often invoked\n\nto explain the formation of EMRIs, EMRIs and notably\n\nIMRIs can form in this region.\n\n2.8. Two Body Relaxation Processes\n\nA BH orbiting the SMBH experiences weak gravita-\n\ntional interactions with other objects in the GN. Over a\n\nrelaxation time, these interactions alter its orbit about\n\nthe SMBH. The two-body relaxation timescale for a\n\nsingle-mass system is:\n\ntrelax = 0.34\n\u03c33\n\nG2\u03c1\u3008M\u2217\u3009 ln \u039brlx\n, (10)\n\nwhere ln \u039brlx is the Coulomb logarithm and \u3008M\u2217\u3009 is the\n\naverage mass of the surrounding objects, here assumed\n\nto be 1M\ufffd (Spitzer 1987; Binney & Tremaine 2008,\n\nEq. (7.106)). This equation represents the approximate\n\ntimescale for a BH on a semi-circular orbit to change\n\nits orbital energy and angular momentum by order of\n\nthemselves. The BH experiences diffusion in its angular\n\nmomentum and energy as a function of time (depending\n\non the eccentricity of the orbit, this process can be more\n\nefficient Fragione & Sari 2018; Sari & Fragione 2019). In\n\nFigure 1, we plot the relaxation timescale in gold for a\n\nrange of \u03b1. We note that the Bahcall & Wolf (1976) pro-\n\nfile, \u03b1 = 7/4, corresponds to zero net flux and therefore\n\ndoes not preferentially migrate objects inward.\n\nAdditionally, because they are more massive on\n\naverage than the surrounding objects, BHs are ex-\n\npected to segregate inwards in the GN (e.g., Shapiro\n\n& Marchant 1978; Cohn & Kulsrud 1978; Morris 1993;\n\nMiralda-Escude\u0301 & Gould 2000; Baumgardt et al. 2004).\n\n\n\n6 Rose et al.\n\nFigure 3. On the right, we plot final masses of 500 BHs using different values of \u03b1 in the density profile, shallow (\u03b1 = 1) to\ncuspy (\u03b1 = 2). For the latter case, the purple line shows the analytical result from Eq. 8, taking minitial to be the average mass\nof the population. Faded stars indicate BHs that merged with the SMBH through GWs. On the left, we plot the masses and\nmerger times of these BHs.\n\nThey sink toward the SMBH on the mass segregation\n\ntimescale, tseg \u2248 \u3008M\u2217\u3009/mBH \u00d7 trelax (e.g., Spitzer 1987;\n\nFregeau et al. 2002; Merritt 2006), which is typically an\n\norder of magnitude smaller than the relaxation timescale\n\nplotted in Figure 1.\n\nWe incorporate relaxation processes by introducing a\n\nsmall change in the BH\u2019s energy and angular momen-\n\ntum each time it orbits the SMBH. We apply a small\n\ninstantaneous velocity kick to the BH, denoted as \u2206v.\n\nWe draw \u2206v from a Guassian distribution with average\n\nof zero and a standard deviation of \u2206vrlx/\n\u221a\n\n3, where\n\n\u2206vrlx = v\u2022\n\u221a\nP\u2022/trlx (see Bradnick et al. 2017, for an\n\napproach to changes in the angular momentum). The\n\nnew orbital parameters can be calculated following Lu\n\n& Naoz (2019), and see Naoz et al. in prep for full set\n\nof equations.\n\nWe account for the effects of relaxation processes,\nincluding mass-segregation, using a multi-faceted ap-\n\nproach. We begin by migrating each BH towards the\n\ncenter over its mass-segregation timescale, shifting it in-\n\ncrementally inward such that its orbital energy changes\n\nby order of itself within the segregation timescale.\n\nAs the BHs segregate down the potential well, their\n\nabundance with respect to stars increases, until at some\n\nturnover radius, BHs become the dominant source of\n\nscattering for both black holes and stars. Within this ra-\n\ndius, BH self-interaction dominates over two-body scat-\n\nterings with the now rarer main-sequence stars. The\n\nBHs will then settle onto a Bahcall-Wolf profile, while\n\nthe stars may follow a shallower profile, with approx-\n\nimately n? \u221d r\u22121.5, inwards of the transition radius\n\n(Linial & Sari in prep.).\n\nTherefore, after the initial mass segregation, we allow\n\nthe BHs to begin diffusing over a relaxation timescale,\n\ntheir orbital parameters changing slowly through a ran-\n\ndom process. In this random process, some of the BHs\n\nmay migrate closer to the SMBH. We terminate mass\n\ngrowth when the BH enters the inner 200 au of the GN,\n\nwithin which the density of stars is uncertain. This cut-\n\noff is based on the 120 au pericenter of S0-2, the closest\n\nknown star to the SMBH (e.g., Ghez et al. 2005).\n\nAnother physical process that causes inward migra-\n\ntion is dynamical friction. A cursory derivation based\n\non the dynamical friction equations described in Binney\n\n& Tremaine (2008) reveals the process to have a simi-\n\nlar timescale to mass segregation. If a BH diffuses to\n\na distance greater than 2 pc from the SMBH, exiting\n\nthe sphere of influence, we have it sink inwards, back\n\ntowards the center, over a dynamical friction timescale.\n\nAfter one dynamical friction timescale has passed, we\n\nrestart diffusion.\n\nWe note that our prescription ignores self-interactions\n\nbetween the BHs. As mentioned above, as the BHs sink\n\ntowards the SMBH, their concentration in the inner re-\n\ngion of the GN increases, allowing them to dominate the\n\nscattering. We reserve the inclusion of these interactions\n\nfor future study.\n\n2.9. Effect of Relaxation Processes\n\nAs depicted in Figure 4, two-body relaxation processes\n\nresult in more EMRIs and IMRIs events. These pro-\n\ncesses allow BHs that begin further from the SMBH\n\nto migrate inwards and grow more efficiently in mass.\n\nHowever, it also impedes the growth of BHs that are\n\ninitially closer to the SMBH by allowing them to dif-\n\n\n\nIMBH Formation in Galactic Nuclei 7\n\nFigure 4. Similar to Figure 3, we plot the initial masses versus initial distance (grey) and final mass versus final distance (red)\nfor 500 BHs. This simulation includes relaxation processes, including mass segregation, diffusion, and dynamical friction. We\nassume \u03b1 = 1.75 for the GN density profile. Faded stars represent BHs that merged with the SMBH. As a result of inward\nmigration, BHs merge more quickly with the SMBH, before they can become as massive as those in Figure 3. Additionally, more\nBHs become EMRIs and IMRIs. Additionally, in the third panel, we show a histogram of the simulated IMBH masses for two\ndifferent values of \u03b1, 1.5 (orange, solid), \u03b1, 1.75 (red, dashed), and 2 (purple, dash-dotted), accounting for relaxation processes.\nThe dashed, faded lines represent the corresponding initial histograms. We assume \u03b1 = 1.75 for the GN density profile. Faded\nstars represent BHs that merged with the SMBH.\n\nfuse out of the inner region where collisions are efficient.\n\nAs can be seen in Figure 4, the net result is that more\n\nBHs grow, but the maximum mass is lower compared\n\nto the scenario that ignores two-body relaxation. The\n\nhistogram in Figure 4 presents the final BH mass distri-\n\nbutions for different power law indices \u03b1. As expected,\n\nthe two-body relaxation suppresses the \u03b1 dependence\n\nhighlighted in Figure 3. In fact, using a KS test, we\n\nfind that we cannot reject the hypothesis that the two\n\ndistributions were drawn from the same sample for the\n\n\u03b1 = 1.75 and \u03b1 = 2 results. Interestingly, a BH mass\n\nIMF with an average of 10 M\ufffd leads to a final distri-\n\nbution with an average of \u223c 200 M\ufffd and a median of\n\n\u223c 45 M\ufffd, which lies within the mass gap.\n\n3. DISCUSSION AND PREDICTIONS\n\nWe explore the feasibility of forming IMBHs in a\nGN through successive collisions between a stellar-mass\n\nBH and main-sequence stars. Taking both a statisti-\n\ncal and analytic approach, we show that this channel\n\ncan produce IMBHs efficiently with masses as high as\n\n103\u22124 M\ufffd and may result in many IMBH-SMBH merg-\n\ners (intermediate-mass ratio inspiral, IMRIs) and EM-\n\nRIs.\n\nAs the stellar mass BH collides with a star, the BH\n\nwill grow in mass. The increase may equal star\u2019s en-\n\ntire mass if the relative velocity is smaller than the es-\n\ncape velocity from the BH at 1 R\ufffd. However, near the\n\nSMBH, the velocity dispersion may be larger than the\n\nescape velocity from the BH at the star\u2019s radius. In this\n\nlimit, the BH accretes a \u201ctunnel\u201d of material through\n\nthe star, estimated using Bondi-Hoyle-Lyttleton accre-\n\ntion. In our statistical analysis, we account for Bondi-\n\nHoyle-Lyttleton accretion and find that BHs outside of\n\n10\u22122 pc from the SMBH can accrete the entire star (see\n\nFigure 2).\n\nThe efficiency of collisions, and therefore IMBH,\n\nEMRI, and IMRI formation as well, are sensitive to\n\nthe underlying stellar density. As shown in Figure 3, a\n\nsteeper density profile results in larger IMBHs. This be-\n\nhavior can be understood from the collision timescale\u2019s\n\ndependence on the stellar density profile. A steeper pro-\n\nfile yields shorter collision timescales near the SMBH.\n\nHowever, the inclusion of relaxation processes in the\n\nsimulations dampens the influence of the stellar density\n\nprofile by allowing BHs to diffuse into regions of more\n\nor less efficient growth. As a result, more BHs grow in\n\nmass, but their maximum mass is smaller (\u223c 104 M\ufffd).\n\nAdditionally, the final masses have no apparent depen-\n\ndence on distance from the SMBH (see Figure 4).\n\nMass growth through BH-main-sequence star colli-\n\nsions may act in concert with other IMBH formation\n\nchannels, such as compact object binary mergers (e.g.,\n\nHoang et al. 2018; Stephan et al. 2019; Fragione et al.\n\n2021; Wang et al. 2021). While in some cases colli-\n\nsions can unbind a binary (e.g., Sigurdsson & Phinney\n\n1993; Fregeau et al. 2004), BH binaries can be tightly\n\nbound enough to withstand the collisions. Wide bina-\n\nries may also become unbound due to interactions with\n\nthe neighboring stars and compact objects (e.g., Binney\n\n& Tremaine 1987; Rose et al. 2020, see latter study for\n\nthe timescale for an arbitrary eccentricity). However,\n\nas highlighted in previous studies, a substantial frac-\n\ntion of these binaries may merge due to the Eccentric\n\nKozai Lidov mechanism, leaving behind a single star or\n\na single compact object (e.g., Stephan et al. 2016, 2019;\n\nHoang et al. 2018). Additionally, to be susceptible to\n\nevaporation, BH binaries must have a wider configura-\n\ntion. Otherwise, they will be more tightly bound that\n\n\n\n8 Rose et al.\n\nthe average kinetic energy of the surrounding objects,\n\nand will only harden through weak gravitational inter-\n\nactions with neighboring stars (see for example Figure\n\n6 in Rose et al. 2020).\n\nNot included in this study, collisions between the BH\n\nand other compact objects will increase the BH growth\n\nrate. BH-BH mergers (e.g., O\u2019Leary et al. 2009; Fra-\n\ngione et al. 2021) and even neutron star BH mergers\n\n(e.g., Hoang et al. 2020) become more likely as the BHs\n\nincrease in mass through stellar collisions. As a result,\n\nthe BH-BH collision timescale, discussed in Section 2.2,\n\nwill become relevant to our simulations, allowing the\n\nBHs to grow through this channel in addition to stel-\n\nlar collisions. Additionally, this compact object mergers\n\nresult in GW recoil, which may have a large impact on\n\nthe dynamics (e.g., Baibhav et al. 2020; Fragione et al.\n\n2021)\n\nThe BH\u2019s mass growth increases GW emission, which\n\ndissipates energy from the orbit. Along with relaxation\n\nprocesses, GW emission causes BHs to sink towards the\n\nSMBH and eventually undergo a merger. As a result,\n\nthe GN environment is conducive to the formation of\n\nEMRIs and IMRIs. The GW emission from EMRIs and\n\nIMRIs is expected to be at mHz frequencies, making\n\nthem promising candidates for LISA to observe. While\n\nthe exact rate calculation is beyond the scope of this\n\nstudy, the mechanism outlined here seems very promis-\n\ning.\n\nOur results also suggest that IMBHs are likely to ex-\n\nists in many galactic nuclei, as well as within our own\n\ngalactic center. This implication seems to be consis-\n\ntent with recent observational and theoretical studies\n\n(e.g., Hansen & Milosavljevic\u0301 2003; Maillard et al. 2004;\n\nGu\u0308rkan & Rasio 2005; Gualandris & Merritt 2009; Chen\n\n& Liu 2013; Generozov & Madigan 2020; Fragione et al.\n\n2020a; Zheng et al. 2020; Naoz et al. 2020; GRAVITY\n\nCollaboration et al. 2020).\n\nLastly, the collisions between stellar mass BHs and\n\nstars may contribute to the x-ray emission from our\n\ngalactic centre (e.g., Muno et al. 2005, 2009; Hailey et al.\n\n2018; Zhu et al. 2018; Cheng et al. 2018)5. These inter-\n\nactions, in particular grazing collisions, may also result\n\nin tidal disruption events (e.g., Perets et al. 2016; Sam-\n\nsing et al. 2019; Kremer et al. 2021). Thus, the process\n\noutlined here may produce electromagnetic signatures\n\nin addition to GW mergers.\n\nSR thanks the Charles E Young fellowship, the Nina\n\nByers Fellowship, and the Michael A. Jura Memorial\n\nGraduate Award for support. SR and SN acknowledge\n\nthe partial support from NASA ATP 80NSSC20K0505.\n\nSN thanks Howard and Astrid Preston for their gener-\n\nous support. IL thanks support from the Adams Fellow-\n\nship. SN and RS thank the Bhaumik Institute visitor\n\nprogram.\n\nREFERENCES\n\nAbbott, B. P., Abbott, R., Abbott, T. D., et al. 2016,\n\nPhRvL, 116, 241102,\n\ndoi: 10.1103/PhysRevLett.116.241102\n\n\u2014. 2017a, PhRvL, 118, 221101,\n\ndoi: 10.1103/PhysRevLett.118.221101\n\n\u2014. 2017b, PhRvL, 119, 141101,\n\ndoi: 10.1103/PhysRevLett.119.141101\n\nAlexander, T. 1999, ApJ, 527, 835, doi: 10.1086/308129\n\nAlexander, T., & Pfuhl, O. 2014, ApJ, 780, 148,\n\ndoi: 10.1088/0004-637X/780/2/148\n\nArca Sedda, M., Mapelli, M., Benacquista, M., & Spera, M.\n\n2021, arXiv e-prints, arXiv:2109.12119.\n\nhttps://arxiv.org/abs/2109.12119\n\nBahcall, J. N., & Wolf, R. A. 1976, ApJ, 209, 214,\n\ndoi: 10.1086/154711\n\n5 The connection between the observed X-ray sources at the Galac-\ntic Center and tidal capture has been suggested by Generozov\net al. (2018), but see Zhu et al. (2018); Stephan et al. (2019) for\nalternative channels.\n\nBaibhav, V., Gerosa, D., Berti, E., et al. 2020, PhRvD, 102,\n\n043002, doi: 10.1103/PhysRevD.102.043002\n\nBaumgardt, H., Makino, J., & Ebisuzaki, T. 2004, ApJ,\n\n613, 1143, doi: 10.1086/423299\n\nBegelman, M. C., Volonteri, M., & Rees, M. J. 2006,\n\nMNRAS, 370, 289, doi: 10.1111/j.1365-2966.2006.10467.x\n\nBelczynski, K., Hirschi, R., Kaiser, E. A., et al. 2020a, ApJ,\n\n890, 113, doi: 10.3847/1538-4357/ab6d77\n\n\u2014. 2020b, ApJ, 890, 113, doi: 10.3847/1538-4357/ab6d77\n\nBertone, G., Fornasa, M., Taoso, M., & Zentner, A. R.\n\n2009, New Journal of Physics, 11, 105016,\n\ndoi: 10.1088/1367-2630/11/10/105016\n\nBinney, J., & Tremaine, S. 1987, Galactic dynamics\n\n\u2014. 2008, Galactic Dynamics: Second Edition\n\nBlaes, O., Lee, M. H., & Socrates, A. 2002, ApJ, 578, 775,\n\ndoi: 10.1086/342655\n\nBlecha, L., Ivanova, N., Kalogera, V., et al. 2006, ApJ, 642,\n\n427, doi: 10.1086/500727\n\nBondi, H. 1952, MNRAS, 112, 195,\n\ndoi: 10.1093/mnras/112.2.195\n\nhttp://doi.org/10.1103/PhysRevLett.116.241102\nhttp://doi.org/10.1103/PhysRevLett.118.221101\nhttp://doi.org/10.1103/PhysRevLett.119.141101\nhttp://doi.org/10.1086/308129\nhttp://doi.org/10.1088/0004-637X/780/2/148\nhttps://arxiv.org/abs/2109.12119\nhttp://doi.org/10.1086/154711\nhttp://doi.org/10.1103/PhysRevD.102.043002\nhttp://doi.org/10.1086/423299\nhttp://doi.org/10.1111/j.1365-2966.2006.10467.x\nhttp://doi.org/10.3847/1538-4357/ab6d77\nhttp://doi.org/10.3847/1538-4357/ab6d77\nhttp://doi.org/10.1088/1367-2630/11/10/105016\nhttp://doi.org/10.1086/342655\nhttp://doi.org/10.1086/500727\nhttp://doi.org/10.1093/mnras/112.2.195\n\n\nIMBH Formation in Galactic Nuclei 9\n\nBondi, H., & Hoyle, F. 1944, MNRAS, 104, 273,\n\ndoi: 10.1093/mnras/104.5.273\n\nBradnick, B., Mandel, I., & Levin, Y. 2017, MNRAS, 469,\n\n2042, doi: 10.1093/mnras/stx1007\n\nBringmann, T., Huang, X., Ibarra, A., Vogl, S., & Weniger,\n\nC. 2012, JCAP, 2012, 054,\n\ndoi: 10.1088/1475-7516/2012/07/054\n\nCentrella, J., Baker, J. G., Kelly, B. J., & van Meter, J. R.\n\n2010, Reviews of Modern Physics, 82, 3069,\n\ndoi: 10.1103/RevModPhys.82.3069\n\nChen, X., & Liu, F. K. 2013, ApJ, 762, 95,\n\ndoi: 10.1088/0004-637X/762/2/95\n\nCheng, Z., Li, Z., Xu, X., & Li, X. 2018, ApJ, 858, 33,\n\ndoi: 10.3847/1538-4357/aaba16\n\nChoi, J.-H., Shlosman, I., & Begelman, M. C. 2015,\n\nMNRAS, 450, 4411, doi: 10.1093/mnras/stv694\n\nChristensen-Dalsgaard, J., Dappen, W., Ajukov, S. V.,\n\net al. 1996, Science, 272, 1286,\n\ndoi: 10.1126/science.272.5266.1286\n\nCohn, H., & Kulsrud, R. M. 1978, ApJ, 226, 1087,\n\ndoi: 10.1086/156685\n\nDall\u2019Amico, M., Mapelli, M., Di Carlo, U. N., et al. 2021,\n\nMNRAS, 508, 3045, doi: 10.1093/mnras/stab2783\n\nDi Carlo, U. N., Giacobbo, N., Mapelli, M., et al. 2019,\n\nMNRAS, 487, 2947, doi: 10.1093/mnras/stz1453\n\nDi Carlo, U. N., Mapelli, M., Pasquato, M., et al. 2021,\n\nMNRAS, 507, 5132, doi: 10.1093/mnras/stab2390\n\nEda, K., Itoh, Y., Kuroyanagi, S., & Silk, J. 2013, PhRvL,\n\n110, 221101, doi: 10.1103/PhysRevLett.110.221101\n\nEdgar, R. 2004, NewAR, 48, 843,\n\ndoi: 10.1016/j.newar.2004.06.001\n\nFerrara, A., Salvadori, S., Yue, B., & Schleicher, D. 2014,\n\nMonthly Notices of the Royal Astronomical Society, 443,\n\n2410, doi: 10.1093/mnras/stu1280\n\nFishbach, M., Farr, W. M., & Holz, D. E. 2020, ApJL, 891,\n\nL31, doi: 10.3847/2041-8213/ab77c9\n\nFragione, G., Kocsis, B., Rasio, F. A., & Silk, J. 2021,\n\narXiv e-prints, arXiv:2107.04639.\n\nhttps://arxiv.org/abs/2107.04639\n\nFragione, G., Loeb, A., Kremer, K., & Rasio, F. A. 2020a,\n\nApJ, 897, 46, doi: 10.3847/1538-4357/ab94b2\n\nFragione, G., Loeb, A., & Rasio, F. A. 2020b, ApJL, 902,\n\nL26, doi: 10.3847/2041-8213/abbc0a\n\nFragione, G., & Sari, R. 2018, ApJ, 852, 51,\n\ndoi: 10.3847/1538-4357/aaa0d7\n\nFregeau, J. M., Cheung, P., Portegies Zwart, S. F., &\n\nRasio, F. A. 2004, MNRAS, 352, 1,\n\ndoi: 10.1111/j.1365-2966.2004.07914.x\n\nFregeau, J. M., Joshi, K. J., Portegies Zwart, S. F., &\n\nRasio, F. A. 2002, ApJ, 570, 171, doi: 10.1086/339576\n\nFreitag, M., Amaro-Seoane, P., & Kalogera, V. 2006, ApJ,\n\n649, 91, doi: 10.1086/506193\n\nGenerozov, A., & Madigan, A.-M. 2020, ApJ, 896, 137,\n\ndoi: 10.3847/1538-4357/ab94bc\n\nGenerozov, A., Stone, N. C., Metzger, B. D., & Ostriker,\n\nJ. P. 2018, MNRAS, 478, 4030,\n\ndoi: 10.1093/mnras/sty1262\n\nGenzel, R., Eisenhauer, F., & Gillessen, S. 2010, Reviews of\n\nModern Physics, 82, 3121,\n\ndoi: 10.1103/RevModPhys.82.3121\n\nGenzel, R., Scho\u0308del, R., Ott, T., et al. 2003, ApJ, 594, 812,\n\ndoi: 10.1086/377127\n\nGhez, A. M., Salim, S., Hornstein, S. D., et al. 2005, ApJ,\n\n620, 744, doi: 10.1086/427175\n\nGonda\u0301n, L., Kocsis, B., Raffai, P., & Frei, Z. 2018, ApJ,\n\n860, 5, doi: 10.3847/1538-4357/aabfee\n\nGonza\u0301lez, E., Kremer, K., Chatterjee, S., et al. 2021, ApJL,\n\n908, L29, doi: 10.3847/2041-8213/abdf5b\n\nGRAVITY Collaboration, Abuter, R., Amorim, A., et al.\n\n2020, A&A, 636, L5, doi: 10.1051/0004-6361/202037813\n\nGualandris, A., & Merritt, D. 2009, ApJ, 705, 361,\n\ndoi: 10.1088/0004-637X/705/1/361\n\nGu\u0308rkan, M. A., Fregeau, J. M., & Rasio, F. A. 2006, ApJL,\n\n640, L39, doi: 10.1086/503295\n\nGu\u0308rkan, M. A., & Rasio, F. A. 2005, ApJ, 628, 236,\n\ndoi: 10.1086/430694\n\nHailey, C. J., Mori, K., Bauer, F. E., et al. 2018, Nature,\n\n556, 70, doi: 10.1038/nature25029\n\nHansen, B. M. S., & Milosavljevic\u0301, M. 2003, ApJL, 593,\n\nL77, doi: 10.1086/378182\n\nHeger, A., Fryer, C. L., Woosley, S. E., Langer, N., &\n\nHartmann, D. H. 2003, ApJ, 591, 288,\n\ndoi: 10.1086/375341\n\nHoang, B.-M., Naoz, S., Kocsis, B., Rasio, F. A., &\n\nDosopoulou, F. 2018, ApJ, 856, 140,\n\ndoi: 10.3847/1538-4357/aaafce\n\nHoang, B.-M., Naoz, S., & Kremer, K. 2020, ApJ, 903, 8,\n\ndoi: 10.3847/1538-4357/abb66a\n\nJohnson, J. L., & Bromm, V. 2007, Monthly Notices of the\n\nRoyal Astronomical Society, 374, 1557,\n\ndoi: 10.1111/j.1365-2966.2006.11275.x\n\nKremer, K., Lu, W., Piro, A. L., et al. 2021, ApJ, 911, 104,\n\ndoi: 10.3847/1538-4357/abeb14\n\nKremer, K., Spera, M., Becker, D., et al. 2020, ApJ, 903,\n\n45, doi: 10.3847/1538-4357/abb945\n\nLimongi, M., & Chieffi, A. 2018a, ApJS, 237, 13,\n\ndoi: 10.3847/1538-4365/aacb24\n\n\u2014. 2018b, ApJS, 237, 13, doi: 10.3847/1538-4365/aacb24\n\nLu, C. X., & Naoz, S. 2019, MNRAS, 484, 1506,\n\ndoi: 10.1093/mnras/stz036\n\nhttp://doi.org/10.1093/mnras/104.5.273\nhttp://doi.org/10.1093/mnras/stx1007\nhttp://doi.org/10.1088/1475-7516/2012/07/054\nhttp://doi.org/10.1103/RevModPhys.82.3069\nhttp://doi.org/10.1088/0004-637X/762/2/95\nhttp://doi.org/10.3847/1538-4357/aaba16\nhttp://doi.org/10.1093/mnras/stv694\nhttp://doi.org/10.1126/science.272.5266.1286\nhttp://doi.org/10.1086/156685\nhttp://doi.org/10.1093/mnras/stab2783\nhttp://doi.org/10.1093/mnras/stz1453\nhttp://doi.org/10.1093/mnras/stab2390\nhttp://doi.org/10.1103/PhysRevLett.110.221101\nhttp://doi.org/10.1016/j.newar.2004.06.001\nhttp://doi.org/10.1093/mnras/stu1280\nhttp://doi.org/10.3847/2041-8213/ab77c9\nhttps://arxiv.org/abs/2107.04639\nhttp://doi.org/10.3847/1538-4357/ab94b2\nhttp://doi.org/10.3847/2041-8213/abbc0a\nhttp://doi.org/10.3847/1538-4357/aaa0d7\nhttp://doi.org/10.1111/j.1365-2966.2004.07914.x\nhttp://doi.org/10.1086/339576\nhttp://doi.org/10.1086/506193\nhttp://doi.org/10.3847/1538-4357/ab94bc\nhttp://doi.org/10.1093/mnras/sty1262\nhttp://doi.org/10.1103/RevModPhys.82.3121\nhttp://doi.org/10.1086/377127\nhttp://doi.org/10.1086/427175\nhttp://doi.org/10.3847/1538-4357/aabfee\nhttp://doi.org/10.3847/2041-8213/abdf5b\nhttp://doi.org/10.1051/0004-6361/202037813\nhttp://doi.org/10.1088/0004-637X/705/1/361\nhttp://doi.org/10.1086/503295\nhttp://doi.org/10.1086/430694\nhttp://doi.org/10.1038/nature25029\nhttp://doi.org/10.1086/378182\nhttp://doi.org/10.1086/375341\nhttp://doi.org/10.3847/1538-4357/aaafce\nhttp://doi.org/10.3847/1538-4357/abb66a\nhttp://doi.org/10.1111/j.1365-2966.2006.11275.x\nhttp://doi.org/10.3847/1538-4357/abeb14\nhttp://doi.org/10.3847/1538-4357/abb945\nhttp://doi.org/10.3847/1538-4365/aacb24\nhttp://doi.org/10.3847/1538-4365/aacb24\nhttp://doi.org/10.1093/mnras/stz036\n\n\n10 Rose et al.\n\nLu, J. R., Ghez, A. M., Hornstein, S. D., et al. 2009, ApJ,\n\n690, 1463, doi: 10.1088/0004-637X/690/2/1463\n\nMadau, P., & Rees, M. J. 2001, ApJL, 551, L27,\n\ndoi: 10.1086/319848\n\nMaillard, J. P., Paumard, T., Stolovy, S. R., & Rigaut, F.\n\n2004, A&A, 423, 155, doi: 10.1051/0004-6361:20034147\n\nMapelli, M., Bouffanais, Y., Santoliquido, F., Arca Sedda,\n\nM., & Artale, M. C. 2021a, arXiv e-prints,\n\narXiv:2109.06222. https://arxiv.org/abs/2109.06222\n\nMapelli, M., Dall\u2019Amico, M., Bouffanais, Y., et al. 2021b,\n\nMNRAS, 505, 339, doi: 10.1093/mnras/stab1334\n\nMerritt, D. 2006, Reports on Progress in Physics, 69, 2513,\n\ndoi: 10.1088/0034-4885/69/9/R01\n\nMiralda-Escude\u0301, J., & Gould, A. 2000, ApJ, 545, 847,\n\ndoi: 10.1086/317837\n\nMorris, M. 1993, ApJ, 408, 496, doi: 10.1086/172607\n\nMuno, M. P., Pfahl, E., Baganoff, F. K., et al. 2005, ApJL,\n\n622, L113, doi: 10.1086/429721\n\nMuno, M. P., Bauer, F. E., Baganoff, F. K., et al. 2009,\n\nApJS, 181, 110, doi: 10.1088/0067-0049/181/1/110\n\nNaoz, S., & Silk, J. 2014, ApJ, 795, 102,\n\ndoi: 10.1088/0004-637X/795/2/102\n\nNaoz, S., Silk, J., & Schnittman, J. D. 2019, ApJL, 885,\n\nL35, doi: 10.3847/2041-8213/ab4fed\n\nNaoz, S., Will, C. M., Ramirez-Ruiz, E., et al. 2020, ApJL,\n\n888, L8, doi: 10.3847/2041-8213/ab5e3b\n\nO\u2019Leary, R. M., Kocsis, B., & Loeb, A. 2009, MNRAS, 395,\n\n2127, doi: 10.1111/j.1365-2966.2009.14653.x\n\nO\u2019Leary, R. M., Rasio, F. A., Fregeau, J. M., Ivanova, N.,\n\n& O\u2019Shaughnessy, R. 2006, ApJ, 637, 937,\n\ndoi: 10.1086/498446\n\nPerets, H. B., Li, Z., Lombardi, James C., J., & Milcarek,\n\nStephen R., J. 2016, ApJ, 823, 113,\n\ndoi: 10.3847/0004-637X/823/2/113\n\nPeters, P. C., & Mathews, J. 1963a, Physical Review, 131,\n\n435, doi: 10.1103/PhysRev.131.435\n\n\u2014. 1963b, Physical Review, 131, 435,\n\ndoi: 10.1103/PhysRev.131.435\n\nPortegies Zwart, S. F., Baumgardt, H., Hut, P., Makino, J.,\n\n& McMillan, S. L. W. 2004, Nature, 428, 724,\n\ndoi: 10.1038/nature02448\n\nPortegies Zwart, S. F., & McMillan, S. L. W. 2000, ApJL,\n\n528, L17, doi: 10.1086/312422\n\n\u2014. 2002, ApJ, 576, 899, doi: 10.1086/341798\n\nRashkov, V., & Madau, P. 2014, ApJ, 780, 187,\n\ndoi: 10.1088/0004-637X/780/2/187\n\nRenzo, M., Farmer, R., Justham, S., et al. 2020, A&A, 640,\n\nA56, doi: 10.1051/0004-6361/202037710\n\nRodriguez, C. L., Amaro-Seoane, P., Chatterjee, S., &\n\nRasio, F. A. 2018, PhRvL, 120, 151101,\n\ndoi: 10.1103/PhysRevLett.120.151101\n\nRodriguez, C. L., Chatterjee, S., & Rasio, F. A. 2016,\n\nPhRvD, 93, 084029, doi: 10.1103/PhysRevD.93.084029\n\nRodriguez, C. L., Zevin, M., Amaro-Seoane, P., et al. 2019,\n\nPhys. Rev. D, 100, 043027,\n\ndoi: 10.1103/PhysRevD.100.043027\n\nRose, S. C., Naoz, S., Gautam, A. K., et al. 2020, ApJ, 904,\n\n113, doi: 10.3847/1538-4357/abc557\n\nSakstein, J., Croon, D., McDermott, S. D., Straight, M. C.,\n\n& Baxter, E. J. 2020, arXiv e-prints, arXiv:2009.01213.\n\nhttps://arxiv.org/abs/2009.01213\n\nSamsing, J., Venumadhav, T., Dai, L., et al. 2019, PhRvD,\n\n100, 043009, doi: 10.1103/PhysRevD.100.043009\n\nSari, R., & Fragione, G. 2019, ApJ, 885, 24,\n\ndoi: 10.3847/1538-4357/ab43df\n\nSchneider, R., Ferrara, A., Natarajan, P., & Omukai, K.\n\n2002, The Astrophysical Journal, 571, 30,\n\ndoi: 10.1086/339917\n\nSchnittman, J. D., & Buonanno, A. 2007, ApJL, 662, L63,\n\ndoi: 10.1086/519309\n\nShapiro, S. L., & Marchant, A. B. 1978, ApJ, 225, 603,\n\ndoi: 10.1086/156521\n\nShima, E., Matsuda, T., Takeda, H., & Sawada, K. 1985,\n\nMNRAS, 217, 367, doi: 10.1093/mnras/217.2.367\n\nShlosman, I., Choi, J.-H., Begelman, M. C., & Nagamine,\n\nK. 2016, MNRAS, 456, 500, doi: 10.1093/mnras/stv2700\n\nSigurdsson, S., & Phinney, E. S. 1993, ApJ, 415, 631,\n\ndoi: 10.1086/173190\n\nSpera, M., & Mapelli, M. 2017a, MNRAS, 470, 4739,\n\ndoi: 10.1093/mnras/stx1576\n\n\u2014. 2017b, MNRAS, 470, 4739, doi: 10.1093/mnras/stx1576\n\nSpitzer, L. 1987, Dynamical evolution of globular clusters\n\nStephan, A. P., Naoz, S., Ghez, A. M., et al. 2016, ArXiv\n\ne-prints. https://arxiv.org/abs/1603.02709\n\n\u2014. 2019, ApJ, 878, 58, doi: 10.3847/1538-4357/ab1e4d\n\nThe LIGO Scientific Collaboration, the Virgo\n\nCollaboration, Abbott, R., et al. 2020a, arXiv e-prints,\n\narXiv:2009.01075. https://arxiv.org/abs/2009.01075\n\n\u2014. 2020b, arXiv e-prints, arXiv:2009.01190.\n\nhttps://arxiv.org/abs/2009.01190\n\nUmbreit, S., Fregeau, J. M., Chatterjee, S., & Rasio, F. A.\n\n2012, ApJ, 750, 31, doi: 10.1088/0004-637X/750/1/31\n\nValiante, R., Schneider, R., Volonteri, M., & Omukai, K.\n\n2016, Monthly Notices of the Royal Astronomical\n\nSociety, 457, 3356, doi: 10.1093/mnras/stw225\n\nVink, J. S., Higgins, E. R., Sander, A. A. C., & Sabhahit,\n\nG. N. 2021, MNRAS, 504, 146,\n\ndoi: 10.1093/mnras/stab842\n\nhttp://doi.org/10.1088/0004-637X/690/2/1463\nhttp://doi.org/10.1086/319848\nhttp://doi.org/10.1051/0004-6361:20034147\nhttps://arxiv.org/abs/2109.06222\nhttp://doi.org/10.1093/mnras/stab1334\nhttp://doi.org/10.1088/0034-4885/69/9/R01\nhttp://doi.org/10.1086/317837\nhttp://doi.org/10.1086/172607\nhttp://doi.org/10.1086/429721\nhttp://doi.org/10.1088/0067-0049/181/1/110\nhttp://doi.org/10.1088/0004-637X/795/2/102\nhttp://doi.org/10.3847/2041-8213/ab4fed\nhttp://doi.org/10.3847/2041-8213/ab5e3b\nhttp://doi.org/10.1111/j.1365-2966.2009.14653.x\nhttp://doi.org/10.1086/498446\nhttp://doi.org/10.3847/0004-637X/823/2/113\nhttp://doi.org/10.1103/PhysRev.131.435\nhttp://doi.org/10.1103/PhysRev.131.435\nhttp://doi.org/10.1038/nature02448\nhttp://doi.org/10.1086/312422\nhttp://doi.org/10.1086/341798\nhttp://doi.org/10.1088/0004-637X/780/2/187\nhttp://doi.org/10.1051/0004-6361/202037710\nhttp://doi.org/10.1103/PhysRevLett.120.151101\nhttp://doi.org/10.1103/PhysRevD.93.084029\nhttp://doi.org/10.1103/PhysRevD.100.043027\nhttp://doi.org/10.3847/1538-4357/abc557\nhttps://arxiv.org/abs/2009.01213\nhttp://doi.org/10.1103/PhysRevD.100.043009\nhttp://doi.org/10.3847/1538-4357/ab43df\nhttp://doi.org/10.1086/339917\nhttp://doi.org/10.1086/519309\nhttp://doi.org/10.1086/156521\nhttp://doi.org/10.1093/mnras/217.2.367\nhttp://doi.org/10.1093/mnras/stv2700\nhttp://doi.org/10.1086/173190\nhttp://doi.org/10.1093/mnras/stx1576\nhttp://doi.org/10.1093/mnras/stx1576\nhttps://arxiv.org/abs/1603.02709\nhttp://doi.org/10.3847/1538-4357/ab1e4d\nhttps://arxiv.org/abs/2009.01075\nhttps://arxiv.org/abs/2009.01190\nhttp://doi.org/10.1088/0004-637X/750/1/31\nhttp://doi.org/10.1093/mnras/stw225\nhttp://doi.org/10.1093/mnras/stab842\n\n\nIMBH Formation in Galactic Nuclei 11\n\nWang, H., Stephan, A. P., Naoz, S., Hoang, B.-M., &\n\nBreivik, K. 2021, ApJ, 917, 76,\n\ndoi: 10.3847/1538-4357/ac088d\n\nWoosley, S. E. 2017, ApJ, 836, 244,\n\ndoi: 10.3847/1538-4357/836/2/244\n\nYue, B., Ferrara, A., Salvaterra, R., Xu, Y., & Chen, X.\n\n2014, Monthly Notices of the Royal Astronomical\n\nSociety, 440, 1263, doi: 10.1093/mnras/stu351\n\nZheng, X., Lin, D. N. C., & Mao, S. 2020, arXiv e-prints,\n\narXiv:2011.04653. https://arxiv.org/abs/2011.04653\n\nZhu, Z., Li, Z., & Morris, M. R. 2018, ApJS, 235, 26,\n\ndoi: 10.3847/1538-4365/aab14f\n\nhttp://doi.org/10.3847/1538-4357/ac088d\nhttp://doi.org/10.3847/1538-4357/836/2/244\nhttp://doi.org/10.1093/mnras/stu351\nhttps://arxiv.org/abs/2011.04653\nhttp://doi.org/10.3847/1538-4365/aab14f\n\n\t1 Introduction\n\t2 Methodology\n\t2.1 Physical Picture\n\t2.2 Direct Collisions\n\t2.3 Statistical Approach to Collisions\n\t2.4 Mass Growth\n\t2.5 GW Inspiral\n\t2.6 IMBH growth\n\t2.7 Gravitational Wave Mergers and Intermediate and Extreme Mass Ratio Inspiral Candidates\n\t2.8 Two Body Relaxation Processes\n\t2.9 Effect of Relaxation Processes\n\n\t3 Discussion and Predictions\n\n"}
{"Title": "The landscape of massive black-hole spectroscopy with LISA and Einstein Telescope", "Authors": "Swetha Bhagwat, Costantino Pacilio, Enrico Barausse, Paolo Pani", "Abstract": "  Measuring the quasi-normal mode~(QNM) spectrum emitted by a perturbed black-hole~(BH) --~also known as BH spectroscopy~-- provides an excellent opportunity to test the predictions of general relativity in the strong-gravity regime. We investigate the prospects and precision of BH spectroscopy in massive binary black hole ringdowns, one of the primary science objectives of the future Laser Interferometric Space Antenna~(LISA) mission. We simulate various massive binary BH population models, featuring competing prescriptions for the Delays between galaxy and BH mergers, for the impact of supernova feedback on massive BH growth, and for the initial population of high redshift BH seeds (light versus heavy seeds). For each of these scenarios, we compute the average number of expected events for precision BH spectroscopy using a Fisher-matrix analysis. We find that, for any heavy seed scenario, LISA will measure the dominant mode frequency within ${\\cal O}(0.1) \\%$ relative uncertainty and will estimate at least 3 independent QNM parameters within $1 \\%$ error. The most optimistic heavy seed scenarios produce $\\mathcal{O}(100)$ events with $1 \\%$ measurability for 3 or more QNM quantities during LISA's operational time. On the other hand, light seed scenarios produce lighter merger remnants, which ring at frequencies higher than LISA's sensitivity. Interestingly, the light seed models give rise to a fraction of mergers in the band of Einstein Telescope, allowing for the measurement of 3 QNM parameters with $\\sim 10 \\%$ relative errors in approximately a few to ten events/yr. More precise BH spectroscopy in the light seed scenarios would require instruments operating in the deciHertz band.      ", "Subject": "General Relativity and Quantum Cosmology (gr-qc)", "ID": "arXiv:2201.00023", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nET-0465A-21\n\nThe landscape of massive black-hole spectroscopy\nwith LISA and Einstein Telescope\n\nSwetha Bhagwat1, Costantino Pacilio1, Enrico Barausse2,3, Paolo Pani1.\n1Dipartimento di Fisica, \u201cSapienza\u201d Universita\u0300 di Roma & Sezione INFN Roma1, P.A. Moro 5, 00185, Roma, Italy\n\n2SISSA, Via Bonomea 265, 34136 Trieste, Italy and INFN Sezione di Trieste and\n3IFPU - Institute for Fundamental Physics of the Universe, Via Beirut 2, 34014 Trieste, Italy\n\nMeasuring the quasi-normal mode (QNM) spectrum emitted by a perturbed black-hole (BH)\n\u2013 also known as BH spectroscopy \u2013 provides an excellent opportunity to test the predictions of\ngeneral relativity in the strong-gravity regime. We investigate the prospects and precision of BH\nspectroscopy in massive binary black hole ringdowns, one of the primary science objectives of the\nfuture Laser Interferometric Space Antenna (LISA) mission. We simulate various massive binary\nBH population models, featuring competing prescriptions for the Delays between galaxy and BH\nmergers, for the impact of supernova feedback on massive BH growth, and for the initial population\nof high redshift BH seeds (light versus heavy seeds). For each of these scenarios, we compute the\naverage number of expected events for precision BH spectroscopy using a Fisher-matrix analysis.\nWe find that, for any heavy seed scenario, LISA will measure the dominant mode frequency within\nO(0.1)% relative uncertainty and will estimate at least 3 independent QNM parameters within 1%\nerror. The most optimistic heavy seed scenarios produce O(100) events with 1% measurability\nfor 3 or more QNM quantities during LISA\u2019s operational time. On the other hand, light seed\nscenarios produce lighter merger remnants, which ring at frequencies higher than LISA\u2019s sensitivity.\nInterestingly, the light seed models give rise to a fraction of mergers in the band of Einstein Telescope,\nallowing for the measurement of 3 QNM parameters with \u223c 10% relative errors in approximately\na few to ten events/yr. More precise BH spectroscopy in the light seed scenarios would require\ninstruments operating in the deciHertz band.\n\nI. INTRODUCTION\n\nWhen a binary black hole (BH) merges, it forms a\ndistorted BH which then settles down by emitting gravi-\ntational waves (GWs) at characteristic complex frequen-\ncies [1, 2]. This part of the signal is called the ring-\ndown and the characteristic frequency spectrum is called\nthe quasi-normal modes (QNMs) [3, 4]. Kerr BHs in\nthe general theory of relativity (GR) satisfy the no-hair\ntheorem, which mandates that its (infinite) QNM spec-\ntrum be uniquely and fully determined by just 2 ob-\nservable parameters \u2014 namely the mass Mf and the\ndimensionless spin \u03c7f of the remnant BH [5]. Verify-\ning whether the observed QNM spectrum satisfies the\nno-hair theorem allows us to perform clean and robust\nnull-hypothesis tests of the Kerr metric and of GR in the\nstrong-field regime [6\u201310]. BHs in most modified gravity\ntheories [11, 12] either have a different dynamics or are\nnot described by a Kerr metric [13, 14]; therefore we ex-\npect their QNM spectrum to differ from that of a Kerr\nBH in GR. Furthermore, the QNM spectra also allow us\nto probe the nature of the remnant, e.g., if it is a GR BH\nor an exotic compact object [15\u201321].\n\nInformation from the ringdown can also be combined\nwith the inspiral-merger part of the signal to perform\nconsistency tests, wherein one checks if the mass and\nspin of the remnant inferred by the pre-ringdown sig-\nnal is consistent with that measured using the ringdown.\nThis test could be done even when only a single QNM\nparameter is measured. Currently, the best measure-\nment of the dominant mode frequency agrees with the\nGR predictions within \u223c 16% measurement uncertainty\n\nfor GW150914 [22\u201327].\n\nPerforming model-independent tests of the no-hair the-\norem using BH spectroscopy alone is a more ambitious\nprogram, which requires measuring at least 3 indepen-\ndent QNM parameters [28\u201330]. The first two QNM pa-\nrameters are inverted to find the mass and spin of the\nremnant, assuming the latter is a Kerr BH. This fixes\nthe whole QNM spectrum. Then, the measurement of\nthe third (and possibly more) QNM parameter(s) can be\nused to check for consistency with GR\u2019s predictions.\n\nCurrently, with the LIGO-Virgo data, the statistical\nuncertainty in the measurement of the QNM parame-\nters limits the precision of ringdown-based tests. BH\nspectroscopy was attempted for GW150914 using over-\ntones [31] and for GW190814 and GW190412 using the\nsecondary angular QNM [32]. BH spectroscopy with\novertones has potential limitations related to resolvabil-\nity of the QNMs, the number of overtones to be included,\nand is sensitive to the choice of start time of the ring-\ndown [33\u201336]. On the other hand, the analysis of [32] has\na low signal-to-noise ratio (SNR) in the secondary angu-\nlar mode, limiting the constraining power of the test.\n\nGiven the current state of affairs, it is relevant to fore-\ncast the prospects for BH spectroscopy with the future\nGW detectors. In particular, the coalescence of massive\nBH (MBH) binaries could provide an ideal setting for BH\nspectroscopy [28, 37, 38], as the ringdown SNR scales as\n\n\u223cM3/2\nf , where Mf is the remnant mass [37].\n\nIn this work, we quantify the landscape of BH spec-\ntroscopy for astrophysically-motivated population mod-\nels of MBH binaries. We estimate the measurement er-\nrors expected for multiple-QNM parameters in the ring-\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n3v\n1 \n\n [\ngr\n\n-q\nc]\n\n  3\n1 \n\nD\nec\n\n 2\n02\n\n1\n\n\n\n2\n\ndowns produced by these populations. Our main focus\nis on MBH binaries detectable by the forthcoming Laser\nInterferometric Space Antenna (LISA) [39]. However, for\nreasons that will be explained in a moment, we shall also\ninvestigate the potential of next-generation ground-based\ndetectors [40], such as Cosmic Explorer (CE) [41, 42] and\nEinstein Telescope (ET) [43, 44], to perform ringdown-\nbased tests using (light) MBH binaries. In particular, we\nshall focus on ET since it has a better sensitivity at low\nfrequency and is better suited to detect MBH ringdowns.\n\nThe motivation for our study is twofold. First, LISA\nis expected to have an unprecedented sensitivity towards\nMBH ringdowns [28, 45]; for instance, an equal-mass bi-\nnary BH with a total mass of 106M\ufffd at 2 Gpc will have\nan optimal ringdown SNR \u03c1rd \u223c 2000 in the LISA data.\nTesting the nature of massive compact objects and the\nunderlying theory of gravity in the strong-field regime\nusing BH spectroscopy is one of the main science ob-\njectives of the LISA mission [16, 46] and of its possible\nextensions [47, 48]. However, to get a more realistic pic-\nture of the science objectives achievable by LISA, these\nstudies need to fold-in knowledge on the expected binary\nMBH population in the universe. In order to assess this\nissue, we study 8 MBH binary populations [49, 50] that\nshould bracket the expected astrophysical modelling un-\ncertainties. These models produce different distributions\nof the coalescence parameters, such as mass ratio and\nspins of the binary BH system, its redshift, as well as the\nremnant mass and spin; these determine the expected\nevent rates seen by LISA (see Sec. II for a brief sum-\nmary of the population models). A major ingredient for\nthese population models in the context of this work is the\nseed mass function \u2014 which broadly classifies our mod-\nels into heavy seeds (HS) and light seeds (LS). The seed\nmass plays a dominant role in determining the remnant\nBH\u2019s mass and, in turn, the scale of the QNM frequencies\nin the ringdown. While the LS models produce lighter\nremnants whose ringdown is dominated by unfavourably\nhigh frequencies with respect to the LISA\u2019s sensitivity\ncurve, the HS scenarios produce ringdowns that lie in\nthe sweet spot of LISA\u2019s power spectral density. There-\nfore, we foresee the best ringdown tests with LISA within\nthe HS scenario.\n\nSecondly, most studies assessing LISA\u2019s potential for\nringdown tests are based either on the detectability of sec-\nondary modes (i.e., requiring that SNR in the secondary\nmode be above a given detectability threshold, see e.g.,\n[37, 51\u201353]) or on their resolvability from the fundamen-\ntal mode (i.e., requiring that the frequencies and damp-\ning times of the two QNMs are sufficiently different to be\nmeasured unambiguously at a given SNR [28, 54\u201356]).\nWhile useful, the information carried by these analyses\nis limited because it does not quantify the measurabil-\nity of different modes (i.e., the precision at which QNM\nmeasurements can be done and hence the quality of a BH\nspectroscopy test achievable) [35]. Our work focuses on\nmeasurability of QNM parameters.\n\nFor this study, we first simulate 100 years of data con-\n\ntaining analytical ringdown signals for each of the MBH\npopulation models. We then estimate the uncertainty\nin the parameter estimation for the QNM spectra us-\ning a numerical Fisher matrix (FM) formalism for up\nto 5 QNM parameters. We also identify the combina-\ntions of the QNM parameters that produce the smallest\nmeasurement errors for each of the MBH binary popula-\ntion. The relative measurement uncertainty of the QNM\nparameters, which we refer to as \u2018measurability\u2019 (follow-\ning the definition in [35, 36]) decides how well we can\nconstrain a putative modified theory or alternative rem-\nnant model with the observations, and how constraining\nthe ringdown-based null tests of GR will be using these\nevents. We present the details of our analysis framework\nin Sec. III.\n\nThis paper is organized as follows \u2013 In Sec. II, we\npresent a brief discussion on the binary MBH popula-\ntion models used in this study and their implications for\nBH spectroscopy. Next, in Sec. III, we outline our frame-\nwork and define the notion of detectability, resolvability,\nand measurability as used in this work. Our results for\nthe prospects of BH spectroscopy with LISA and ET are\npresented in Sec. IV and Sec. V, respectively. Finally,\nwe conclude with a discussion and future directions in\nSec. VI.\n\nII. EXPLORING THE MBH POPULATION IN\nTHE CONTEXT OF RINGDOWN\n\nA. MBH population models\n\nWe describe the population of MBH binaries targeted\nby LISA using the semi-analytic model of Ref. [57], with\nsuccessive improvements described in Refs. [49, 58\u201362].\nThe model tracks the evolution of MBHs in their galac-\ntic hosts as a function of cosmic time. Galaxies are\nmodelled as dark matter halos accreting chemically pris-\ntine gas from the intergalactic medium. This gas can\neither accrete to the centre of the halo along cold fila-\nments (at high redshift or in low-mass systems) [63\u201365],\nor it can get shock-heated to the halo\u2019s virial tempera-\nture, then cooling down to the center of the halo. The\ncold gas accumulating in the center can then give rise to\ndisk structures (because of conservation of angular mo-\nmentum) [66], where star formation can take place and\ncontribute to the gas chemical evolution. Galactic disks\n(gaseous or stellar) can also become unstable to bar insta-\nbilities, or be disrupted by galaxy mergers, thus forming\ngaseous and stellar spheroids (which can also undergo\nstar formation, typically in bursts). On smaller scales,\nthe model also includes additional components, such as\nnuclear star clusters [59, 60], a nuclear gas \u201creservoir\u201d\nfrom which MBHs can accrete [67], as well as MBHs\n(for which mass and spin are consistently evolved un-\nder accretion and mergers). Feedback on the growth of\nstructures is accounted for in the form of both super-\nnova (SN) explosions (which tend to quench star forma-\n\n\n\n3\n\ntion in low-mass galaxies) [68\u201370] and jets/disk winds\nfrom active galactic nuclei (AGNs), whose effect is dom-\ninant in large galaxies [71\u201373]. Besides suppressing star\nformation, both SN and AGN feedback also eject gas\nfrom the nuclear region from which MBHs accrete. In\nparticular, SN explosions may quench MBH accretion in\nsystems with escape velocities . 270 km/s [74], thus hin-\ndering the growth of MBHs in shallow potential wells\nand the hardening of MBH binaries (by suppressing gas-\ndriven migration).\n\nThe halo merger history is followed by using an ex-\ntended Press-Schechter formalism [75], modified to re-\nproduce results from N-body simulations [76]. Mergers of\ngalaxies track those of halos, but with Delays accounting\nfor: (i) the survival of the smaller halo within the larger\none as a subhalo, which is slowly dragged to the center of\nthe system by dynamical friction while undergoing tidal\ndisruption and evaporation [77, 78]; and for (ii) the dy-\nnamical friction (including again tidal effects leading to\ndisruption and evaporation) between the baryonic com-\nponents [79]. On smaller scales, the mergers of MBHs\n(when the latter are present) track those of galaxies, but\nagain with potentially significant Delays. These account\nfor the evolution of MBH pairs at separations ranging\nfrom kpc down to the binary\u2019s influence radius (includ-\ning the effect of dynamical friction [80] and incorporating\nthe results of hydrodynamic simulations [81]). Further-\nmore, at the smaller separations where a bound binary\nforms, the Delays account for gas-driven migration (if a\ngaseous disk is present) [82\u201388], three-body interactions\nwith stars (stellar hardening) [89, 90] and Kozai-Lidov\nand/or chaotic interactions with another MBH/MBH bi-\nnary (when the latter are present as a result of an earlier\ngalaxy merger) [61, 62, 91\u201393]. When a MBH binary fi-\nnally reaches sufficiently small separations (depending on\nthe mass, but typically \u223c 10\u22122\u201310\u22123 pc), it is driven to\ncoalescence by GW emission alone in less than a Hubble\ntime. When the merger happens, the MBH mass and spin\nare evolved using semi-analytic prescription reproducing\nthe results of numerical-relativity simulations [94, 95].\nGW-induced kicks are also accounted for [96], and can\nresult in the ejection of the merger remnant from the\nhost galaxy.\n\nA crucial ingredient of the model is also given by the\ninitial conditions for the MBH population at high red-\nshift. In this work, we follow, e.g., Refs. [45, 49, 50, 62]\nand adopt two possible scenarios. In the LS scenario,\nwe assume that the MBH population grows from seeds\nof a few hundred M\ufffd, produced as remnants of Pop III\nstars [97]. In more detail, we populate large halos col-\nlapsing from the 3.5\u03c3 peaks of the primordial density field\nat z & 15 with seed BHs, whose mass we assume to be\nabout 2/3 of the initial Pop III stellar mass (to account\nfor SN winds). The star\u2019s initial mass is drawn from a\nlog-normal distribution peaking at 300M\ufffd and with root-\nmean-square of 0.2 dex (with an exclusion region between\n140 and 260M\ufffd to account for pair instability SNe).\n\nWe also consider a HS scenario where MBHs form al-\n\nready with mass \u223c 105M\ufffd. For concreteness, we use\nthe model of Ref. [98], where seeds form from the bar-\ninstability driven collapse of protogalactic disks at high\nredshift (z & 15) and in halos with spin parameter and\nvirial temperature below critical threshold values. In\nmore detail, these thresholds are provided by Eq. (4)\n\u2013 with Qc = 3 \u2013 and Eq. (5) of Ref. [98], while the seed\nmass is set by Eq. (3) of the same work. In reality, it is\nof course possible (if not likely) that both HSs and LSs\nform in nature, effectively leading to a \u201cmixture\u201d of the\ntwo scenarios, which LISA will shed light on [99].\n\nIn this paper, we consider several possible versions of\nboth seed models. Besides the default SN-Delays models\nin which all the aforementioned physical ingredients are\nconsidered, in the noSN models we switch off the effect\nof SN feedback on the nuclear gas reservoir, while in the\nshortDelays models we neglect the Delays occurring as\nMBHs move from kpc to pc separations. In more detail,\nin the shortDelays models we switch off the dynamical\nfriction on the satellite galaxy and/or on its MBH, but\nwe maintain the Delays due to dynamical friction be-\ntween the halos, and the Delays due to stellar hardening,\ngas-driven migration, and triple/quadruple interactions\nbetween MBHs.1\n\nB. MBH population in the context of BH\nspectroscopy\n\nIn this section, we consider the implications of the dif-\nferent MBH populations on the ringdown analysis. The\nQNM spectrum depends dominantly on Mf and subdom-\ninantly on \u03c7f . The top panels of Fig. 1 show the distri-\nbutions of Mf and \u03c7f for the binary MBH populations\nused in our study. Notice the clear segregation of the Mf\n\ndistributions for the LS (warm colored histograms) from\nthe HS models (cool colored histograms). The Mf distri-\nbutions for all the HS models peak around 106M\ufffd with\na substantial support in Mf \u2208 [105 \u2212 107]M\ufffd, whereas\nfor LS models Mf \u2208 [103\u2212106]M\ufffd. While the seed mass\ndominantly decides the mass of the remnant, among the\nLS models we see that the models without SN feedback\nallow for a slightly higher mass of the remnant BHs, mak-\ning them more promising LS models for BH spectroscopy\nwith LISA. In the LS models accounting for SN feedback,\nthe latter prevents efficient accretion and thus the growth\nof MBHs, giving rise to lighter remnants, with a Mf dis-\ntribution peaking around \u223c 103M\ufffd. Overall, depending\non the underlying population model, the support for the\nremnant mass in a MBH binary merger can vary between\n102 \u2212 108M\ufffd.\n\nAll models except LS noSN-Delays have remnant spin\ndistributions that peak at \u03c7f \u223c 0.68, but have a broad\n\n1 The shortDelays models correspond to those with the same name\nin Refs. [50, 99], which are also the same as the noDelays models\nof [49].\n\n\n\n4\n\n1 0 1 2 3 4\nLog( 22) (in sec)\n\n0.00\n\n0.25\n\n0.50\n\n0.75\n\n1.00\n\n1.25\n\n1.50\n\n1.75\n\nPD\nF\n\n22 Distribution\n\nFIG. 1. Top panels: distributions of remnant detector-frame mass (left panel) and spin (right panel) for different MBH\npopulation models. Bottom panels: the corresponding distribution of the dominant QNM frequency (left panel) and damping\ntime (right panel).\n\nsupport across \u03c7f \u2208 [0.3, 0.9]; note that \u03c7f \u223c 0.68 cor-\nresponds to the spin of remnant BH for a nonspinning\nequal mass binary BHs, and that the \u03c7f distributions\nare consistent with a clustering of events close to q \u223c 1\n(see Fig. 3 below). LS noSN-Delays has \u03c7f distribution\nrailing against extremal spin, as the absence of SN feed-\nback and the long time Delays allow accretion to spin the\nprogenitor BHs up. We observe in our simulated popula-\ntions that the systems that have nearly extremal spinning\nremnant also have the heavier progenitor BH with spin\n\u223c 1. Nonetheless, we have checked that the results of our\nanalysis are robust when we cap the BH spin to 0.9.\n\nNext, the QNM frequencies and damping-times scale\ninversely and linearly with Mf , respectively; we see how\nthe features in the final mass distribution translate to\nthe QNM frequencies and damping times in the bottom\npanels of Fig. 1. In particular, the distribution of f22\n\ndetermines whether the QNMs fall within the sensitiv-\nity range of a given instrument. For the HS models, the\ndistribution of f22 peaks at \u223c 10 mHz and has a sup-\nport approximately in the range [1 mHz, 1 Hz]. Note that\nthe LISA power spectral density [100, 101] has a sweet\nspot at \u223c 10 mHz and is therefore perfectly suited for\n\na ringdown analysis in these scenarios.2 LS models on\nthe other hand have f22 peaking at \u223c 5 Hz. with sup-\nport in f22 \u2208 [10\u22121, 50] Hz, making them suboptimal\nfor BH spectroscopy with LISA. For example, a rem-\nnant BH with Mf = 103M\ufffd and \u03c7f = 0.68 will pro-\nduce a ringdown at \u223c 17 Hz, outside the LISA sensitivity\nband. Note also that the HS models have \u03c422 \u2208 [1, 103] s\nwith a peak around 100 s, while the LS models have\n\u03c422 \u2208 [0.05, 5] s. This means that typically the ringdown\nwill last significantly longer than the ringdowns currently\ndetected in the LIGO-Virgo band, and it is more likely\nto be contaminated by other simultaneous signals from\nother sources.\n\nIn Fig. 2, we show the number of events/yr with\n\u03c1rd > \u03c10\n\nrd for LISA (left panel) and ET (right panel).\n(Details of the SNR calculation and noise curves are\n\n2 Interestingly, overall the distributions have small support at\nf22 < 1 mHz, as expected from the exponential suppression of\nthe high end of the MBH mass function. This suggests that the\ndetails of the LISA power spectral density at low frequency are\nnot relevant for this analysis.\n\n\n\n5\n\nFIG. 2. Cumulative number of events/yr with \u03c1rd greater than or equal to a threshold SNR indicated on the x-axis of the plot.\nWe plot the optimal ringdown SNR. The left and right panels refer to the case of a LISA and ET detection, respectively. The\nwarm (cold) color scheme indicates the HS (LS) models. We see that LISA and ET are complementary: LISA will be sensitive\nto ringdown signals mostly for the HS scenarios, whereas it could detect only the high-mass tail of the merger remnants in the\nLS scenarios. On the other hand, ET will be insensitive to the HS populations but will detect the low-mass tail of the remnants\nin the LS scenario.\n\nSeed Population Models Total number of BBH events/yr\nSN-shortDelays \u223c 317/yr\n\nHS SN-Delays \u223c 6/yr\nnoSN-shortDelays \u223c 322/yr\n\nnoSN-Delays \u223c 2.5/yr\n\nSN-shortDelays \u223c 45/yr\nLS SN-Delays \u223c 12/yr\n\nnoSN-shortDelays \u223c 290/yr\nnoSN-Delays \u223c 45/yr\n\nTABLE I. Total intrinsic event rates for massive binary merg-\ners in the catalogs, obtained by averaging 100 realizations of\nthe population predicted by each of the 8 SMBH population\nmodels considered in this work, and ignoring SNR thresholds.\n\ngiven in the next section.) The number of events above\na certain SNR in a detector will depend prominently on\nthe mass-spin distribution of the remnant BH, distance\nof the system, and the intrinsic event rate predicted in\na population model. HS models are optimal for spec-\ntroscopy using LISA, with the shortDelays models pre-\ndicting \u223c 2 events/yr and Delays models predicting \u223c 1\nevent/yr with \u03c1rd as large as 1000. Furthermore, HS De-\nlays models have a low event rate and LISA will see \u223c 5\nevents/yr with \u03c1rd \u2208 [1, 1000], while for the HS short-\nDelays models LISA will see \u223c 100\u2212 200 events/yr with\n\u03c1rd \u2208 [100, 1000]. Refer to Table I for the intrinsic merger\nrates predicted by the various population models.\n\nHowever, the HS Delays models have events with \u03c1rd\n\ndistribution sharply peaked around \u03c1rd \u223c 103 with a\nlong tail towards lower SNR, while the HS shortDelays\nmodels have a \u03c1rd distribution with a broad support in\n\u03c1rd \u2208 [1, 500]. We also see from our simulated popula-\ntions that the HS Delays models merge at closer lumi-\nnosity distance distribution (\u223c 1\u2212 50 Gpc) compared to\nthe shortDelays (\u223c 25 \u2212 125) Gpc ones. Therefore, al-\nthough the HS Delays models predict lower event rates,\n\nthe events they produce are likely to have a very loud\nringdown in LISA and serve as golden events for spec-\ntroscopy.\n\nAs for the LS scenario, LISA might see just a few events\nfor LS noSN models \u2013 a few events with \u03c1rd \u2208 [10, 100]\nfor noSN-shortDelays, and \u223c 1 or 2 events/yr with\n\u03c1rd \u223c 10 for noSN-Delays. From the distribution in\nFig. 1, we see that both the noSN models have Mf\n\npeaking close to 104M\ufffd but the noSN-Delays model\nhas a tail that extends further to higher mass com-\npared to noSN-shortDelays. Furthermore, the noSN-\nDelays model has a closer redshift distribution compared\nto noSN-shortDelays (the former has a considerable sup-\nport for z \u2208 [1, 10] and the latter for z \u2208 [1, 20]). Naively,\nit seems puzzling that in Fig. 2 the noSN-Delays model\nshows lower rates than the noSN-shortDelays model.\nThis can be attributed to the intrinsic event rates in each\nof the models (see Table I) \u2014 while the noSN-Delays\nmodel predicts 1.5 mergers/yr, the noSN-shortDelays\nmodel predicts \u223c 290 events/yr. Subleading to this is\nthe fact that \u03c7f of the remnant BH formed in noSN-\nDelays population is higher, shifting f22 to a slightly\nhigher frequency. Furthermore, LISA will be insensitive\nto ringdowns produced by the LS models that incorpo-\nrate SN feedback, as those scenarios predict light rem-\nnants. Note also that the worst-performing HS model\n(i.e., noSN-Delays) yields rates comparable to the best\ncase LS model (i.e., noSN-shortDelays).\n\nAs shown in Fig. 2, LISA and ET will be complemen-\ntary with respect to the HS versus LS scenarios. Indeed,\nthe right panel of Fig. 2 shows that ET is insensitive to\nthe ringdown produced by all the HS models, but will\nhave interesting rates in the LS scenarios. In particular,\nthe LS noSN-shortDelays model has significantly smaller\nrates (\u2264 10 events/yr with \u03c1rd \u2265 10) compared to the\nother LS models. However, the latter have comparable\n\n\n\n6\n\n\u03c1rd \u2013 i.e., \u223c 1 \u2212 3 events/yr with \u03c1rd \u2265 100 and 10-20\nevents/yr with \u03c1rd \u2265 10.\n\nFinally, in order to perform BH spectroscopy, the sub-\ndominant modes have to be sufficiently excited. The am-\nplitude of the QNM excitation depends on the perturba-\ntion conditions setup before the ringdown, which in turn\ndepend on the asymmetry of the binary BH system. Gen-\nerally, to excite the odd angular modes, an asymmetric\nbinary (i.e., with either a mass ratio q sufficiently differ-\nent from unit3 or sufficiently large component spins4) is\nneeded. In Fig. 3, we plot the asymmetry of the MBH\nbinary on the q \u2212 \u03c7eff plane and find that all models\npredict fairly asymmetric binary systems, with a consid-\nerable spread in q and/or in \u03c7eff . Furthermore, we note\nthat while all the HS models produce binaries with a\nlarge range of \u03c7eff , the shortDelays HS models also pro-\nduce more binaries BH events with large q, making them\nmore promising for BH spectroscopy. (Note that even\nthough the probability density functions of q for the HS\nmodels are similar \u2013 c.f. Fig. 11 of Ref. [50] \u2013 the short-\nDelays models predict a higher event rate, thus sampling\nthe large-q tails of the distribution more efficiently.)\n\nIII. FRAMEWORK\n\nA. Computation of measurement uncertainties\n\nWe model the ringdown waveform as a linear superpo-\nsition of damped sinusoids with individual mode ampli-\ntudes Almn, phases \u03c6lmn, and the QNM frequencies and\ndamping times {flmn, \u03c4lmn} as independent parameters:\n\nh(t) = h+(t) + ih\u00d7(t) ,\n\nh+(t) =\n\u2211\nlmn\n\nAlmn cos (2\u03c0flmnt+ \u03c6lmn) e\u2212t/\u03c4lmn Y lm+ (\u03b9) ,\n\nh\u00d7(t) =\n\u2211\nlmn\n\nAlmn sin (2\u03c0flmnt+ \u03c6lmn) e\u2212t/\u03c4lmn Y lm\u00d7 (\u03b9) ,\n\n(1)\n\nwhere \u03b9 is the inclination angle of the remnant spin\nand the {+,\u00d7} harmonics are defined in terms of spin-\nweighted spherical harmonics as [54, 105]\n\nY+,\u00d7(\u03b9) = Y lm\u22122 (\u03b9, 0)\u00b1 (\u22121)l Y l\u2212m\u22122 (\u03b9, 0) . (2)\n\nHere, the integers {l,m, n} correspond to the multi-\npolar, azimuthal, and overtone indices, respectively. For\n\n3 Note, however, that in the large-q limit, the total energy output\nof the ringdown decreases for a fixed total binary mass [102]. For\ninstance, the EMOP energy in the subdominant modes peaks\nat q = O(a few) depending on the mode and on individual\nspins [103].\n\n4 As a direct measure of spin-induced asymmetry of the binary,\nwe shall use the effective spin \u03c7eff \u2208 [\u22121, 1], which is the\nmass-weighted average of the individual dimensionless compo-\nnent spins \u03c71 and \u03c72, projected along the unit vector parallel to\nthe binary\u2019s orbital angular momentum [104].\n\neach (l,m), we focus only on the fundamental (n = 0)\ntone, neglecting the overtones. This is motivated by two\nconsiderations: a) resolving overtones from the funda-\nmental mode and measuring them is challenging [33, 36];\nb) For MBH binary populations, the initial binary BH\nsystems are typically asymmetric (either q > 1 or\n\u03c7eff 6= 0, see Fig. 3) and the subdominant angular\nmodes (unlike with equal mass systems) are sufficiently\nexcited [33, 34, 36]. Thus, for MBH binaries, we expect\nBH spectroscopy with multiple angular modes to be more\npractical. Henceforth, we drop the index n for simplicity.\n\nWe estimate the statistical uncertainties in the mea-\nsurements of the QNM parameters, i.e., frequency and\ndamping time, for each event in a population of MBHs.\nLet \u0398 =\n\n\u22c3\nlm\n\n{flm, \u03c4lm,Alm, \u03c6lm} be the set of indepen-\n\ndent parameters of the ringdown model in Eq. (1). In\nthis agnostic form, the ringdown waveform depends on\n4 real parameters (frequency, damping time, amplitude\nand phase) for each angular mode included in its mod-\nelling. In our analysis, we include up to 4 of the loudest\nmodes, i.e., (l,m) = (2, 2), (3, 3), (2, 1), (4, 4).\n\nTo compute the uncertainties, we use an FM formal-\nism [106], which provides an accurate estimate of the sta-\ntistical errors in the high-SNR limit with Gaussian noise\nand in the absence of errors from waveform systemat-\nics [107].\n\nFor a given waveform h(t) defined in terms of \u0398 = {\u03b8i}\nparameters, the FM is defined as\n\n\u0393ij =\n\u2329 \u2202h\n\u2202\u03b8i\n\n\u2223\u2223\u2223 \u2202h\n\u2202\u03b8j\n\n\u232a\n\u03b8=\u03b8\u0302\n\n, (3)\n\nwhere \u03b8\u0302 are the true (injected) values, and the scalar\nproduct is defined as\n\n\u3008h1|h2\u3009 = 4<\n\u222b fmax\n\nfmin\n\nh\u03031(f)h\u0303\u22172(f)\n\nSn(f)\ndf , (4)\n\nwhere the detector spectral density is denoted by Sn and\nh\u0303 is the Fourier transform of the signal. The statistical\n\nerror on the i-th parameter is then given by \u03c3\u03b8i = \u03a3\n1/2\nii ,\n\nwhere \u03a3 = \u0393\u22121.\nWe evaluate Eq. (3) numerically using directly Eq. (1)\n\nand a Python implementation based on the sympy pack-\nage [108]. We also assume that different angular modes\nare independent and thereby ignore the mixing. 5 We\nadopt the LISA SciRD6 power-spectral density [100] and\nthe ET-D configuration [43], respectively. In our imple-\nmentation of the FM, we perform an average over the sky-\nposition and polarization angle. For LISA, this average\n\n5 Note that this assumption would break for different overtones of\nthe same angular mode [28, 33, 36].\n\n6 We neglect the white-dwarf confusion noise, which anyway affects\nsignals with frequency smaller than \u2248 1 mHz. As shown in Fig. 1,\nthe ringdown in the catalogs is always at higher frequencies due\nto the lack of very massive remnants. Therefore, including the\nwhite-dwarf confusion noise would not change our results.\n\n\n\n7\n\n100 101\n\nq\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n0.25\n\n0.50\n\n0.75\n\n1.00\nef\n\nf\n\nSN-shortDelays\nHS\nLS\n\n100 101\n\nq\n\n0.6\n\n0.4\n\n0.2\n\n0.0\n\n0.2\n\n0.4\n\n0.6\n\nef\nf\n\nSN-Delays\nHS\nLS\n\n100 101\n\nq\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n0.25\n\n0.50\n\n0.75\n\n1.00\n\nef\nf\n\nnoSN-shortDelays\nHS\nLS\n\n100 101\n\nq\n\n1.00\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\n0.25\n\n0.50\n\n0.75\n\n1.00\n\nef\nf\n\nSN-Delays\nHS\nLS\n\nFIG. 3. Realizations of the binary mass ratio q and effective spin \u03c7eff for the HS and LS models. Here we plot a scatter of\nevents (intrinsic) corresponding to a 4-year data realization. The color scheme in each panel follows that of Figs. 1 and 2.\n\nis incorporated in the power spectral density [100, 101],\nwhile for ET we explicitly set \u3008F 2\n\n+\u3009 = \u3008F 2\n\u00d7\u3009 = 1/5,\n\nwhere F+,\u00d7 are the sky-position dependent detector re-\nsponse function. For further details refer to the formalism\nin [28].\n\nNext, the ringdown SNR is defined as \u03c1rd = \u3008h|h\u30091/2.\nWe use the expression of \u03c1rd given by Eq. (17) of [51] and\nassume that the remnant is optimally inclined at \u03b9 = 0,\nwhile still averaging over sky position and polarization\nangle.\n\nWe interpolate the tabulated data provided in [109] to\nestimate the Kerr QNMs, {flm, \u03c4lm}. As shown in Fig. 3,\nall the models predict a significant spread in the distri-\nbution of \u03c7eff \u2208 {\u22120.75, 0.75}. Therefore, accounting\nfor the effect of both q and the binary component spins\nin the excitation amplitude Alm is crucial for assessing\nthe prospects for BH spectroscopy. For example, even\nan equal-mass BH binary with nonzero \u03c7eff could excite\nmeasurable subdominant QNMs.\n\nWe compute the amplitude ratios ARlm = Alm/A22 for\neach mode using the ringdown energy Elm (also known\nas EMOP energy) fits presented in [103].7 To compute\n\n7 Note that, while most QNM amplitude fits in literature (e.g., [36,\n110]) generally assume that all the QNMs start simultaneously,\n\nthe amplitude we note that\n\nElm(q, \u03c71, \u03c72) \u221d\n\u222b\n\u2202hlm\n\u2202t\n\n\u2202h\u2217lm\n\u2202t\n\ndt , (5)\n\nand that the ringdown energy is proportional to the\nsquare of amplitudes, namely\n\nAlm \u221d\n\n\u221a\nElm\n\n2\u03c4lm\n1 + 4\u03c02f2\n\nlm\u03c4\n2\nlm\n\n. (6)\n\nWe use the analytical fitting formula provided in [29]\nfor the dominant mode amplitude,\n\nA22 = 0.864\nq\n\n(1 + q)2\n. (7)\n\nin [103] the start time for each mode is separately obtained by\nmaximizing the EMOP energy. While this is a desirable fea-\nture, the amplitude calculated from the EMOP energy does not\ncontain information about the relative phase difference between\nthe modes. However, as long as we are looking at different angu-\nlar modes and not overtones, the modes are fairly independent of\neach other and the errors \u03c3\u03b8i on the QNM parameters are almost\nindependent of the relative phase difference between modes. We\nrefer to [33, 36] for more details on this effect.\n\n\n\n8\n\nThe expression for A22 neglects the dependence on \u03c7eff ,\nwhose inclusion affects the ringdown SNR by only a small\noverall factor and is not crucial for a population-based\nstatistical analysis (for instance, see the variation of A22\n\nin Fig. 1 of [111]). Finally, without loss of generality, we\nset \u03c622 = 0.\n\nAlthough in Fig. 3 we show the q-axis up to q = 15 for\nthe sake of visualization, there is a small fraction of events\nwith very large mass ratio (some as large as q = 103, see\nFig. 11 in Ref. [50]). The EMOP energy fits in [103] that\nwe use to calculate the amplitudes are calibrated against\nnumerical relativity waveforms for reasonably low q, as\nwell as against extreme mass-ratio waveforms obtained\nby perturbation theory. Furthermore, the angular modes\nexcitations approximately reach the test particle limit\n(q \u2192 \u221e) already at q \u223c 10 (see Fig. 6 of [36]). In other\nwords, the dependence of Alm at large q is not significant,\nand we do not expect any fitting errors to influence our\nresults.\n\nB. Detectability, resolvability, and measurability\n\nThe simplest quantifier one could use to assess the im-\npact of secondary QNMs is to check for their detectability\nby setting some SNR threshold for the secondary mode.\nHowever, detectability alone is not informative about the\nability to resolve multipole modes or measure their fre-\nquencies and damping times, which is at the root of per-\nforming BH spectroscopy.\n\nWe use two criteria to quantitatively assess the\nprospects of BH spectroscopy [36]: a) resolvability, and\nb) measurability of the QNM parameters {flm, \u03c4lm}. The\nresolvability criterion ensures that the measured QNM\nparameters can be resolved from each other unambigu-\nously by requiring that the estimated posterior distribu-\ntions for the QNM parameters satisfy a minimum separa-\ntion demanded by the Rayleigh criterion [54]. The QNM\nparameters {\u03b8i, \u03b8j} \u2208 \u0398 are resolvable if the standard de-\nviations of their posterior (\u03c3\u03b8i , \u03c3\u03b8i) satisfy the following\ncondition,\n\nmax[\u03c3\u03b8i , \u03c3\u03b8j ] < |\u03b8\u0302i \u2212 \u03b8\u0302j |, (8)\n\nwhere \u03b8\u0302 is the most likely estimate (or the true value, in\nthe case of FM) of the parameter \u03b8.\n\nHowever, resolvability alone is not adequate to gauge\nthe prospects of BH spectroscopy; we need to quantify\nour ability to measure the QNM parameters. For in-\nstance, two QNM parameters that are sufficiently far\napart could be resolved even in a weak signal, but their\nmeasurement can have large uncertainties, and it can be\npoorly informative for a no-hair theorem test. Thus, fol-\nlowing [36], we define measurability \u2206\u03b8i as the relative\nstatistical uncertainty in the measurement of the param-\neters \u03b8i. An event has x% measurability if it satisfies the\nfollowing criterion:\n\nmaxi [\u2206\u03b8i] <\nx\n\n100\n, \u2200{\u03b8i} \u2208 \u0398 . (9)\n\n100 101\n\nq\n\n10 2\n\n10 1\n\n100\n\n101\nMeasurability\n\nf22/f22\n\nf21/f21\n\nf33/f33\n\nf44/f44\n\n22/ 22\n\n21/ 21\n\n33/ 33\n\n44/ 44\n\nFIG. 4. Measurability of various QNM parameters for a MBH\nat z = 10 detected with LISA. The progenitor system is a\nnonspinning binary BH with Mf = 106M\ufffd and af = af (q).\nNote that nonzero \u03c7eff can alter this plot at a subleading level.\n\nwhere \u0398 are the set of parameters we are interested in\n\nmeasuring and \u2206\u03b8i = \u03c3\u03b8i/\u03b8\u0302i . In our study, we shall\nhierarchically check for resolvability and measurability\nfor each event and for different combinations of QNM\nquantities. For a signal with x% measurability, all the\nQNM parameters under consideration are measured with\nat least x% relative precision. We stress again that it is\nthe measurability of the QNM parameters that determine\nthe precision of BH spectroscopy, and the extent to which\none can constrain modified-gravity theories or validate\nthe Kerr metric through null tests.\n\nIn Fig. 4 we investigate the variation of measurability\nof various QNM parameters with respect to q for a non-\nspinning binary [95, 112\u2013114]. 8 Figure 4 displays the\nrelative measurement error i.e., \u2206\u03b8i of QNM parameters\nas a function of q, for a fiducial mass of Mf = 106M\ufffd\nand for z = 10. Different choices of Mf and z will only\nscale \u03c3\u03b8i by an overall factor.\n\nFrom Fig. 4, we note the hierarchy of measurability\nat high q (q \u2265 5) goes as follows: \u2206f22 < \u2206f33 <\n\u2206f21 < \u2206f44 < \u2206\u03c422 \ufffd \u2206\u03c433 \u223c \u2206\u03c421 \ufffd \u2206\u03c444. At\nlow q, however, the excitation of subdominant modes is\nsuppressed and the hierarchy of measurability goes as:\n\u2206f22 \ufffd \u2206\u03c422 \ufffd \u2206f33 < \u2206f21 < \u2206f44 \ufffd \u2206\u03c433 \u223c \u2206\u03c421 <\n\u2206\u03c444 . We further highlight two interesting crossing points\naround q \u223c 1.5: for q > 1.5 \u2206f33 < \u2206\u03c422 and \u2206f44 < \u2206f21\n\n.\n\n8 For a fixed mass, given a binary mass ratio q all the parameters\nof the ringdown are fixed for a nonspinning binary BH system.\nNote that the individual BH spins have a subleading effect on\nthe measurability compared to the mass ratio.\n\n\n\n9\n\nIV. RINGDOWN TESTS WITH LISA\n\nIn this section, we present the results of our ringdown\nanalysis for LISA. We first briefly summarize our analysis\nsetup.\n\nOur injected waveforms include the four angular modes\n(l,m) \u2208 {(2, 2), (3, 3), (2, 1), (4, 4)}. For each population\nmodel, we simulate 100 realizations of one year of data.\nThe figures and numbers presented throughout the next\ntwo sections are the mean expectation obtained by aver-\naging these realizations. Moreover, a Poisson error bars\nor counting error, i.e.,\n\n\u221a\nN (where N is the number of\n\nevents satisfying a given criterion) is plotted in shaded\ncolors in all the result figures.\n\nWe summarize the prospects of performing the no-hair\ntheorem test with LISA in Sec. IV A. This is followed\nby a detailed discussion on the prospects of measuring 3\nor more QNM parameters, including a study on different\ncombination of QNM parameters in Sec. IV B. Finally,\nin Sec. IV C we consider the cases in which the events\ndo not necessarily allow for 3 independent QNM param-\neters to be extracted; this could still be used to perform\npowerful consistency tests when combined with the in-\nformation about binary masses and spins obtained from\nthe inspiral part of the signal. Since we wish to quantify\nthe landscape of BH spectroscopy with LISA in its entire\neffective operational time, we present results for 4 years\nof LISA data in Sec. IV B and IV C.\n\nThe same analysis setup and structure is used for dis-\ncussing the results for ET in Sec. V.\n\nA. Summary on prospects of no-hair theorem tests\nwith LISA\n\nFigure 5 and Table II summarize the overall prospects\nfor performing the no-hair theorem tests with MBHs us-\ning LISA. Here we marginalized over all combinations of\n3 QNM parameters and present the overall rate of events\nthat allow for the no-hair theorem test at a given level of\nmeasurability. A more detailed result for each combina-\ntion is presented in detail in Sec. IV B.\n\n1. Heavy seed models\n\nFirstly, note that the intrinsic rates of binary BH\nevents predicted for the HS shortDelays models (\u223c 300\u2212\n320 /yr) are about two order of magnitude larger than\nthat for the Delays models (1.5 \u2212 6 events/yr), see Ta-\nble I. However, the distribution of \u03c1rd for the binary BH\nevents expected for the Delays models peaks sharply at\n\u03c1rd \u223c 103, higher compared to models with shortDelays,\nfor which \u03c1rd is more broadly spread in \u03c1rd \u2208 [1, 103]).\n\nFrom Fig. 5 (left), we note that the two shortDelays\nmodels have similar rates and are the most promising\ncases for BH spectroscopy. They predict \u223c 30 events/yr\nwith \u2264 1% measurability (with at least one event a year\n\nthat would allow for \u223c 0.5% measurability). Next, we\nobserve that the Delays models predict about \u223c 1 \u2212 2\nevents/yr with \u223c 1% measurability. This is not surpris-\ning because of the intrinsically low event rates predicted\nby these models. Thus, if the underlying population of\nMBH binaries have HSs, LISA will realistically perform\nBH spectroscopy with a precision of at least 1%.\n\n2. Light seed models\n\nWhile, for the HS models, Delays versus shortDelays\nis the dominant factor for BH spectroscopy, for the LS\nmodels the effect of SN feedback is more pronounced. As\ndiscussed in [49], this is due to the combination of two\nfactors: by halting their growth, SN feedback prevents LS\nfrom forming BHs in the frequency band to which LISA\nis most sensitive; and it also makes gas driven migration\nof BH pairs (which is particularly important for low-mass\nsystems) inefficient by ejecting gas in the nuclear region\nof the galaxy, thus reducing the merger rate. We verify\nthis in Fig. 5 (right) by noting that the two SN LS mod-\nels seem unlikely to allow for spectroscopy with LISA; al-\nthough both SN-shortDelays and SN-Delays models have\nan intrinsic rate of O(10) event/yr, most of their ring-\ndowns have frequencies that are higher than the LISA\nsensitivity and are undetectable by LISA. The noSN-\nshortDelays model seems to be the most promising case\namong the LS scenarios, with \u223c 2 events/yr allowing\nfor measurability at 10% level. Finally, the noSN-Delays\nmodel predicts less than 1 event/yr with 10% measura-\nbility. Note that this level of measurability for BH spec-\ntroscopy is anyway better than what can be achieved\nwith the current data from the LIGO-Virgo detectors.\nFurthermore, it refers to sources at a different curvature\nscale, so it would be in principle relevant to constrain\ndifferent classes of modified theories of gravity [9, 15].\n\nB. BH spectroscopy with LISA by measuring 3 or\nmore QNM parameters\n\nWe explore the measurability for different combina-\ntions of the QNM parameters for the 4 HS models in\nFig. 6. Firstly, across all the MBH population models we\nhave considered, we find that f22 and f33 are the easi-\nest QNM parameters to be measured. For initial binary\nBHs with moderate to large mass ratios, the third best\nmeasured parameter is f44, while for small or equal mass\nratios \u03c422 performs better. Next, note that while in most\ncases the measurability of a QNM parameter is limited by\nthe relative uncertainty in its measurement (i.e., \u03c3\u03b8i/\u03b8i),\ncertain combinations of QNM frequencies can pose a chal-\nlenge due to resolvability. The most likely combinations\nbased on the frequency spacing are \u2013 a) f21 with f22 and\nb) f44 with f33. In the population we study, with the\nformer poses a considerable bottleneck. For instance, in\nthe HS shortDelays models, \u223c 125 events/yr have f21\n\n\n\n10\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\n#/\nyr\n\nEvent Rate for Spectroscopy - HS\n\nHS-SN-shortDelays\nHS-noSN-shortDelays\nHS-SN-Delays\nHS-noSN-Delays\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n#/\nyr\n\nEvent Rate for Spectroscopy - LS\n\nLS-SN-shortDelays\nLS-noSN-shortDelays\nLS-SN-Delays\nLS-noSN-Delays\n\nFIG. 5. Rates of events for which any 3 independent ringdown parameters can be resolved and measured by LISA with a\ngiven precision for the HS (left panel) and LS (right panel) scenarios considered in this work. A Poisson error bars or counting\n\nerror, i.e.,\n\u221a\nN (where N is the number of events satisfying a given criterion) is plotted in shaded colors. The solid curves\n\nindicate the average expectation obtained using 100 realization of 1-year data. The most favorable MBH population models\nbelong to the HS scenario with shortDelays (green and pink curves in the left panel).\n\nSeed Population Models Rate (0.1% measurable) Rate (1% measurable) Rate (10% measurable)\n\nSN-shortDelays 0/yr 33.8/yr 132.8/yr\nHS noSN-shortDelays 0.2/yr 34.5/yr 132.7/yr\n\nSN-Delays 0.04/yr 2.2/yr 3.9/yr\nnoSN-Delays 0.1/yr 1.0/yr 1.5/yr\n\nSN-shortDelays 0/yr 0/yr 0/yr\nLS noSN-shortDelays 0/yr 0.7/yr 2.1/yr\n\nSN-Delays 0.21/yr 0/yr 0/yr\nnoSN-Delays 0/yr 0.2/yr 0.7/yr\n\nTABLE II. Rates of events for which any 3 independent ringdown parameters can be resolved and measured by LISA with\n0.1, 1, 10% precision for the 8 different MBH population scenarios considered in this work.\n\nresolvable from f22 while \u223c 175 events/yr have f44 that\nis resolvable from f22; therefore, despite having typically\nlower amplitude of excitation the (4,4) mode performs\nbetter in figure 6. Also note that \u223c 145 events/yr have\nf44 resolvable from f33. We shall see that resolvability\ncriteria substantially reduces the number of signals that\nallow for measurability of QNM combination involving\nthe f21 \u2212 f22.\n\nWe divide the subsequent discussion into shortDelays\nand Delays models based on the similarity in the quali-\ntative behaviors for BH spectroscopy. First, we focus on\nthe shortDelays models, which are the best case scenario\nfor BH spectroscopy with LISA. From Fig. 6, we see that\nthe number of events that allow for certain percent mea-\nsurability in a population depends on the chosen com-\nbination of the QNM parameters. Statistically, for the\nshortDelays models, the hierarchy is as follows:\n\n#({f22, f33, \u03c422}) > #({f22, f33, f44}) >\n#({f22, f21, f33}) \u223c #({f22, f21, \u03c433}) .\n\nInterestingly, f44 performs statistically better than f21\n\neven though (2,1) mode is typically excited more than\n\n(4,4) (except for systems with q \u223c 1).\n\nFrom Fig. 6, we see that \u223c 100 events will allow\nfor \u223c 1% measurability for both {f22, f33, \u03c422} and\n{f22, f33, f44}. Note that the set of signals that allow\nfor the former combination and the latter combination\ncan be different, since in Fig. 6 we only check for the\nnumber of events. The difference in the number and set\nof signals is more pronounced for higher-precision mea-\nsurability thresholds \u2013 for instance, for a 0.2% measura-\nbility, we find \u223c 8 events for {f22, f33, \u03c422}, \u223c 3 events for\n{f22, f33, f44} and \u223c 1 event for {f22, f33, f44, \u03c422}. How-\never, at \u223c 10% measurability 300\u2212 400 events will allow\nfor each of the above QNM parameter combinations. In-\nspired by this, we further investigate the prospects of BH\nspectroscopy beyond 3 QNM parameters. Interesting, we\nfind that, in 4 years of LISA data, \u223c 10 events will allow\nsubpercent measurability and \u223c 20 events will allow 1%\nmeasurability for as much as 5 QNM parameters, namely\n{f22, f33, f21, f44, \u03c422}. Extracting more than 4 indepen-\ndent QNM parameters might help improve the precision\nof the no-hair theorem test, as the spectrum in the ring-\ndown needs to satisfy additional constraints that come\nfrom the measurement of the additional parameters.\n\n\n\n11\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\n103\nCu\n\nm\nm\n\nul\nat\n\niv\ne \n\n# \nof\n\n e\nve\n\nnt\ns\n\nHS-SN-shortDelays (4 years)\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\n103\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-noSN-shortDelays (4 years)\n\nf22 + f33 + 22\nf22 + f33 + f44\nf22 + f33 + f44 + 22\nf22 + f21 + f33\nf22 + f21 + f33 + 22\nf22 + f21 + f33 + f44\nf22 + f33 + f44 + f21 + 22\nf22 + 22 + 33\nf22 + f33 + 22 + 33\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-SN-Delays (4 years)\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-noSN-Delays (4 years)\n\nFIG. 6. Cumulative number of events in 4 year of data that allows for measurability of 3 or more QNM parameters with LISA\nin the HS scenarios. Note that the black and the green curves, and the brown and the purple curves, overlap.\n\nNext, unlike for the case of shortDelays models, in the\nDelays models we see that the QNM combinations do not\nhave a clear hierarchy in the number of signals allowing\nfor given percent measurability. Recall that these mod-\nels predict a small event rate and that the error bars on\nthe number of events satisfying a certain criterion goes as\u221a\nN . Therefore, a small event rate would induce a large\n\nrelative error in the estimation of a number of spectro-\nscopically valuable events, and it is not meaningful to\nread the hierarchy from Fig. 6. However, broadly, the\ncombination {f22, f33, \u03c422} seems to perform better than\nthe other combinations.\n\nFor the SN-Delays model, \u223c 2 events will allow for\n1% measurability for 5 QNM parameters. Moreover,\n\u223c 5 events will allow for either of the combinations\n{f22, f33, f44} or {f22, f21, f33}, and \u223c 10 events for\n{f22, f33, \u03c422}. Similarly, for the noSN-Delays models we\nwill be able to perform 5-parameter QNM spectroscopy\nwith 1% measurability for \u223c 1 \u2212 2 events, whereas 3-4\nevents will allow for 1% measurability of either of the fol-\nlowing combinations of QNM parameters: {f22, f33, \u03c422}\nor {f22, f33, f44} or {f22, f21, f33}.\n\nC. BH spectroscopy with LISA by measuring less\nthan 3 parameters\n\nFrom the previous section, we see that for the HS mod-\nels, a fraction of total events allow for precision measure-\nment of mores than 3 QNM parameters and would al-\nlow for an unprecedented no-hair theorem test using the\nringdown alone. In Fig. 7, we focus on the events in the\npopulation that do not necessarily allow for the precision\nmeasurement of 3 QNM parameters \u2013 either because the\nvalues of q and of the spins do not allow for sufficient ex-\ncitation of the subdominant mode or because of low \u03c1rd.\nThese events can still be used for stringent tests of GR,\nincluding the no-hair theorem, when combined with the\ninformation obtained from the inspiral. In the context of\ninspiral-merger-ringdown tests, a ringdown detection at\nthe optimal frequency would typically correspond to an\ninspiral-merger with even higher SNR. The typical situa-\ntion is that the remnant mass and spin inferred from the\ninspiral-merger part of the signal are more accurate than\nthose measured through the ringdown. In such a case,\nthe accuracy of the test is limited by the measurability\nof the ringdown modes.\n\nFrom Fig. 7, we note that more than 100 events in the\nshortDelays models would allow for 0.1% measurability of\nf22 along, and about 10 events would allow for 0.1% mea-\n\n\n\n12\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\n103\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-SN-shortDelays (4 years)\n\n10 1 100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\n102\n\n103\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-noSN-shortDelays (4 years)\n\nf22\nf22 + f33\nf22 + 22\n\n22\nf22 + f44\nf22 + f21\n\n10 1 100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-SN-Delays (4 years)\n\n10 1 100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nHS-noSN-Delays (4 years)\n\nFIG. 7. Same as in Fig. 6 but for the measurability with LISA of 1 or 2 QNM parameters in various combinations.\n\nsurability of the combination of {f22, f33} . Even though\nthese events do not allow for a no-hair theorem test us-\ning the ringdown alone, they can be used to perform a\nhigh-precision consistency check of GR. For the Delays\nmodel, 10 events will allow for the estimation of f22 and\n\u223c 1 event for the combined estimation of {f22, f33} with\n0.1% measurability.\n\nStatistically, we see that the measurability of the dif-\nferent QNM parameters for the population corresponding\nto shortDelays models are as follows \u2013 \u2206f22 > \u2206f33 >\n\u2206\u03c422 > \u2206f44 > \u2206f21. On the other hand, for the De-\nlays populations, we see that measurability of the QNM\nparameters goes as follows \u2013 \u2206f22 > \u2206f33 \u223c \u2206\u03c422 >\n\u2206f44 \u223c \u2206f21.\n\nThis difference in the trend can be understood by look-\ning at Fig. 3 along with Fig. 4. Unlike the shortDelays\nmodels, the Delays models have binary BHs that clus-\nter more around q \u2248 1. Therefore, a substantial fraction\nof signals produced by the Delays models will have rela-\ntively low subdominant mode excitation and will follow\nthe low q measurability trend.\n\nV. RINGDOWN TEST WITH ET\n\nThe LS models seem unsuitable for spectroscopy with\nLISA, as they produce remnant BHs with lower masses,\n\nringing at frequencies higher than the LISA bandwidth.\nGiven the low event rates for BH spectroscopy with LISA\nin the LS scenario, in this section we explore if ringdowns\nexpected in some LS models can be accurately measured\nby the ET detector [44] that will operate at higher fre-\nquencies [43]. However, throughout this discussion, the\nreader should bear in mind that ET is not optimized to\ndetect MBH ringdowns, as it can be seen from the cumu-\nlative SNR plot in Fig. 2. The ringdown frequency distri-\nbution in the LS scenario peaks in between the LISA and\nthe ground-based GW detector (ET/CE/LIGO/Virgo)\nbandwidths, but the tail of the distribution extends above\n\u2248 10 Hz (see Fig. 1). Although we focus on MBH ring-\ndown here, it should be stressed that the performance\nof third-generation detectors such as ET will far exceed\nthe results presented in this work when spectroscopy is\nperformed on stellar origin BH binaries.\n\nA. Summary on prospects of no-hair theorem tests\nwith ET\n\nHS models ring at frequencies that are much below the\nlower frequency sensitivity of ET. From Fig. 8, we note\nthat the HS models are unsuitable for performing spec-\ntroscopy with ET, with less than 1 event in 10 years that\nmight allow for no-hair theorem tests with 10% measura-\nbility. On the other hand, with LS models, we expect to\n\n\n\n13\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n#/\nyr\n\nEvent Rate for Spectroscopy - HS\nHS-SN-shortDelays\nHS-noSN-shortDelays\nHS-SN-Delays\nHS-noSN-Delays\n\n10 1 100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\n#/\nyr\n\nEvent Rate for Spectroscopy - LS\nLS-SN-shortDelays\nLS-noSN-shortDelays\nLS-SN-Delays\nLS-noSN-Delays\n\nFIG. 8. Same as Fig. 5 but for ET. Rates of events for which any 3 independent ringdown parameters can be resolved and\nmeasured by ET with a given precision for the HS (left panel) and LS (right panel) scenarios considered in this work. The\nshaded areas indicate the Poisson error in the estimation of the number of events for each model, while the solid curve indicates\nthe average number of events. The most favorable MBH population models belong to the LS scenario with shortDelays (green\nand pink curves in the right panel).\n\nSeed Population Models Rate (0.1% measurable) Rate (1% measurable) Rate (10% measurable)\n\nSN-shortDelays 0/yr 0.2/yr 18.2/yr\nLS noSN-shortDelays 0/yr 0/yr 5.2/yr\n\nSN-Delays 0/yr 0/yr 8.3/yr\nnoSN-Delays 0/yr 0.3/yr 5.6/yr\n\nTABLE III. Same of Table II but for ET and focusing on the LS scenario only. Rates of events for which any 3 independent\nringdown parameters can be resolved and measured by ET with 0.1, 1, 10% precision for the 8 different MBH population\nscenarios considered in this work.\n\nperform no-hair theorem tests with at least 2% measur-\nability in 1 event/yr, for all but the noSN-shortDelays\nmodel. Moreover, LS models with SN-shortDelays will\nhave 20 events/yr with \u223c 10% measurability while the\nother LS models will have few to ten events at the same\nmeasurability level. Table III quantitatively summarizes\nthe prospects of no-hair theorem tests with ET.\n\nB. BH spectroscopy with ET by measuring 3 or\nmore QNM parameters\n\nWe explore the measurability for different combina-\ntions of the QNM parameters for the 4 LS models in\nFig. 9 and discuss the results in this section. The re-\nsults are presented for 4 years of ET data for the sake\nof comparison with the LISA results in the previous sec-\ntion, although the realistic lifespan of ET is expected to\nbe longer.\n\nFirst, we focus on the SN models. In this case, by\ncomparing the pink, red and black curve in Fig. 9, we\nsee that the hierarchy of number of events allowing for\nmeasurability at a given level is as follows\n\n#({f22, f33, \u03c422}) > #({f22, f33, f44}) >\n#({f22, f21, f33})\n\nNote that measuring f21 is the bottleneck in the latter\ncombination. Also, by looking at the blue curve indi-\ncating the number of events that will allow for measur-\nability of 4 QNM parameters {f22, f33, \u03c422, f44}, we can\ninfer that not all systems that allow for measuring the\nQNM parameter combination {f22, f33, \u03c422} will allow for\n{f22, f33, f44} combination simultaneously.\n\nWe also note that the SN-shortDelays model is best\nsuited for ringdown analysis with ET. With both SN\nmodels, we expect \u223c 10 events or more to allow for 5%\nmeasurability of {f22, f33, \u03c422} as well as of {f22, f33, f44}.\nThe intrinsic event rate of the SN-Delays model is much\nsmaller than that of the SN-shortDelays model and this\nis reflected starkly into the number of expected events\nallowing for a higher level of measurability. For ex-\nample, the SN-shortDelays model predicts \u223c 80 events\nwith 20% measurability for {f22, f33, \u03c422}, while the\nSN-Delays model predicts \u223c 40 events. Furthermore,\nwhile 30 events of the SN-shortDelays population al-\nlow for the estimation of QNM parameter combination\n{f22, f33, \u03c422, f44} at 10% measurability, less than 20\nevents will allow for the same for SN-Delays.\n\nLet us now present the results for the noSN models. In\nthis case the hierarchy of number of events allowing for\n\n\n\n14\n\nmeasurability at a given level is\n\n#({f22, f33, f44})\ufffd #({f22, f33, \u03c422}) \u223c\n#({f22, f33, f44, \u03c422})\n\nFor these models, f44 is measured significantly better\nthan \u03c422 within our statistical sample.\n\nNote that ringdowns from these populations are not\nthe ideal candidates for the ET detector. About \u223c20\nevents and 10 events allow for few-percent measurabil-\nity of {f22, f33, f44} in the noSN-shortDelays and noSN-\nDelays models, respectively. At the less stringent level\nof 10% measurability of this QNM combination, we ex-\npect the noSN-shortDelays model to have \u223c 100 events\nin 4 years, whereas there are only \u223c 40 \u2212 50 events in\nthe noSN-Delays population. Moreover, in each of these\nmodels, \u223c 20 events in 4-year data allow for measuring\nthe QNM parameter combination {f22, f33, \u03c422} at 10%\nlevel.\n\nC. BH spectroscopy with ET by measuring less\nthan 3 parameters\n\nSimilarly to the study for LISA in Sec. IV C, in Fig. 10,\nwe focus on the events in the population that do not nec-\nessarily allow for the precision measurement of 3 QNM\nparameters. Again, the ringdown measurements of these\nevents can be combined with the information obtained\nfrom the inspiral to perform tests of GR.9\n\nFrom Fig. 10, we see that the trend of the number of\nevents allowing for a certain level of measurability quali-\ntatively changes between the SN and noSN models. For\nSN models, the hierarchy goes as\n\n#(f22) > #(f33) > #(\u03c422) > #(f44) > #(f21) ,\n\nwhile for the noSN models it goes as\n\n#(f22) > #(f33) > #(f44) > #(\u03c422) > #(f21) .\n\nAgain this trend is consistent with the expectation we\nhave by looking at the asymmetry of the progenitor bi-\nnary system in Fig. 3 and relative measurement uncer-\ntainty in Fig. 4.\n\nFrom Fig. 10, \u223c 1 event within 4 years would allow\nfor 0.1% measurability of f22 for both the SN mod-\nels. Further, while the SN-shortDelays model predicts\n\u223c 50, 10 and 1 event in 4 years with 1% measurability of\nf22, {f22, f33}, and {f22, \u03c422}, respectively, the SN-Delays\nmodel predicts \u223c 30 and less than 10 with 1% measura-\nbility of f22 and {f22, f33}, respectively.\n\n9 Note however that here the inspiral can be scarcely measured,\nbecause the ringdown frequency is at the lower end of the ET\nbandwidth. In this case, a multiwavelength approach [115] would\nbe needed, wherein the binary parameters can be measured by\nLISA detecting the inspiral and the subsequent ringdown could\nbe measured by ET [116].\n\nFor the noSN-shortDelays model, we expect that \u223c 1\nevent in 4 years would allow for 0.2% measurability of\nf22 and up to 10 events with subpercent measurability of\n{f22, f33}. Moreover, approximately 100 events will allow\nfor 10% measurability of {f22, f33} and {f22, f44}. On the\nother hand, for the noSN-Delays model, \u223c 2 events and\nup to few tens of events will respectively allow for 0.1%\nand 1% measurability for both f22 and f33. About 10\nevents will also allow for 1% measurability of {f22, f44}.\nAlso, approximately 50 events will allow for 10% measur-\nability of {f22, f33} and of {f22, f44}.\n\nVI. DISCUSSION\n\nOne of LISA\u2019s main science goals is to probe the\nnature of massive compact objects and the nature of\ngravity through the ringdown of MBH merger rem-\nnants [39, 46]. While ringdown signals from MBHs with\nmass O(105)M\ufffd are expected to have very large SNR in\nLISA, the actual rates for such events crucially depend\non the underlying MBH populations. We have assessed\nLISA\u2019s ability to perform BH spectroscopy by measur-\ning multiple ringdown modes in several scenarios that\nbracket current uncertainties in MBH population mod-\nels. We found that the prospects for BH spectroscopy\nwith LISA depend significantly on the underlying MBH\npopulation. In the HS scenario, we found that approx-\nimately O(100) (less than 1) events in LISA\u2019s effective\noperational time, i.e. 4 years of data, would allow for\nringdown test at 1% (O(0.1)%) precision for at least 3\nindependent QNM parameters. Furthermore, the dom-\ninant mode frequency can be measured with O(0.1)%\nprecision in more than 100 events in 4-year data. On the\nother hand, in the LS scenarios, only one model (noSN-\nshortDelays) might allow for 1% precision measurement\nof 3 QNM parameters in 1\u2212 3 events in 4-year data.\n\nWe argued that the unfavorable prospect is due to the\nsmaller remnant mass predicted in the LS scenario com-\npared to the HS one, which makes the ringdown SNR low\nin LISA bandwidth. Given the smaller remnant masses\n(i.e., higher QNM frequency) we explored the possibil-\nity that BH spectroscopy in the LS scenario might be\nperformed with the next-generation ground-based inter-\nferometer ET. Interestingly, we found that a tail of the\nLS population will merge in the ET frequency window,\nallowing for 3-QNM spectroscopy at a few percent mea-\nsurability in a few events/yr. Furthermore, in the LS\nscenario ET could measure the fundamental mode alone\nat O(0.1)% level in at least 1 event in 4 years, and per-\nform a 2-QNM measurement (useful for inspiral-merger-\nringdown tests) at 1% level in a handful of events. The\nexact numbers depend on the LS scenarios (see Figs. 9\nand 10). We note that the low-frequency end of ET\u2019s sen-\nsitivity curve is particularly relevant for these rates, since\neven the tail of the MBH population in the LS scenarios\nhas support at higher masses compared to stellar-origin\nBHs. For this reason, we expect lower rates for CE, due\n\n\n\n15\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\n102\nCu\n\nm\nm\n\nul\nat\n\niv\ne \n\n# \nof\n\n e\nve\n\nnt\ns\n\nLS-SN-shortDelays (4 years)\n\n100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-noSN-shortDelays (4 years)\n\nf22 + f33 + 22\nf22 + f33 + f44\nf22 + f33 + f44 + 22\nf22 + f21 + f33\nf22 + f21 + f33 + 22\nf22 + f21 + f33 + f44\nf22 + f33 + f44 + f21 + 22\nf22 + 22 + 33\nf22 + f33 + 22 + 33\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-SN-Delays (4 years)\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\n102\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-noSN-Delays (4 years)\n\nFIG. 9. Same as Fig. 6 but for ET and focusing on the LS scenario only.\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\n102\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-SN-shortDelays (4 years)\n\n100 101 102\n\n% measurablity\n\n10 2\n\n10 1\n\n100\n\n101\n\n102\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-noSN-shortDelays (4 years)\n\nf22\nf22 + f33\nf22 + 22\n\n22\nf22 + f44\nf22 + f21\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-SN-Delays (4 years)\n\n100 101 102\n\n% measurablity\n\n10 1\n\n100\n\n101\n\n102\n\nCu\nm\n\nm\nul\n\nat\niv\n\ne \n# \n\nof\n e\n\nve\nnt\n\ns\n\nLS-noSN-Delays (4 years)\n\nFIG. 10. Same as Fig. 7 but for ET and focusing on the LS scenario only.\n\n\n\n16\n\nto its expected lower sensitivity at low frequencies.\nClearly, the accuracy of these tests is much lower than\n\nwhat third-generation detectors will be able to do using\nstellar-origin BH binaries, but it is nevertheless interest-\ning that a fraction of the population of light MBHs can\nbe detected by the ground-based detectors. In particular,\nthe light BHs predicted in the LS scenario call for a multi-\nwavelength GW approach [115]: the low-frequency early\ninspiral can be detected by LISA and the subsequent\nringdown could be measured by ET [116]. Nonetheless, if\nsome LS scenarios turn out to be realized in nature, the\nbest prospects for MBH spectroscopy would be reached\nin the deci-Hz band, for example by the proposed DE-\nCIGO [117] or by similar concepts. We leave a detailed\nanalysis of this case for a future work.\n\nAnother interesting result of our analysis is that BH\nspectroscopy with LISA can be performed beyond 3\nQNM parameters (4 or even 5 parameters) with a high\nlevel of precision for favorable HS models. In fact, for\na measurability threshold \u2265 1%, the prospects of ex-\ntracting 3 or 4 QNM parameters are similar; for in-\nstance, LISA will be able to measure at least 4 inde-\npendent QNM parameters with less than 1% uncertainty\n(in each parameter) for \u223c 100 events. Additional inde-\npendent measurements could be used to devise multiple\nnull-hypothesis tests of the no-hair theorem. We have\nalso considered the case of measuring 5 QNM parameters\nof the first four dominant angular modes, those for which\namplitude and phase fits are available. An interesting\nquestion is whether even more than 4-5 QNM parame-\nters can be measured in the HS shortDelays models. In\nfuture work, it would be interesting to explore the possi-\nbility of extracting the best 5 or more QNM parameters\nin this optimistic scenario and also to understand how\nmany modes should the ringdown waveform include for\noptimal ringdown parameter estimation with LISA. This\nwould require well-calibrated numerical-relativity fits of\nthe amplitude ratios and the phase differences for several\nQNMs across the whole parameter space identified by\nthe binary\u2019s mass ratio and individual spins. These re-\n\nsults could eventually be used to select the optimal set of\nQNM parameters depending on the progenitor binary pa-\nrameters as to inform tests of gravity with parametrized\napproaches [9].\n\nFinally, we focused on BH spectroscopy with multiple\nQNMs from a single source. For particularly pessimistic\nscenarios (especially in the LS case) and in the absence of\nsingle golden event allowing for accurate measurability,\nstacking a statistical number of ringdowns [118\u2013120] with\nindividually low measurability could be an alternative to\nperforming no-hair theorem tests. For example, an event\nrate of\u2248 25 events/yr with 10% measurability can lead to\nan overall measurability of 1% or better10 by stacking the\n\u2248 100 events expected in 4 years. Assuming one is able\nto efficiently stack all these events, stacking might also\nbe used in the HS scenario to reach sub0.1% precision.\n\nACKNOWLEDGMENTS\n\nThe authors are grateful to Vishal Baibhav for dis-\ncussion on EMOP energy and amplitude computations\nused in this work, and to Emanuele Berti and Vitor Car-\ndoso for useful discussions. Numerical computations were\nperformed at the Vera cluster of the Amaldi Research\nCenter funded by the MIUR program \u201cDipartimento di\nEccellenza\u201d (CUP: B81I18001170001). S.B., C.P., and\nP.P. acknowledge the financial support provided under\nthe European Union\u2019s H2020 ERC, Starting Grant agree-\nment no. DarkGRA\u2013757480. We also acknowledge sup-\nport under the MIUR PRIN and FARE programmes\n(GW- NEXT, CUP: B84I20000100001). E.B. acknowl-\nedges financial support provided under the European\nUnion\u2019s H2020 ERC Consolidator Grant \u201cGRavity from\nAstrophysical to Microscopic Scales\u201d grant agreement no.\nGRAMS-815673. This work was supported by the EU\nHorizon 2020 Research and Innovation Programme un-\nder the Marie Sklodowska-Curie Grant Agreement No.\n101007855.\n\n[1] S. Chandrasekhar and S. Detweiler, Proceedings of the\nRoyal Society of London Series A 344, 441 (1975).\n\n[2] C. V. Vishveshwara, Nature (London) 227, 936 (1970).\n[3] K. D. Kokkotas and B. G. Schmidt, Living Rev. Rel. 2,\n\n2 (1999), arXiv:gr-qc/9909058.\n[4] E. Berti, V. Cardoso, and A. O. Starinets, Class. Quant.\n\nGrav. 26, 163001 (2009), arXiv:0905.2975 [gr-qc].\n\n10 Note that our criterion for x% measurability is that all (say)\n3 QNM parameters are measured with at least x% precision.\nThis means that typically most of the QNM parameters under\nconsideration are measured with greater precision, so stacking N\ndifferent events might lead to higher precision than the standard\nN\u22121/2x% (assuming one is able to efficiently stack all N events)\n\n[5] B. Carter, Phys. Rev. Lett. 26, 331 (1971).\n[6] H.-P. Nollert, 16, R159 (1999).\n[7] E. Berti, K. Yagi, H. Yang, and N. Yunes, Gen. Rel.\n\nGrav. 50, 49 (2018), arXiv:1801.03587 [gr-qc].\n[8] T. G. F. Li, W. Del Pozzo, S. Vitale, C. Van Den Broeck,\n\nM. Agathos, J. Veitch, K. Grover, T. Sidery, R. Sturani,\nand A. Vecchio, Phys. Rev. D 85, 082003 (2012).\n\n[9] A. Maselli, P. Pani, L. Gualtieri, and E. Berti, Phys.\nRev. D 101, 024043 (2020), arXiv:1910.12893 [gr-qc].\n\n[10] S. H. Vo\u0308lkel and E. Barausse, Phys. Rev. D 102, 084025\n(2020), arXiv:2007.02986 [gr-qc].\n\n[11] E. Berti et al., Class. Quant. Grav. 32, 243001 (2015),\narXiv:1501.07274 [gr-qc].\n\n[12] K. Yagi and L. C. Stein, Class. Quant. Grav. 33, 054001\n(2016), arXiv:1602.02413 [gr-qc].\n\n[13] E. Barausse and T. P. Sotiriou, Phys. Rev. Lett. 101,\n\nhttp://dx.doi.org/10.1098/rspa.1975.0112\nhttp://dx.doi.org/10.1098/rspa.1975.0112\nhttp://dx.doi.org/10.1038/227936a0\nhttp://dx.doi.org/10.12942/lrr-1999-2\nhttp://dx.doi.org/10.12942/lrr-1999-2\nhttp://arxiv.org/abs/gr-qc/9909058\nhttp://dx.doi.org/10.1088/0264-9381/26/16/163001\nhttp://dx.doi.org/10.1088/0264-9381/26/16/163001\nhttp://arxiv.org/abs/0905.2975\nhttp://dx.doi.org/10.1103/PhysRevLett.26.331\nhttp://dx.doi.org/10.1088/0264-9381/16/12/201\nhttp://dx.doi.org/ 10.1007/s10714-018-2372-6\nhttp://dx.doi.org/ 10.1007/s10714-018-2372-6\nhttp://arxiv.org/abs/1801.03587\nhttp://dx.doi.org/10.1103/PhysRevD.85.082003\nhttp://dx.doi.org/10.1103/PhysRevD.101.024043\nhttp://dx.doi.org/10.1103/PhysRevD.101.024043\nhttp://arxiv.org/abs/1910.12893\nhttp://dx.doi.org/10.1103/PhysRevD.102.084025\nhttp://dx.doi.org/10.1103/PhysRevD.102.084025\nhttp://arxiv.org/abs/2007.02986\nhttp://dx.doi.org/10.1088/0264-9381/32/24/243001\nhttp://arxiv.org/abs/1501.07274\nhttp://dx.doi.org/10.1088/0264-9381/33/5/054001\nhttp://dx.doi.org/10.1088/0264-9381/33/5/054001\nhttp://arxiv.org/abs/1602.02413\nhttp://dx.doi.org/10.1103/PhysRevLett.101.099001\n\n\n17\n\n099001 (2008), arXiv:0803.3433 [gr-qc].\n[14] P. Pani and V. Cardoso, Phys. Rev. D 79, 084031\n\n(2009), arXiv:0902.1569 [gr-qc].\n[15] E. Barausse, V. Cardoso, and P. Pani, Phys. Rev. D\n\n89, 104059 (2014), arXiv:1404.7149 [gr-qc].\n[16] V. Cardoso and P. Pani, Living Rev. Rel. 22, 4 (2019),\n\narXiv:1904.05363 [gr-qc].\n[17] V. Cardoso, S. Hopper, C. F. B. Macedo, C. Palen-\n\nzuela, and P. Pani, Phys. Rev. D 94, 084031 (2016),\narXiv:1608.08637 [gr-qc].\n\n[18] E. Maggio, P. Pani, and G. Raposo, arXiv e-prints ,\narXiv:2105.06410 (2021), arXiv:2105.06410 [gr-qc].\n\n[19] E. Maggio, L. Buoninfante, A. Mazumdar, and P. Pani,\nPhys. Rev. D 102, 064053 (2020), arXiv:2006.14628 [gr-\nqc].\n\n[20] J. C. Bustillo, P. D. Lasky, and E. Thrane, Phys. Rev.\nD 103, 024041 (2021).\n\n[21] V. Cardoso and P. Pani, Living Reviews in Relativity\n22, 4 (2019), arXiv:1904.05363 [gr-qc].\n\n[22] B. P. Abbott et al. (LIGO Scientific, Virgo), Phys. Rev.\nLett. 116, 221101 (2016), [Erratum: Phys.Rev.Lett.\n121, 129902 (2018)], arXiv:1602.03841 [gr-qc].\n\n[23] A. Ghosh, R. Brito, and A. Buonanno, Phys. Rev. D\n103, 124041 (2021), arXiv:2104.01906 [gr-qc].\n\n[24] A. Ghosh et al., Phys. Rev. D 94, 021101 (2016),\narXiv:1602.02453 [gr-qc].\n\n[25] B. P. Abbott et al. (LIGO Scientific, Virgo), Phys. Rev.\nD 100, 104036 (2019), arXiv:1903.04467 [gr-qc].\n\n[26] R. Abbott et al. (LIGO Scientific, Virgo), Phys. Rev. D\n103, 122002 (2021), arXiv:2010.14529 [gr-qc].\n\n[27] R. Abbott et al. (LIGO Scientific, VIRGO, KAGRA),\n(2021), arXiv:2112.06861 [gr-qc].\n\n[28] E. Berti, V. Cardoso, and C. M. Will, Phys. Rev. D\n73, 064030 (2006), arXiv:gr-qc/0512160.\n\n[29] S. Gossan, J. Veitch, and B. S. Sathyaprakash, Phys.\nRev. D 85, 124056 (2012), arXiv:1111.5819 [gr-qc].\n\n[30] O. Dreyer, B. J. Kelly, B. Krishnan, L. S. Finn, D. Gar-\nrison, and R. Lopez-Aleman, Class. Quant. Grav. 21,\n787 (2004), arXiv:gr-qc/0309007.\n\n[31] M. Isi, M. Giesler, W. M. Farr, M. A. Scheel, and\nS. A. Teukolsky, Phys. Rev. Lett. 123, 111102 (2019),\narXiv:1905.00869 [gr-qc].\n\n[32] C. D. Capano and A. H. Nitz, Phys. Rev. D 102, 124070\n(2020), arXiv:2008.02248 [gr-qc].\n\n[33] S. Bhagwat, X. J. Forteza, P. Pani, and V. Ferrari,\nPhys. Rev. D 101, 044033 (2020), arXiv:1910.08708 [gr-\nqc].\n\n[34] I. Ota and C. Chirenti, Phys. Rev. D 101, 104005\n(2020), arXiv:1911.00440 [gr-qc].\n\n[35] S. Bhagwat, X. J. Forteza, P. Pani, and V. Ferrari,\nPhys. Rev. D 101, 044033 (2020), arXiv:1910.08708 [gr-\nqc].\n\n[36] X. Jime\u0301nez Forteza, S. Bhagwat, P. Pani, and\nV. Ferrari, Phys. Rev. D 102, 044053 (2020),\narXiv:2005.03260 [gr-qc].\n\n[37] E. Berti, A. Sesana, E. Barausse, V. Cardoso, and\nK. Belczynski, Phys. Rev. Lett. 117, 101102 (2016),\narXiv:1605.09286 [gr-qc].\n\n[38] L. Barack et al., Class. Quant. Grav. 36, 143001 (2019),\narXiv:1806.05195 [gr-qc].\n\n[39] P. Amaro-Seoane et al. (LISA), (2017),\narXiv:1702.00786 [astro-ph.IM].\n\n[40] V. Kalogera et al., (2021), arXiv:2111.06990 [gr-qc].\n[41] B. P. Abbott et al. (LIGO Scientific), Class. Quant.\n\nGrav. 34, 044001 (2017), arXiv:1607.08697 [astro-\nph.IM].\n\n[42] R. Essick, S. Vitale, and M. Evans, Phys. Rev. D96,\n084004 (2017), arXiv:1708.06843 [gr-qc].\n\n[43] S. Hild et al., Class. Quant. Grav. 28, 094013 (2011),\narXiv:1012.0908 [gr-qc].\n\n[44] M. Maggiore et al., JCAP 03, 050 (2020),\narXiv:1912.02622 [astro-ph.CO].\n\n[45] A. Klein, E. Barausse, A. Sesana, A. Petiteau, E. Berti,\nS. Babak, J. Gair, S. Aoudia, I. Hinder, F. Ohme,\nand B. Wardell, Phys. Rev. D 93, 024003 (2016),\narXiv:1511.05581 [gr-qc].\n\n[46] E. Barausse et al., Gen. Rel. Grav. 52, 81 (2020),\narXiv:2001.09793 [gr-qc].\n\n[47] A. Sesana et al., Exper. Astron. 51, 1333 (2021),\narXiv:1908.11391 [astro-ph.IM].\n\n[48] V. Baibhav et al., Exper. Astron. 51, 1385 (2021),\narXiv:1908.11390 [astro-ph.HE].\n\n[49] E. Barausse, I. Dvorkin, M. Tremmel, M. Volon-\nteri, and M. Bonetti, Astrophys. J. 904, 16 (2020),\narXiv:2006.03065 [astro-ph.GA].\n\n[50] E. Barausse and A. Lapi, (2020), arXiv:2011.01994\n[astro-ph.GA].\n\n[51] V. Baibhav and E. Berti, Phys. Rev. D 99, 024005\n(2019), arXiv:1809.03500 [gr-qc].\n\n[52] V. Baibhav, E. Berti, and V. Cardoso, Phys. Rev. D\n101, 084053 (2020), arXiv:2001.10011 [gr-qc].\n\n[53] S. Bhagwat, M. Cabero, C. D. Capano, B. Krishnan,\nand D. A. Brown, Phys. Rev. D 102, 024023 (2020),\narXiv:1910.13203 [gr-qc].\n\n[54] E. Berti, J. Cardoso, V. Cardoso, and M. Cavaglia,\nPhys. Rev. D 76, 104044 (2007), arXiv:0707.1202 [gr-\nqc].\n\n[55] S. Bhagwat, D. A. Brown, and S. W. Ballmer, Phys.\nRev. D 94, 084024 (2016), arXiv:1607.07845 [gr-qc].\n\n[56] I. Ota and C. Chirenti, (2021), arXiv:2108.01774 [gr-\nqc].\n\n[57] E. Barausse, Monthly Notices of the Royal Astronomical\nSociety 423, 2533 (2012), arXiv:1201.5888.\n\n[58] A. Sesana, E. Barausse, M. Dotti, and E. M.\nRossi, The Astrophysical Journal 794, 104 (2014),\narXiv:1402.7088.\n\n[59] F. Antonini, E. Barausse, and J. Silk, The Astrophysical\nJournal Letters 806, L8 (2015), arXiv:1504.04033.\n\n[60] F. Antonini, E. Barausse, and J. Silk, The Astrophysical\nJournal 812, 72 (2015), arXiv:1506.02050.\n\n[61] M. Bonetti, F. Haardt, A. Sesana, and E. Barausse,\nMonthly Notices of the Royal Astronomical Society 477,\n3910 (2018), arXiv:1709.06088.\n\n[62] M. Bonetti, A. Sesana, F. Haardt, E. Barausse, and\nM. Colpi, Monthly Notices of the Royal Astronomi-\ncal Society 486, 4044 (2019), arXiv:1812.01011 [astro-\nph.GA].\n\n[63] A. Dekel and Y. Birnboim, Monthly Notices of the Royal\nAstronomical Society 368, 2 (2006), astro-ph/0412300.\n\n[64] A. Cattaneo, A. Dekel, J. Devriendt, B. Guiderdoni,\nand J. Blaizot, Monthly Notices of the Royal Astronom-\nical Society 370, 1651 (2006), astro-ph/0601295.\n\n[65] A. Dekel, Y. Birnboim, G. Engel, J. Freundlich,\nT. Goerdt, M. Mumcuoglu, E. Neistein, C. Pichon,\nR. Teyssier, and E. Zinger, Nature 457, 451 (2009),\narXiv:0808.0553.\n\n[66] H. J. Mo, S. Mao, and S. D. M. White, Monthly No-\ntices of the Royal Astronomical Society 295, 319 (1998),\n\nhttp://dx.doi.org/10.1103/PhysRevLett.101.099001\nhttp://arxiv.org/abs/0803.3433\nhttp://dx.doi.org/10.1103/PhysRevD.79.084031\nhttp://dx.doi.org/10.1103/PhysRevD.79.084031\nhttp://arxiv.org/abs/0902.1569\nhttp://dx.doi.org/10.1103/PhysRevD.89.104059\nhttp://dx.doi.org/10.1103/PhysRevD.89.104059\nhttp://arxiv.org/abs/1404.7149\nhttp://dx.doi.org/10.1007/s41114-019-0020-4\nhttp://arxiv.org/abs/1904.05363\nhttp://dx.doi.org/ 10.1103/PhysRevD.94.084031\nhttp://arxiv.org/abs/1608.08637\nhttp://arxiv.org/abs/2105.06410\nhttp://dx.doi.org/ 10.1103/PhysRevD.102.064053\nhttp://arxiv.org/abs/2006.14628\nhttp://arxiv.org/abs/2006.14628\nhttp://dx.doi.org/10.1103/PhysRevD.103.024041\nhttp://dx.doi.org/10.1103/PhysRevD.103.024041\nhttp://dx.doi.org/10.1007/s41114-019-0020-4\nhttp://dx.doi.org/10.1007/s41114-019-0020-4\nhttp://arxiv.org/abs/1904.05363\nhttp://dx.doi.org/10.1103/PhysRevLett.116.221101\nhttp://dx.doi.org/10.1103/PhysRevLett.116.221101\nhttp://arxiv.org/abs/1602.03841\nhttp://dx.doi.org/10.1103/PhysRevD.103.124041\nhttp://dx.doi.org/10.1103/PhysRevD.103.124041\nhttp://arxiv.org/abs/2104.01906\nhttp://dx.doi.org/10.1103/PhysRevD.94.021101\nhttp://arxiv.org/abs/1602.02453\nhttp://dx.doi.org/10.1103/PhysRevD.100.104036\nhttp://dx.doi.org/10.1103/PhysRevD.100.104036\nhttp://arxiv.org/abs/1903.04467\nhttp://dx.doi.org/10.1103/PhysRevD.103.122002\nhttp://dx.doi.org/10.1103/PhysRevD.103.122002\nhttp://arxiv.org/abs/2010.14529\nhttp://arxiv.org/abs/2112.06861\nhttp://dx.doi.org/10.1103/PhysRevD.73.064030\nhttp://dx.doi.org/10.1103/PhysRevD.73.064030\nhttp://arxiv.org/abs/gr-qc/0512160\nhttp://dx.doi.org/10.1103/PhysRevD.85.124056\nhttp://dx.doi.org/10.1103/PhysRevD.85.124056\nhttp://arxiv.org/abs/1111.5819\nhttp://dx.doi.org/ 10.1088/0264-9381/21/4/003\nhttp://dx.doi.org/ 10.1088/0264-9381/21/4/003\nhttp://arxiv.org/abs/gr-qc/0309007\nhttp://dx.doi.org/ 10.1103/PhysRevLett.123.111102\nhttp://arxiv.org/abs/1905.00869\nhttp://dx.doi.org/10.1103/PhysRevD.102.124070\nhttp://dx.doi.org/10.1103/PhysRevD.102.124070\nhttp://arxiv.org/abs/2008.02248\nhttp://dx.doi.org/10.1103/PhysRevD.101.044033\nhttp://arxiv.org/abs/1910.08708\nhttp://arxiv.org/abs/1910.08708\nhttp://dx.doi.org/10.1103/PhysRevD.101.104005\nhttp://dx.doi.org/10.1103/PhysRevD.101.104005\nhttp://arxiv.org/abs/1911.00440\nhttp://dx.doi.org/10.1103/PhysRevD.101.044033\nhttp://arxiv.org/abs/1910.08708\nhttp://arxiv.org/abs/1910.08708\nhttp://dx.doi.org/10.1103/PhysRevD.102.044053\nhttp://arxiv.org/abs/2005.03260\nhttp://dx.doi.org/ 10.1103/PhysRevLett.117.101102\nhttp://arxiv.org/abs/1605.09286\nhttp://dx.doi.org/10.1088/1361-6382/ab0587\nhttp://arxiv.org/abs/1806.05195\nhttp://arxiv.org/abs/1702.00786\nhttp://arxiv.org/abs/2111.06990\nhttp://dx.doi.org/10.1088/1361-6382/aa51f4\nhttp://dx.doi.org/10.1088/1361-6382/aa51f4\nhttp://arxiv.org/abs/1607.08697\nhttp://arxiv.org/abs/1607.08697\nhttp://dx.doi.org/10.1103/PhysRevD.96.084004\nhttp://dx.doi.org/10.1103/PhysRevD.96.084004\nhttp://arxiv.org/abs/1708.06843\nhttp://dx.doi.org/10.1088/0264-9381/28/9/094013\nhttp://arxiv.org/abs/1012.0908\nhttp://dx.doi.org/10.1088/1475-7516/2020/03/050\nhttp://arxiv.org/abs/1912.02622\nhttp://dx.doi.org/10.1103/PhysRevD.93.024003\nhttp://arxiv.org/abs/1511.05581\nhttp://dx.doi.org/10.1007/s10714-020-02691-1\nhttp://arxiv.org/abs/2001.09793\nhttp://dx.doi.org/10.1007/s10686-021-09709-9\nhttp://arxiv.org/abs/1908.11391\nhttp://dx.doi.org/10.1007/s10686-021-09741-9\nhttp://arxiv.org/abs/1908.11390\nhttp://dx.doi.org/ 10.3847/1538-4357/abba7f\nhttp://arxiv.org/abs/2006.03065\nhttp://arxiv.org/abs/2011.01994\nhttp://arxiv.org/abs/2011.01994\nhttp://dx.doi.org/10.1103/PhysRevD.99.024005\nhttp://dx.doi.org/10.1103/PhysRevD.99.024005\nhttp://arxiv.org/abs/1809.03500\nhttp://dx.doi.org/10.1103/PhysRevD.101.084053\nhttp://dx.doi.org/10.1103/PhysRevD.101.084053\nhttp://arxiv.org/abs/2001.10011\nhttp://dx.doi.org/ 10.1103/PhysRevD.102.024023\nhttp://arxiv.org/abs/1910.13203\nhttp://dx.doi.org/10.1103/PhysRevD.76.104044\nhttp://arxiv.org/abs/0707.1202\nhttp://arxiv.org/abs/0707.1202\nhttp://dx.doi.org/10.1103/PhysRevD.94.084024\nhttp://dx.doi.org/10.1103/PhysRevD.94.084024\nhttp://arxiv.org/abs/1607.07845\nhttp://arxiv.org/abs/2108.01774\nhttp://arxiv.org/abs/2108.01774\nhttp://dx.doi.org/10.1111/j.1365-2966.2012.21057.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2012.21057.x\nhttp://arxiv.org/abs/1201.5888\nhttp://dx.doi.org/10.1088/0004-637X/794/2/104\nhttp://arxiv.org/abs/1402.7088\nhttp://dx.doi.org/10.1088/2041-8205/806/1/L8\nhttp://dx.doi.org/10.1088/2041-8205/806/1/L8\nhttp://arxiv.org/abs/1504.04033\nhttp://dx.doi.org/10.1088/0004-637X/812/1/72\nhttp://dx.doi.org/10.1088/0004-637X/812/1/72\nhttp://arxiv.org/abs/1506.02050\nhttp://dx.doi.org/10.1093/mnras/sty896\nhttp://dx.doi.org/10.1093/mnras/sty896\nhttp://arxiv.org/abs/1709.06088\nhttp://dx.doi.org/ 10.1093/mnras/stz903\nhttp://dx.doi.org/ 10.1093/mnras/stz903\nhttp://arxiv.org/abs/1812.01011\nhttp://arxiv.org/abs/1812.01011\nhttp://dx.doi.org/10.1111/j.1365-2966.2006.10145.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2006.10145.x\nhttp://arxiv.org/abs/astro-ph/0412300\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2006.10608.x\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2006.10608.x\nhttp://arxiv.org/abs/astro-ph/0601295\nhttp://dx.doi.org/ 10.1038/nature07648\nhttp://arxiv.org/abs/0808.0553\nhttp://dx.doi.org/10.1046/j.1365-8711.1998.01227.x\nhttp://dx.doi.org/10.1046/j.1365-8711.1998.01227.x\n\n\n18\n\narXiv:astro-ph/9707093 [astro-ph].\n[67] G. L. Granato, G. De Zotti, L. Silva, A. Bressan, and\n\nL. Danese, Astrophys. J. 600, 580 (2004), arXiv:astro-\nph/0307202.\n\n[68] V. Springel and L. Hernquist, Monthly Notices of\nthe Royal Astronomical Society 333, 649 (2002),\narXiv:astro-ph/0111016 [astro-ph].\n\n[69] A. Fujita, M.-M. Mac Low, A. Ferrara, and A. Meiksin,\nThe Astrophysical Journal 613, 159 (2004), arXiv:astro-\nph/0405611 [astro-ph].\n\n[70] Y. Rasera and R. Teyssier, Astronomy and Astrophysics\n445, 1 (2006), arXiv:astro-ph/0505473 [astro-ph].\n\n[71] D. J. Croton, V. Springel, S. D. M. White, G. De Lucia,\nC. S. Frenk, L. Gao, A. Jenkins, G. Kauffmann, J. F.\nNavarro, and N. Yoshida, Monthly Notices of the Royal\nAstronomical Society 365, 11 (2006), astro-ph/0508046.\n\n[72] P. F. Hopkins, T. J. Cox, D. Keres\u030c, and L. Hern-\nquist, The Astrophysical Journals 175, 390 (2008),\narXiv:0706.1246 [astro-ph].\n\n[73] R. G. Bower, A. J. Benson, R. Malbon, J. C. Helly,\nC. S. Frenk, C. M. Baugh, S. Cole, and C. G. Lacey,\nMonthly Notices of the Royal Astronomical Society 370,\n645 (2006), arXiv:astro-ph/0511338 [astro-ph].\n\n[74] M. Habouzit, M. Volonteri, and Y. Dubois, Monthly\nNotices of the Royal Astronomical Society 468, 3935\n(2017), arXiv:1605.09394 [astro-ph.GA].\n\n[75] W. H. Press and P. Schechter, The Astrophysical Jour-\nnal 187, 425 (1974).\n\n[76] H. Parkinson, S. Cole, and J. Helly, Monthly No-\ntices of the Royal Astronomical Society 383, 557 (2008),\narXiv:0708.1382.\n\n[77] M. Boylan-Kolchin, C.-P. Ma, and E. Quataert,\nMonthly Notices of the Royal Astronomical Society 383,\n93 (2008), arXiv:0707.2960.\n\n[78] G. Taffoni, L. Mayer, M. Colpi, and F. Governato,\nMonthly Notices of the Royal Astronomical Society 341,\n434 (2003), astro-ph/0301271.\n\n[79] J. Binney and S. Tremaine, Galactic Dynamics: Second\nEdition, by James Binney and Scott Tremaine. ISBN\n978-0-691-13026-2 (HB). Published by Princeton Uni-\nversity Press, Princeton, NJ USA, 2008. (Princeton\nUniversity Press, 2008).\n\n[80] F. Dosopoulou and F. Antonini, The Astrophysi-\ncal Journal 840, 31 (2017), arXiv:1611.06573 [astro-\nph.GA].\n\n[81] M. Tremmel, F. Governato, M. Volonteri, T. R. Quinn,\nand A. Pontzen, Monthly Notices of the Royal Astro-\nnomical Society 475, 4967 (2018), arXiv:1708.07126.\n\n[82] A. I. MacFadyen and M. Milosavljevic\u0301, The Astrophys-\nical Journal 672, 83-93 (2008), astro-ph/0607467.\n\n[83] J. Cuadra, P. J. Armitage, R. D. Alexander, and M. C.\nBegelman, Monthly Notices of the Royal Astronomical\nSociety 393, 1423 (2009), arXiv:0809.0311.\n\n[84] G. Lodato, S. Nayakshin, A. R. King, and J. E. Pringle,\nMonthly Notices of the Royal Astronomical Society 398,\n1392 (2009), arXiv:0906.0737.\n\n[85] C. Roedig, M. Dotti, A. Sesana, J. Cuadra, and\nM. Colpi, Monthly Notices of the Royal Astronomical\nSociety 415, 3033 (2011), arXiv:1104.3868.\n\n[86] C. J. Nixon, P. J. Cossins, A. R. King, and J. E. Pringle,\nMonthly Notices of the Royal Astronomical Society 412,\n1591 (2011), arXiv:1011.1914 [astro-ph.HE].\n\n[87] P. C. Duffell, D. D\u2019Orazio, A. Derdzinski, Z. Haiman,\nA. MacFadyen, A. L. Rosen, and J. Zrake, arXiv\n\ne-prints , arXiv:1911.05506 (2019), arXiv:1911.05506\n[astro-ph.SR].\n\n[88] D. J. Mun\u0303oz, R. Miranda, and D. Lai, The Astrophys-\nical Journal 871, 84 (2019), arXiv:1810.04676 [astro-\nph.HE].\n\n[89] G. D. Quinlan, Nature Astronomy 1, 35 (1996), astro-\nph/9601092.\n\n[90] A. Sesana and F. M. Khan, Monthly Notices of\nthe Royal Astronomical Society 454, L66 (2015),\narXiv:1505.02062.\n\n[91] L. Hoffman and A. Loeb, Monthly Notices of the\nRoyal Astronomical Society 377, 957 (2007), astro-\nph/0612517.\n\n[92] M. Bonetti, F. Haardt, A. Sesana, and E. Barausse,\nMonthly Notices of the Royal Astronomical Society 461,\n4419 (2016), arXiv:1604.08770.\n\n[93] M. Bonetti, A. Sesana, E. Barausse, and F. Haardt,\nMonthly Notices of the Royal Astronomical Society 477,\n2599 (2018), arXiv:1709.06095.\n\n[94] E. Barausse, V. Morozova, and L. Rezzolla, Astro-\nphys. J. 758, 63 (2012), [Erratum: Astrophys.J. 786,\n76 (2014)], arXiv:1206.3803 [gr-qc].\n\n[95] F. Hofmann, E. Barausse, and L. Rezzolla, Astrophys.\nJ. Lett. 825, L19 (2016), arXiv:1605.01938 [gr-qc].\n\n[96] J. R. van Meter, M. C. Miller, J. G. Baker, W. D.\nBoggs, and B. J. Kelly, Astrophys. J. 719, 1427 (2010),\narXiv:1003.3865 [astro-ph.HE].\n\n[97] P. Madau and M. J. Rees, The Astrophysical Journal\nLetters 551, L27 (2001), astro-ph/0101223.\n\n[98] M. Volonteri, G. Lodato, and P. Natarajan, Monthly\nNotices of the Royal Astronomical Society 383, 1079\n(2008), arXiv:0709.0529.\n\n[99] A. Toubiana, K. W. K. Wong, S. Babak, E. Ba-\nrausse, E. Berti, J. R. Gair, S. Marsat, and\nS. R. Taylor, (2021), 10.1103/PhysRevD.104.083027,\narXiv:2106.13819 [gr-qc].\n\n[100] S. Babak, A. Petiteau, and M. Hewitson, (2021),\narXiv:2108.01167 [astro-ph.IM].\n\n[101] T. Robson, N. J. Cornish, and C. Liu, Class. Quant.\nGrav. 36, 105011 (2019), arXiv:1803.01944 [astro-\nph.HE].\n\n[102] E. Berti, V. Cardoso, J. A. Gonzalez, U. Sperhake,\nM. Hannam, S. Husa, and B. Bruegmann, Phys. Rev.\nD 76, 064034 (2007), arXiv:gr-qc/0703053.\n\n[103] V. Baibhav, E. Berti, V. Cardoso, and G. Khanna,\nPhys. Rev. D 97, 044048 (2018), arXiv:1710.02156 [gr-\nqc].\n\n[104] P. Ajith et al., Phys. Rev. Lett. 106, 241101 (2011),\narXiv:0909.2867 [gr-qc].\n\n[105] I. Kamaretsos, M. Hannam, S. Husa, and B. S.\nSathyaprakash, Phys. Rev. D 85, 024018 (2012).\n\n[106] R. A. Fisher, Philosophical Transactions of the Royal\nSociety of London, A 222, 309 (1922).\n\n[107] M. Vallisneri, Phys. Rev. D 77, 042001 (2008), arXiv:gr-\nqc/0703086.\n\n[108] A. Meurer, C. P. Smith, M. Paprocki, O. C\u030cert\u0301\u0131k, S. B.\nKirpichev, M. Rocklin, A. Kumar, S. Ivanov, J. K.\nMoore, S. Singh, T. Rathnayake, S. Vig, B. E. Granger,\nR. P. Muller, F. Bonazzi, H. Gupta, S. Vats, F. Johans-\nson, F. Pedregosa, M. J. Curry, A. R. Terrel, v. Rouc\u030cka,\nA. Saboo, I. Fernando, S. Kulal, R. Cimrman, and\nA. Scopatz, PeerJ Computer Science 3, e103 (2017).\n\n[109] E. Berti and V. Cardoso, \u201cKerr qnm frequencies,\u201d\nhttps://pages.jh.edu/\u02dceberti2/ringdown/,\n\nhttp://arxiv.org/abs/astro-ph/9707093\nhttp://dx.doi.org/ 10.1086/379875\nhttp://arxiv.org/abs/astro-ph/0307202\nhttp://arxiv.org/abs/astro-ph/0307202\nhttp://dx.doi.org/10.1046/j.1365-8711.2002.05445.x\nhttp://dx.doi.org/10.1046/j.1365-8711.2002.05445.x\nhttp://arxiv.org/abs/astro-ph/0111016\nhttp://dx.doi.org/10.1086/422861\nhttp://arxiv.org/abs/astro-ph/0405611\nhttp://arxiv.org/abs/astro-ph/0405611\nhttp://dx.doi.org/10.1051/0004-6361:20053116\nhttp://dx.doi.org/10.1051/0004-6361:20053116\nhttp://arxiv.org/abs/astro-ph/0505473\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2005.09675.x\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2005.09675.x\nhttp://arxiv.org/abs/astro-ph/0508046\nhttp://dx.doi.org/10.1086/524363\nhttp://arxiv.org/abs/0706.1246\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2006.10519.x\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2006.10519.x\nhttp://arxiv.org/abs/astro-ph/0511338\nhttp://dx.doi.org/10.1093/mnras/stx666\nhttp://dx.doi.org/10.1093/mnras/stx666\nhttp://dx.doi.org/10.1093/mnras/stx666\nhttp://arxiv.org/abs/1605.09394\nhttp://dx.doi.org/10.1086/152650\nhttp://dx.doi.org/10.1086/152650\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12517.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12517.x\nhttp://arxiv.org/abs/0708.1382\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12530.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12530.x\nhttp://arxiv.org/abs/0707.2960\nhttp://dx.doi.org/10.1046/j.1365-8711.2003.06395.x\nhttp://dx.doi.org/10.1046/j.1365-8711.2003.06395.x\nhttp://arxiv.org/abs/astro-ph/0301271\nhttp://dx.doi.org/10.3847/1538-4357/aa6b58\nhttp://dx.doi.org/10.3847/1538-4357/aa6b58\nhttp://arxiv.org/abs/1611.06573\nhttp://arxiv.org/abs/1611.06573\nhttp://dx.doi.org/10.1093/mnras/sty139\nhttp://dx.doi.org/10.1093/mnras/sty139\nhttp://arxiv.org/abs/1708.07126\nhttp://dx.doi.org/10.1086/523869\nhttp://dx.doi.org/10.1086/523869\nhttp://arxiv.org/abs/astro-ph/0607467\nhttp://dx.doi.org/10.1111/j.1365-2966.2008.14147.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2008.14147.x\nhttp://arxiv.org/abs/0809.0311\nhttp://dx.doi.org/10.1111/j.1365-2966.2009.15179.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2009.15179.x\nhttp://arxiv.org/abs/0906.0737\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2011.18927.x\nhttp://dx.doi.org/ 10.1111/j.1365-2966.2011.18927.x\nhttp://arxiv.org/abs/1104.3868\nhttp://dx.doi.org/10.1111/j.1365-2966.2010.17952.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2010.17952.x\nhttp://arxiv.org/abs/1011.1914\nhttp://arxiv.org/abs/1911.05506\nhttp://arxiv.org/abs/1911.05506\nhttp://dx.doi.org/10.3847/1538-4357/aaf867\nhttp://dx.doi.org/10.3847/1538-4357/aaf867\nhttp://arxiv.org/abs/1810.04676\nhttp://arxiv.org/abs/1810.04676\nhttp://dx.doi.org/10.1016/S1384-1076(96)00003-6\nhttp://arxiv.org/abs/astro-ph/9601092\nhttp://arxiv.org/abs/astro-ph/9601092\nhttp://dx.doi.org/10.1093/mnrasl/slv131\nhttp://dx.doi.org/10.1093/mnrasl/slv131\nhttp://arxiv.org/abs/1505.02062\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.11694.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.11694.x\nhttp://arxiv.org/abs/astro-ph/0612517\nhttp://arxiv.org/abs/astro-ph/0612517\nhttp://dx.doi.org/10.1093/mnras/stw1590\nhttp://dx.doi.org/10.1093/mnras/stw1590\nhttp://arxiv.org/abs/1604.08770\nhttp://dx.doi.org/10.1093/mnras/sty874\nhttp://dx.doi.org/10.1093/mnras/sty874\nhttp://arxiv.org/abs/1709.06095\nhttp://dx.doi.org/10.1088/0004-637X/758/1/63\nhttp://dx.doi.org/10.1088/0004-637X/758/1/63\nhttp://arxiv.org/abs/1206.3803\nhttp://dx.doi.org/10.3847/2041-8205/825/2/L19\nhttp://dx.doi.org/10.3847/2041-8205/825/2/L19\nhttp://arxiv.org/abs/1605.01938\nhttp://dx.doi.org/10.1088/0004-637X/719/2/1427\nhttp://arxiv.org/abs/1003.3865\nhttp://dx.doi.org/10.1086/319848\nhttp://dx.doi.org/10.1086/319848\nhttp://arxiv.org/abs/astro-ph/0101223\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12589.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12589.x\nhttp://dx.doi.org/10.1111/j.1365-2966.2007.12589.x\nhttp://arxiv.org/abs/0709.0529\nhttp://dx.doi.org/ 10.1103/PhysRevD.104.083027\nhttp://arxiv.org/abs/2106.13819\nhttp://arxiv.org/abs/2108.01167\nhttp://dx.doi.org/10.1088/1361-6382/ab1101\nhttp://dx.doi.org/10.1088/1361-6382/ab1101\nhttp://arxiv.org/abs/1803.01944\nhttp://arxiv.org/abs/1803.01944\nhttp://dx.doi.org/10.1103/PhysRevD.76.064034\nhttp://dx.doi.org/10.1103/PhysRevD.76.064034\nhttp://arxiv.org/abs/gr-qc/0703053\nhttp://dx.doi.org/10.1103/PhysRevD.97.044048\nhttp://arxiv.org/abs/1710.02156\nhttp://arxiv.org/abs/1710.02156\nhttp://dx.doi.org/10.1103/PhysRevLett.106.241101\nhttp://arxiv.org/abs/0909.2867\nhttp://dx.doi.org/10.1103/PhysRevD.85.024018\nhttp://dx.doi.org/10.1103/PhysRevD.77.042001\nhttp://arxiv.org/abs/gr-qc/0703086\nhttp://arxiv.org/abs/gr-qc/0703086\nhttp://dx.doi.org/10.7717/peerj-cs.103\nhttps://pages.jh.edu/~eberti2/ringdown/\n\n\n19\n\nhttps://centra.tecnico.ulisboa.pt/\nnetwork/grit/files/ringdown/.\n\n[110] L. London, D. Shoemaker, and J. Healy, Phys. Rev. D\n90, 124032 (2014), [Erratum: Phys.Rev.D 94, 069902\n(2016)], arXiv:1404.3197 [gr-qc].\n\n[111] I. Kamaretsos, M. Hannam, and B. Sathyaprakash,\nPhys. Rev. Lett. 109, 141102 (2012), arXiv:1207.0399\n[gr-qc].\n\n[112] Y. Pan, A. Buonanno, M. Boyle, L. T. Buchman, L. E.\nKidder, H. P. Pfeiffer, and M. A. Scheel, Phys. Rev. D\n84, 124052 (2011), arXiv:1106.1021 [gr-qc].\n\n[113] S. Bhagwat and C. Pacilio, Phys. Rev. D 104, 024030\n(2021), arXiv:2101.07817 [gr-qc].\n\n[114] E. Barausse and L. Rezzolla, Astrophys. J. Lett. 704,\n\nL40 (2009), arXiv:0904.2577 [gr-qc].\n[115] A. Sesana, Phys. Rev. Lett. 116, 231102 (2016),\n\narXiv:1602.06951 [gr-qc].\n[116] Z. Carson and K. Yagi, Phys. Rev. D 101, 044047\n\n(2020), arXiv:1911.05258 [gr-qc].\n[117] S. Kawamura et al., Class. Quant. Grav. 28, 094011\n\n(2011).\n[118] R. Brito, A. Buonanno, and V. Raymond, Phys. Rev.\n\nD 98, 084038 (2018), arXiv:1805.00293 [gr-qc].\n[119] H. Yang, K. Yagi, J. Blackman, L. Lehner, V. Pascha-\n\nlidis, F. Pretorius, and N. Yunes, Phys. Rev. Lett. 118,\n161101 (2017), arXiv:1701.05808 [gr-qc].\n\n[120] G. Carullo et al., Phys. Rev. D 98, 104020 (2018),\narXiv:1805.04760 [gr-qc].\n\nhttps://centra.tecnico.ulisboa.pt/network/grit/files/ringdown/\nhttps://centra.tecnico.ulisboa.pt/network/grit/files/ringdown/\nhttp://dx.doi.org/10.1103/PhysRevD.90.124032\nhttp://dx.doi.org/10.1103/PhysRevD.90.124032\nhttp://arxiv.org/abs/1404.3197\nhttp://dx.doi.org/10.1103/PhysRevLett.109.141102\nhttp://arxiv.org/abs/1207.0399\nhttp://arxiv.org/abs/1207.0399\nhttp://dx.doi.org/ 10.1103/PhysRevD.84.124052\nhttp://dx.doi.org/ 10.1103/PhysRevD.84.124052\nhttp://arxiv.org/abs/1106.1021\nhttp://dx.doi.org/10.1103/PhysRevD.104.024030\nhttp://dx.doi.org/10.1103/PhysRevD.104.024030\nhttp://arxiv.org/abs/2101.07817\nhttp://dx.doi.org/10.1088/0004-637X/704/1/L40\nhttp://dx.doi.org/10.1088/0004-637X/704/1/L40\nhttp://arxiv.org/abs/0904.2577\nhttp://dx.doi.org/10.1103/PhysRevLett.116.231102\nhttp://arxiv.org/abs/1602.06951\nhttp://dx.doi.org/10.1103/PhysRevD.101.044047\nhttp://dx.doi.org/10.1103/PhysRevD.101.044047\nhttp://arxiv.org/abs/1911.05258\nhttp://dx.doi.org/10.1088/0264-9381/28/9/094011\nhttp://dx.doi.org/10.1088/0264-9381/28/9/094011\nhttp://dx.doi.org/10.1103/PhysRevD.98.084038\nhttp://dx.doi.org/10.1103/PhysRevD.98.084038\nhttp://arxiv.org/abs/1805.00293\nhttp://dx.doi.org/10.1103/PhysRevLett.118.161101\nhttp://dx.doi.org/10.1103/PhysRevLett.118.161101\nhttp://arxiv.org/abs/1701.05808\nhttp://dx.doi.org/10.1103/PhysRevD.98.104020\nhttp://arxiv.org/abs/1805.04760\n\n\t The landscape of massive black-hole spectroscopy with LISA and Einstein Telescope \n\tAbstract\n\tI Introduction\n\tII Exploring the MBH population in the context of ringdown\n\tA MBH population models\n\tB MBH population in the context of BH spectroscopy\n\n\tIII Framework\n\tA Computation of measurement uncertainties\n\tB Detectability, resolvability, and measurability\n\n\tIV Ringdown tests with LISA\n\tA Summary on prospects of no-hair theorem tests with LISA\n\t1 Heavy seed models\n\t2 Light seed models\n\n\tB BH spectroscopy with LISA by measuring 3 or more QNM parameters\n\tC BH spectroscopy with LISA by measuring less than 3 parameters\n\n\tV Ringdown test with ET\n\tA Summary on prospects of no-hair theorem tests with ET\n\tB BH spectroscopy with ET by measuring 3 or more QNM parameters\n\tC BH spectroscopy with ET by measuring less than 3 parameters\n\n\tVI Discussion\n\t Acknowledgments\n\t References\n\n\n"}
{"Title": "Q-balls with Multiple Charges and Cores", "Authors": "Olivier Lennon", "Abstract": "  Q-balls -- whether in the single-field or multi-field context -- are usually studied in theories containing only one stabilising symmetry. However, this is not the most general scenario. In this paper, we study a class of theories with multiple symmetries. We consider both the traditional thin- and thick-wall limits of these theories, deriving sufficient conditions for existence in the latter case. Moreover, we also introduce a new state that could exist in this class of theory -- a cored Q-ball. We show that this new state can be energetically stable, but leave a detailed phenomenological study to later work.      ", "Subject": "High Energy Physics - Phenomenology (hep-ph)", "ID": "arXiv:2201.00024", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrepared for submission to JHEP OUTP-21-31P\n\nQ-balls with Multiple Charges and Cores\n\nOlivier Lennon\n\nRudolf Peierls Centre for Theoretical Physics, University of Oxford, Clarendon Laboratory, Parks\n\nRoad, Oxford OX1 3PU, United Kingdom\n\nE-mail: olivier.lennon@physics.ox.ac.uk\n\nAbstract: Q-balls \u2013 whether in the single-field or multi-field context \u2013 are usually studied\n\nin theories containing only one stabilising symmetry. However, this is not the most general\n\nscenario. In this paper, we study a class of theories with multiple symmetries. We con-\n\nsider both the traditional thin- and thick-wall limits of these theories, deriving sufficient\n\nconditions for existence in the latter case. Moreover, we also introduce a new state that\n\ncould exist in this class of theory \u2013 a cored Q-ball. We show that this new state can be\n\nenergetically stable, but leave a detailed phenomenological study to later work.\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n4v\n1 \n\n [\nhe\n\np-\nph\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\nmailto:olivier.lennon@physics.ox.ac.uk\n\n\nContents\n\n1 Introduction 1\n\n2 Multi-Charged Q-balls 3\n\n2.1 Minimising the Energy in a Sector of Fixed Charge 3\n\n2.2 Thin-Wall Q-balls 5\n\n2.3 Thick-Wall Q-balls 7\n\n3 Cored Q-balls 9\n\n3.1 Q-balls in the Background of Another Field 9\n\n3.1.1 The Minimisation Procedure 10\n\n3.1.2 The Thick-Wall Limit 11\n\n3.2 Cored Q-balls 13\n\n4 Summary 15\n\nA Thin-Wall Q-balls in the Background of Another Field 16\n\n1 Introduction\n\nThe states with the lowest mass-to-charge ratio that exist in many theories of complex\n\nscalar fields are referred to as Q-balls [1]. These objects are an example of a non-topological\n\nsoliton [2]. These semi-classical objects are kept stable by a combination of energy and\n\nNoether charge conservation. Usually, this charge is taken to correspond to be some global\n\nU(1) symmetry, but the analysis has been extended to accommodate more complicated\n\nsymmetry groups [3], or even gauging the symmetry [4, 5].\n\nFinding the functional form of these states is a complex process that involves extrem-\n\nising the energy functional of the theory. This is not analytically tractable in the most\n\ngeneral of theories. However, analytic limits do exist and can be studied. These are the\n\nfamiliar thin- and thick-wall limits [1, 6], with language borrowed from the mathematically\n\nsimilar study of bounce equations [7\u20139]. These descriptions are valid in the limits of large\n\nand small charge, respectively. Not every theory that possesses an energetically stable\n\nthin-wall limit has a stable thick-wall limit [10\u201312], implying that there is some gap over\n\nwhich enough charge must accumulate before stability is achieved. Recently, work has been\n\ndone in Ref. [13] to analytically extend the thin-wall limit to smaller charges.\n\nQ-balls are theoretically interesting objects in their own right. However, they also are\n\ninteresting phenomenological objects. Due to their stability, they are often considered as\n\n\u2013 1 \u2013\n\n\n\ncandidates for the perceived dark matter in our universe [14\u201317]. They could also appear\n\nin supersymmetric extensions to the standard model [14, 18], and have been studied in\n\nthe context of extra dimensions [19, 20]. Despite not being yet seen in experiments, it is\n\nbelieved that Q-balls will have striking signals [21\u201323].\n\nThe previous works on single-field theories \u2013 with canonical [1] and non-canonical [12]\n\nkinetic terms \u2013 or multi-field theories \u2013 either coupling a charged field to an arbitrary\n\nnumber of scalars [24, 25], or coupling multiple fields charged under the same symmetry [18]\n\n\u2013 do not represent the most general of theories. One can generalise these ideas further\n\nto incorporate multiple symmetries into the theory. Under these circumstances, Q-balls\n\nemerge with properties that are different than those from simpler sectors. This work does\n\nnot represent an exhaustive list of all structures that can exist in this kind of theory, but\n\nwe hope that it can be the beginning of work towards such a list. One such structure \u2013 a\n\n\u201cbarnacled Q-ball\u201d in the same vein as \u201cbounces with barnacles\u201d studied in Refs. [26\u201328]\n\n\u2013 will be returned to in future work.\n\nIn Section 2.1, we outline the class of theory of study of this paper. The most straight-\n\nforward example is a multi-field theory in which each scalar transforms non-trivially under\n\nits own symmetry, and is a singlet under all others \u2013 in some sense, this is similar to\n\nmultiple copies of a single-field theory. The key to this analysis is then the requirement\n\nthat the potential associated to a single field does not admit Q-ball solutions, and that\n\nstability is only achieved due to the couplings between the fields. We then perform the\n\nminimisation procedure analogously to the previous Q-ball works. In Section 2.2, we per-\n\nform the thin-wall analysis. We determine the differential equation governing the value of\n\nthe vacuum expectation value (VEV) of the fields inside the resultant Q-ball. Contrary\n\nto previous findings, we find that this condition is dependent on the total number of each\n\nof the quanta that comprise the Q-ball \u2013 previously, these equations have been charge-\n\nindependent. In Section 2.3, we perform the thick-wall analysis, once again making use of\n\nthe assumption that all fields have the same spatial profile up to a positive semi-definite\n\nnormalisation constant. Under this assumption, we produce sufficient constraints on the\n\ntheories that may possess a thick-wall limit. Interestingly, despite the added complexity in\n\nthe analysis, we find the same result as for single-field theories \u2013 that the next-to-quadratic\n\nterm must have have an index p such that 2 < p < 10/3. This result certainly adds to the\n\nidea that this scenario is similar to multiple copies of a single field theory.\n\nIn Section 3, we close out this work with a predominantly heuristic discussion of a\n\nnew structure within multi-field theories: a cored Q-ball. We envisage a thin-wall Q-ball\n\nin one field which possesses a core composed of a thick-wall Q-ball of another field that is\n\nstabilised precisely in the homogeneous VEV of the larger Q-ball.1 Each field is stabilised\n\n1In principle, these objects are a subclass of \u201cspeckled\u201d Q-balls, whereby the larger Q-ball is populated\nby many smaller ones throughout its core \u2013 this is beyond this work, but is an interesting avenue of research\nfor the future. This is an interesting addition to the consideration of Q-balls that interact with other fields.\n\n\u2013 2 \u2013\n\n\n\nby its own global U(1) symmetry, and so this structure is in principle stable. We first\n\nconsider the scenario whereby one field exists in the background VEV of another. We seek\n\nQ-ball solutions that are stabilised precisely due to this background VEV. We perform\n\nthe thick-wall analysis in this scenario, but we note that the calculation proceeds precisely\n\nas it would for the single-field case.2 We include these calculations here for completeness\n\nand for introducing the notation in the rest of the section. We then consider the case\n\nwhen the background VEV is provided by a large, thin-wall Q-ball. We then merely seek\n\nto see whether a cored Q-ball is a stable structure. This leads to two inequalities to be\n\nsatisfied: the first arises from the requirement that the Q-ball be stable against decay into\n\nthe individual quanta of both fields; the second arises from the demand that the core be\n\nsmaller than the Q-ball that houses it. These requirements are model-dependent.\n\n2 Multi-Charged Q-balls\n\nWe begin this work by analysing the most straightforward example of a multi-field theory\n\nwith multiple stabilising symmetries \u2013 when each of the fields is charged under its own\n\nsymmetry.\n\n2.1 Minimising the Energy in a Sector of Fixed Charge\n\nWe consider a theory of N complex scalars, \u03a6i(~x, t). The Lagrangian density describing\n\nthe theory is given by\n\nL =\n\nN\u2211\ni\n\n\u2202\u00b5\u03a6i\u2202\n\u00b5\u03a6\u2217\n\ni \u2212 U(\u03a6i,\u03a6\n\u2217\ni ), (2.1)\n\nwhere U(\u03a6i,\u03a6\n\u2217\ni ) is some generic potential that is a function of the fields only, and not their\n\nderivatives, and vanishes for vanishing field. The Euler-Lagrange equations for this theory\n\nare\n\n\u2202\u00b5\u2202\n\u00b5\u03a6i +\n\n\u2202U\n\n\u2202\u03a6\u2217\ni\n\n= 0, (2.2)\n\nwith a similar equation governing the dynamics of \u03a6\u2217\ni .\n\nWe demand that the theory be invariant under an N -fold global symmetry,\n\nU(1)N = U(1)1 \u00d7 U(1)2 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 U(1)N , (2.3)\n\nthat is, N independent U(1) symmetries. We consider here the special case that each field\n\n\u03a6i is charged under its own independent U(1) symmetry and is uncharged under all other\n\nThis line of thinking has obvious similarities to theories with multiple vacua in the early universe such that\nthe vacuum bubbles develop \u201cbarnacles\u201d of other vacua \u2013 see Refs. [26\u201328].\n\n2For completeness, we include the thin-wall analysis as an appendix to this paper.\n\n\u2013 3 \u2013\n\n\n\nU(1) symmetries. For each U(1), its corresponding field transforms as\n\n\u03a6i \u2192 eiqi\u03b1\u03a6i, (2.4)\n\nwhere \u03b1 \u2208 R and qi is the charge of the i-th species of complex scalar under the i-th U(1)\n\nsymmetry. Associated to each U(1) symmetry is a Noether current density given by\n\nj\u00b5i = iqi (\u03a6i\u2202\n\u00b5\u03a6\u2217\n\ni \u2212 \u03a6\u2217\ni \u2202\n\n\u00b5\u03a6i) . (2.5)\n\nThis symmetry places the constraint on the potential that it be a function of the absolute\n\nvalue of the individual fields. We further demand that this potential does not support\n\nQ-balls if all but one of the fields vanish: otherwise, this system reduces to that of the\n\nsingle-field case as first discussed in Ref. [1]. We thus assume that the field content is the\n\nminimal set of fields, greater than a single field, required to support a Q-ball state.\n\nA Q-ball is the state in a theory which minimises the energy per unit charge. The\n\nHamiltonian for this theory is\n\nH =\n\n\u222b\nd3x\n\n[\nN\u2211\ni\n\n(\n\u03a6\u0307i\u03a6\u0307\n\n\u2217\ni + ~\u2207\u03a6i \u00b7 ~\u2207\u03a6\u2217\n\ni\n\n)\n+ U(\u03a6i,\u03a6\n\n\u2217\ni )\n\n]\n. (2.6)\n\nTo determine if this system admits Q-ball solutions, we introduce a set of Lagrange multi-\n\npliers, {\u03c9k}, similar to Ref. [18], that each enforce charge conservation upon minimisation\n\nwith respect to them:\n\nE\u03c9 = H +\n\nK\u2211\nk\n\n\u03c9k\n\n(\nQk \u2212\n\n\u222b\nd3x j0\n\nk\n\n)\n, (2.7)\n\nwhere j0\nk is the zeroth component of the Noether current density associated to the k-th\n\nU(1) symmetry given in Eq. (2.5). Thus, the functional we wish to analyse is given by\n\nE\u03c9 =\nN\u2211\ni\n\n\u03c9iQi\n\n+\n\n\u222b\nd3x\n\n[\nN\u2211\ni\n\n(\n\u03a6\u0307i\u03a6\u0307\n\n\u2217\ni \u2212 i\u03c9iqi\n\n(\n\u03a6i\u03a6\u0307\n\n\u2217\ni \u2212 \u03a6\u2217\n\ni \u03a6\u0307i\n\n)\n+ ~\u2207\u03a6i \u00b7 ~\u2207\u03a6\u2217\n\ni\n\n)\n+ U(\u03a6i,\u03a6\n\n\u2217\ni )\n\n]\n.\n\n(2.8)\n\nWe may complete the square on the first two terms under the integral to give\n\nE\u03c9 =\nN\u2211\ni\n\n\u03c9iQi\n\n+\n\n\u222b\nd3x\n\n[\nN\u2211\ni\n\n(\u2223\u2223\u2223\u03a6\u0307i \u2212 i\u03c9iqi\u03a6i\n\n\u2223\u2223\u22232 + ~\u2207\u03a6i \u00b7 ~\u2207\u03a6\u2217\ni \u2212 \u03c92\n\ni q\n2\ni \u03a6\n\n\u2217\ni\u03a6i\n\n)\n+ U(\u03a6i,\u03a6\n\n\u2217\ni )\n\n]\n.\n\n(2.9)\n\n\u2013 4 \u2013\n\n\n\nThe terms containing derivatives with respect to time are the only terms with explicit time\n\ndependence. These are positive semi-definite and are minimised if they vanish. Thus, we\n\nrequire, for each species of scalar, that\n\n\u03a6i(~x, t) = ei\u03c9iqit\u03c6i(~x), (2.10)\n\nwhere \u03c6i(~x) are functions purely of the spatial coordinate which we take, without loss of\n\ngenerality, to be real-valued. The energy functional is then\n\nE\u03c9 =\nN\u2211\ni\n\n\u03c9iQi +\n\n\u222b\nd3x\n\n[\nN\u2211\ni\n\n(\n~\u2207\u03c6i \u00b7 ~\u2207\u03c6i \u2212 \u03c92\n\ni q\n2\ni \u03c6\n\n2\ni\n\n)\n+ U(\u03c6i)\n\n]\n. (2.11)\n\nNotice that spatial profiles for the \u03c6i that vanish everywhere lead to a configuration of zero\n\ncharge. Thus, a configuration of non-zero charge must have spatial profiles for the charged\n\nfields that differs from zero in some finite domain. The spatial profiles satisfy the equations\n\n\u22072\u03c6i =\n1\n\n2\n\n\u2202\n\n\u2202\u03c6i\n\n(\nU(\u03c6i)\u2212 \u03c92\n\ni q\n2\ni \u03c6\n\n2\ni\n\n)\n. (2.12)\n\nThese differential equations take the form of a bounce equation [7\u20139], under the potentials\n\ngiven by U(\u03c6i, \u03c8i)\u2212\u03c92q2\ni \u03c6\n\n2\ni . The lowest energy configurations are known to be spherically\n\nsymmetric [9], under the boundary conditions of the field vanishing at spatial infinity, and\n\nbeing constant at the coordinate origin, and the first derivative vanishing at spatial infinity\n\nand the coordinate origin.\n\nThese coupled differential equations cannot, in general, be solved analytically. How-\n\never, under certain assumptions, analytic progress can be made. Namely, in analogy\n\nwith the discussion in Ref. [6], for stable Q-ball solutions to be found, we require that\n\n\u03c9i,0 \u2264 \u03c9i < mi/qi, where mi is the mass of the i-th complex scalar. The thin-wall limit\n\ncorresponds to the limit that \u03c9i = \u03c9i,0 \u2013 in fact, the thin-wall limit defines \u03c9i,0. The\n\nthick-wall limit corresponds to the limit qi\u03c9i \u2192 m\u2212\ni .\n\n2.2 Thin-Wall Q-balls\n\nQ-balls in the thin-wall limit are characterised by a spherical, homogeneous core and a\n\nthin-shell through which the field interpolates between its core and vacuum values. The\n\nQ-ball properties are then well-approximated by those of the core. In this regime, we have\n\nthat\n\nE\u03c9 \u2248\nN\u2211\ni\n\n\u03c9iQi + V\n\n[\nU(\u03c6i)\u2212\n\nN\u2211\ni\n\n\u03c92\ni q\n\n2\ni \u03c6\n\n2\ni\n\n]\n. (2.13)\n\nMinimisation of this expression with respect to each of the \u03c9k yields\n\nQk = 2\u03c9kV q\n2\nk\u03c6\n\n2\nk, (2.14)\n\n\u2013 5 \u2013\n\n\n\nas would be expected from the Noether current density given in Eq. (2.5). Eliminating the\n\nLagrange multipliers from the energy yields\n\nE =\n1\n\n4V\n\nN\u2211\ni\n\nQ2\ni\n\nq2\ni \u03c6\n\n2\ni\n\n+ U(\u03c6i)V. (2.15)\n\nMinimisation with respect to the volume gives us that\n\nV 2 =\n1\n\n4U(\u03c6i)\n\nN\u2211\ni\n\nQ2\ni\n\nq2\ni \u03c6\n\n2\ni\n\n, (2.16)\n\nwhich, upon substitution, finally gives us that\n\nmQ =\n\n\u221a\u221a\u221a\u221aU(\u03c6i)\n\nN\u2211\ni\n\nQ2\ni\n\nq2\ni \u03c6\n\n2\ni\n\n. (2.17)\n\nThis expression must be minimised with respect to the field content subject to the condition\n\nmQ <\nN\u2211\ni\n\nQi\nqi\nmi, (2.18)\n\nwhere mi are the masses of the quanta associated to the field \u03c6i. This ensures that these\n\nQ-balls are classically stable against evaporation into the field content. The result of this\n\nminimisation is the constraint on the potential:\n\n\u2202U(\u03c6i)\n\n\u2202\u03c6k\n\nN\u2211\ni\n\nQ2\ni\n\nq2\ni \u03c6\n\n2\ni\n\n= 2\nQ2\nk\n\nq2\nk\u03c6\n\n3\nk\n\nU(\u03c6i). (2.19)\n\nSince this must be true for all k, we therefore find that\n\n\u2202U(\u03c6i)\n\n\u2202\u03c6j\n\nq2\nj\u03c6\n\n3\nj\n\nQ2\nj\n\n=\n\u2202U(\u03c6i)\n\n\u2202\u03c6k\n\nq2\nk\u03c6\n\n3\nk\n\nQ2\nk\n\n. (2.20)\n\nNote, for the single field case \u2013 for a field with unit charge \u2013 the rest mass of a Q-ball\n\nis given simply by\n\nmQ = Q\n\n\u221a\nU(\u03c6)\n\n\u03c62\n, (2.21)\n\nwhere \u03c6 satisfies\ndU(\u03c6)\n\nd\u03c6\n= 2\n\nU(\u03c6)\n\n\u03c6\n. (2.22)\n\nIn the single-field case, the VEV of the field inside the core is independent of the charge\n\nof the Q-ball. As the field has unit charge, this means that it is independent of the total\n\n\u2013 6 \u2013\n\n\n\nnumber of quanta which make up the Q-ball.3 However, in the multi-symmetry case above,\n\nwe note that the VEVs of the fields inside the Q-ball do depend on the total number of\n\nquanta (as Ni = Qi/qi). This is in stark contrast to the known Q-ball cases. As the mass\n\nof the core does not simply scale with particle number, we must conclude that it is not\n\ncomposed of ordinary Q-matter.\n\n2.3 Thick-Wall Q-balls\n\nWe now consider the thick-wall limit of this theory. This corresponds to the small-field limit\n\nof the field theory, as discussed at length in Ref. [6]. Thus, we will perform a small-field\n\nexpansion on the function denoting the potential to proceed analytically.\n\nAs in the multi-field case with only a single symmetry [11, 25, 29], this theory suffers\n\nfrom the fact that it is not analytically tractable due to the number of fields. As in earlier\n\nworks, this problem must be circumvented by assuming that all the spatial profiles of the\n\nfields are the same up to some semi-positive-definite normalisation constant \u2013 we must then\n\nminimise the energy with respect to each of these normalisation constants. We thus write\n\nthat\n\n\u03c6i = \u03b1i\u03c6, (2.23)\n\nwhere \u03c6 \u2208 {\u03c6i} is some reference field \u2013 it does not affect the analysis in this case which\n\nfield is used. The purpose of this ansatz is to provide sufficient conditions for the existence\n\nof thick-wall Q-balls in this class of multi-field theories, as well as to provide approximate\n\nvalues for the Q-ball properties. In reality, the spatial profiles of the fields might differ, but\n\nthis extra freedom in the minimisation process can only further lower the Q-ball energy. To\n\nprovide necessary conditions for the thick-wall limit, we must pursue a dedicated numerical\n\nanalysis of the true spatial profiles of all individual fields. Since we have effectively reduced\n\nour multi-field system into one of a single-field, we expect to find results similar to those\n\nin Ref. [10\u201312]. We will thus be unsurprised when this does indeed happen below.\n\nGiven this approximation scheme, the full bounce potential can be written in the small\n\nfield limit as\n\nU\u2126(\u03c6, \u03b1i) \u2248\n\n[\nN\u2211\ni\n\n\u03b12\nim\n\n2\ni (1\u2212 \u21262\n\ni )\n\n]\n\u03c62 \u2212 g(\u03b1i)\u03c6\n\np, (2.24)\n\nwhere p > 2 and we have defined\n\n\u2126i \u2261\nqi\u03c9i\nmi\n\n, (2.25)\n\nwith \u2126i \u2208 (0, 1), such that the coefficient of the quadratic term is always positive. The\n\nfunction g(\u03b1i) is model-dependent and we leave it general apart from the fact that it must\n\nbe positive definite for the potential to allow Q-ball solutions. We have omitted the next\n\nterm in the series, but it is assumed that it is positive definite and stabilises the potential\n\n3This is also true in the single-symmetry multi-field case, both when there is only a single charged\nscalar [25] and when there are multiple fields charged under the same symmetry [18].\n\n\u2013 7 \u2013\n\n\n\nat high field values. The energy in Eq. (2.11) is then\n\nE\u03c9 =\nN\u2211\ni\n\nmi\u2126i\nQi\nqi\n\n+\n\n\u222b\nd3x\n\n[\nN\u2211\ni\n\n\u03b12\ni\n\n(\n~\u2207\u03c6 \u00b7 ~\u2207\u03c6+m2\n\ni (1\u2212 \u21262\ni )\u03c6\n\n2\n)\n\u2212 g(\u03b1i)\u03c6\n\np\n\n]\n. (2.26)\n\nWe wish to render the integral dimensionless. To do so, we define the dimensionless vari-\n\nables\n\n\u03d5 \u2261 \u03c6\n\n[\ng(\u03b1i)\u2211N\n\ni \u03b1\n2\nim\n\n2\ni (1\u2212 \u21262\n\ni )\n\n]1/(p\u22122)\n\nand \u03bei \u2261 xi\n\n[\u2211N\ni \u03b1\n\n2\nim\n\n2\ni (1\u2212 \u21262\n\ni )\u2211N\ni \u03b1\n\n2\ni\n\n]1/2\n\n. (2.27)\n\nThe functional of study is then given by\n\nE\u03c9 =\n\nN\u2211\ni\n\nmi\u2126i\nQi\nqi\n\n+\nS\u03d5\n\ng(\u03b1i)2/(p\u22122)\n\n[\nN\u2211\ni\n\n\u03b12\ni\n\n]3/2 [ N\u2211\ni\n\n\u03b12\nim\n\n2\ni (1\u2212 \u21262\n\ni )\n\n](6\u2212p)/(2p\u22124)\n\n, (2.28)\n\nwhere S\u03d5 is a dimensionless integral, defined as\n\nS\u03d5 =\n\n\u222b\nd3\u03be\n\n[\n~\u2207\u03be\u03d5 \u00b7 ~\u2207\u03be\u03d5+ \u03d52 \u2212 \u03d5p\n\n]\n. (2.29)\n\nFor different values of p, this has been numerically minimised in Ref. [30], with the general\n\ntrend being that S\u03d5 increases for increasing p. This expression must be minimised with\n\nrespect to the {\u2126i} and {\u03b1i}. Without specifying the model, it is difficult to make progress.\n\nHowever, as in previous work [10\u201312, 25], we can place limits on the theories that can house\n\nQ-ball states.\n\nWe minimise the above function in Eq. (2.28) with respect to some \u2126k. This yields\n\nthe condition\n\nQk\nqk\u03b1\n\n2\nkmk\u2126k\n\n=\nS\u03d5\n\ng(\u03b1i)2/(p\u22122)\n\n[\n6\u2212 p\np\u2212 2\n\n][ N\u2211\ni\n\n\u03b12\ni\n\n]3/2 [ N\u2211\ni\n\n\u03b12\nim\n\n2\ni (1\u2212 \u21262\n\ni )\n\n](10\u22123p)/(2p\u22124)\n\n. (2.30)\n\nNotice, the left hand-side is k-dependent, but the right-hand side is not. Since this condition\n\nholds for all k, we can readily write\n\nQk\nqk\u03b1\n\n2\nkmk\u2126k\n\n=\nQi\n\nqi\u03b12\nimi\u2126i\n\n(2.31)\n\nfor all k, i \u2208 {1, \u00b7 \u00b7 \u00b7 , N}. Given that \u03b1 = 1 for, say, the field \u03c61, we have that\n\n\u03b12\nk =\n\nq1\n\nQ1\n\nQk\nqk\n\nm1\n\nmk\n\n\u21261\n\n\u2126k\n, (2.32)\n\nand so \u03b1 is now defined for all fields in the theory.\n\n\u2013 8 \u2013\n\n\n\nUsing our above condition for minimisation, we can rewrite Eq. (2.28) as\n\nE\u03c9 =\nN\u2211\ni\n\nmi\u2126i\nQi\nqi\n\n+\nQk\n\nqk\u03b1\n2\nkmk\u2126k\n\n[\np\u2212 2\n\n6\u2212 p\n\n][ N\u2211\ni\n\n\u03b12\ni\n\n]3/2 [ N\u2211\ni\n\n\u03b12\nim\n\n2\ni (1\u2212 \u21262\n\ni )\n\n]\n. (2.33)\n\nAt its minimum, this expression must satisfy\n\nE\u03c9 <\nN\u2211\ni\n\nQi\nqi\nmi (2.34)\n\nin order for the resulting Q-balls to be classically stable against decay to the constituent\n\nquanta of the complex scalar fields. From Eq. (2.31), we see that we can write\n\nN\u2211\ni\n\nmi\u2126i\nQi\nqi\n\n=\nQk\n\nqk\u03b1\n2\nkmk\u2126k\n\nN\u2211\ni\n\n\u03b12\nim\n\n2\ni\u2126\n\n2\ni , (2.35)\n\nand\nN\u2211\ni\n\nQi\nqi\nmi =\n\nQk\nqk\u03b1\n\n2\nkmk\u2126k\n\nN\u2211\ni\n\n\u03b12\nim\n\n2\ni\u2126i. (2.36)\n\nThus, our condition on the minimum becomes\n\nN\u2211\ni\n\n\u03b12\nim\n\n2\ni\n\n[\n\u21262\ni +\n\n(\np\u2212 2\n\n6\u2212 p\n\n)\n(1\u2212 \u21262\n\ni )\u2212 \u2126i\n\n]\n< 0. (2.37)\n\nFor this condition to hold, we necessarily require that that term in brackets be negative for\n\nsome i in the range \u2126 \u2208 (0, 1). However, this is nothing more than the same requirement\n\non the canonical single-field case \u2013 see Ref. [12]. We thus infer that, for stable thick-wall\n\nQ-balls to form in this theory, we must have that 2 < p < 10/3.\n\n3 Cored Q-balls\n\nWe now turn our attention to another type of Q-ball that can plausibly exist in multi-field\n\ntheories with multiple global symmetries. We refer to these as \u201ccored Q-balls\u201d. In this\n\nsection, we merely show that these objects can be classically stable against decay into\n\nconstituent quanta.\n\n3.1 Q-balls in the Background of Another Field\n\nA key component of this section is the idea of a Q-ball stabilised in the background of\n\nanother field. We therefore formulate this idea for a background VEV extending over all\n\nspace.\n\n\u2013 9 \u2013\n\n\n\n3.1.1 The Minimisation Procedure\n\nConsider the N = 2 case of the Lagrangian given in Eq. (2.1). We write the potential of\n\nthis theory as\n\nU(\u03a61,\u03a62) = f(\u03a61) + g(\u03a62) + h(\u03a61,\u03a62), (3.1)\n\nwhere it is understood that h contains all terms that couple the two fields together. We\n\nassume that the field \u03a61 acquires some constant VEV \u2013 in this subsection, we leave the\n\nmethod of acquisition of this VEV open, but in the next subsection, we will assume that\n\nit comes after the formation of a thin-wall Q-ball. We thus seek Q-ball solutions for the\n\nfield \u03a62 in this constant background. Furthermore, this constant background will merely\n\nchange the coefficients of the field \u03a62 by constant amounts, and so this analysis will proceed\n\nexactly as for a single-field system. For definiteness, we perform the analysis below.\n\nThe energy of a configuration of \u03a62 in the background of \u03c6\u03041 is\n\nH =\n\n\u222b\nd3x\n\n[\n\u03a6\u03072\u03a6\u0307\u2217\n\n2 + ~\u2207\u03a62 \u00b7 ~\u2207\u03a6\u2217\n2 + g(\u03a62) + h(\u03c6\u03041,\u03a62)\n\n]\n. (3.2)\n\nA Q-ball is a state that minimises the energy for a given charge and so we introduce a\n\nLagrange multiplier, \u03c92, that ensures charge conservation upon minimisation with respect\n\nto it. The functional we wish to analyse is then\n\nE\u03c9 = H + \u03c92\n\n(\nQ2 \u2212\n\n\u222b\nd3x j0\n\n2\n\n)\n, (3.3)\n\nwhere j0\n2 is the zeroth component of the Noether current density associated to the U(1)2\n\nsymmetry,\n\nj0\n2 = iq2\n\n(\n\u03a6\u0307\u2217\n\n2\u03a62 \u2212 \u03a6\u2217\n2\u03a6\u03072\n\n)\n. (3.4)\n\nWe may thus rewrite our functional of study as\n\nE\u03c9 =\n\n\u222b\nd3x\n\n[\u2223\u2223\u2223\u03a6\u03072 \u2212 i\u03c92q2\u03a62\n\n\u2223\u2223\u22232 + ~\u2207\u03a62 \u00b7 ~\u2207\u03a6\u2217\n2 + g(\u03a62) + h(\u03c6\u03041,\u03a62)\u2212 \u03c92\n\n2q\n2\n2\u03a6\u2217\n\n2\u03a62\n\n]\n+ \u03c92Q2.\n\n(3.5)\n\nNote, the term containing explicit time-dependence is positive semi-definite. This is there-\n\nfore minimised when it vanishes, i.e., if\n\n\u03a62(~x, t) = ei\u03c92q2t\u03c62(~x), (3.6)\n\nwhere we take the spatial profile to be real-valued, without loss of generality. Reinsertion\n\nof this into the functional of study leads to\n\nE\u03c9 = \u03c92Q2 +\n\n\u222b\nd3x\n\n[\n~\u2207\u03c62 \u00b7 ~\u2207\u03c62 + g(\u03c62) + h(\u03c6\u03041, \u03c62)\u2212 \u03c92\n\n2q\n2\n2\u03c6\n\n2\n2\n\n]\n. (3.7)\n\n\u2013 10 \u2013\n\n\n\nMinimisation with respect to the spatial profile yields a differential equation governing\n\na \u201cbounce\u201d solution associated to the formation of vacuum bubbles during phase transi-\n\ntions [7\u20139]. These equations are well-studied and, for a set of boundary conditions appro-\n\npriate for Q-balls, are known to yield spherically symmetric solutions for the lowest energy\n\nconfigurations.\n\n3.1.2 The Thick-Wall Limit\n\nWe now pursue the thick-wall limit of this analysis, which is also known as the small field\n\nlimit.4 In principle, we could also form thin-wall Q-balls in the background of another field\n\n\u2013 this will not be relevant to the discussion of cored Q-balls, but we include the analysis\n\nin Appendix A for completeness.\n\nTo proceed in the thick-wall limit, we expand \u03c62 to its lowest order terms. As stated\n\nabove, this analysis is essentially identical to a single field case and so is bound by the\n\nrequirement that the next-to-quadratic term must be cubic in the bounce potential \u2013 see\n\nRefs. [10\u201312]. We thus assume that this term exists. We therefore have, in the small-field\n\nlimit, that\n\ng(\u03c62) + h(\u03c6\u03041, \u03c62) \u2248\n(\n\u00b52 + h2(\u03c6\u03041)\n\n)\n\u03c62\n\n2 \u2212\n(\nh3(\u03c6\u03041)\u2212A\n\n)\n\u03c63\n\n2, (3.8)\n\nwhere h2(\u03c6\u03041) and h3(\u03c6\u03041) are the components, functionally dependent on \u03c6\u03042, of the terms\n\nquadratic and cubic in \u03c62 contained within h(\u03c6\u03041, \u03c62), respectively, and similarly for \u00b52 and\n\nA in g(\u03c62). We assume that some positive definite term of a higher order exists to stabilise\n\nthe potential at large field. In this scenario, a Q-ball may only form if the coefficients of\n\nthe quadratic and cubic terms are positive and negative, respectively:\n\n\u00b52 + h2(\u03c6\u03041) > 0 and h3(\u03c6\u03041)\u2212A > 0. (3.9)\n\nHowever, recall that we demanded that the pure \u03a62 potential could not support Q-ball\n\nsolutions. This sets A \u2265 0, hence the sign assignment on the cubic term.\n\nFor notational purposes, we will write the effective quadratic and cubic couplings in\n\nthe background as\n\n\u00b52\neff(\u03c6\u03041) \u2261 \u00b52 + h2(\u03c6\u03041) and Aeff(\u03c6\u03041) \u2261 h3(\u03c6\u03041)\u2212A, (3.10)\n\nnoting that both of these new parameters are positive definite. The bounce potential can\n\nnow be written in the familiar form,\n\nU\u03c9(\u03c6\u03041, \u03c62) \u2248 (\u00b52\neff \u2212 \u03c92\n\n2q\n2\n2)\u03c62\n\n2 \u2212Aeff\u03c6\n3\n2. (3.11)\n\nFor a barrier to form in the bounce potential, and thus for a bounce solution to exist \u2013 see\n\n4We note that \u201csmall-field\u201d here only relates to \u03c62, as it is from this that this Q-ball is being formed.\n\n\u2013 11 \u2013\n\n\n\nRef. [6] \u2013 we see that\n\n\u03c92\n2 <\n\n\u00b52\neff\n\nq2\n2\n\n, (3.12)\n\nwhich is the familiar requirement of Q-ball solutions. The thick-wall limit is thus equivalent\n\nto the limit \u03c92q2 \u2192 \u00b5\u2212eff .\n\nWe redefine the spatial coordinate and field by choosing\n\n\u03bei =\n(\n\u00b52\n\neff \u2212 \u03c92\n2q\n\n2\n2\n\n)1/2\nxi\n\n\u03c8 =\n(\n\u00b52\n\neff \u2212 \u03c92\n2q\n\n2\n2\n\n)\u22121\nAeff\u03c62.\n\n(3.13)\n\nOur functional of study thus reduces to\n\nE\u03c9 = \u00b53\neff\n\n(\n1\u2212 \u21262\n\n)3/2\nA2\n\neff\n\nS\u03c8 + \u03c92Q2, (3.14)\n\nwhere we have defined \u2126 \u2261 \u03c92q2/\u00b5eff and\n\nS\u03c8 =\n\n\u222b\nd3\u03be\n\n[\n~\u2207\u03be\u03c8 \u00b7 ~\u2207\u03be\u03c8 + \u03c82 \u2212 \u03c83\n\n]\n(3.15)\n\nis a dimensionless integral that may be minimised numerically. This has been numerically\n\nfound to be approximately 38.8 [30].\n\nA stable Q-ball in the background of \u03c6\u03041 is found when minimising this expression with\n\nrespect to \u2126 under the constraint that \u21262 < 1. If this constraint is not satisfied, it is more\n\nenergetically favourable for the quanta of \u03a62 to remain seperate within the background of\n\n\u03c6\u03041. This requirement leads us to the condition\n\n\u03b5 = \u2126(1\u2212 \u21262)1/2, (3.16)\n\nwhere we define\n\n\u03b5 \u2261 1\n\n3S\u03d5\n\nQ2\n\nq2\n\nA2\neff\n\n\u00b52\neff\n\n. (3.17)\n\nThe solution to this condition is that\n\n\u21262 =\n1 +\n\u221a\n\n1\u2212 4\u03b52\n\n2\n, (3.18)\n\nwhere 0 < \u03b5 < 1/2. The mass of the resulting Q-ball is then given by\n\nmQ = \u00b5eff\nQ2\n\nq2\n\n(\n1\u2212 1\n\n6\n\u03b52 +O(\u03b54)\n\n)\n. (3.19)\n\nWe note that\n\nmQ < \u00b5eff\nQ2\n\nq2\n, (3.20)\n\n\u2013 12 \u2013\n\n\n\nwhich is precisely the requirement for classical stability of this Q-ball within the background\n\nof \u03c6\u03041. The radius of the resulting Q-ball is given by \u03be \u223c 1, and so\n\nR\u22121 \u223c \u03b5\u00b5eff\n\n(\n1 +O\n\n(\n\u03b52\n))\n. (3.21)\n\nThis solution is also subject to the constraint that \u03b5 < 1/2, which translates to the\n\nrequirement on the charge that\nQ2\n\nq2\n< 58.2\n\n\u00b5eff\n\nA2\neff\n\n. (3.22)\n\nThe solution is also subject to the constraint that the higher order term that stabilises the\n\npotential is indeed small enough inside the Q-ball to ignore in our analysis \u2013 see Ref. [6]\n\nfor details.\n\n3.2 Cored Q-balls\n\nWe assume that the potential f(\u03a61) admits Q-balls composed of the field \u03a61. In the thin-\n\nwall limit, these Q-balls are spherically-symmetric, extended objects comprised of a large\n\ncore of homogeneous \u201cQ-matter\u201d, and a thin shell which interpolates between the core and\n\nthe vacuum of the theory. The VEV in the core is therefore the origin of the VEV of \u03a61\n\nin the previous subsection. The physical properties of the Q-ball \u2013 it\u2019s mass and volume \u2013\n\nare well-approximated by the properties of the core in this limit. Inside the Q-ball, where\n\nthe field is homogeneous, \u03a61 takes on the well-known functional form\n\n\u03a61(t) = eiq1\u03c9t\u03c6\u03041, (3.23)\n\nwhere \u03c6\u03041 \u2208 R. The rest mass and volume of the Q-ball are then given by\n\nmQ = Q1\n\n\u221a\nf(\u03c6\u03041)\n\nq2\n1\u03c6\n\n2\n1\n\nand V =\nQ1\n\n2\n\u221a\nq2\n\n1\u03c6\u0304\n2\n1f(\u03c6\u03041)\n\n, (3.24)\n\nwhere \u03c6\u03041 must satisfy\n\u2202f(\u03c6\u03041)\n\n\u2202\u03c6\u03041\n=\n\n2f(\u03c6\u03041)\n\n\u03c6\u03041\n, (3.25)\n\nsuch that E/Q1 must be less than the mass per unit charge of individual quanta of the \u03a61\n\nfield. It is in this way that these Q-balls are said to be classically stable.\n\nWe assume that, if anything, h(\u03a61,\u03a62) provides, at most, a small perturbation to this\n\nQ-ball solution. For definiteness, we assume that g(\u03a62) does not admit Q-ball solutions\n\nin isolation from \u03a61, and we further assume, for simplicity, that U(\u03a61,\u03a62) does not admit\n\nQ-balls charged under both symmetries when all terms are considered.\n\nNow, consider a configuration where a thin-wall Q-ball composed of \u03a61 is surrounded\n\nby quanta of the field \u03a62. The potential h(\u03a61,\u03a62) defines how these entities interact. Let\n\n\u2013 13 \u2013\n\n\n\nus consider an attractive potential such that the quanta of \u03a62 become bound within the\n\nQ-ball. We will only consider a small amount entering the Q-ball such that the value of \u03c6\u03041\n\nis still consistent with that defined above. Though the core of the Q-ball is, in principle,\n\nhomogeneous, the presence of the new quanta slightly breaks this homogeneity, and we\n\nexpect these to settle in the core of the Q-ball as this is the symmetric point of the Q-ball.5\n\nIf enough quanta are collected, it is reasonable to ask whether a Q-ball composed of\n\n\u03a62, in the background of \u03c6\u03041, can form. Moreover, if this Q-ball does not get too large, such\n\nthat the terms in h(\u03a61,\u03a62) greatly perturb the Q-ball background, it should not greatly\n\naffect the value of \u03c6\u03041. We will assume that the core is a thick-wall Q-ball, as this is more\n\nconsistent with our assumption that the new Q-ball does not overly affect the value of \u03c6\u03041,\n\nsince the VEV is smaller. We can take the results directly from the previous section.\n\nWe require that the whole system be energetically stable against classical decay to\n\nquanta of both fields. The total mass of the cored Q-ball is\n\nEtot =\nQ1\n\nq1\n\n\u221a\nf(\u03c6\u03041)\n\n\u03c6\u03042\n1\n\n+\nQ2\n\nq2\n\u00b5eff\n\n(\n1\u2212 1\n\n6\n\u03b52\n)\n. (3.26)\n\nFor this to be classically stable against decay to the quanta of both of the fields, we require\n\nthat\n\nEtot <\nQ1\n\nq1\nm+\n\nQ2\n\nq2\n\u00b5, (3.27)\n\nwhere m is the mass of quanta of the field \u03a61 and, as before, \u00b5 is the mass of the quanta\n\nof the field \u03a62 in the vacuum of the theory, \u03a61 = 0. Note that, the first term of the total\n\nenergy is less than the first term of this constraint. If \u00b5eff < \u00b5, then this constraint is\n\nsatisfied. If this is not true, then a sufficient condition is for6\n\n\u00b5eff\n\n(\n1\u2212 1\n\n6\n\u03b52\n)\n< \u00b5. (3.29)\n\nThis constraint, in terms of the charge of the thick-wall Q-ball, evaluates to\n\nQ2\n\nq2\n> 201.6\n\n\u221a\nh2(\u03c6\u03041)\n\n\u00b5eff\n\nA2\neff\n\n. (3.30)\n\nThis implies that, for this structure to be classically stable, there is a minimum charge\n\n5We could also consider the case that many thick-wall Q-balls form within the homogeneous background\nof the thin-wall Q-ball. However, we do not consider this \u201cspeckled\u201d Q-ball here.\n\n6The necessary condition is that the the binding energy of the thin-wall Q-ball is greater than any energy\ncost that the thick-wall Q-ball expanded in the background of \u03c6\u03041 brings over the vacuum of the theory,\n\nQ1\n\nq1\n\n(\nm\u2212\n\n\u221a\nf(\u03c6\u03041)\n\n\u03c6\u03042\n1\n\n)\n>\nQ2\n\nq2\n\n[\n\u00b5eff\n\n(\n1 \u2212 1\n\n6\n\u03b52\n)\n\u2212 \u00b5\n\n]\n. (3.28)\n\nThis is a model-dependent condition, so we say nothing more of this here.\n\n\u2013 14 \u2013\n\n\n\nthat must accumulate in the thick-wall core. For this to be compatible with Eq. (3.22), we\n\nrequire that\n\n11h2 < \u00b5. (3.31)\n\nWe thus see that we require that the coupling between the two fields not be too large. If\n\nthis is satisfied, then it is sufficient to prove that this structure is classically stable over\n\nsome range of charge. The total system is therefore adequately described as a thin-wall\n\nQ-ball, stabilised by the conservation of some charge, with a core composed of a thick-wall\n\nQ-ball, stabilised by the conservation of some other charge, over the background field of\n\nthe thin-wall Q-ball. This is because the field \u03c62 will remain \u201csmall\u201d and thus will not\n\noverly affect the background field, \u03c6\u03041.\n\nBy definition, a Q-ball is the state that minimises the energy per unit charge of a sector\n\nof a theory. Thus, the combination of energy and Noether charge conservation implies that\n\nthis configuration is more stable than emitting the individual quanta of \u03a62 outside the\n\nQ-ball formed from \u03a61. One could also question whether a Q-ball composed of \u03a61 and\n\n\u03a62 could be emitted as a decay channel. However, the ability for the potential defined\n\nthrough g(\u03a62) and h(\u03a61,\u03a62) in the background of \u03c6\u03041 to house stable Q-ball solutions does\n\nnot imply that the full potential U(\u03a61,\u03a62) will allow for stable \u201cdoubly-charged\u201d Q-balls\n\nto exist in isolation. In the absence of this decay mode, the cored Q-ball is indeed stable.\n\nWe also require that the Q-ball in the core be smaller than the thin-wall Q-ball it\n\nresides in, as otherwise we cannot assume the results of the previous section. From the\n\nsizes of the respective Q-balls given in Eqs. (3.21) and (3.24), together with the definition\n\nfor \u03b5 given in Eq. (3.17), we find that\n\n36\u03c0(S\u03d5)3 q\n3\n2\n\nQ3\n2\n\n\u00b53\neff\n\nA6\neff\n\n\ufffd Q1\n\n2\n\u221a\nq2\n\n1\u03c6\u0304\n2\n1f(\u03c6\u03041)\n\n, (3.32)\n\nwhich is a model-dependent condition which relates the charge accumulation of both Q-\n\nballs.\n\n4 Summary\n\nIn this work, we studied a subclass of multi-field and multi-symmetry theories for Q-ball\n\nsolutions. Specifically, we considered a theory of N complex scalar fields, each charged\n\nunder their own U(1) symmetry. Thus, the stabilising symmetry is an N -fold U(1) sym-\n\nmetry. In this scheme, we studied both the thin- and thick-wall limits, using the standard\n\nmulti-field approximation of similar spatial profiles in order to progress analytically.\n\nIn the thin-wall case, we determined the physical properties of the Q-ball, together\n\nwith the differential equation that governs the VEV of the fields inside the Q-ball. In\n\nsharp contrast to all previous studies, we have found that the VEVs depend upon the\n\n\u2013 15 \u2013\n\n\n\ncharge of the Q-ball itself. The differential equation must then be solved for each charge\n\nconfiguration, independently. It would be interesting to solve this in future work in, say,\n\nthe \u201cdoubly-charged\u201d case.\n\nIn the thick-wall case, we demanded that the minimum of energy be classically stable\n\nagainst decay into constituent quanta of the fields. We thus gave sufficient constraints on\n\nthe theories that possess a thick-wall limit. The general set up of the theory was such that\n\nwe had, in some sense, N copies of the single-field case, and so it comes to no surprise that\n\nthe restriction of theories is the same as in Refs. [10\u201312], namely, that 2 < p < 10/3, where\n\np denotes the index of the next-to-quadratic term in the bounce potential.\n\nIn the latter half of this work, we heuristically studied a new type of object that\n\nwe called a \u201ccored Q-ball\u201d. This is a thin-wall Q-ball whose homogeneous interior acts\n\nas a stabilising background VEV for a thick-wall Q-ball composed of another field. In\n\nthis work, we merely concerned ourselves with the question of stability of these objects.\n\nRealistic theories that lead to the formation of these objects is a direction for future work.\n\nSpecifically, a phenomenological analysis is required in which all timescales are taken into\n\naccount, together with a mechanism for the release of the additional energy. Moreover, one\n\ncould also extend the ideas here to the case where a stable, \u201cdoubly-charged\u201d Q-ball can\n\nexist. This would open up the decay channel whereby a mixed Q-ball is emitted, leaving\n\nbehind a pure thin-wall Q-ball.\n\nIntriguingly, these objects could be important in DM experiments. Consider the case\n\nthat the Q-ball at the core is charged under the SM, whereas the larger thin-wall Q-ball\n\nis not directly coupled to the SM. If this object were to pass through a direct detection\n\nexperiment, we would only see the core, and not the Q-ball at large. This would cause a\n\nmisidentification of the DM until experiments are sensitive enough to determine the other\n\ncomponent, which could indirectly couple to the SM via the cored field.\n\nAcknowledgments\n\nOL would like to thank John March-Russell for useful comments on this work, which\n\nwas completed while OL was supported by the Colleges of St John and St Catherine,\n\nOxford. Conversations with Fady Bishara on Q-ball physics over the years have also been\n\nparticularly fruitful.\n\nA Thin-Wall Q-balls in the Background of Another Field\n\nFor completeness, we now include the thin-wall analysis. A thin-wall Q-ball\u2019s physical\n\nproperties are well-described by those of its homogeneous core. We thus write\n\nE\u03c9 \u2248 \u03c9\u03042Q2 + V\n[\ng(\u03c6\u03042) + h(\u03c6\u03041, \u03c6\u03042)\u2212 \u03c9\u03042\n\n2q\n2\n2\u03c6\u0304\n\n2\n2\n\n]\n, (A.1)\n\n\u2013 16 \u2013\n\n\n\nwhere V is the volume of the core, and we use bars to represent values of variables within\n\nthe core. Minimisation of this with respect to the Lagrange multiplier yields, as expected,\n\nthe expression for the charge of this configuration,\n\nQ2 = 2\u03c9\u03042q\n2\n2\u03c6\u0304\n\n2\n2V. (A.2)\n\nEliminating \u03c9\u03042 and minimising with respect to the volume leads to\n\nV 2 =\nQ2\n\n2\n\n4q2\n2\u03c6\u0304\n\n2\n2\n\n1[\ng(\u03c6\u03042) + h(\u03c6\u03041, \u03c6\u03042)\n\n] . (A.3)\n\nFinally, upon elimination of the volume, we obtain the rest mass of the configuration\n\nmQ = Q2\n\n\u221a\ng(\u03c6\u03042) + h(\u03c6\u03041, \u03c6\u03042)\n\nq2\n2\u03c6\u0304\n\n2\n2\n\n, (A.4)\n\nwhich is completely expected from the single-field theory, since U(\u03c6\u03042) = g(\u03c6\u03042) + h(\u03c6\u03041, \u03c6\u03042).\n\nFor the resultant Q-ball to be stable in the background of the VEV of \u03a61, we must have\n\nthat\n\nmQ < \u00b5eff\nQ2\n\nq2\n, (A.5)\n\nwhere \u00b5eff(\u03c6\u03041) is defined as in the previous section. The VEV of \u03c6\u03042 must obey the differ-\n\nential equation given by\n\u2202g\n\n\u2202\u03c6\u03042\n+\n\n\u2202h\n\n\u2202\u03c6\u03042\n= 2\n\n(\ng\n\n\u03c6\u03042\n+\n\nh\n\n\u03c6\u03042\n\n)\n. (A.6)\n\nThis concludes the thin-wall analysis of this theory.\n\nReferences\n\n[1] S. R. Coleman, Q Balls, Nucl. Phys. B262 (1985) 263. [Erratum: Nucl. Phys. B269, 744\n\n(1986)].\n\n[2] T. D. Lee and Y. Pang, Nontopological solitons, Phys. Rept. 221 (1992) 251\u2013350.\n\n[3] A. M. Safian, S. R. Coleman and M. Axenides, Some non-Abelian Q-balls, Nucl. Phys. B297\n\n(1988) 498\u2013514.\n\n[4] K.-M. Lee, J. A. Stein-Schabes, R. Watkins and L. M. Widrow, Gauged Q Balls, Phys. Rev.\n\nD39 (1989) 1665.\n\n[5] J. Heeck, A. Rajaraman, R. Riley and C. B. Verhaaren, Mapping Gauged Q-Balls, Phys.\n\nRev. D 103 (2021) 116004, [2103.06905].\n\n[6] A. Kusenko, Small Q balls, Phys. Lett. B404 (1997) 285, [hep-th/9704073].\n\n[7] S. R. Coleman, The Fate of the False Vacuum. 1. Semiclassical Theory, Phys. Rev. D15\n\n(1977) 2929\u20132936. [Erratum: Phys. Rev. D16, 1248 (1977)].\n\n\u2013 17 \u2013\n\nhttps://doi.org/10.1016/0550-3213(85)90286-X\nhttps://doi.org/10.1016/0550-3213(86)90520-1\nhttps://doi.org/10.1016/0550-3213(86)90520-1\nhttps://doi.org/10.1016/0370-1573(92)90064-7\nhttps://doi.org/10.1016/0550-3213(88)90315-X\nhttps://doi.org/10.1016/0550-3213(88)90315-X\nhttps://doi.org/10.1103/PhysRevD.39.1665\nhttps://doi.org/10.1103/PhysRevD.39.1665\nhttps://doi.org/10.1103/PhysRevD.103.116004\nhttps://doi.org/10.1103/PhysRevD.103.116004\nhttps://arxiv.org/abs/2103.06905\nhttps://doi.org/10.1016/S0370-2693(97)00582-0\nhttps://arxiv.org/abs/hep-th/9704073\nhttps://doi.org/10.1103/PhysRevD.15.2929\nhttps://doi.org/10.1103/PhysRevD.15.2929\nhttps://doi.org/10.1103/PhysRevD.16.1248\n\n\n[8] C. G. Callan, Jr. and S. R. Coleman, The Fate of the False Vacuum. 2. First Quantum\n\nCorrections, Phys. Rev. D16 (1977) 1762\u20131768.\n\n[9] S. R. Coleman, V. Glaser and A. Martin, Action Minima Among Solutions to a Class of\n\nEuclidean Scalar Field Equations, Commun. Math. Phys. 58 (1978) 211.\n\n[10] F. Paccetti Correia and M. G. Schmidt, Q balls: Some analytical results, Eur. Phys. J. C 21\n\n(2001) 181\u2013191, [hep-th/0103189].\n\n[11] M. Postma, Solitosynthesis of Q balls, Phys. Rev. D 65 (2002) 085035, [hep-ph/0110199].\n\n[12] O. Lennon, Non-Canonical Q-balls, 2112.12547.\n\n[13] J. Heeck, A. Rajaraman, R. Riley and C. B. Verhaaren, Understanding Q-Balls Beyond the\n\nThin-Wall Limit, 2009.08462.\n\n[14] A. Kusenko and M. E. Shaposhnikov, Supersymmetric Q balls as dark matter, Phys. Lett.\n\nB418 (1998) 46\u201354, [hep-ph/9709492].\n\n[15] A. Kusenko and P. J. Steinhardt, Q ball candidates for selfinteracting dark matter, Phys.\n\nRev. Lett. 87 (2001) 141301, [astro-ph/0106008].\n\n[16] P. W. Graham, S. Rajendran and J. Varela, Dark Matter Triggers of Supernovae, Phys. Rev.\n\nD92 (2015) 063007, [1505.04444].\n\n[17] E. Ponto\u0301n, Y. Bai and B. Jain, Electroweak Symmetric Dark Matter Balls, JHEP 09 (2019)\n\n011, [1906.10739].\n\n[18] A. Kusenko, Solitons in the supersymmetric extensions of the standard model, Phys. Lett.\n\nB405 (1997) 108, [hep-ph/9704273].\n\n[19] D. A. Demir, Stable Q balls from extra dimensions, Phys. Lett. B 495 (2000) 357\u2013362,\n\n[hep-ph/0006344].\n\n[20] S. Abel and A. Kehagias, Q-branes, JHEP 11 (2015) 096, [1507.04557].\n\n[21] G. Gelmini, A. Kusenko and S. Nussinov, Experimental identification of nonpointlike dark\n\nmatter candidates, Phys. Rev. Lett. 89 (2002) 101302, [hep-ph/0203179].\n\n[22] A. Kusenko, V. Kuzmin, M. E. Shaposhnikov and P. Tinyakov, Experimental signatures of\n\nsupersymmetric dark matter Q balls, Phys. Rev. Lett. 80 (1998) 3185\u20133188,\n\n[hep-ph/9712212].\n\n[23] D. Croon, A. Kusenko, A. Mazumdar and G. White, Solitosynthesis and Gravitational\n\nWaves, Phys. Rev. D 101 (2020) 085010, [1910.09562].\n\n[24] R. Friedberg, T. Lee and A. Sirlin, A Class of Scalar-Field Soliton Solutions in Three Space\n\nDimensions, Phys. Rev. D 13 (1976) 2739\u20132761.\n\n[25] O. Lennon, Multi-Field Q-balls with Real Scalars, 2112.14263.\n\n[26] V. Balasubramanian, B. Czech, K. Larjo and T. S. Levi, Vacuum decay in multidimensional\n\nfield landscapes: thin, thick and intersecting walls, Phys. Rev. D 84 (2011) 025019,\n\n[1012.2065].\n\n\u2013 18 \u2013\n\nhttps://doi.org/10.1103/PhysRevD.16.1762\nhttps://doi.org/10.1007/BF01609421\nhttps://doi.org/10.1007/s100520100710\nhttps://doi.org/10.1007/s100520100710\nhttps://arxiv.org/abs/hep-th/0103189\nhttps://doi.org/10.1103/PhysRevD.65.085035\nhttps://arxiv.org/abs/hep-ph/0110199\nhttps://arxiv.org/abs/2112.12547\nhttps://arxiv.org/abs/2009.08462\nhttps://doi.org/10.1016/S0370-2693(97)01375-0\nhttps://doi.org/10.1016/S0370-2693(97)01375-0\nhttps://arxiv.org/abs/hep-ph/9709492\nhttps://doi.org/10.1103/PhysRevLett.87.141301\nhttps://doi.org/10.1103/PhysRevLett.87.141301\nhttps://arxiv.org/abs/astro-ph/0106008\nhttps://doi.org/10.1103/PhysRevD.92.063007\nhttps://doi.org/10.1103/PhysRevD.92.063007\nhttps://arxiv.org/abs/1505.04444\nhttps://doi.org/10.1007/s13130-019-11194-5\nhttps://doi.org/10.1007/s13130-019-11194-5\nhttps://arxiv.org/abs/1906.10739\nhttps://doi.org/10.1016/S0370-2693(97)00584-4\nhttps://doi.org/10.1016/S0370-2693(97)00584-4\nhttps://arxiv.org/abs/hep-ph/9704273\nhttps://doi.org/10.1016/S0370-2693(00)01262-4\nhttps://arxiv.org/abs/hep-ph/0006344\nhttps://doi.org/10.1007/JHEP11(2015)096\nhttps://arxiv.org/abs/1507.04557\nhttps://doi.org/10.1103/PhysRevLett.89.101302\nhttps://arxiv.org/abs/hep-ph/0203179\nhttps://doi.org/10.1103/PhysRevLett.80.3185\nhttps://arxiv.org/abs/hep-ph/9712212\nhttps://doi.org/10.1103/PhysRevD.101.085010\nhttps://arxiv.org/abs/1910.09562\nhttps://doi.org/10.1103/PhysRevD.13.2739\nhttps://arxiv.org/abs/2112.14263\nhttps://doi.org/10.1103/PhysRevD.84.025019\nhttps://arxiv.org/abs/1012.2065\n\n\n[27] B. Czech, A Novel Channel for Vacuum Decay, Phys. Lett. B 713 (2012) 331\u2013334,\n\n[1112.1638].\n\n[28] J. H. C. Scargill, Barnacles and Gravity, JHEP 09 (2017) 080, [1705.09010].\n\n[29] F. Bishara, G. Johnson, O. Lennon and J. March-Russell, Higgs Assisted Q-balls from\n\nPseudo-Nambu-Goldstone Bosons, JHEP 11 (2017) 179, [1708.04620].\n\n[30] A. D. Linde, Decay of the False Vacuum at Finite Temperature, Nucl. Phys. B216 (1983)\n\n421. [Erratum: Nucl. Phys. B223, 544 (1983)].\n\n\u2013 19 \u2013\n\nhttps://doi.org/10.1016/j.physletb.2012.06.018\nhttps://arxiv.org/abs/1112.1638\nhttps://doi.org/10.1007/JHEP09(2017)080\nhttps://arxiv.org/abs/1705.09010\nhttps://doi.org/10.1007/JHEP11(2017)179\nhttps://arxiv.org/abs/1708.04620\nhttps://doi.org/10.1016/0550-3213(83)90293-6\nhttps://doi.org/10.1016/0550-3213(83)90293-6\nhttps://doi.org/10.1016/0550-3213(83)90072-X\n\n\t1 Introduction\n\t2 Multi-Charged Q-balls\n\t2.1 Minimising the Energy in a Sector of Fixed Charge\n\t2.2 Thin-Wall Q-balls\n\t2.3 Thick-Wall Q-balls\n\n\t3 Cored Q-balls\n\t3.1 Q-balls in the Background of Another Field\n\t3.1.1 The Minimisation Procedure\n\t3.1.2 The Thick-Wall Limit\n\n\t3.2 Cored Q-balls\n\n\t4 Summary\n\tA Thin-Wall Q-balls in the Background of Another Field\n\n"}
{"Title": "On thermodynamics of compact objects", "Authors": "Ufuk Aydemir, Jing Ren", "Abstract": "  With the recent progress in observations of astrophysical black holes, it has become more important to understand in detail the physics of strongly gravitating horizonless objects. If the objects identified in the observations are indeed horizonless and ultracompact, high curvature effects may come into play, and their explorations may be intimately related to new physics beyond General Relativity (GR). In this paper, we revisit the concept of statistical thermodynamics in curved spacetime, focusing on self-gravitating compact systems without event horizons. Differently from the previous studies in this context, we develop a generic framework with no explicit dependence on the gravitational field equations, which is then applicable to a general theory of gravity. Defining the global variables directly from the local counterparts, the conventional thermodynamics follows for a generic curved spacetime. The key step is the appropriate identification of thermodynamic volume to ensure the first law of thermodynamics, which is in general different from the geometric volume. For demonstration, we consider familiar examples of self-gravitating gas in GR, where the connection to previous studies becomes clear. We also discuss 2-2-holes in quadratic gravity, a novel example of black hole mimickers that features super-Planckian curvatures in the interior. When the physical mass is treated as the total internal energy, interesting connections to black hole thermodynamics emerge. We find universal high curvature effects in thermodynamics for these objects, and the dominant effects happen to be conveniently encoded in the thermodynamic volume.      ", "Subject": "General Relativity and Quantum Cosmology (gr-qc)", "ID": "arXiv:2201.00025", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn thermodynamics of compact objects\n\nUfuk Aydemir\u2217 and Jing Ren\u2020\n\nInstitute of High Energy Physics, Chinese Academy of Sciences, Beijing 100049, China\n\nJanuary 4, 2022\n\nAbstract\n\nWith the recent progress in observations of astrophysical black holes, it has become\nmore important to understand in detail the physics of strongly gravitating horizonless ob-\njects. If the objects identified in the observations are indeed horizonless and ultracompact,\nhigh curvature effects may come into play, and their explorations may be intimately re-\nlated to new physics beyond General Relativity (GR). In this paper, we revisit the concept\nof statistical thermodynamics in curved spacetime, focusing on self-gravitating compact\nsystems without event horizons. Differently from the previous studies in this context, we\ndevelop a generic framework with no explicit dependence on the gravitational field equa-\ntions, which is then applicable to a general theory of gravity. Defining the global variables\ndirectly from the local counterparts, the conventional thermodynamics follows for a generic\ncurved spacetime. The key step is the appropriate identification of thermodynamic volume\nto ensure the first law of thermodynamics, which is in general different from the geomet-\nric volume. For demonstration, we consider familiar examples of self-gravitating gas in\nGR, where the connection to previous studies becomes clear. We also discuss 2-2-holes in\nquadratic gravity, a novel example of black hole mimickers that features super-Planckian\ncurvatures in the interior. When the physical mass is treated as the total internal energy,\ninteresting connections to black hole thermodynamics emerge. We find universal high cur-\nvature effects in thermodynamics for these objects, and the dominant effects happen to be\nconveniently encoded in the thermodynamic volume.\n\n\u2217uaydemir@ihep.ac.cn\n\u2020renjing@ihep.ac.cn\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n5v\n1 \n\n [\ngr\n\n-q\nc]\n\n  3\n1 \n\nD\nec\n\n 2\n02\n\n1\n\n\n\nContents\n\n1 Introduction 2\n\n2 Thermodynamics in curved spacetime and thermodynamic volume 3\n2.1 Properties of local variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n2.2 The global picture and the role of thermodynamic volume . . . . . . . . . . . . 6\n2.3 Semi-classical ideal gas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.4 Quantum ideal gas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n\n3 Examples of horizonless compact objects 13\n3.1 Compact objects in GR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.2 Not quite black holes in quadratic gravity . . . . . . . . . . . . . . . . . . . . . 16\n\n4 Summary 20\n\nA Microcanonical ensemble 21\n\nB Field equations for compact objects 23\n\n1 Introduction\n\nThermodynamics in curved spacetime is usually addressed in the context of black hole physics.\nThe thermodynamical interpretation of laws of black hole mechanics derived from GR [1] and\nthe discovery of Hawking radiation [2] are milestones, bringing in big surprises but also great\npuzzles. The Bekenstein-Hawking formula indicates that black holes have enormous amounts\nof thermal entropy scaled with the area [3], while its microscopic origin remains obscure except\nfor in some specific models [4]. Hawking radiation is predicted to be purely thermal from the\noriginal calculation, yielding the information loss problem for black hole evaporation. Based on\nparticular setups inspired by the AdS/CFT correspondence, recent studies identified the missing\ncontributions in Hawking\u2019s calculation that may provide a resolution for the problem [5, 6]. Yet\nthe issues of whether and how these ideas apply to more general cases remain as open questions\n(see Ref. [7] for a review).\n\nThe key ingredient behind the black hole thermodynamics is the event horizon. Yet, current\nobservations of astrophysical black holes in the electromagnetic and gravitational wave windows\nonly confirm the GR predictions at the order of the horizon size with no direct implications\nregarding physics immediately outside the horizon. This motivates a more close investigation\non the possibility of horizonless ultracompact objects being the endpoint of gravitational col-\nlapse. A variety of theoretical candidates have been proposed, and their potential observational\nconsequences have been studied (see Ref. [8] for a review). Among all, the less explored is ther-\nmodynamics of ultracompact objects that may serve as black hole mimickers. Without the\nevent horizon, the nontrivial contribution from background spacetime is absent [9], and the\nfocus is rather on the matter source contribution and how conventional thermodynamics is\ninfluenced by curvature effects.\n\n2\n\n\n\nStatistical thermodynamics of self-gravitating systems in GR have long been explored. It was\nshown that the maximum entropy principle of statistical mechanics could be used to derive the\nbasic equations describing a static and spherically symmetric self-gravitating gas in GR [10, 11]\n(see Ref. [12, 13] for recent reviews). Explicit examples include the self-gravitating black-body\nradiation [14, 15] and fermion gas [16], corresponding to the equilibrium solutions for photon\nstars and neutron stars. As a result, the total internal energy for the system is identified as\nthe physical mass of the object, and an intimate relation between thermodynamic stability\nand dynamical stability is revealed. This method, nonetheless, also has some limitations [12].\nSince the Einstein equations are implicitly assumed in the derivation, this procedure may not\nbe attainable for theories of modified gravity, given the more complicated structure of field\nequations. Also, not all information encoded in the field equations can be derived from the\nmaximum entropy principle.\n\nIn this paper, we study thermodynamics of self-gravitating systems from a different per-\nspective. Instead of deriving the profile of local thermodynamic quantities from the global ones\nby using a subset of the gravitational field equations, we focus on the curved spacetime effects\non generic laws governing the global thermodynamic quantities for a general theory of gravity\n(GR and beyond). This is particularly important for horizonless ultracompact objects where\nthe metric resembles black hole spacetime closely from the exterior, while the interior may\nfeature high curvatures.\n\nIn this picture, without the explicit input of field equations, we define global extensive\nvariables directly from the local ones, given that the conventional thermodynamics always\napplies in a sufficiently small volume due to the equivalence principle. The total internal energy\nthen takes the conventional form by properly integrating out the energy density, rather than the\nphysical mass as in the case of self-gravitating systems in GR. Intensive variables are given by\nthe matter properties measured at spatial infinity. The first law of thermodynamics for global\nvariables applies once a so-called thermodynamic volume is appropriately identified, which is\ndifferent from the ordinary geometric one. This then provides a generic framework to study\nequilibrium thermodynamics for compact objects without event horizon. We consider explicit\nexamples of horizonless compact objects in different theories of gravity for demonstration. The\nexplicit form of thermodynamic volume can be identified for certain cases. Also, the relation\nbetween the generic laws developed in this paper and those involving the physical mass can be\nexplored. The thermodynamic volume contribution turns out to be crucial for understanding\ntheir difference.\n\nThe rest of the paper is organized as follows. In Sec. 2, we explore the generic laws for\nthermodynamic variables. In Sec. 3, we discuss examples of horizonless compact objects in both\nGR and quadratic gravity. We summarize in Sec. 4. We adopt the convention c = ~ = kB = 1\nthroughout this work, unless stated otherwise.\n\n2 Thermodynamics in curved spacetime and thermody-\nnamic volume\n\nIn this section, we revisit thermodynamics and statistical mechanics for self-gravitating systems\nin curved spacetime. For simplicity, we restrict to static, asymptotically flat, and spherically\n\n3\n\n\n\nsymmetric spacetimes, for which the line element is generically expressed as\n\nds2 = \u2212B(r) dt2 + A(r) dr2 + r2d\u03b82 + r2 sin2 \u03b8d\u03c62 , (1)\n\nand the metric functions A(r) and B(r) are determined through the field equations imposed\nby the corresponding theory of gravity. We treat the matter source as a perfect fluid, whose\nenergy-momentum tensor is given as\n\nT \u00b5\u03bd = diag(\u2212\u03c1, p, p, p) , (2)\n\nwhere \u03c1 and p denote the proper energy density and the isotropic pressure.\nIn the following, we first review the well-known properties of local variables in Sec. 2.1. Then,\n\nwe turn to global thermodynamical variables in Sec. 2.2 by assuming additivity of the extensive\nvariables. As a result, we find a local-global thermodynamic correspondence for a generic curved\nspacetime. We argue that the conventional internal energy U for the matter source (instead of\nthe physical mass M) can be used to established a well-defined thermodynamic system as long\nas one can identify an appropriate form of thermodynamic volume. In Sec. 2.3 and Sec. 2.4, we\nillustrate the idea by considering examples of non-interacting gas described by canonical and\ngrand canonical ensembles. The additivity of global thermodynamic potentials can be verified\nby derivations from the global partition function. The specific form of thermodynamic volume\nis also displayed.\n\n2.1 Properties of local variables\n\nIn curved spacetime, a fluid element sufficiently small can be described by local thermodynamic\nvariables in the local rest frame of the fluid element [17]. According to the equivalence principle,\nthese local thermodynamic variables shall respect the fundamental laws of thermodynamics.\nHere, we take two basic relations as the starting point. One is the Gibbs-Duhem relation for\nthe proper quantities in the local frame,\n\ns =\n\u03c1+ p\u2212 \u00b5n\n\nT\n, (3)\n\nwhere s is the entropy density, n is the number density, \u00b5 is the chemical potential and T is\nthe temperature. The other relation is the first law,\n\nd\u03c1 =\n\u03c1+ p\u2212 s T\n\nn\ndn+ Tds = \u00b5 dn+ T ds , (4)\n\nwhere the energy density \u03c1 is treated as a function of number density n and entropy density s.\nFor the canonical ensemble, the local thermodynamic potential is the Helmholtz free energy\n\ndensity f . It is clear from the fundamental equation that f = \u03c1\u2212 s T is a function of n and T .\nFollowing Eq. (4), we have\n\ndf = \u00b5 dn\u2212 s dT , (5)\n\nfrom which the chemical potential and entropy density can directly be found as\n\n\u00b5 =\n\n(\n\u2202f\n\n\u2202n\n\n)\nT\n\n, s = \u2212\n(\n\u2202f\n\n\u2202T\n\n)\nn\n\n. (6)\n\n4\n\n\n\nUsing Eq. (6) and the Gibbs-Duhem relation, given in Eq. (3), together with the definition of\nf , one obtains the energy density \u03c1 and the pressure p in terms of f as\n\n\u03c1 = \u2212T 2 \u2202\n\n\u2202T\n\n(\nT\u22121f\n\n)\nn\n, p = \u2212 \u2202\n\n\u2202n\n(n f)T . (7)\n\nSimilarly, for the grand canonical ensemble, we consider the grand potential density \u03c9 =\n\u03c1\u2212 s T \u2212 \u00b5n = \u2212p. As a function of T and \u00b5, the total differential is\n\nd\u03c9 = \u2212s dT \u2212 n d\u00b5 . (8)\n\nIn analogy with Eqs. (6) and (7), we obtain the derived quantities as follows:\n\nn = \u2212\n(\n\u2202\u03c9\n\n\u2202\u00b5\n\n)\nT\n\n, s = \u2212\n(\n\u2202w\n\n\u2202T\n\n)\n\u00b5\n\n, p = \u2212\u03c9 , \u03c1 = \u2212T 2 \u2202\n\n\u2202T\n\n(\nT\u22121\u03c9\n\n)\n\u00b5\n\u2212 n\u00b5 . (9)\n\nThe spacetime variation of local thermodynamic quantities are governed by the conservation\nlaw of the stress tensor, \u2207\u00b5T\u00b5\u03bd = 0. For a static and spherically symmetric spacetime, this\nyields a single constraint from the momentum conservation along the radial direction. For the\nmetric in Eq. (1) and stress tensor in Eq. (2), this constraint is obtained as\n\np\u2032 + (p+ \u03c1)\nB\u2032\n\n2B\n= 0 , (10)\n\nwhere (\u2032) denotes derivative with respect to r.\nAs recently emphasized in Ref. [18], the momentum conservation of the stress tensor is\n\ndirectly related to the Tolman\u2019s law for local thermal equilibrium in curved spacetime. With\nuse of the Gibbs-Duhem relation, given in Eq. (3), Eq. (10) can be expressed as\n\nB\u2032\n\n2B\n= \u2212 1\n\n\u03c1+ p\n(\u2212\u03c1\u2032 + T s\u2032 + \u00b5n\u2032)\u2212 T \u2032\n\nT\n\u2212 nT\n\n\u03c1+ p\n\n(\u00b5\nT\n\n)\u2032\n. (11)\n\nThe term in the parenthesis vanishes due to the first law given in Eq. (4), and therefore\n\nB\u2032\n\n2B\n+\nT \u2032\n\nT\n= \u2212 nT\n\n\u03c1+ p\n\n(\u00b5\nT\n\n)\u2032\n. (12)\n\nWhen the chemical potential is zero, as for the photon gas, Eq. (12) reduces to the commonly\nknown Tolman\u2019s law [10, 11]: T (r)\n\n\u221a\nB(r) = T\u221e. The constant T\u221e is the temperature of the\n\ngas at spatial infinity or the redshifted temperature for observers at spatial infinity. More\ngenerally, the quantitiy \u00b5/T , the exponential of which is commonly called fugacity, is position\nindependent, i.e. (\u00b5/T )\u2032 = 0, as the condition of vanishing heat flow and diffusion for a system\nin equilibrium [19]. This then leads to the generalized version of Tolman\u2019s law [20]\n\nT (r)\n\u221a\nB(r) = T\u221e , \u00b5(r)\n\n\u221a\nB(r) = \u00b5\u221e . (13)\n\nThis means that the temperature and chemical potential as intensive quantities are each\nuniquely specified by single numbers, T\u221e and \u00b5\u221e, respectively. Since we consider only equilib-\nrium thermodynamics, we employ the condition of constant fugacity throughout this work.\n\n5\n\n\n\n2.2 The global picture and the role of thermodynamic volume\n\nThe global thermodynamic characteristics of a strongly gravitating system are of interest for\nobservers far away from the gravitational potential. For a generic discussion here, we write down\nglobal extensive thermodynamic variables in terms of their local counterparts by assuming\nadditivity. This is expected for a variaty of matter sources, and will be explicitly verified\nfor non-interacting gas in later subsections. Thermodynamic potentials are then obtained by\nappropriately integrating the corresponding potential energy density such as\n\nU =\n\n\u222b R\n\n0\n\n\u221a\nAB \u03c1d3r , F =\n\n\u222b R\n\n0\n\n\u221a\nAB f d3r , \u2126 =\n\n\u222b R\n\n0\n\n\u221a\nAB \u03c9 d3r , (14)\n\nwhere\n\u221a\nAB =\n\n\u221a\n\u2212g is the determinant of the metric and R denotes the boundary of the matter\n\ndistribution. U , F and \u2126 are the total internal energy, Helmholtz free energy and the grand\npotential, respectively. The total number of particles N and entropy S are associated with the\nspatial integral of the conserved currents and given as\n\nN =\n\n\u222b R\n\n0\n\n\u221a\nAnd3r , S =\n\n\u222b R\n\n0\n\n\u221a\nAs d3r . (15)\n\nLet\u2019s start from the canonical ensemble to verify the conventional thermodynamics. Given\nthe Helmholtz free energy density f = \u03c1 \u2212 s T and the Tolman\u2019s law Eq. (13), we can first\nobtain the fundamental equation\n\nF =\n\n\u222b R\n\n0\n\n\u221a\nAB (\u03c1\u2212 s T ) d3r = U \u2212 T\u221eS . (16)\n\nThen, taking the total differential of the Helmholtz free energy F and implementing Eqs. (5)\nand (13), we have\n\ndF =\n\n\u222b R\n\n0\n\n\u221a\nAB (\u00b5 dn\u2212 s dT ) d3r + (dF )f\n\n= \u00b5\u221e\n\n\u222b R\n\n0\n\n\u221a\nA dn d3r \u2212\n\n\u222b R\n\n0\n\n\u221a\nAB sd\n\nT\u221e\u221a\nB\nd3r + (dF )f\n\n= \u00b5\u221e dN \u2212 S dT\u221e + (dF )N,T\u221e . (17)\n\nThe last term (dF )N,T\u221e denotes variation of the metric function or size of the system indepen-\ndent of N and T\u221e. If we attribute this change to the variation of a thermodynamic volume\nelement\n\ndVth = \u2212p\u22121\u221e (dF )T\u221e,N , (18)\n\nthe conventional equation can be recovered\n\ndF = \u2212SdT\u221e \u2212 p\u221edVth + \u00b5\u221edN . (19)\n\nThus, by considering F as a function of N , T\u221e and Vth, one gets the consistent picture with\nthe desired relations\n\nS = \u2212\n(\n\u2202F\n\n\u2202T\u221e\n\n)\nVth,N\n\n, p\u221e = \u2212\n(\n\u2202F\n\n\u2202Vth\n\n)\nT\u221e,N\n\n, \u00b5\u221e =\n\n(\n\u2202F\n\n\u2202N\n\n)\nT\u221e,Vth\n\n. (20)\n\n6\n\n\n\nBy using these relations and Eq. (16), the internal energy can be simply expressed as U =\n\u2212T 2\n\u221e (\u2202(T\u22121\u221e F )/\u2202T\u221e)Vth,N . Then, with Eqs. (16) and (19), one obtains the fundamental ther-\n\nmodynamic relation for internal energy,\n\ndU = T\u221edS \u2212 p\u221edVth + \u00b5\u221edN , (21)\n\nas the manifestation of the first law of thermodynamics for global variables.\nSimilarly, for the grand canonical ensemble, given the Tolman\u2019s law in Eq. (13), the global\n\ngrand potential satisfies\n\n\u2126 =\n\n\u222b R\n\n0\n\n\u221a\nAB (\u03c1\u2212 s T \u2212 \u00b5n) d3r = U \u2212 T\u221eS \u2212 \u00b5\u221eN , (22)\n\nwhere the term in parenthesis is the grand potential density w = \u2212p, as defined above Eq. (8).\nTogether with Eq. (19), the total differential of \u2126 is given as\n\nd\u2126 = \u2212SdT\u221e \u2212 p\u221edVth \u2212Nd\u00b5\u221e , (23)\n\nwhere the thermodynamic volume can be expressed in terms of the grand potential as\n\ndVth = \u2212p\u22121\u221e (d\u2126)T\u221e,\u00b5\u221e =\n\n(\nd\n\n\u222b R\n\n0\n\n\u221a\nAB\n\np\n\np\u221e\nd3r\n\n)\nT\u221e,\u00b5\u221e\n\n, (24)\n\nand consequently the required relations are obtained as\n\nS = \u2212\n(\n\u2202\u2126\n\n\u2202T\u221e\n\n)\nVth,\u00b5\u221e\n\n, p\u221e = \u2212\n(\n\u2202\u2126\n\n\u2202Vth\n\n)\nT\u221e,\u00b5\u221e\n\n, N = \u2212\n(\n\u2202\u2126\n\n\u2202\u00b5\u221e\n\n)\nT\u221e,Vth\n\n. (25)\n\nIn short; we have seen that global thermodynamic variables obey the conventional thermo-\ndynamics in the sense that their definitions fully enocde the curved spacetime effects. The key\ningredient is to appropriately identify the thermodynamic volume Vth as in Eqs. (18) and (24).\nFinding the explicit expression for Vth is not in general straightforward and its attainability\nhighly depends on the equation of state in question. This can be conveniently seen from the\ndefinition given in Eq. (24). Unlike T (r), \u00b5(r) that follow Tolman\u2019s law, the spatial variation of\npressure depends on the equation of state as we will see later in our examples. The difficulty is\nin separating the spatial integral from the T\u221e when the latter is tangled in a position dependent\nnon-trivial functions. If such a separation is possible, then one can have a clear expression for\nVth. For instance, in the case of massless ideal gas with equation of state \u03c1 = 3p, which yields\np \u221d T 4, we have p(r)/p\u221e = B2(r) from the Tolman\u2019s law, and the thermodynamic volume\nemerges as\n\nVth =\n\n\u222b R\n\n0\n\n\u221a\nA(r)\n\nB3(r)\nd3r , (26)\n\nwith \u2126 = \u2212p\u221eVth. Apparently, Vth differs from the geometric volume\n\nVgeo =\n\n\u222b R\n\n0\n\n\u221a\nA d3r . (27)\n\n7\n\n\n\nWhen the curved spacetime features a deep gravitational potential, i.e. B(r) \ufffd 1, Vth will be\nmuch larger than Vgeo. As we will show later in Sec. 3 by explicit examples of compact objects\nwith back-reaction taken into account, a larger Vth is responsible for the difference between the\nphysical mass M and internal energy U . Thus, in comparison to previous studies where M\nis interpreted as the internal energy, we keep U unchanged but replace Vgeo by Vth, where the\ngravitational field contribution is more conveniently encoded.\n\n2.3 Semi-classical ideal gas\n\nAs the first example, we consider a box of semi-classical ideal gas in thermal equilibrium. The\nlocal thermodynamic variables can be derived from the Boltzmann distribution in the local\nrest frame. For later discussion, we display expressions for the number density, energy density,\npressure and entropy density,\n\nn =\ne\u00b5/T\n\n(2\u03c0)3\n\n\u222b\ne\u2212E/Td3p =\n\ne\u00b5/Tm2\n\n2\u03c02\nTK2(b) , (28)\n\n\u03c1 = nT\n\n(\n3 + b\n\nK1(b)\n\nK2(b)\n\n)\n, (29)\n\np = nT , (30)\n\ns = n\n\n(\n4 + b\n\nK1(b)\n\nK2(b)\n\u2212 \u00b5\n\nT\n\n)\n, (31)\n\nwhere E =\n\u221a\n\np2 +m2 is the locally measured proper energy of a particle, K1, K2 are the\nmodified Bessel functions and b \u2261 m/T .\n\nTo complete our previous derivation of consistency between local and global pictures, we\nfirst verify the additivity of the global Helmholtz free energy in Eq. (14). The starting point is\nthe fundamental equation in the canonical ensemble, namely,\n\nF = \u2212T\u221e lnZN(T\u221e) , (32)\n\nwhere ZN is the N-particle global partition function. As usual, we evaluate the one-particle\npartition function Z1 first. Taking the energy eigenstates of the Hamiltonian H\u0302, we have\n\nZ1(T\u221e) = Tr[e\u2212H\u0302/T\u221e ] =\n\u2211\nl\n\ne\u2212El,\u221e/T\u221e =\n\n\u222b\ne\u2212E\u221e/T\u221eg(E\u221e)dE\u221e , (33)\n\nwhere l = (lx, ly, lz) labels the momentum eigenstates in the box, and the summation over l is\napproximated by an integral for the box sufficiently large. E\u221e = \u03be\u00b5p\u00b5 is the conserved energy,\nwhere \u03be\u00b5 = (1,0) is the timelike killing vector of the static spacetime and p\u00b5 is the particle\u2019s\nfour-momentum. The density of states available to one-particle g(E\u221e) for a given energy E\u221e\ncan be obtained by g(E\u221e) = dP (E\u221e)/dE\u221e, with the invariant phase space volume [21, 22]\n\nP (E\u221e) =\n\n\u222b\nd3r d3p\u0398(E\u221e \u2212 \u03be\u00b5p\u00b5) =\n\n4\n\n3\n\u03c0\n\n\u222b\n(E2\n\u221e/B \u2212m2)3/2\n\n\u221a\nAd3r . (34)\n\nThe one-particle partition function is then\n\nZ1(T\u221e) =\n\n\u222b\ne\u2212E\u221e/T\u221e\n\ndP (E\u221e)\n\ndE\u221e\ndE\u221e =\n\n1\n\n(2\u03c0)3\n\n\u222b\ne\u2212E/T\n\n\u221a\nAd3rd3p = Ne\u2212\u00b5\u221e/T\u221e , (35)\n\n8\n\n\n\nwhere E = E\u221e/\n\u221a\nB is the proper energy and so E/T = E\u221e/T\u221e.1 Eqs. (15) and (28) are used\n\nin the last step to relate Z1 and N .\nAs in the case of flat spacetime, the N-particle global partition function, ZN , in the semi-\n\nclassical limit is related to the one-particle partition function by ZN \u2248 ZN\n1 /N ! \u2248 (Z1e/N)N ,\n\nwhere the Stirling approximation is used. Thus, with Eqs. (30), (32) and (35), the global\nHelmholtz free energy is\n\nF \u2248 \u2212T\u221eN\n(\n\n1 + ln\nZ1\n\nN\n\n)\n= N(\u00b5\u221e \u2212 T\u221e)\n\n=\n\n\u222b R\n\n0\n\n\u221a\nAB (n\u00b5\u2212 p) d3r =\n\n\u222b R\n\n0\n\n\u221a\nAB f d3r , (36)\n\nwhere the Gibbs-Duhem relation, given in Eq. (3), and f = \u03c1 \u2212 s T are used in the last step.\nThis supports the earlier definition Eq. (14) based on additivity.\n\nNext, let us examine the explicit expressions for global variables. Considering the massless\nparticle case first, the one-particle partition function is given as\n\nZ1(T\u221e) =\n1\n\n\u03c02\nT 3\n\u221e\n\n\u222b R\n\n0\n\n\u221a\nA(r)\n\nB3(r)\nd3r \u2261 1\n\n\u03c02\nT 3\n\u221eVth . (37)\n\nIn the last step, the thermodynamic volume is directly identified as that in Eq. (26) since the\nT\u221e dependence is fully separable from the spatial integral. This is consistent with the general\ndefinition of dVth in Eq. (18) from the global Helmholtz free energy F . To see this, we first\nwrite down F as a function of N , T\u221e and Vth,\n\nF = \u2212T\u221e lnZN(T\u221e) = \u2212T\u221eN\n(\n\n1 + ln\nT 3\n\u221eVth\n\u03c02N\n\n)\n. (38)\n\nEq. (18) implies that the intensive quantity p\u221e is the conjugate to Vth from Eq. (20),\n\np\u221e = \u2212\n(\n\u2202F\n\n\u2202Vth\n\n)\nT\u221e,N\n\n=\nNT\u221e\nVth\n\n. (39)\n\nOn the other hand, in the massless limit, the local pressure p \u221d T 4 from Eq. (28\u201331) and\nsatisfies p(r)B2(r) = p\u221e from Tolamn\u2019s law Eq. (13). Together with Eq. (30), we can find\n\np\u221eVth =\n\n\u222b R\n\n0\n\n\u221a\nA(r)\n\nB3(r)\nB(r)2 n(r)T (r) d3r = T\u221eN . (40)\n\nThis agrees with the derivative definition in Eq. (39), and so it validates the Vth definition in\nEq. (26). This shows that the thermodynamic system mimics the one in flat spacetime with the\nextensive global variables properly encoding the curvature effects and the intensive quantities\ngiven by the ideal gas properties at spatial infinity.\n\n1Note that the physics behind the metric dependence for E and T is different. E = E\u221e/\n\u221a\nB is gravitational\n\nredshift due to the change of reference frames, while T = T\u221e/\n\u221a\nB is the Tolman\u2019s law due to thermodynamic\n\nequilibrium.\n\n9\n\n\n\nThen from Eq. (20), we can find the total entropy and chemical potential from F as\n\nS = \u2212\n(\n\u2202F\n\n\u2202T\u221e\n\n)\nVth,N\n\n= N\n\n(\n4 + ln\n\n[\nT 3\n\u221eVth\n\u03c02N\n\n])\n, (41)\n\n\u00b5\u221e =\n\n(\n\u2202F\n\n\u2202N\n\n)\nT\u221e,Vth\n\n= \u2212T\u221e ln\n\n[\nT 3\n\u221eVth\n\u03c02N\n\n]\n. (42)\n\nAs expected S, derived in this way, agrees with the definition in Eq. (15) with the local variable\ns = n(4\u2212 \u00b5/T ) from Eq. (31). The internal energy is obtained as\n\nU = F + T\u221eS = 3NT\u221e , (43)\n\nwhich agrees with the local definition in Eq. (14) as well, with \u03c1 = 3nT from Eq. (29). The\nfirst law of thermodynamics, given in Eq. (21), follows accordingly.\n\nFor the massive particle case, the one-particle partition function is\n\nZ1 =\nm2T\u221e\n\n2\u03c02\n\n\u222b\nd3r\n\n\u221a\nA\n\nB\nK2(m\n\n\u221a\nB/T\u221e) , (44)\n\nand the global Helmholtz free energy F is given as\n\nF = \u2212T\u221e lnZN(T\u221e) = \u2212T\u221eN\n\n(\n1 + ln\n\n[\nm2T\u221e\n2\u03c02N\n\n\u222b\nd3r\n\n\u221a\nA\n\nB\nK2(m\n\n\u221a\nB/T\u221e)\n\n])\n. (45)\n\nIn contrast to the massless case, the thermodynamic volume Vth cannot be simply identified\nas the spatial integral part in the partition function due to the T\u221e dependence in the Bessel\nfunction K2(m\n\n\u221a\nB/T\u221e). Instead, we determine its differential form by evaluating the total\n\nderivative of F as given in Eq. (18). By using the pressure at infinity p\u221e, found from Eqs. (28)\nand (30) as\n\np\u221e =\nm2e\u00b5\u221e/T\u221e\n\n2\u03c02\nT 2\n\u221e K2(m/T\u221e) , (46)\n\nwe obtain the differential form of thermodynamic volume\n\ndVth = \u2212p\u22121\u221e (dF )N,T\u221e =\n1\n\nK2(m/T\u221e)\nd\n\n(\u222b\nd3r\n\n\u221a\nA\n\nB\nK2(m\n\n\u221a\nB/T\u221e)\n\n)\nN,T\u221e\n\n. (47)\n\nIn the massless limit, with K2(b) = b2/2, this agrees with Eq. (26). In general, dVth is sensitive\nto the particle mass m, and is quite different from the universal geometric volume. As we will\nshow later in Sec. 3.2, the combination p\u221edVth might be insensitive to the mass if ultracompact\nobjects feature a deep gravitational potential and the spatial integral is dominated by the\nrelativistic contribution.\n\nThe total entropy, chemical potential, and total internal energy are derived in a similar way\nas\n\nS = \u2212\n(\n\u2202F\n\n\u2202T\u221e\n\n)\nVth,N\n\n= N\n\n(\n4\u2212 \u00b5\u221e\n\nT\u221e\n+\ne\u00b5\u221e/T\u221em3\n\n2\u03c02N\n\n\u222b\nK1(m\n\n\u221a\nB/T\u221e)\n\n\u221a\nA d3r\n\n)\n, (48)\n\n\u00b5\u221e =\n\n(\n\u2202F\n\n\u2202N\n\n)\nT\u221e,Vth\n\n= \u2212T\u221e ln\n\n[\nm2T\u221e\n2\u03c02N\n\n\u222b\nd3r\n\n\u221a\nA\n\nB\nK2(m\n\n\u221a\nB/T\u221e)\n\n]\n, (49)\n\nU = F + T\u221eS = 3T\u221eN +\ne\u00b5\u221e/T\u221em3T\u221e\n\n2\u03c02\n\n\u222b\nK1(m\n\n\u221a\nB/T\u221e)\n\n\u221a\nA d3r , (50)\n\n10\n\n\n\nwhich agree with the quantities obtained from the local parameters. In comparison to the\nmassless gas, S and U include additional terms that depend on the spatial integral of K1(b).\nThis is also related to the difficulty in defining the full form of Vth from Eq. (47).\n\n2.4 Quantum ideal gas\n\nWhen the quantum nature of the source is taken into account, the particle number can fluctuate\nand hence is not appropriate to be treated as a state parameter in equilibrium thermodynamics.\nTherefore, the grand canonical ensemble is generally used to describe quantum gases where the\nchemical potential \u00b5, in addition to temperature and volume, can be a state parameter that\nhandles the change of particle number and is appropriately fixed.\n\nIn similarity with the canonical ensemble, we verify the consistency between the global and\nlocal pictures in the grand canonical ensemble by demonstrating the additivity of the global\ngrand potential \u2126, given in Eq. (14). In the global picture, the grand potential can be derived\nby the fundamental equation\n\n\u2126 = \u2212T\u221e lnZ , (51)\n\nwhere the global partition function Z is\n\nZ = Tr[e\u2212(H\u0302\u2212\u00b5\u221eN\u0302)/T\u221e ] = \u03a0l\n\n\u2211\nnl\n\ne\u2212(nlEl,\u221e\u2212\u00b5\u221enl)/T\u221e . (52)\n\nFor a given quantum state labelled by l, the trace is evaluated with the number eigenstates nl.\nFor Bose\u2013Einstein and Fermi-Dirac gas, summing over nl leads to\n\n\u2126 = \u2212T\u221e\n\n\uf8f1\uf8f2\uf8f3\ng\n\u2211\nl\n\nln\n[\n1 + e\u2212(El,\u221e\u2212\u00b5\u221e)/T\u221e\n\n]\n, Fermi-Dirac\n\n\u2212\n\u2211\nl\n\nln\n[\n1\u2212 e\u2212(El,\u221e\u2212\u00b5\u221e)/T\u221e\n\n]\n, Bose\u2013Einstein ,\n\n(53)\n\nwhere g = 2\u03c3+ 1 denotes the multiplicity for fermions with spin \u03c3. As in the case of canonical\nensemble, the sum can be approximated by the integral over the density of states P (E\u221e). From\nEq. (34), one obtains that\n\n\u2126 = \u2212\n\u222b R\n\n0\n\n\u221a\nAB d3r\n\nT\n\n(2\u03c0)3\n\n\u222b\nd3p\n\n{\ng ln\n\n[\n1 + e\u2212(E\u2212\u00b5)/T\n\n]\n, Fermi-Dirac\n\n\u2212 ln\n[\n1\u2212 e\u2212(E\u2212\u00b5)/T\n\n]\n, Bose\u2013Einstein\n\n=\n\n\u222b R\n\n0\n\n\u221a\nAB w d3r (54)\n\nwhere \u03c9 = \u2212p is the grand potential density. The main difference for grand canonical ensemble\nhere is that the connection between local and global pictures in Eq. (54) is established through\nthe logarithm of the partition function, given that the sum over states appears after taking the\nlogarithm. For canonical ensemble, we take sum over states before taking the logarithm, and\nthe additivity emerges from the overall dependence on N .\n\nNow we will proceed to examine some examples and identify the thermodynamic volume in\neach case.\n\n11\n\n\n\nPhoton gas: As massless Bose-Einstein gas, the particle number of photon gas is not\nconserved, and so its chemical potential vanishes, i.e. \u00b5 = 0. The local variables in this case\nare given as\n\n\u03c1 = 3p =\n\u03c02\n\n15\nT 4 , s =\n\n4\u03c02\n\n45\nT 3 . (55)\n\nPlugging in the Tolman\u2019s law, given in Eq. (13), we can obtain the relations\n\np(r)B2(r) = p\u221e , \u03c1(r)B2(r) = \u03c1\u221e , s(r)B3/2(r) = s\u221e , (56)\n\nwhere \u03c1\u221e = 3p\u221e = \u03c02T 4\n\u221e/15 and s\u221e = 4\u03c02T 3\n\n\u221e/45 denote the gas properties at spatial infinity.\nThese relations are insensitive to the numerical coefficients in Eq. (55), and can be directly\nread from the momentum conservation law in Eq. (10), given the equation of state \u03c1 = 3p and\nthe Gibbs-Duhem relation, given in Eq (3).\n\nWith Eqs. (54) and (55), the global grand potential is obtained as\n\n\u2126 = \u2212\n\u222b \u221a\n\nA(r)B(r) p d3r = \u2212p\u221e\n\u222b R\n\n0\n\n\u221a\nA(r)\n\nB3(r)\nd3r \u2261 \u2212p\u221eVth . (57)\n\nWith vanishing chemical potential, \u2126 is a function of T\u221e and Vth. The thermodynamic\nvolume Vth is again identified as that in Eq. (26), consistent with the derivative relation\np\u221e = \u2212(\u2202\u2126/\u2202Vth)T\u221e in Eq. (25). It is not surprising that the thermodynamic volume of\nthe photon gas takes the same form as in the case of the semi-classical massless gas. From\nEq. (24), the expression of Vth in Eq. (26) follows from the relation p(r)B2(r) = p\u221e, as dictated\nby the corresponding equation of state, \u03c1 = 3p. From Eqs. (57) and (25), we can obtain the\ntotal entropy and internal energy\n\nS = \u2212\n(\n\u2202\u2126\n\n\u2202T\u221e\n\n)\nVth\n\n= s\u221eVth , (58)\n\nU = \u2126 + T\u221eS = \u03c1\u221eVth , (59)\n\nwith s\u221e, \u03c1\u221e given below Eq. (56). These expressions are consistent with the expected local\ndefinitions, given in Eqs. (14) and (15).\n\nCold Fermi gas at T = 0: At zero temperature, all states of the cold Fermi gas be-\nlow the cutoff Fermi energy are occupied. The local variables are then characterized by the\ncorresponding Fermi momentum kF and the fermion mass m as\n\np = 3g\u03c1c hp\n\n(\nkF\nm\n\n)\n, \u03c1 = 3g\u03c1c h\u03c1\n\n(\nkF\nm\n\n)\n, n = g\n\nk3F\n6\u03c02\n\n, (60)\n\nwhere g = 2 is the multiplicity in Eq. (53), \u03c1c = m4/(6\u03c02) is the critical density, and\n\nhp(x) =\n1\n\n8\n\n[\nx\n\n(\n2\n\n3\nx2 \u2212 1\n\n)\u221a\nx2 + 1 + sinh\u22121 x\n\n]\n,\n\nh\u03c1(x) =\n1\n\n8\n\n[\nx(2x2 + 1)\n\n\u221a\nx2 + 1\u2212 sinh\u22121 x\n\n]\n. (61)\n\n12\n\n\n\nWith vanishing temperature, the Gibbs-Duhem relation now becomes \u03c1 + p = n\u00b5, where the\nchemical potential is given as \u00b5 =\n\n\u221a\nk2F +m2 and Tolman\u2019s law in Eq. (13) imposes the con-\n\nstraint \u00b5(r) = \u00b5\u221e\n\u221a\nB(r).\n\nThe global grand potential is a function of the chemical potential \u00b5\u221e and thermodynamic\nvolume Vth, and is given as\n\n\u2126 = \u2212\n\u222b \u221a\n\nA(r)B(r) p d3r = \u22123\u03c1c\n\n\u222b R\n\n0\n\n\u221a\nA(r)B(r)hp\n\n(\nkF\nm\n\n)\nd3r . (62)\n\nIn similar to the massive case for semi-classical ideal gas, the thermodynamic volume Vth cannot\nsimply be identified as the spatial integral part in \u2126 due to the complicated T\u221e dependence\nin hp(kF/m). It is then found from the generic derivative definition Eq. (24). By using p\u221e =\n3\u03c1chp(kF,\u221e/m) from Eq. (60), we obtain\n\ndVth = d\n\n\uf8eb\uf8ed 1\n\nhp\n\n(\nkF,\u221e\nm\n\n) \u222b d3r\n\u221a\nAB hp\n\n(\nkF\nm\n\n)\uf8f6\uf8f8\n\u00b5\u221e\n\n, (63)\n\nwhere kF/m =\n\u221a\n\u00b52\n\u221e/(Bm2)\u2212 1 and the demanded relation, p\u221e = \u2212(\u2202\u2126/\u2202Vth)\u00b5\u221e , is then\n\nrecovered. Similarly, dVth is sensitive to the fermion mass, in general.\n\n3 Examples of horizonless compact objects\n\nWe discuss explicit examples of horizonless compact objects by starting from self-gravitating gas\nin GR in Sec. 3.1. The relation of the generic law developed in Sec. 2 to those in previous studies\nin the literature is discussed. Then, in Sec. 3.2, we consider a novel example of horizonless\nultracompact objects, 2-2-holes, in quadratic gravity. They are as compact as black holes, but\nfeature a novel high curvature interior. The high curvature effects turn out to make significant\ncontributions to global thermodynamic variables, where interesting connections to black hole\nthermodynamics emerge.\n\n3.1 Compact objects in GR\n\nSelf-gravitating systems in GR provide us natural examples to see the curvature effects on\nstatistical thermodynamics. Here, we consider two concrete examples of compact objects, self-\ngravitating photon gas confined to a spherical box [14] and neutron stars composed of cold\nFermi gas (i.e. the Oppenheimer-Volkof model) [23].\n\nConsidering static and spherically symmetric solutions, the Einstein field equations can be\nsimplified as the momentum conservation of the stress-tensor Eq. (10) and the ToV equation\nEq. (93). For a given equation of state (EoS) of the matter source, the pressure p(r) and\nmass profilesM(r) \u2261\n\n\u222b r\n0\n\n4\u03c0r\u20322\u03c1(r\u2032)dr\u2032 can be solved simultaneously as functions of the central\npressure pc at the origin. The solutions obey a simple scaling behavior, with the following\nrescaled dimensionless quantities\n\np\u0303(r\u0303) = p(r)\u03bb4, M\u0303(r\u0303) =M(r)\u03bb\u22122`3Pl , r\u0303 = r \u03bb\u22122`Pl, (64)\n\n13\n\n\n\nuniquely determined by the field equations. A one-parameter family of solution for p(r),M(r)\ncan then be obtained by scaling with an arbitrary length scale \u03bb. In GR, the physical mass of\nthe object takes a simple form\n\nM =M(R) \u2261\n\u222b R\n\n0\n\n4\u03c0r2\u03c1(r)dr . (65)\n\nGiven that the metric determinant\n\u221a\nAB < 1 in the interior, the total internal energy U is\n\nalways smaller than the mass M , and its smallness reflects the contribution from gravitational\nfield.\n\nLet\u2019s first consider self-gravitating photon gas confined to a spherical box, with the EoS\ngiven in Eq. (55). Here, a finite box of radius R is imposed to prevent the massless gas from\nspreading all the way to the infinity. Self-gravitating photon gas confined to a spherical box is\nthen described by a two-parameters family of solutions, and the scaling behavior in Eq. (64)\ncan be used to relate solutions of different pc with \u03bb = p\n\n\u22121/4\nc .\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\n\u25cf\n\u25cf\u25cf\u25cf\n\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\n0.00 0.05 0.10 0.15 0.20 0.25\n0.00\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\n0.25\n\n0.30\n\n0.35\n\nM /R\n\n4\n\u03c0\nR\n2\n\u03c1\n(R\n\n)\u2113\nP\nl\n2\n\n\u25cf\u25cf\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\n0.00 0.05 0.10 0.15 0.20 0.25\n\n0.65\n\n0.70\n\n0.75\n\n0.80\n\n0.85\n\n0.90\n\n0.95\n\n1.00\n\nM /R\n\nU\n/M\n\n0.01 0.10 1 10 100\n\n0.001\n\n10\n\n105\n\nR\n\u02dc\n\nS\u02dc\n,V\n\u02dc\nth\n,V\n\u02dc\nge\no\n\nFigure 1: Properties of self-gravitating photon gas confined to a spherical box in terms of\ndimensionless quantities. The red and blue denote the stable and unstable branches of the\nsolutions. S\u0303 = S p\n\n3/4\nc `3Pl, R\u0303 = Rp\n\n1/2\nc `Pl, V\u0303 = V p\n\n3/2\nc `3Pl are the rescaled dimensionless quantities.\n\nIn the third panel, the solid, dash and dotted lines are for S\u0303, V\u0303th (for Vth in Eq. (26)), V\u0303geo (for\nVgeo in Eq. (27)) respectively.\n\nFigure 1 displays properties for self-gravitating photon gas. The global thermodynamic\nvariables are related by U = 3T\u221eS/4 = 3 p\u221eVth as given in Eqs. (58) and (59). Starting from\na small mass-to-radius ratio M/R is the solution for dilute photon gas in a box. Gravitational\neffects become strong with increasing M/R. The maximal M/R \u2248 0.25 defines a turning\npoint, beyond which the solutions become unstable. Along the way, the internal-energy-to-\nmass ratio U/M decreases slowly from unity, and reaches the minimum U \u2248 0.64M around\nthe turning point. In the weak gravity regime, the thermodynamic volume Vth is very close to\nthe geometric one Vgeo and the entropy S \u221d R3 with T\u221e roughly a constant. In the unstable\nbranch, Vth becomes slightly larger and S \u221d R3/2 grows slower with R given T\u221e \u221d R\u22121/2.\n\nThe numerical solutions can be used to examine the first law of thermodynamics. Since the\nsolutions are described by the two parameters pc and R, the entropy S (or the temperature T\u221e)\nand the thermodynamic volume Vth can vary independently. The conventional first law then\napplies, i.e. dU = T\u221edS \u2212 p\u221edVth, as we would expect from the general derivation in Sec. 2.\n\n14\n\n\n\nOn the other hand, it has been proved in GR [14] that the physical mass M satisfies the first\nlaw below\n\ndM = T\u221edS \u2212 p(R)\n\u221a\nB(R) dVgeo = T\u221edS \u2212 p\u221eB(R)\u22123/2 dVgeo , (66)\n\nwhere M is considered as a function of S and Vgeo instead. The difference between the physical\nmass and total internal energy is then\n\ndM \u2212 dU = p\u221e\n(\ndVth \u2212 dVgeoB(R)\u22123/2\n\n)\n. (67)\n\nConsidering the gravitational potential in the object\u2019s interior, i.e. B(R) > B(r) for r < R,\nwe expect Vth > VgeoB(R)\u22123/2 and then dM > dU . This reveals the U and M relation from a\ndifferent perspective apart from their definitions. Interestingly, we find no discussion of such\nrelation between Eq. (66) and the conventional first law in the literature.\n\nAs the second example, we consider neutron stars composed of cold Fermi gas at zero\ntemperature, with the EoS given in Eq. (60). In contrast to the self-gravitating photon gas, the\nradius R of neutron stars is determined with p(R) = 0, and is not an independent parameter.\nNeutron stars composed of cold Fermi gas are then described by a two-parameter family of\nsolutions, i.e. the central pressure pc and the Fermion mass m, and the scaling behavior in\nEq. (94) can be used to relate solutions of different mass m, with \u03bb = 1/m.\n\n2 4 6 8 10 12\n\n0.05\n\n0.10\n\n0.15\n\n0.20\n\n0.25\n\n0.30\n\n0.35\n\n0.40\n\nR\n\u02dc\n\nM\u02dc\n\n0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14\n\n0.75\n\n0.80\n\n0.85\n\n0.90\n\n0.95\n\n1.00\n\nM /R\n\nU\n/M\n\n0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\nM\n\u02dc\n\nN\u02dc\n\nFigure 2: Properties of neutron stars composed of the cold Fermi gas for dimensionless quanti-\nties. The red and blue denote the stable and unstable branches of the solutions. M\u0303 = M m2`3Pl,\nR\u0303 = Rm2`Pl, N\u0303 = N m3`Pl are the rescaled dimensionless quantities.\n\nFigure 2 shows properties for neutron stars composed of cold Fermi gas. Similarly, the\ngravitational effects become stronger with increasing central pressure. In the stable branch of\nsolutions, the physical mass M and total number of particles N increase, and the radius R\ndecreases. In the weak gravity regime, we find N \u221d rH/(m`2Pl), \u00b5\u221e \u221d r0H m. The maximum of\nM/R remains the turning point, but the value is slightly smaller than that of self-gravitating\nphoton gas. The internal energy to mass ratio U/M decreases from one in a similar way, and\nis bounded from below by U \u2248 0.72M . For the first law of thermodynamics, since the solution\nfor a given Fermion mass m is described by only one parameter, the particle number N and the\nthermodynamic volume Vth cannot vary independently. The conventional first law Eq. (21) then\nmay not be properly defined at zero temperature limit. Instead, we find from the numerical\nsolutions that\n\ndM \u2248 \u00b5\u221edN . (68)\n\n15\n\n\n\nThis can be viewed as the first law built up on the physical mass M . Since the thermodynamic\nvolume accounts purely for the gravitational field contribution, it is absorbed into dM . In\npractice, neutron stars may have a small but nonvanishing temperature. The pressure then\nwould not drop to zero at a hard surface, and so a small independent dVth term would appear\nin Eq. (68). For the unstable solutions, the global variables vary less with the central pressure,\nand become attracted by the infinite pressure limit [23].\n\nAs a final remark, the compactness M/R is sensitive to source matter properties. With\nexotic EoSs, it is possible to realize ultracompact objects in GR with R smaller than the\nphoton sphere radius, i.e. M/R & 0.33, or even black hole mimickers with M/R \u223c 0.5 and no\nhorizon [8]. Nonetheless, no candidate make connections between black hole thermodynamics\nand the conventional one as we focus on here. In the following subsection, we will discuss\na candidate in a theory of modified gravity, where such a connection appears due to super-\nPlanckian high curvature effects.\n\n3.2 Not quite black holes in quadratic gravity\n\nAn interesting candidate for horizonless ultracompact objects is a new type of solution, 2-2-\nholes [24, 25], in quadratic gravity as described by the classical action Eq. (97). The existence\nof 2-2-holes relies on the Weyl term C\u00b5\u03bd\u03c1\u03c3C\u00b5\u03bd\u03c1\u03c3, which introduces a new spin-2 mode with\nthe Compton wavelength \u03bb2. In the presence of a compact matter source, a typical 2-2-hole\nwith mass M much larger than the minimum mass Mmin \u223c m2\n\nPl\u03bb2 resembles a black hole\nclosely from the exterior, while a novel interior takes over right above the would-be horizon\nrH = 2M`2Pl. The interior curvature can easily reach super-Planckian values when \u03bb2 \u223c `Pl,\nand approaches infinity at the origin. In contrast to proposed ultracompact objects in GR,\nthe 2-2-hole properties are crucially determined by the high curvature interior, while being\nquite insensitive to the details of EoS. Thus, 2-2-holes provide a tractable model to study the\ninfluence of high curvature effects on statistical thermodynamics. In the following, we consider\nconcrete examples of 2-2-holes sourced by various simple forms of matter.\n\nFirstly, we consider thermal 2-2-holes sourced by massless particles, i.e. photon gas [26, 27]\nand relativistic classical ideal gas. The gas profile and the metric functions can be solved\nfrom the momentum conservation of the stress-tensor Eq. (10), which yields p(r)B(r)2 = p\u221e\nfor relativistic gas, and two field equations in Eq. (98). Fig. 3 displays the 2-2-hole solutions\nwith two different values of mass M \ufffd Mmin. Despite the complicated form of field equations\nin quadratic gravity, the numerical solutions of 2-2-holes turn out to be governed by simple\nqualitative features. The exterior (r & rH), where the curvature becomes lower for increasing\nsize of the object, obeys the Einstein field equations to a good approximation, and follows the\nconventional scaling in Eq. (64). The interior r < rH , on the other hand, is a high curvature\nregime and features a huge gravitational potential. At the leading order of high curvature\nexpansion, it is described by a novel scaling behavior, with the following rescaled dimensionless\nquantities [25]\n\np\u0303(r\u0303) = p(r)\u03bb22 `\n2\nPl, A\u0303(r\u0303) = A(r)\n\nr2H\n\u03bb22\n, B\u0303(r\u0303) = B(r)\n\nr2H\n\u03bb22\n\n(69)\n\nuniquely determined as functions of r\u0303 = r/rH . Similarly, a box has to be imposed to make the\ntotal energy finite, and the box radius R has to be considerably larger than rH to not ruin the\n\n16\n\n\n\nsimple behavior.\n\n0.2 0.4 0.6 0.8 1.0 1.2 1.4\n\n10-7\n\n10-4\n\n0.1\n\n100\n\nr / rH\n\nmetric function\n\n0.2 0.4 0.6 0.8 1.0 1.2 1.4\n0.001\n\n0.010\n\n0.100\n\n1\n\n10\n\nr / rH\n\nT\uf77d1\uf00c4M\uf111 min\n1\uf00c2\n\n/mPl\n\nFigure 3: Properties of thermal 2-2-holes sourced by relativistic gas with EoS \u03c1 = 3p. Left:\nthe metric A (solid) and B (dashed) as functions of r/rH , where rH is the would-be horizon\nsize. Right: the thermal gas temperature T as a function of r/rH . The red and blue are for\nrH/\u03bb2 = 6, 100 respectively.\n\nFrom the novel scaling in Eq. (69) and the numerical solutions, we find the rescaled gas\npressure at infinity\n\np\u0303\u221e = p\u0303(r\u0303)B\u0303(r\u0303)2 = p\u221e\n`2Pl\n\u03bb22\nr4H \u2248 1.35\u00d7 10\u22125 . (70)\n\nThe thermodynamic volume Vth in Eq. (26) can be separated into two parts, the interior con-\ntribution V\n\n(in)\nth for r . rH and the exterior contribution V\n\n(ex)\nth for rH . r . R. The interior\n\ncontribution is governed by the novel scaling in Eq. (69), satisfying\n\nV\u0303\n(in)\nth = V\n\n(in)\nth\n\n\u03bb22\nr5H\n\u2248 4.63\u00d7 103 . (71)\n\nIn comparison to the flat spacetime scaling V (in)\nth \u223c r3H , the high curvature effects lead to a\n\nlarge enhancement of order (rH/\u03bb2)\n2. The gain could be enormous given that \u03bb2 can be as\n\nsmall as `Pl. The exterior contribution encodes the box radius R dependence. Since the gas\ntemperature drops drastically at r > rH as shown in Fig. 3, we expect a trivial dependence\nV\n\n(ex)\nth \u221d R3 from the cold and dilute gas outside as in the case of GR.\nThus, for macroscopic 2-2-holes with R not significantly larger than rH , we expect Vth to\n\nbe dominated by the interior contribution. This is also true for the total internal energy and\nentropy of the gas, which are proportional to Vth. With Eqs. (59), (70), and (71), the total\ninternal energy is\n\nU \u2248 U (in) = 3 p\u221e V\n(in)\nth \u2248 3\n\n8\nM . (72)\n\nSince the compactness of 2-2-holes is nearly maximal, it is not surprising that its internal\nenergy to mass ratio is far smaller than that for compact objects in GR. The same ratio has\nalso been obtained in the brick wall model [28], but there the back-reaction has not been taken\n\n17\n\n\n\ninto account. Using Eqs. (55), (58), (70), and (71), we can obtain the temperature at spatial\ninfinity and the entropy\n\nT\u221e \u2248 1.4 M\u0302\n1/2\nmin TBH , S \u2248 S(in) \u2248 0.71 M\u0302\n\n\u22121/2\nmin SBH , (73)\n\nwhere M\u0302min = Mmin/mPl = 0.63\u03bb2/`Pl, the Hawking temperature TBH = m2\nPl/8\u03c0M and the\n\nBekenstein-Hawking entropy SBH = \u03c0 r2H/`\n2\nPl. As a result of high curvature effects, 2-2-hole\n\nsourced by relativistic particles exhibit Hawking-like temperature and the entropy area law [25].\nGiven that S = s\u221eVth in Eq. (58), we can see that the enormous amount of microscopic entropy\nare achieved here mainly through the huge value of V (in)\n\nth given in Eq. (71). This is usually\nconsidered difficult for self-gravitating objects with no horizon. The numerical values of T\u221e\nand S differ from the black hole counterparts due to the Mmin or \u03bb2 dependence.\n\nFor the first law of thermodynamics, as 2-2-holes sourced by photon gas are described by two\nparameters rH and R, the entropy S and thermodynamic volume Vth can vary independently,\nand the conventional first law still applies, i.e. dU = T\u221edS \u2212 p\u221edVth, as we would expect. It\nis the variation of the physical mass M required to be checked numerically, given the absence\nof analytical solutions. With T\u221eS\n\n(in) = 4 p\u221eV\n(in)\nth \u2248 M/2 from Eq. (72) and T\u221e \u221d M\u22121,\n\nS(in) \u221dM2 in Eq. (75), we obtain\n\ndM \u2248 T\u221edS\n(in) \u2248 T\u221edS . (74)\n\nIn comparison to Eq. (66), the work performed at the box radius is numerically negligible for\nmacroscopic 2-2-holes with Vgeo \u223c R3 \ufffd V\n\n(in)\nth . The major difference between the physical mass\n\nand total internal energy is then accounted for by the thermodynamic volume contribution\np\u221edVth \u2248 5dM/8 with dM \u2248 dU + p\u221edVth.\n\nIt is instructive to make some comparison with black hole thermodynamics. For Schwarzschild\nblack holes, dM = T\u221edS applies without the volume term because of the vanishing thermody-\nnamic pressure.2 For thermal 2-2-holes, Eq. (74) holds at the leading order of high curvature\nexpansion since the volume term associated with variation of the box boundary has negligible\ncontribution. This shows that certain aspects of black hole thermodynamics could be derived\nfrom conventional thermodynamics by utilizing non-trivial structure of curved spacetime, and\nthus are not too mysterious.\n\nFor 2-2-holes sourced by semiclassical ideal gas, there is the additional dependence on the\nconserved number of particles N or the nonzero chemical potential \u00b5\u221e given in Eq. (42). The\nrelation between U and M remains the same as in Eq. (72), while the temperature and total\nentropy change. With Eqs. (28), (30), and (41) for the massless ideal gas, we obtain\n\nT\u221e \u2248 1.7 M\u0302\n1/2\nmin e\n\n\u2212 1\n4\n\u00b5\u221e/T\u221e TBH , S\n\n(in) \u2248 0.59 M\u0302\n\u22121/2\nmin e\n\n1\n4\n\u00b5\u221e/T\u221e\n\n(\n1\u2212 \u00b5\u221e\n\n4T\u221e\n\n)\nSBH . (75)\n\nGiven that exp(\u00b5\u221e/T\u221e) \ufffd 1 for semiclassical ideal gas, the corresponding thermal 2-2-holes\nhave higher temperature and lower entropy than holes sourced by photon gas of the same mass\n\n2In the extended black hole thermodynamics [29, 30] (see [31] for a review), which concerns spacetimes with\nnonzero cosmological constant \u039b, the pressure P is identified with the cosmological constant, the mass of the\nblack hole is interpreted as enthalpy H, and the thermodynamic volume is then given as Vth = (\u2202H/\u2202P )S . This\ndefinition of thermodynamic volume is apparently irrelevant to our definition of Vth in this work.\n\n18\n\n\n\nin Eq. (73). As the generalization of conventional thermodynamics, it is not surprising that\nthermal 2-2-hole characteristics can depend on certain aspects of matter properties.\n\nConsidering the entropy S as a function of two independent variables M and N as given in\nEq. (41), the total differential of S for the interior contribution is\n\ndS(in) \u2248 dN (in) ln(e\u2212\u00b5/T ) +N (in)\n\n(\n5\ndM\n\nM\n+ 3\n\ndM\n\nM\n\n)\n\u2248 \u2212\u00b5\u221e\n\nT\u221e\ndN (in) +\n\n1\n\nT\u221e\ndM , (76)\n\nwith V (in)\nth \u221dM5 and T\u221eN (in) \u221dM . This yields a generalization of Eq. (74) with the additional\n\ncontribution from the conserved number of particles,\n\ndM \u2248 T\u221e dS + \u00b5\u221edN . (77)\n\nThe exterior contributions are again ignored. Since black holes carry no global charges, this has\nno counterpart in black hole thermodynamics. For a macroscopic 2-2-hole, the particle-number-\nto-mass ratio NmPl/M \u2248 mPl/(8T\u221e) \u221d M/mPl is enormous, and it can increase indefinitely\nwith the hole mass unlike the local charge of black holes to be bounded by the extremal limit.\n\n2-2-holes can also be sourced by semiclassical ideal gas with nonzero mass. As the tem-\nperature satisfies the Tolman\u2019s law T (r)\n\n\u221a\nB(r) = T\u221e, the gas becomes relativistic around the\n\norigin, while the density and pressure are suppressed by the Boltzmann factor when T (r) drops\nbelow the particle mass m. Although the field equations in Eq. (100) are more involved for\nthis case, the interior metric functions and gas profile remain characterized by the same scaling\nbehavior Eq. (69) as for relativistic thermal gas, for a given m\n\n\u221a\n\u03bb2`Pl. Interestingly, global\n\nthermodynamic quantities such as T\u221e, S, N , U are found to be quite insensitive to the particle\nmass due to the dominance by the relativistic contribution. Thus, the above results for the\nmassless case apply, although the thermodynamic volume cannot be directly identified for this\ncase.\n\nAnother example is 2-2-holes sourced by the cold Fermi gas, which may serve as the endpoint\nof gravitational collapse of neutron stars after sufficient cooling. Together with the Tolman\u2019s\nlaw Eq. (13) for chemical potential, the metric functions and gas profile are solved from the\nfield equations Eq. (100) with EoS given in Eq. (60). The cold Fermi gas becomes relativistic\naround the origin due to the quantum pressure. As in the case of neutron stars in GR, the\npressure (and the Fermi momentum kF ) drops to zero at some radius R and defines the object\nsurface. The difference is that R is within the would-be horizon rH for 2-2-holes, while it is\nconsiderably larger than rH for neutron stars.\n\nFor a given m\n\u221a\n\u03bb2`Pl, the interior is again characterized by the novel scaling behavior in\n\nEq. (69). With this scaling, the rescaled chemical potential redshifted to infinity is\n\n\u00b5\u0303\u221e = \u00b5\u221e\n\n\u221a\n`Pl\n\u03bb2\nrH \u2248 0.22 . (78)\n\nSince R < rH , the total internal energy and (average) number of particles only receive contri-\nbution from the 2-2-hole interior. The internal energy to mass ratio U/M remains roughly 3/8.\nThe rescaled number of particles is\n\nN\u0303 = N\n`\n3/2\nPl \u03bb\n\n1/2\n2\n\nr2H\n\u2248 1.15 . (79)\n\n19\n\n\n\nNote that the rH (or M) dependences of \u00b5\u221e and N are quite different from that for neutron\nstars, but resemble closely that for T\u221e and S for thermal 2-2-holes in Eq. (75). With Eqs. (78)\nand (79), it is straightforward to obtain\n\ndM \u2248 \u00b5\u221e dN , (80)\n\nthe analog of Eq. (68) for neutron stars and of Eq. (77) for thermal 2-2-holes. Again, the\nthermodynamic volume term accounts for the difference 1\u2212 U/M , and the contribution is the\nsame as in the case of thermal 2-2-holes.\n\nIn summary, the global thermodynamic variables of 2-2-holes exhibit interesting universal\ncharacteristics due to the high curvature interior and its novel scaling behavior. It is intimately\nrelated to the greatly enhanced interior thermodynamic volume that dominates the contribu-\ntion for macroscopic holes. This renders the EoS dependence rather weak, as opposed to the\nsituation in GR.\n\n4 Summary\n\nWe have studied thermodynamics of self-gravitating systems in a new approach to better char-\nacterize horizonless ultracompact objects in a general theory of gravity. In Sec. 2, we have\nderived generic thermodynamic laws of global variables, without the explicit input of gravita-\ntional field equations, from the curved spacetime generalizations of thermodynamic potentials\nfor different statistical ensembles. Consequently, there is no direct reference to the physical\nmass, and the total internal energy U is just naively defined in Eq. (14). The conventional\nthermodynamic laws then follow directly from the global and local correspondence, except that\nthermodynamic volume Vth has to be appropriately identified. The most generic definition of\nVth can be derived from the first law of thermodynamics, as given by Eqs. (18) and (24) for\ncanonical and grand canonical ensembles, respectively. For illustration, we have considered\nexamples of non-interacting gas, where the global thermodynamic potentials can be derived\nfrom the global partition functions. The explicit form of global thermodynamic variables are\ndisplayed. For relativistic gas in particular, i.e. with EoS \u03c1 = 3p, it is possible to identify the\nexplicit form of Vth, as given in Eq. (26), with the help of Tolman\u2019s law, given in Eq. (13). It is in\ngeneral larger than the geometric volume Vgeo, given in Eq. (27), due to the extra enhancement\nfrom gravitational redshift.\n\nThen in Sec. 3, we have studied specific examples of horizonless ultracompact objects by tak-\ning into account the back-reaction. We have first considered familiar examples of self-gravitating\ngas in GR, including photon gas in a box and the cold Fermi gas. In comparison with the previ-\nous studies, where the physical mass M of the system is identified as the total internal energy,\nwe have highlighted the difference between the forms the first law takes in these two approaches.\nThe difference betweenM and U turns out to be directly related to the difference between ther-\nmodynamic volume Vth and the geometric one Vgeo, as given in Eq. (67). For the case where\nthe object boundary is determined by gravitational field equations, e.g. the cold Fermi gas, Vth\ndoes not vary independently and its contribution has to be absorbed into the variation of M .\n\nFurthermore in Sec. 3, we have considered another candidate for horizonless ultracompact\nobjects, 2-2-hole in quadratic gravity, sourced by similar kind of gases used in the previous\nexamples. These objects are as compact as black holes, and are drastically different from the\n\n20\n\n\n\nproposed ultracompact objects in GR due to the novel interior with super-Planckian curvatures.\nA novel scaling behavior in Eq. (69) emerges for the interior solution, to be compared with the\nGR scaling in Eq. (64). As a result, the interior thermodynamic volume V (in)\n\nth is strongly\nenhanced by a factor of r2H/`2Pl for macroscopic holes in comparison to the naive estimate of\norder r3H . This then leads to Hawking-like temperature and the entropy area law for 2-2-holes\nfrom conventional thermodynamics as given in Eqs. (73) and (75). Such large Vth is also what\nis necessary to account for the large difference between M and U . Because of the dominance\nof the high curvature effects, the 2-2-hole thermodynamics shows universal characteristics, and\nis much less sensitive to matter EoS than compact objects in GR. Note that the peculiar\nthermodynamic characteristics for 2-2-holes are only verified numerically due to the absence of\nanalytical relations between M and the source properties. The possibility for a more analytical\nderivation, as in the case of GR, requires further investigation.\n\nAcknowledgements\nWork of U.A. is supported in part by the Chinese Academy of Sciences President\u2019s International\nFellowship Initiative (PIFI) under Grant No. 2020PM0019, and the Institute of High Energy\nPhysics, Chinese Academy of Sciences, under Contract No. Y9291220K2. J.R. is supported by\nthe Institute of High Energy Physics under Contract No. Y9291220K2.\n\nA Microcanonical ensemble\n\nWe have focused on canonical and grand canonical ensembles throughout the paper. Here,\nwe simply address the other commonly used framework, microcanonical ensemble, in a simple\nexample of massless semi-classical ideal gas. The corresponding thermodynamic potential is\nentropy S, determined by counting of number of microstates for specific parameters. The state\nparameters in this ensemble are total internal energy U , the total number of particles N , and\nthermodynamic volume Vth.\n\nBefore going into the example, let\u2019s first have a general discussion. The total differential of\nentropy S(U, Vth, N), directly from the fundamental relation (21), is given as\n\ndS =\n1\n\nT\u221e\ndU +\n\np\u221e\nT\u221e\n\ndVth \u2212\n\u00b5\u221e\nT\u221e\n\ndN , (81)\n\nwhere\n1\n\nT\u221e\n=\n\n(\n\u2202S\n\n\u2202U\n\n)\nVth,N\n\n, p\u221e = T\u221e\n\n(\n\u2202S\n\n\u2202Vth\n\n)\nU,N\n\n, \u00b5\u221e = \u2212T\u221e\n(\n\u2202S\n\n\u2202N\n\n)\nU,Vth\n\n. (82)\n\nIt is clear that in order to have a consistent picture we have to define the thermodynamic\nvolume, in analogy to the canonical (18) and grand canonical (24) cases, as\n\ndVth =\nT\u221e\np\u221e\n\n(dS)U,N =\nT\u221e\np\u221e\n\n(\nd\n\n\u222b R\n\n0\n\n\u221a\nAs d3r\n\n)\nU,N\n\n. (83)\n\nHere again we have the issue we ran into in the other ensembles. If the spatial dependence in s\ncan be separated from the quantities measured at infinity, we can simply find the expression for\n\n21\n\n\n\nVth, otherwise it is not clear if an explicit expression can be obtained. The entropy is obtained\nas\n\nS = ln \u2126 , (84)\n\nwhere \u2126 is the number of microstates for N indistinguishable particles and given as\n\n\u2126 =\nPN\n\n(2\u03c0)3N\n1\n\nN !\n, (85)\n\nPN is the N-particle phase space and ~ = 1 as usual. In analogy with the 1-particle phase\nspace, given in (34), PN can be expressed as\n\nPN =\n\n\u222b\nAN/2d3r1d\n\n3r2...d\n3rN d3p1d\n\n3p2...d\n3pN \u0398\n\n[\nU \u2212\n\nN\u2211\ni\n\nEi(pi)\n\n]\n, (86)\n\nwith a \u0398 function is included to account for the fact that the total energy of the system is fixed\nin the microcanonical ensemble.\n\nThe connection of S to the local parameter s, the entropy density, can we seen as in the\nfollowing. Since the number of microstates changes multiplicatively, which is why the entropy\nis defined logarithmically providing it a additive nature, one can argue that\n\n\u2126 =\n\u220f\n\n\u2206\u03c9i\n\nS = ln \u2126 =\n\u2211\n\nsi\u2206Vi \u21d2\n\u222b\ns(r)dV . (87)\n\nwhere \u2206\u03c9i is the number of microstates within a small volume \u2206V .\nWe now proceed to the example of semi-classical massless gas to demonstrate the idea and\n\nidentify the corresponding thermodynamic volume. The equation of state of semi-classical\nmassless gas can be obtained as the massless limit of the general case, given in (28), as\n\np = nT , \u03c1 = 3nT , s = n\n(\n\n4\u2212 \u00b5\n\nT\n\n)\n, n = e\u00b5/T\n\nT 3\n\n\u03c02\n. (88)\n\nAs we mentioned various times, due to the fact that \u03c1 = 3p (and hence \u03c1, p \u221d T 4), a simple\nrelation arises as \u03c1, p \u221d B\u22122 in consistency with the Tolman\u2019s law T (r)\n\n\u221a\nB(r) = T\u221e (and\n\n\u00b5(r)\n\u221a\nB(r) = \u00b5\u221e since \u00b5/T is constant as the equilibrium condition in curved spacetime).\n\nRecall that we prefer to keep the chemical potential \u00b5 non-zero here for the purpose of generality.\nIn general case, it is accepted that the chemical potential for the massless gas is zero but here\nthe massless limit is a good approximation for ultra-relativistic gas with small mass and hence\nnon-zero chemical potential. So it is informative to keep it as non-vanishing, keeping in mind\nthat the vanishing limit can be simply obtained as \u00b5\u2192 0 at the end.\n\nThe phase space volume for the massless case can simply be found as\n\nPN =\n(8\u03c0)N\n\n(3N)!\nU3N\n\n\u222b \u221a\nA(r)\n\nB(r)3\nd3r...\n\n\u222b \u221a\nA(r)\n\nB(r)3\nd3r\ufe38 \ufe37\ufe37 \ufe38\n\nN terms\n\n=\n(8\u03c0)N\n\n(3N)!\nU3NV N\n\nth . (89)\n\n22\n\n\n\nAs in the case of the canonical ensemble, we identify at this stage the thermodynamic volume\nas that in Eq. (26). Then, from Eqs. (84), (85), and (89), we have\n\nS = ln \u2126 = N\n\n(\n4 + ln\n\n[\nU3Vth\n\n27\u03c02N4\n\n])\n. (90)\n\nwhere N ! \u2248 (N/e)N is employed as usual. From Eq. (82), the global variables are then found\nto satisfy\n\nU = 3NT\u221e , p\u221e =\nNT\u221e\nVth\n\n, \u00b5\u221e = \u2212T\u221e ln\n\n[\nU3Vth\n\n27\u03c02N4\n\n]\n, (91)\n\njustifying the identification of Vth. Therefore, entropy becomes\n\nS = ln \u2126 = N\n\n(\n4\u2212 \u00b5\u221e\n\nT\u221e\n\n)\n,\n\n=\n\n\u222b R\n\n0\n\n(\n4\u2212 \u00b5\n\nT\n\n)\nn\n\u221a\nA d3r =\n\n\u222b R\n\n0\n\ns\n\u221a\nA d3r (92)\n\nin consistency with the local framework. Here, the local Gibbs-Duhem relation, given in (3), is\nused for \u03c1 = 3p, as well as the condition that \u00b5/T is constant. Finally, notice that thermody-\nnamic volume Vth found above is by default consistent with our general definition in Eq. (83)\nbased on entropy, given in Eq. (90), further confirming this identification of Vth.\n\nB Field equations for compact objects\n\nIn this appendix, we provide details for field equations used in Sec. 3. Firstly in GR, Einstein\nfield equations for static, spherically symmetric solutions can be reduced to the momentum\nconservation of the stress tensor Eq. (10) and the ToV equation\n\n\u2212r2p\u2032(r) = GM(r)\u03c1(r)\n\n[\n1 +\n\np(r)\n\n\u03c1(r)\n\n] [\n1 +\n\n4\u03c0r3p(r)\n\nM(r)\n\n] [\n1\u2212 2GM(r)\n\nr\n\n]\u22121\n, (93)\n\nwhere G = `2Pl is the Newtonian constant andM(r) \u2261\n\u222b r\n0\n\n4\u03c0r\u20322\u03c1(r\u2032)dr\u2032 is the mass profile. For\na given EoS, the profiles p(r) andM(r) are solved simultaneously for a given value of central\npressure pc at the origin. It turns out that these solutions have a simple scaling behavior.\nDefining the following dimensionless quantities\n\np\u0303 = p \u03bb4, \u03c1\u0303 = \u03c1 \u03bb4, r\u0303 = r \u03bb\u22122`Pl, M\u0303(r\u0303) =M(r)\u03bb\u22122`3Pl . (94)\n\nwhere \u03bb is some length scale. Eq. (93) can be used to solve p\u0303(r\u0303),M\u0303(r\u0303), and then solutions for\np(r),M(r) for an arbitrary \u03bb can be obtained by the scaling.\n\nInside the objects, r < R, the metric functions are given by\n\nA(r) =\n\n[\n1\u2212 2GM(r)\n\nr\n\n]\u22121\n,\n\nB(r)\n\nB(R)\n= exp\n\n(\n\u2212\n\u222b R\n\nr\n\n2G\n\nr\u20322\n[\nM(r\u2032) + 4\u03c0r\u20323p(r\u2032)\n\n] [\n1\u2212 2GM(r\u2032)\n\nr\u2032\n\n]\u22121\ndr\u2032\n\n)\n. (95)\n\n23\n\n\n\nOutside the objects, r \u2265 R, it is simply the Schwarzschild solution with B(r) = A(r)\u22121 =\n1\u2212 2M/r and the physical mass\n\nM =M(R) \u2261\n\u222b R\n\n0\n\n4\u03c0r2\u03c1(r)dr . (96)\n\nIt is worth mentioning that this simple expression for the physical mass is a consequence of the\nEinstein field equations, and shall not be expected to be valid in a general theory of gravity.\n\nClassical quadratic gravity is used as an example of modified gravity in the paper, with the\nclassical action below\n\nSCQG =\n1\n\n16\u03c0\n\n\u222b\nd4x\n\u221a\n\u2212g\n(\nm2\n\nPlR\u2212 \u03b1C\u00b5\u03bd\u03b1\u03b2C\u00b5\u03bd\u03b1\u03b2 + \u03b2R2\n)\n, (97)\n\nwhere \u03b1, \u03b2 are dimensionless couplings associated with the quadratic curvature terms. This is\ntreated as the classical approximation of the renormalizable and asymptotically free quantum\nquadratic gravity [32], rather than a truncation of the effective field theory. Since the Weyl\nterm C\u00b5\u03bd\u03b1\u03b2C\n\n\u00b5\u03bd\u03b1\u03b2 softens gravitational interaction with increasing energy, quantum quadratic\ngravity provides a weakly coupled field theory description for gravity at high energy scale [25].\nHowever, it brings in the problematic spin-2 ghost with massm2 = mPl/\n\n\u221a\n2\u03b1. The ghost clearly\n\ncauses problems in the classical theory, but its fate at the quantum level remains under debate.\nPutting aside the ghost problem, the Weyl term in Eq. (97) gives rise to a new type of static\nand spherically symmetric solutions, 2-2-holes, where the volume shrink to zero at the origin.\nIt is more generic than black holes, and then may serve as the endpoint of gravitational collapse\nif quantum quadratic gravity is the fundamental theory for gravity.\n\nThe 2-2-hole solutions are governed by two field equations. For simplicity, we turn off the\nR2 contribution in Eq. (97), and focus on effects of the Weyl term. For relativistic thermal gas,\nby implementing the momentum conservation p(r)B(r)2 = p\u221e, the equations are\n\nH1 = 0, H2 = 8\u03c0\nA\n\nB2\np\u221e . (98)\n\nH1 and H2 are functions of the metric,\n\nH1 =\n\u2212m2\n\nPl\n\nr2A2 (rB\u2032 \u2212 2B)\n\n[\nrBA\u2032 (rB\u2032 + 4B) + A\n\n(\nr2B\u20322 \u2212 2B\n\n(\nr2B\u2032\u2032 + 2rB\u2032\n\n)\n\u2212 4B2\n\n)\n+ 4A2B2\n\n]\nH2 =\n\nm2\nPl\n\nr2B\n(B + rB\u2032 \u2212 AB) +\n\nm2\nPl\u03bb\n\n2\n2\n\n4r4A3B3\n\n[\nr2B2A\u20322 (5B \u2212 4rB\u2032) + A2\n\n(\nr3B\u20323 \u2212 3r2BB\u20322 \u2212 4B3\n\n(rA\u2032 + 2)\n)\n\n+ AB\n(\nr3A\u2032B\u20322 + 2rBB\u2032\n\n(\nr2A\u2032\u2032 + rA\u2032\n\n)\n+ 4B2\n\n(\nrA\u2032 \u2212 r2A\u2032\u2032\n\n))\n+ 8A3B3\n\n]\n,\n\n(99)\n\nwhere H1 depends only on the Einstein term and H2 includes the essential contribution from\nthe Weyl term. \u03bb2 = 1/m2 is the Compton wavelength of the spin-2 mode.\n\nMore generally, for the stress tensor with a nonzero trace, the field equations in Eq. (98)\nbecome\n\nH1 = 8\u03c0 T \u00b5\u00b5 , H2 = 8\u03c0 T2 . (100)\n\n24\n\n\n\nThe right hand sides take more complicated forms with\n\nT \u00b5\u00b5 = 3p\u2212 \u03c1, T2 = Ap\u2212X 2B2\n\nrB\u2032 \u2212 2B\nT \u00b5\u00b5 \u2212 Y\n\n(\n2B2\n\nrB\u2032 \u2212 2B\nT \u00b5\u00b5\n\n)\u2032\n, (101)\n\nwhere T \u00b5\u00b5 denotes the trace of the stress tensor and\n\nX =\nrB\u2032 \u2212 2B\n\n48AB4\n\n\u03bb22\nr2\n[\nrBA\u2032 (rB\u2032 \u2212 8B) + A\n\n(\n4B2 \u2212 7r2B\u20322 + 2B\n\n(\nr2B\u2032\u2032 + 8rB\u2032\n\n))\n\u2212 4A2B2\n\n]\n,\n\nY =\n(rB\u2032 \u2212 2B)2\n\n12B3\n\n\u03bb22\nr2\n. (102)\n\nReferences\n[1] J. M. Bardeen, B. Carter, and S. W. Hawking, Commun. Math. Phys. 31, 161 (1973).\n\n[2] S. W. Hawking, Commun. Math. Phys. 43, 199 (1975), [Erratum: Commun.Math.Phys.\n46, 206 (1976)].\n\n[3] J. D. Bekenstein, Phys. Rev. D 7, 2333 (1973).\n\n[4] A. Strominger and C. Vafa, Phys. Lett. B 379, 99 (1996), arXiv:hep-th/9601029 .\n\n[5] G. Penington, JHEP 09, 002 (2020), arXiv:1905.08255 [hep-th] .\n\n[6] A. Almheiri, N. Engelhardt, D. Marolf, and H. Maxfield, JHEP 12, 063 (2019),\narXiv:1905.08762 [hep-th] .\n\n[7] A. Almheiri, T. Hartman, J. Maldacena, E. Shaghoulian, and A. Tajdini, Rev. Mod.\nPhys. 93, 035002 (2021), arXiv:2006.06872 [hep-th] .\n\n[8] V. Cardoso and P. Pani, Living Rev. Rel. 22, 4 (2019), arXiv:1904.05363 [gr-qc] .\n\n[9] G. W. Gibbons and S. W. Hawking, Phys. Rev. D 15, 2752 (1977).\n\n[10] R. C. Tolman, Phys. Rev. 35, 904 (1930).\n\n[11] R. C. Tolman and P. Ehrenfest, Phys. Rev. 36, 1791 (1930).\n\n[12] P.-H. Chavanis, Eur. Phys. J. Plus 135, 290 (2020), arXiv:1908.10806 [gr-qc] .\n\n[13] P.-H. Chavanis, Eur. Phys. J. Plus 135, 310 (2020), arXiv:1908.10817 [gr-qc] .\n\n[14] R. D. Sorkin, R. M. Wald, and Z. J. Zhang, Gen. Rel. Grav. 13, 1127 (1981).\n\n[15] P.-H. Chavanis, Astron. Astrophys. 483, 673 (2008), arXiv:0707.2292 [astro-ph] .\n\n[16] N. Bilic and R. D. Viollier, Gen. Rel. Grav. 31, 1105 (1999), arXiv:gr-qc/9903034 .\n\n[17] C. W. Misner, K. S. Thorne, and J. A. Wheeler, Gravitation (W. H. Freeman, San\nFrancisco, 1973) p. 557.\n\n[18] J. A. S. Lima, A. Del Popolo, and A. R. Plastino, Phys. Rev. D 100, 104042 (2019),\narXiv:1911.09060 [gr-qc] .\n\n[19] W. Israel, Annals Phys. 100, 310 (1976).\n\n[20] O. Klein, Rev. Mod. Phys. 21, 531 (1949).\n\n25\n\nhttp://dx.doi.org/10.1007/BF01645742\nhttp://dx.doi.org/10.1007/BF02345020\nhttp://dx.doi.org/10.1103/PhysRevD.7.2333\nhttp://dx.doi.org/10.1016/0370-2693(96)00345-0\nhttp://arxiv.org/abs/hep-th/9601029\nhttp://dx.doi.org/10.1007/JHEP09(2020)002\nhttp://arxiv.org/abs/1905.08255\nhttp://dx.doi.org/10.1007/JHEP12(2019)063\nhttp://arxiv.org/abs/1905.08762\nhttp://dx.doi.org/ 10.1103/RevModPhys.93.035002\nhttp://dx.doi.org/ 10.1103/RevModPhys.93.035002\nhttp://arxiv.org/abs/2006.06872\nhttp://dx.doi.org/10.1007/s41114-019-0020-4\nhttp://arxiv.org/abs/1904.05363\nhttp://dx.doi.org/10.1103/PhysRevD.15.2752\nhttp://dx.doi.org/10.1103/PhysRev.35.904\nhttp://dx.doi.org/10.1103/PhysRev.36.1791\nhttp://dx.doi.org/10.1140/epjp/s13360-020-00268-0\nhttp://arxiv.org/abs/1908.10806\nhttp://dx.doi.org/10.1140/epjp/s13360-020-00291-1\nhttp://arxiv.org/abs/1908.10817\nhttp://dx.doi.org/10.1007/BF00759862\nhttp://dx.doi.org/10.1051/0004-6361:20078287\nhttp://arxiv.org/abs/0707.2292\nhttp://dx.doi.org/10.1023/A:1026748002175\nhttp://arxiv.org/abs/gr-qc/9903034\nhttp://dx.doi.org/10.1103/PhysRevD.100.104042\nhttp://arxiv.org/abs/1911.09060\nhttp://dx.doi.org/10.1016/0003-4916(76)90064-6\nhttp://dx.doi.org/10.1103/RevModPhys.21.531\n\n\n[21] T. Padmanabhan, Phys. Lett. A 136, 203 (1989).\n\n[22] S. Kolekar and T. Padmanabhan, Phys. Rev. D 83, 064034 (2011), arXiv:1012.5421\n[gr-qc] .\n\n[23] J. R. Oppenheimer and G. M. Volkoff, Phys. Rev. 55, 374 (1939).\n\n[24] B. Holdom, Phys. Rev. D 66, 084010 (2002), arXiv:hep-th/0206219 .\n\n[25] B. Holdom and J. Ren, Phys. Rev. D 95, 084034 (2017), arXiv:1612.04889 [gr-qc] .\n\n[26] B. Holdom, in Scale invariance in particle physics and cosmology (2019)\narXiv:1905.08849 [gr-qc] .\n\n[27] J. Ren, Phys. Rev. D 100, 124012 (2019), arXiv:1905.09973 [gr-qc] .\n\n[28] G. \u2019t Hooft, Nucl. Phys. B 256, 727 (1985).\n\n[29] D. Kastor, S. Ray, and J. Traschen, Class. Quant. Grav. 26, 195011 (2009),\narXiv:0904.2765 [hep-th] .\n\n[30] M. Cvetic, G. W. Gibbons, D. Kubiznak, and C. N. Pope, Phys. Rev. D 84, 024037\n(2011), arXiv:1012.2888 [hep-th] .\n\n[31] D. Kubiznak, R. B. Mann, and M. Teo, Class. Quant. Grav. 34, 063001 (2017),\narXiv:1608.06147 [hep-th] .\n\n[32] K. S. Stelle, Phys. Rev. D 16, 953 (1977).\n\n26\n\nhttp://dx.doi.org/10.1016/0375-9601(89)90562-8\nhttp://dx.doi.org/10.1103/PhysRevD.83.064034\nhttp://arxiv.org/abs/1012.5421\nhttp://arxiv.org/abs/1012.5421\nhttp://dx.doi.org/10.1103/PhysRev.55.374\nhttp://dx.doi.org/10.1103/PhysRevD.66.084010\nhttp://arxiv.org/abs/hep-th/0206219\nhttp://dx.doi.org/10.1103/PhysRevD.95.084034\nhttp://arxiv.org/abs/1612.04889\nhttp://arxiv.org/abs/1905.08849\nhttp://dx.doi.org/10.1103/PhysRevD.100.124012\nhttp://arxiv.org/abs/1905.09973\nhttp://dx.doi.org/10.1016/0550-3213(85)90418-3\nhttp://dx.doi.org/10.1088/0264-9381/26/19/195011\nhttp://arxiv.org/abs/0904.2765\nhttp://dx.doi.org/10.1103/PhysRevD.84.024037\nhttp://dx.doi.org/10.1103/PhysRevD.84.024037\nhttp://arxiv.org/abs/1012.2888\nhttp://dx.doi.org/10.1088/1361-6382/aa5c69\nhttp://arxiv.org/abs/1608.06147\nhttp://dx.doi.org/10.1103/PhysRevD.16.953\n\n\t1 Introduction\n\t2 Thermodynamics in curved spacetime and thermodynamic volume\n\t2.1 Properties of local variables\n\t2.2 The global picture and the role of thermodynamic volume\n\t2.3 Semi-classical ideal gas\n\t2.4 Quantum ideal gas\n\n\t3 Examples of horizonless compact objects\n\t3.1 Compact objects in GR\n\t3.2 Not quite black holes in quadratic gravity\n\n\t4 Summary\n\tA Microcanonical ensemble\n\tB Field equations for compact objects\n\n"}
{"Title": "From Chern-Tenenblat to Jackiw-Teitelboim via sine-Gordon", "Authors": "Jeff Murugan", "Abstract": "  The study of 2-dimensional surfaces of constant curvature constitutes a beautiful branch of geometry with well-documented ties to the mathematical physics of integrable systems. A lesser known, but equally fascinating, fact is its connection to 2-dimensional gravity; specifically Jackiw-Teitelboim (JT) gravity, where the connection manifests through a coordinate choice that roughly speaking re-casts the gravitational field equations as the sine-Gordon equation. In this language many well-known results, such as the JT-gravity black hole and its properties, were understood in terms of sine-Gordon solitons and their properties. In this brief note, we revisit these ideas in the context of some of the recent exciting developments in JT-gravity and, more generally, low-dimensional quantum gravity and speculate on how some of these new ideas may be similarly understood.      ", "Subject": "High Energy Physics - Theory (hep-th)", "ID": "arXiv:2201.00026", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Chern-Tenenblat to Jackiw-Teitelboim via\n\nsine-Gordon\n\nJeff Murugan\n\nThe Laboratory for Quantum Gravity & Strings, Department of Mathematics &\nApplied Mathematics, University of Cape Town, Cape Town, South Africa\n\nJanuary 4, 2022\n\nAbstract\n\nThe study of 2-dimensional surfaces of constant curvature constitutes a beautiful branch of ge-\nometry with well-documented ties to the mathematical physics of integrable systems. A lesser\nknown, but equally fascinating, fact is its connection to 2-dimensional gravity; specifically\nJackiw-Teitelboim (JT) gravity, where the connection manifests through a coordinate choice\nthat roughly speaking re-casts the gravitational field equations as the sine-Gordon equation.\nIn this language many well-known results, such as the JT-gravity black hole and its properties,\nwere understood in terms of sine-Gordon solitons and their properties. In this brief note, we\nrevisit these ideas in the context of some of the recent exciting developments in JT-gravity\nand, more generally, low-dimensional quantum gravity and speculate on how some of these\nnew ideas may be similarly understood.\n\n1 Introduction\n\nThe marriage between geometry and physics has been a particularly fruitful one, and the name\nof S.S. Chern is instantly recognised as one of the principle architects at this interface. While\nhis development of the theory of characteristic classes is familiar to most graduate students of\ntheoretical physics by its application to topological quantum field theory, his contributions to\nnonlinear analysis are perhaps less so. This line of work is best exemplified in the seminal 1986\nwork of Chern and Tenenblat [1], in which they introduced and studied in painstaking detail, a\nclass of partial differential equations describing pseudospherical surfaces of the type pictured in\nFig.1. To translate between these two descriptions, Chern and Tenenblat noted that the PDE\n\nF\n\n(\nt, x, \u03c6,\n\n\u2202\u03c6\n\n\u2202t\n,\n\u2202\u03c6\n\n\u2202x\n, . . . ,\n\n\u2202l\u2202k\u2212l\u03c6\n\n\u2202tl\u2202xk\u2212l\n\n)\n= 0 , (1)\n\ndescribes a pseudospherical surface M if 1-forms \u03c9i = fi1 dx + fi2 dt can be found, with i = 1, 2, 3\nand smooth function fij (t, x, \u03c6, \u2202t\u03c6, \u2202x\u03c6, . . .), such that the associated structure equations\n\nd\u03c9i =\n1\n\n2\n\u03b5ijk \u03c9j \u2227 \u03c9j (2)\n\nhold if \u03c6 is a solution of (1). Conversely, given a solution of (1) we can always construct a\n\npseudosphere with metric ds2 = (\u03c91)\n2\n\n+ (\u03c92)\n2\n, constant negative Gaussian curvature (which we\n\ncan always normalize to \u22121), and for which we can identify \u03c93 as the Levi-Civita connection 1-form.\n\nOf course, not all differential equations are created equal. One of particular interest, both to Chern\nand Tenenblat in their original work, as well as to us in this article, is the sine-Gordon equation.\nTo see how it arises in this construction, choose 1-forms\n\n\u03c91 = cos\n\u03c6\n\n2\n(dx + dt) ; \u03c92 = sin\n\n\u03c6\n\n2\n(dx\u2212 dt) ; \u03c93 =\n\n1\n\n2\n(\u2202x\u03c6dx\u2212 \u2202t\u03c6dt) (3)\n\nso that (2) holds iff the scalar satisfies\n\n2\u03c6(t, x) = sin\u03c6(t, x) . (4)\n\n1\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n6v\n1 \n\n [\nhe\n\np-\nth\n\n] \n 3\n\n1 \nD\n\nec\n 2\n\n02\n1\n\n\n\nFigure 1: A pseudospherical surface defined parametrically through (x, y, z) =\n(sech(u) cos(v), sech(u) sin(v), u\u2212 tanh(u)).\n\nThis is by no means a unique choice of 1-forms that produce the sine-Gordon equation. In fact,\nChern and Tenenblat themselves use\n\n\u03c91 =\n1\n\n\u03b7\nsin\u03c6dt ; \u03c92 = \u03b7 dx +\n\n1\n\n\u03b7\ncos\u03c6 dt ; \u03c93 = \u2202x\u03c6 dx (5)\n\nas a one-parameter family of 1-forms that all yield the sine-Gordon equation for \u03c6(t, x). Different\nchoices of \u03c9i yield, alternatively, the KdV, modified-KdV, Burgers and sinh-Gordon equations,\namong others. In addition to being prototypical examples of integrable equations, each of these\n2-dimensional classical field theories also possess a rich spectrum of solitonic solutions.\n\nThe connection to 2-dimensional gravity is equally fascinating. Certainly, as everyone knows, Ein-\nstein gravity in (2 + 1)-dimensions is (dynamically) trivial. However it is a (slightly) lesser-known\nfact that Einstein gravity in (1+1)-dimensional is not even trivial. This is because in two spacetime\ndimensions the Einstein tensor G\u00b5\u03bd \u2261 R\u00b5\u03bd\u2212 1\n\n2g\u00b5\u03bdR vanishes identically. To circumvent this rather\nboring state of affairs, Jackiw [3] and, independently, Teitelboim [2] made the suggestion to base\nthe dynamical equations for linear gravity1 on the Reimann scalar instead, since in two dimensions,\nit is the simplest quantity that encodes all the local geometrical information about the spacetime.\nThe resulting dilaton gravity theory, known as Jackiw-Teitelboim (JT) gravity, not only possesses\na great deal of symmetry (SO(2, 1) in D = 2), cosmological [4] and black hole solutions [5] and even\na gauge-theoretic formulation [6, 7], but - and this is the crux of this note - in fact every generic so-\nlution of pseudospherical equations of the form (1) furnishes a classical solution of JT gravity [14].\nIn this sense, it would seem that JT gravity is deeply connected to the theory of integrable systems.\n\nSpurred on by its relation to the Sachdev-Ye-Kitaev (SYK) model [8, 9], JT gravity is currently\nenjoying a dramatic renaissance; one that has produced a slew of results on, among others, gravity\nas an ensemble average [10], replica wormholes [11] and potential resolutions of the information loss\nparadox [13]. A key feature of these new developments is the inclusion of the boundary data which\nencodes the Schwarzian dynamics [12] and associated chaoticity properties of the theory. This is\nto be contrasted with the work carried out in the 1980\u2019s and 1990\u2019s which focused on the bulk\ndynamics. In this light then, it seems timeous to revisit the connection between JT gravity and\nintegrable 2-dimensional models in the hope that there are lessons to be learnt from the geometry\nof pseudo-spherical surfaces that may yet prove valuable for quantum gravity. Alas this article\nwill not contain them. An exposition of a lecture presented at the 2021 Nankai Symposium, it\nis instead two parts review (of the classical JT/sine-Gordon connection, following the treatment\ngiven in [15, 16, 17]), one part wild speculation of how this connection may be used to understand\nsome of the more contemporary questions asked of the 2-dimensional physics of JT gravity. The\ndevil, as they say, is in the details, and these are left to forthcoming work [19].\n\n2 The sine-Gordon/JT connection\n\nThe sine-Gordon equation (4) is the paragon of a nonlinear PDE; integrable, possessing a rich spec-\ntrum of solitonic solutions and (it\u2019s quantum version is even) S-dual to the massive Thirring model\nvia bosonization. Following the prescription above, corresponding to the sine-Gordon equation (4)\nis a pseudospherical Riemannian 2-manifold with metric\n\nds2 = sin2 \u03c6\n\n2\ndt2 + cos2\n\n\u03c6\n\n2\ndx2 (6)\n\n1Not to be confused with linearized gravity, which is something else entirely.\n\n2\n\n\n\nSimilarly, the (perhaps less familiar) Euclidean sine-Gordon equation maps to a Lorentzian pseu-\ndosphere according to(\n\n\u22022t + \u22022x\n)\n\u03c6 = sin\u03c6 \u2190\u2192 ds2 = \u2212 sin2 \u03c6\n\n2\ndt2 + cos2\n\n\u03c6\n\n2\ndx2 . (7)\n\nOf course, which 2-manifold this is, depends on \u03c6(t, x). In differential geometry, Ba\u0308cklund trans-\nforms map pseudospherical surfaces into each other via linear differential equations. Translated\nback into the language of PDEs, these act as solution-generating transforms that, starting with\nsome (usually trivial) initial seed solution, generate arbitrarily many more. A familiar, albeit\ntrivial, example of the Ba\u0308cklund transform is the first order Cauchy-Riemann equations,\n\n\u2202xu = \u2202yv, \u2202yu = \u2212\u2202xv , (8)\n\nthat relate the real and imaginary components of an analytic function f(x, y) = u(x, y) + iv(x, y).\nSince each of these components themselves satisfy the second order Laplace equation \u2206u(x, y) =\n\u2206v(x, y) = 0, the Cauchy-Riemann equations act as an auto-Ba\u0308cklund transformation that maps\nthe function u(x, y) into its harmonic conjugate, v(x, y). On the other hand, the Ba\u0308cklund trans-\nform\n\n\u2202xv = \u2202xu+ 2\u03ba exp\n\n(\nu+ v\n\n2\n\n)\n, \u2202yv = \u2212\u2202yu\u2212\n\n2\n\n\u03ba\nexp\n\n(\nu\u2212 v\n\n2\n\n)\n, (9)\n\nmaps a harmonic function v(x, y) into a solution of the (nonlinear) Liouville equation \u2206u(x, y) =\nexp(u(x, y)) [18]. Of course it is much simpler to solve the linear Laplace equation than the\nnonlinear Liouville equation. More to the point of this article, the linear system,\n\n\u2202Xv = \u2202Xu+ 2\u03ba sin\n\n(\nu+ v\n\n2\n\n)\n, \u2202Y v = \u2212\u2202Y u+\n\n2\n\n\u03ba\nsin\n\n(\nu\u2212 v\n\n2\n\n)\n, (10)\n\nfurnishes an auto-Ba\u0308cklund transformation, B\u03ba for the sine-Gordon equation2, with parameter\n\u03ba. To illustrate the power of (10) as a solution-generating transform, let\u2019s start with the trivial\nsolution of (4), v = 0, as a seed. Substituting into (10), integrating, and converting back to (t, x)\ncoordinates yields\n\nu(t, x) = 4 tan\u22121\n[\nexp\n\n(\nx\u2212 x0 \u2212 v(t\u2212 t0)\u221a\n\n1\u2212 v2\n\n)]\n. (11)\n\nThis is, of course just the sine-Gordon kink (or 1-soliton since it carries topological charge Q = 1).\nMore generally, if \u03c9 is any seed solution, and \u03c912\u00b7\u00b7\u00b7N \u2261 B\u03baN\n\n(\u00b7 \u00b7 \u00b7B\u03ba2\n(B\u03ba1\n\n(\u03c9))), then the Bianchi per-\nmutability theorem [18] gives an entirely algebraic construction of the N -soliton of the sine-Gordon\nequation, given the data {\u03c9, \u03c91, \u03c92, . . . , \u03c9123\u00b7\u00b7\u00b7N\u22121}.\n\nTo appreciate the connection to 2-dimensional gravity, consider the JT-gravity action functional,\n\nIJT [\u03c4, g\u00b5\u03bd ] =\n1\n\n16\u03c0GN\n\n\u222b\nM\n\nd2x\n\u221a\n\u2212g \u03c4 (R+ \u039b) , (12)\n\nwith (dimensionless) Newton\u2019s constant GN , dilaton \u03c4 , and cosmological constant \u039b, which we\nwill set to 2 in what follows. Solutions of the associated equations of motion, R + 2 = 0 and\n(\u2207\u00b5\u2207\u03bd \u2212 g\u00b5\u03bd)\u03c4 = 0, are manifestly constant curvature, and therefore maximally symmetric in the\nsense of admitting three independent Killing vectors k\u00b5(i) = \u03b5\u00b5\u03bd\u2202\u03bd\u03c4(i)/\n\n\u221a\n\u2212g, i = 1, 2, 3. All such\n\nsolutions must be locally diffeomorphic to AdS2 however, because a solution is determined by both\nthe metric g\u00b5\u03bd and the dilaton \u03c4 , it may still be globally distinct from AdS2. An example of this\nis the JT black hole,\n\nds2 = \u2212\n(\nr2 \u2212M\n\n)\ndt2 +\n\n(\nr2 \u2212M\n\n)\u22121\ndr2 , (13)\n\nwhere M is constant and r is linearly related to the dilaton. This solution, which can also be\narrived at by dimensionally truncating a 3-dimensional BTZ black hole, clearly has a horizon at\nr =\n\u221a\nM . While the BTZ black hole is singular at r = 0, the same is not true of (13). However,\n\nthere is a corresponding statement in JT gravity and that is that at \u03c4 = 0, GN blows up.\n\n2In the sense that both u and v each satisfy the sine-Gordon equation, with X and Y regarded as lightcone\ncoordinates for the d\u2019Alembertian operator.\n\n3\n\n\n\nTo make the connection to pseudospherical surfaces, let\u2019s take as an ansatz for the metric the line\nelement given in (7). Substituting into the JT action functional reduces it to the form,\n\nIJT [\u03c4, \u03c6] =\n1\n\n16\u03c0GN\n\n\u222b\nM\n\nd2x \u03c4 (\u2206\u03c6\u2212 sin\u03c6) . (14)\n\nCorrespondingly, the equations of motion that arise from variation of IJT with respect to the\ndilaton and the embedding coordinate,\u03c6 are the Euclidean sine-Gordon equation, \u2206\u03c6 = sin\u03c6 and,\nrespectively, the second order linear equation, (\u2206 \u2212 cos\u03c6)\u03c4 = 0. An interesting observation to\nbe made here is that, even though (one of) the equations of motion reduce to the sine-Gordon\nequation in this gauge, the JT action does not reduce to the sine-Gordon action. In a remarkable\nseries of articles [15, 16, 17], Gegenberg and Kunstatter showed that the theory is nevertheless\nquite rich. Two points in particular should be singled out. The first is that taking \u03c6 to be the\nsine-Gordon kink (11), reduces the ansatz to\n\nds2 = \u2212sech2\u03c1 dt2 + tanh2\u03c1 dx2 , (15)\n\nwith \u03c1 \u2261 (x\u2212 vt)/\n\u221a\n\n1\u2212 v2 and x0 = t0 = 0. Then, defining the new coordinates (t\u2032, r\u2032) through\n\ndt\u20322 \u2261 dt2 \u2212 v\n\u221a\n\n1\u2212 v2 sinh\n2\n\u03c1\n\n1\u2212 v2sinh2\u03c1\nd\u03c1 , r\u2032 \u2261\n\n\u221a\n1\u2212 v2 sech\u03c1 , (16)\n\nyields precisely the JT black hole (13) if we identify the black hole mass M with the (square of\nthe) spectral parameter, v2. The resulting metric has ADM energy E = v2/2GN , is singular at the\nlocation of the kink, \u03c1 = 0 and at \u03c1 =\u221e, and regular at the horizon r\u2032 = v. This construction is\nquite general; indeed the authors of [17] go on to show that an N -soliton solution of the sine-Gordon\nequation (of which the kink is the 1-soliton) can be mapped to a black-hole metric of JT gravity\nwith a unique mass. The second point, while more speculative is no less intriguing, and asks if\nthe N -soliton construction may provide some insight into the nature of the Bekenstein-Hawking\nentropy of the JT black hole. Ignoring much of the exotica3 of the sine-Gordon spectrum, the\ntotal rest energy of an N -soliton is given in terms of the sine-Gordon coupling \u03b2 by E0 = N/\u03b2. As\nargued earlier, the N -soliton state can be constructed from lower topological charge states. This\nis more than just a mathematical statement encoded in the Bianchi permutability theorem; it is\na physical fact. The degeneracy of this state is then computed as the number of ways of writing\nN as a sum of non-negative integers i.e. the partition of N , p(N). While no exact closed form\nexpression exists for p(N), for large N it can be approximated by the Hardy-Ramanujan formula,\n\np(N) \u223c 1\n\n4N\n\u221a\n\n3\nexp\n\n(\n\u03c0\n\n\u221a\n2N\n\n3\n\n)\n. (17)\n\nThe corresponding entropy of the state S \u223c log(p(N)) \u223c \u03c0\n\u221a\nN , matching the Bekenstein-Hawking\n\nentropy of the JT black hole (13), up to (admittedly important) factors of order one. As the\nauthors themselves remark, this argument is rather coarse and in need of refinement. Still, it is\nhardly likely to be merely coincidental.\n\n3 Some speculative comments\n\nHaving summarised, perhaps overly succinctly, what was known about the Chern-Tenenblat/sine-\nGordon/Jackiw-Teitelboim connection around the turn of the last century, we now proceed to\nspeculate as to how this may fit into the present day context in which, at least in the holographic\nquantum gravity community, JT gravity is enjoying somewhat of a deluge of attention. Much of\nthis interest can be traced back to Kitaev\u2019s remarkable observation that the low-energy limit of\nJT gravity matches that of the SYK model of N Majorana fermions interacting with quenched\nrandom q-body interactions [8, 9]. Key to this observation is the Gibbons-Hawking boundary term\n\nIbdy =\n1\n\n8\u03c0GN\n\n\u222b\n\u2202M\n\n\u03c4bK , (18)\n\nthat needs to be added to IJT in the holographic context, when the manifold M has a boundary\n\u2202M in which the dual field theory resides. Here K is the trace of the extrinsic curvature tensor and\n\n3These include, soliton-anti-soliton bound states, breathers etc.\n\n4\n\n\n\n\u03c4b = \u03c4 |\u2202M , is the value of the dilaton on the boundary. If, as in this case, \u2202M is a co-dimension-1\ncurve parameterized by some \u2018time\u2019 variable u then M is cut out along the trajectory (t(u), z(u)).\nIf, in addition, T and n denote the tangent vector field and unit normal to the boundary curve\nrespectively, then\n\nK = \u2212g(T,\u2207Tn)\n\ng(T, T )\n=\nt\u2032(t\u20322 + z\u20322 + zz\u2032\u2032)\u2212 zz\u2032t\u2032\u2032\n\n(t\u20322 + z\u20322)\n3/2\n\n. (19)\n\nImplementing boundary conditions on the induced metric and dilaton of ds|\u2202M = du/\u03b5, \u03c4b = \u03c4r/\u03b5\nand sending \u03b5\u2192 0 allows the extrinsic curvature to be written in terms of the Schwarzian derivative\nas K = 1 + \u03b52Sch(t, u) to leading order in \u03b5. This defines the so-called Schwarzian action that\nencodes the leading order corrections to the conformal limit and, important for the identification\nwith the dual quantum mechanics on the boundary, controls the chaos properties of the theory\nas diagnosed by the out-of-time-order four-point correlators. Evidently, all the action is at the\nboundary4. To see how to understand these developments, particularly the Schwarzian action and\nits implications for chaos, in the sine-Gordon gauge, notice that the pure AdS2 background maps\nto the sine-Gordon equation on the infinite line. The boundary conditions supplied at spatial\ninfinity are famously integrable and precisely the reason we can construct its soliton spectrum via\nthe Ba\u0308cklund transform. Cutting off the spacetime with some boundary curve has the effect of\nputting the sine-Gordon equation on a finite, time-dependent interval. Now, even on a static finite\ninterval, boundary conditions that preserve integrablility are a set of measure zero, but when the\nendpoints of the interval are subject to external driving, the system is generically chaotic [20],\nexhibiting similar characteristics to the Sinai billiard problem one dimension higher (see Figure 2).\n\nFigure 2: A plot of the positions of two classical particles on a time-dependent finite interval,\nstarting a distance of 10\u22123 away from each other with the left boundary remaining fixed and the\nright boundary\u2019s position given by L(t) = 3\n\n(\n1\u2212 1\n\n2 | sin t|\n)\n. The rapid divergence of trajectories is\n\ncharacteristic of classical chaotic behaviour.\n\nHowever, the Schwarzian limit of JT-gravity is not just mildly chaotic; as the putative dual to\nthe SYK model, it is maximally chaotic in the sense of saturating the MSS bound on the leading\nLyapunov exponent [21]. Again, chaos in the bounded sine-Gordon equation should be anticipated,\nbut why and how such a system exhibits maximal chaos remains unclear, especially because there\nis no such expectation of a classical system. On the topic of boundaries, while there is an extensive\nliterature on pseudospheres without boundary, most of which can be faithfully mapped to vari-\nous solitons of the sine-Gordon equation, comparatively little is known about pseudospheres with\nboundaries, save that they are difficult to construct directly. On the other hand, with the map be-\ntween sine-Gordon solutions and pseudospheres at hand, perhaps knowledge of sine-Gordon solitons\non the finite interval, along with their various bound states may well facilitate such constructions.\nOur motivation for studying this problem is more utilitarian; one solution of nearly-AdS2 gravity\nthat has generated significant recent interest, in part because it offers an excellent laboratory for\nthe controlled study of questions of information loss, the Hawking-Page transition, Page curves and\nemergent gravity, is a wormhole configuration that connects the two boundaries of the global space-\ntime [22]. This Maldacena-Qi wormhole is conjectured to be dual to two coupled SYK quantum\ndots and it is tempting to speculate that such a \u201cdouble trumpet\u201d solution may be constructed by\ngluing together two pseudospheres with boundary along the boundary, in which case the wormhole\nwould map to a soliton bound state. Finally, there is the issue of quantization of JT gravity and\nthe corresponding quantum sine-Gordon system, but perhaps that is a story for another Nankai\nsymposium.\n\n4Sorry, couldn\u2019t resist.\n\n5\n\n\n\nAcknowledgements\n\nI owe a debt of gratitude to Kayla Hopley who, in the course of her MSc research, found out about\nthe connection between JT gravity and the sine-Gordon equation, and to Sebastian Zimper for\nproducing Fig.2. I am also indebted to Yang-Hui He for his kind invitation to present this work\nat the Nankai Symposium. I regret only that I, like the other participants, could not be there in\nperson.\n\nReferences\n\n[1] S.S. Chern and K. Tenenblat. Studies in Applied Mathematics 74, 55-83 (1986)\n\n[2] C. Teitelboim, Phys. Lett. B 126, 41-45 (1983) doi:10.1016/0370-2693(83)90012-6\n\n[3] R. Jackiw, Nucl. Phys. B 252, 343-356 (1985) doi:10.1016/0550-3213(85)90448-1\n\n[4] R. B. Mann and S. F. Ross, Phys. Rev. D 47, 3312-3318 (1993) doi:10.1103/PhysRevD.47.3312\n[arXiv:hep-th/9206022 [hep-th]].\n\n[5] R. B. Mann, A. Shiekh and L. Tarasov, Nucl. Phys. B 341, 134-154 (1990) doi:10.1016/0550-\n3213(90)90265-F\n\n[6] K. Isler and C. A. Trugenberger, Phys. Rev. Lett. 63, 834 (1989)\ndoi:10.1103/PhysRevLett.63.834\n\n[7] A. H. Chamseddine and D. Wyler, Phys. Lett. B 228, 75-78 (1989) doi:10.1016/0370-\n2693(89)90528-5\n\n[8] J. Maldacena and D. Stanford, Phys. Rev. D 94, no.10, 106002 (2016)\ndoi:10.1103/PhysRevD.94.106002 [arXiv:1604.07818 [hep-th]].\n\n[9] A. Kitaev and S. J. Suh, JHEP 05, 183 (2018) doi:10.1007/JHEP05(2018)183\n[arXiv:1711.08467 [hep-th]].\n\n[10] D. Stanford and E. Witten, Adv. Theor. Math. Phys. 24, no.6, 1475-1680 (2020)\ndoi:10.4310/ATMP.2020.v24.n6.a4 [arXiv:1907.03363 [hep-th]].\n\n[11] G. Penington, S. H. Shenker, D. Stanford and Z. Yang, [arXiv:1911.11977 [hep-th]].\n\n[12] T. G. Mertens, JHEP 05, 036 (2018) doi:10.1007/JHEP05(2018)036 [arXiv:1801.09605 [hep-\nth]].\n\n[13] T. J. Hollowood, S. Prem Kumar and A. Legramandi, J. Phys. A 53, no.47, 475401 (2020)\ndoi:10.1088/1751-8121/abbc51 [arXiv:2007.04877 [hep-th]].\n\n[14] E. G. Reyes, J. Phys. A 39, L55-L60 (2006) doi:10.1088/0305-4470/39/2/L02\n\n[15] J. Gegenberg and G. Kunstatter, [arXiv:hep-th/9709183 [hep-th]].\n\n[16] J. Gegenberg and G. Kunstatter, Phys. Lett. B 413, 274-280 (1997) doi:10.1016/S0370-\n2693(97)01118-0 [arXiv:hep-th/9707181 [hep-th]].\n\n[17] J. Gegenberg and G. Kunstatter, Phys. Rev. D 58, 124010 (1998)\ndoi:10.1103/PhysRevD.58.124010 [arXiv:hep-th/9807042 [hep-th]].\n\n[18] C. Rogers and W. F. Shadwick,\n\n[19] J. Murugan, \u201cThe sine-Gordon/JT gravity connection revisited,\u201d In progress, (2022)\n\n[20] J. Murugan and S. Zimper, \u201cChaos in the sine-Gordon equation with Floquet boundaries,\u201d In\nprogress, (2022)\n\n[21] J. Maldacena, S. H. Shenker and D. Stanford, JHEP 08, 106 (2016)\ndoi:10.1007/JHEP08(2016)106 [arXiv:1503.01409 [hep-th]].\n\n[22] J. Maldacena and X. L. Qi, [arXiv:1804.00491 [hep-th]].\n\n6\n\n\n\t1 Introduction\n\t2 The sine-Gordon/JT connection\n\t3 Some speculative comments\n\n"}
{"Title": "Boltzmann Meets Lorentz: A Surrogate Model for Black Hole Echoes", "Authors": "Randy S. Conklin, Niayesh Afshordi", "Abstract": "  The existence of black hole horizons has not been strictly proven observationally, and indeed it may not be possible to do so. However, alternatives may be established by the observation of gravitational wave echoes that probe possible near-horizon structure. These echoes are proposed to be generated in exotic compact objects that are horizonless and feature a partially reflecting \"wall\" inside their light rings, creating a cavity in which gravitational perturbations may echo, while leaking out through the angular momentum barrier with each pass. The characteristic signature of echoes is a comb of nearly evenly spaced spectral resonances. While approximately true, deviations from this simple picture can lead to severe observational signal losses. In this paper, we explore such subtleties with the latest results for echo sourcing and geometry. A physically motivated echo model is then developed as a sum over Lorentzian spectral lines, parametrized by functions of the horizon frame frequency and the size of the cavity. Our final spectrum is a function of only the mass and spin of the black hole, as well as the UV scale of the near-horizon physics. We then apply this model in a search for echoes in the gravitational wave event with the loudest ringdown signal in LIGO/Virgo, i.e. GW190521. We interpret our findings as a measurement of the fractional energy in post-merger echoes equal to $E_{echoes} / E_{GR} = 8.9 \\pm 4.5\\%$, where the uncertainty range represents the 90% credible region. The robustness of this result is tested against noise backgrounds and simulated injections, and we find that a signal persists through modifications to the model and changes in the data search.      ", "Subject": "General Relativity and Quantum Cosmology (gr-qc)", "ID": "arXiv:2201.00027", "Text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoltzmann Meets Lorentz: A Surrogate Model for Black Hole Echoes\n\nRandy S. Conklin\u2217\n\nDepartment of Physics, University of Toronto, Toronto, Ontario, Canada, M5S 1A7\n\nNiayesh Afshordi\u2020\n\nDepartment of Physics and Astronomy, University of Waterloo,\n200 University Ave W, N2L 3G1, Waterloo, Canada\n\nWaterloo Centre for Astrophysics, University of Waterloo, Waterloo, ON, N2L 3G1, Canada and\nPerimeter Institute for Theoretical Physics, 31 Caroline Street North, Waterloo, Ontario, N2L 2Y5, Canada\n\nThe existence of black hole horizons has not been strictly proven observationally, and indeed\nit may not be possible to do so. However, alternatives may be established by the observation of\ngravitational wave echoes that probe possible near-horizon structure. These echoes are proposed to\nbe generated in exotic compact objects that are horizonless and feature a partially reflecting \u201cwall\u201d\ninside their light rings, creating a cavity in which gravitational perturbations may echo, while leaking\nout through the angular momentum barrier with each pass. The characteristic signature of echoes is\na comb of nearly evenly spaced spectral resonances. While approximately true, deviations from this\nsimple picture can lead to severe observational signal losses. In this paper, we explore such subtleties\nwith the latest results for echo sourcing and geometry. A physically motivated echo model is then\ndeveloped as a sum over Lorentzian spectral lines, parametrized by functions of the horizon frame\nfrequency and the size of the cavity. Our final spectrum is a function of only the mass and spin of\nthe black hole, as well as the UV scale of the near-horizon physics. We then apply this model in a\nsearch for echoes in the gravitational wave event with the loudest ringdown signal in LIGO/Virgo,\ni.e. GW190521. We interpret our findings as a measurement of the fractional energy in post-merger\nechoes equal to EEchoes/EGR = 8.9\u00b14.5%, where the uncertainty range represents the 90% credible\nregion. The robustness of this result is tested against noise backgrounds and simulated injections,\nand we find that a signal persists through modifications to the model and changes in the data search.\n\nI. INTRODUCTION\n\nA complete theory of quantum gravity has not been\nestablished, partly due to Planck scale experimentation\nseemingly being out of reach. It is nevertheless expected\nthat black hole horizons may be replaced by quantum\neffects such that they are no longer perfectly absorbing,\nand that this may lead to a macroscopic signal in the\nform of gravitational wave echoes, bringing the Planck\nscale into the reach of observations [1, 2].\n\nThere are several motivations for this suggestion, one\nof significance being the information paradox. If black\nholes are actually horizonless objects, then unitarity can\nbe preserved and the issue evaporates. There is also the\nproposal of objects that obey general relativity as normal\nbut in a special configuration with exotic matter (the\ngravastar) [3]. Whatever the case, the test for echoes is\na test for new physics, and with their distinct spectral\nsignature, echoes present an interesting search target for\ngravitational wave observatories.\n\nGravitational wave echoes occur, in the simplest case,\nwhenever there is a gravitational cavity containing an\noscillating perturbation. For the signal to escape and\nreach an observer, one side of the cavity should be leaky\nsuch that upon contact with it part of the perturbation\ntransmits and travels towards infinity. Therefore, in an\n\n\u2217 randysconklin@gmail.com\n\u2020 nafshordi@pitp.ca\n\naugmented black hole geometry, with a classical angular\nmomentum barrier surrounding a (non-classical) reflect-\ning \u201cwall\u201d echoes may be produced by perturbing the\nbackground.\n\nThe wall is different for each theory of quantum grav-\nity, and even for different exotic compact objects (ECO\u2019s)\nwithin each theory. For example, the wall interior to the\nangular momentum barrier for a wormhole is the angu-\nlar momentum barrier on the other side of the origin.\nOf particular interest for the present paper is the re-\ncent proposal that generic quantum considerations may\nlead to a Boltzmann reflection of frequencies at the wall,\nwith temperature dependent on the spin of the ECO [4].\nPhysical perturbative models require absorption at the\nwall to counteract the runaway growth of superradiance\nfor spinning backgrounds, which occurs for frequencies:\n\u03c9 < m\u2126H , where \u2126H is the superradiance frequency de-\nfined by the mass M and spin a of the background, and\nm is the azimuthal harmonic number [5]. Perturbations\nmust therefore dissipate at each contact with the wall.\n\nThe angular momentum barrier acts as a high-pass fil-\nter, and perturbations do leak out upon contact with it.\nIf the source of the perturbation is a single local outgoing\nwavepacket inside the cavity, a high-frequency pulse char-\nacterized by the fundamental quasinormal mode (QNM)\nfrequency [6] of the background, and higher frequencies\nthat are present, will be emitted. After this, each oscil-\nlation of the perturbation will occur over one time delay\ntd \u2248 2|x0|, where |x0| is the distance in the tortoise co-\nordinate between the wall and the angular momentum\n\nar\nX\n\niv\n:2\n\n20\n1.\n\n00\n02\n\n7v\n1 \n\n [\ngr\n\n-q\nc]\n\n  3\n1 \n\nD\nec\n\n 2\n02\n\n1\n\nmailto:randysconklin@gmail.com\nmailto:nafshordi@pitp.ca\n\n\n2\n\nbarrier.\n\nThe formalism developed so far for echoes resides in\nthe linear regime where perturbation theory is valid. For\ncompact merger events, as observed by LIGO and Virgo,\nthe inspiral and merger phase provide the source of per-\nturbations that lead to ringdown and possibly echoes.\nGiven that this sourcing is outside of the perturbative\nregime, a relation must be established connecting this to\nechoes. Recently, advances were made here as sources\nwere developed for infalling particles on spinning back-\ngrounds (compared to static backgrounds [7]) and a link\nbetween this and echoes was established [8, 9]. This\nrepresented significant progress as it was also recently\ndiscovered that source functions must be carefully de-\nfined to quantify echo distortion, and previous models\nwere often simpler than required in the physical picture\n[10, 11]. In this paper, we take the further step of sourc-\ning echoes with surrogate models for gravitational wave\nsignals from realistic binary mergers [12]. Indeed, in our\ncalculation for the energy potentially emitted through\nechoes in GW190521, we measure the GR event energy\nand compare it to the measured energy of the echoes\npartly by sourcing the echoes with the waveform that\nreproduces the main event.\n\nIn Fourier space, echo resonances present their most\nstriking feature - a series of potentially dozens of sharp\npoles that are approximately evenly separated by 1/td.\nThis spectrum resembles a comb with teeth of various\nlengths, a unique pattern that may be used as a target\nsignal in data searches.\n\nThis has been done with proposed success in [13],\nwhere a series of trapezoids of varying width but other-\nwise equal shape were used to search the LIGO O1 data,\nand upper limits on p-values for detection were given.\nThe most recent work on this updates the original trape-\nzoids to become an evenly spaced series of equal triangles\n[14]. In this model, the optimal bandpass and number of\nechoes were inferred a posteriori from the data, and a\nsource was chosen as a Gaussian distribution of frequen-\ncies about the horizon frame frequency in the proposed\ncontext of energy minimization. The background for this\nmodel was a truncated Kerr black hole with near perfect\nenergy reflection at the wall, and \u03b5 damping to counter\ninstability.\n\nIn this paper, we build upon previous work by gener-\nating physically motivated echo spectra for a variety of\ngeometric parameters by incorporating the Boltzmann\nboundary condition and realistic sources, and by repre-\nsenting echo resonances as a sum of Lorentzians accord-\ning to the shapes of their quasinormal modes (QNM\u2019s),\nwith each resonance defined by its phase, amplitude,\nwidth, and location. We then proceed to study these\nfeatures in detail.\n\nFor example, we quantify the departure of the sep-\naration between resonances away from constant integer\nmultiples of \u223c 1/td (as has often been assumed in the\nliterature), and write a more accurate description as a\nTaylor expansion in the horizon frequency k = \u03c9\u2212m\u2126H .\n\nThis nonconstant separation was first noticed as a 1-2%\ndeparture from constancy peaking near the horizon fre-\nquency in [13], and part of our work here has been to\nmodel this efficiently and with significant precision for\nphysically motivated echoes. Because the locations of\nthese resonances are critical for optimal echo detection,\nwe provide a functional form for them valid for all rele-\nvant binary merger parameters.\n\nAfter developing our model, we advocate an optimal\nsearch strategy that involves comparing the results of the\nsignal search to noise backgrounds and injections while\naccounting for LIGO/Virgo/KAGRA measurement un-\ncertainties through Monte Carlo parameter chains, avoid-\ning a posteriori statistics. Finally, as an example, we use\nthis method to measure the energy in post-merger echoes\nin GW190521, which is the LIGO/Virgo event with loud-\nest ringdown signal [15].\n\nThis paper is divided into three main sections. In\nSection II, we introduce the theoretical background and\nterms that will be useful throughout the paper. We then\ncontinue into Section III where we construct the model,\ncalibrate its parameters, and produce a surrogate model\noptimized for numerical efficiency and accuracy. To ap-\nply this in a data search, we continue into Section IV\nwhere we examine GW190521, a promising candidate for\nechoes given its strong ringdown. By the end of the pa-\nper, the reader will have been provided with a calibrated\nsurrogate model with parameters explicitly given, as well\nas the first sample of a data search using this tool along\nwith a statistical analysis of the results. These points are\nsummarized in the conclusion.\n\nII. SETUP\n\nEchoes are clearly distinguished by their representa-\ntion in frequency space, and therefore we begin by defin-\ning their spectrum \u03c8\u03c9 that would be measured by an\nasymptotic observer as a function of frequency \u03c9. In our\nformalism, where x is a tortoise coordinate, the location\nof the observer is approaching x\u2192\u221e.\n\nFor easy access to the most relevant equations, we start\nfrom a high-level perspective showing the primary func-\ntions of significance, and then proceed to explain each\nterm. The following subsections explain the theory in\nmore detail.\n\nEchoes are gravitational wave perturbations, in this\ncontext coming from disturbed exotic compact objects\n(ECOs). Their dynamics are governed by the Teukol-\nsky differential equation [16], and the frequency spec-\ntrum that is a solution to this may be written as (in a\ntransformed notation called the Sasaki-Nakamura (SN)\nformalism [17])\n\n\u03c8\u03c9 = ei\u03c9xKS, (1)\n\nwhere K is called the transfer function. In a way, K is the\nmost important functional form that describes echoes.\nThis is because echoes can almost entirely be described\n\n\n\n3\n\nby a sum of sharp frequency resonances, and these are en-\ncoded in K. Here, S is the source function generated by\ninitial conditions and/or active sourcing, and this plays\nthe important role of modifying the amplitudes of the\nsum of resonances [10, 11].\n\nThe transfer function has multiple representations in\nthe literature. We choose to write [13]\n\nK =\nTBH(\u03c9)\n\n1\u2212RBH(\u03c9)R(\u03c9)e\u22122ikx0\n, (2)\n\nwhere k = \u03c9 \u2212m\u2126H is the horizon frequency and x0 =\ntd/2 is the cavity size (the tortoise coordinate distance\nbetween the wall and the angular momentum barrier).\nTBH and RBH are standard general relativistic quantities\nthat we call the transmission and reflection coefficients.\nFor perturbations with angular momentum, which are\nthose of interest here, they give, respectively, the square\nroot of the ratio of transmitted and reflected energies\nacross the angular momentum barrier of the black hole\nor ECO. They are independent of the boundary condition\nat the wall and the size of the cavity. R(\u03c9) is the square\nroot of the ratio of reflected to incoming energy at the\nwall, sometimes called Rwall in the literature.\n\nBoltzmann reflection, which will be of particular in-\n\nterest in this paper, is defined by R = e\n\u2212 |k|\n\n2\u03b1TH , where\n\nTH =\n\u221a\n1\u2212a2\n\n4\u03c0M(1+\n\u221a\n1\u2212a2) is the ECO temperature and \u03b1 is\n\na number [4]. The standard argument sets \u03b1 = 1 for\ngeneric quantum modifications near the horizon. How-\never, up to \u03b1 = 2 is energetically permitted. In this\npaper, we focus on the standard case, though we do also\nsearch the data with the extremal value since it results\nin a much wider range of significant resonances given the\nreduced suppression that leads to a potentially stronger\nsignal. The superradiance frequency m\u2126H defines the\ncenter of the peak signal region for Boltzmann echoes,\ngiven that at this frequency there is no absorption at\nthe wall. Whether an actual resonance appears at this\nfrequency or whether the highest resonances are imme-\ndiately adjacent to this depends on the net combination\nof phase and amplitude factors, as we will discuss.\n\nThe motivation for this definition of the transfer func-\ntion is largely that it has a sensible interpretation for\nBoltzmann echoes in the geometric optics approximation,\nas is described in the following paragraph. It is also sim-\nply derived as the inverse of the position-independent\nWronskian for the gravitational perturbation equation,\nand so has a concise mathematical definition [13].\n\nThe transfer function has a very useful interpretation\nin which the denominator is replaced by a geometric ex-\npansion in P \u2261 RBHRe\n\n\u22122ikx0 , such that [7]\n\nK \u2248 TBH(1 + P + P 2 + ...), (3)\n\nvalid when |P | < 1. This representation is called the\ngeometric optics approximation. For Boltzmann echoes,\nwhich are of primary interest in this paper, the inequality\nholds everywhere except at the superradiance frequency\n\n(k = 0) where |P | = 1. In contrast to Boltzmann echoes,\nother models often have |P | \u2265 1 due to ergoregion in-\nstability (for example the perfect energy reflection and\nDirichlet models) where this representation breaks down.\n\nBecause of this, for Boltzmann echoes we may inter-\npret the transfer function as an expansion in echo pulses\nwhere each term in the expansion in P is an echo [7].\nIn this picture, for an initial perturbation originating in-\nside the cavity between the wall and the angular momen-\ntum barrier, the first pulse to leave the cavity (generating\nthe ringdown) has frequency content ei\u03c9xTBHS, while the\nsecond has ei\u03c9xTBHPS and so on. The interpretation of\nthese terms as echoes is sensible since the first echo (the\nburst after the initial pulse) results from first reflection\noff the angular momentum barrier, then reflection off the\nwall, then transmission through the barrier, and subse-\nquent echoes pick up additional reflection factors encoded\nby P .\n\nLater, we will find it useful to separate the GR event\nfrom the echo waveform, which is very easy with this in-\nterpretation. The echo component of the spectrum may\nbe subtracted from the total waveform by simply remov-\ning the initial pulse, which is the ringdown, such that\n\n\u03c8\u03c9,echo = ei\u03c9xKechoS\n\n= ei\u03c9x(K \u2212 TBH)S\n\n= ei\u03c9x\nTBH(1\u2212 (1\u2212 P ))\n\n1\u2212 P\nS\n\n= ei\u03c9x\nTBHP\n\n1\u2212 P\nS.\n\n(4)\n\nAs a final introductory word, we qualitatively describe\nthe echo spectrum in terms of the transfer function. We\nmentioned earlier that echoes in Fourier space are sums\nof sharp resonances. These resonances typically occur\nwhen K is maximized, which generally implies the de-\nnominator of K being minimized. In the simplest pic-\nture, where |P | \u2248 1 is always true, resonances are sepa-\nrated by roughly 1/td, corresponding to the periodicity of\nthe phase factor in the exponential. Hence, the transfer\nfunction embodies the characteristic structure of echoes\nwhich is a comb of resonances separated by a function of\nthe inverse time delay. This all remains essentially true\nin the more realistic picture, where P has more magni-\ntude and phase structure than in this toy description, and\nthe numerator can modify the amplitudes of resonances\nthrough the source function.\n\nA. Teukolsky and Strain\n\nHere we proceed to describe the theory in more detail,\nbeginning with the equation from General Relativity that\ndescribes the motion of perturbations on a background\ngravitational geometry. The essential new feature in this\nformalism compared to that of standard GR is the intro-\nduction of a boundary condition (the exotic wall) interior\nto the angular momentum barrier and its consequences.\n\n\n\n4\n\nThe Teukolsky equation for s = \u22122 governs the dy-\nnamics of gravitational perturbations on a Kerr back-\nground of mass M and spin a. In general form in vacuum\nit is [16][\n\n(r2 + a2)2\n\n\u2206\n\u2212 a2 sin2 \u03b8\n\n]\n\u22022\u03c8\n\n\u2202t2\n+\n\n4Mar\n\n\u2206\n\n\u22022\u03c8\n\n\u2202t\u2202\u03c6\n\n+\n\n[\na2\n\n\u2206\n\u2212 1\n\nsin2 \u03b8\n\n]\n\u22022\u03c8\n\n\u2202\u03c62\n\u2212\u2206\u2212s\n\n\u2202\n\n\u2202r\n\n(\n\u2206s+1 \u2202\u03c8\n\n\u2202r\n\n)\n\u2212 1\n\nsin \u03b8\n\n\u2202\n\n\u2202\u03b8\n\n(\nsin \u03b8\n\n\u2202\u03c8\n\n\u2202\u03b8\n\n)\n\u2212 2s\n\n[\na(r \u2212M)\n\n\u2206\n+\ni cos \u03b8\n\nsin2 \u03b8\n\n]\n\u2202\u03c8\n\n\u2202\u03c6\n\n\u2212 2s\n\n[\nM(r2 \u2212 a2)\n\n\u2206\n\u2212 r \u2212 ia cos \u03b8\n\n]\n\u2202\u03c8\n\n\u2202t\n\n+ (s2 cot2 \u03b8 \u2212 s)\u03c8 = 0,\n\n(5)\n\nwhere \u2206 = (r2\u22122Mr+a2). To generate echoes from this\nequation, an exotic boundary condition and a source term\nmust be added. For Boltzmann echoes, which are sta-\nble because they have sufficient absorption, the Teukol-\nsky equation may be immediately Fourier transformed.\nOther common reflectivities, such as those for perfect en-\nergy and Dirichlet boundary conditions, require Laplace\ntransformation when a 6= 0 in the linear perturbative\nregime because of superradiance, since the Fourier trans-\nform is only defined when\u222b \u221e\n\nt0\n\n|\u03c8|2dt <\u221e, (6)\n\na condition that does not hold in the presence of instabil-\nity [18]. Causality is enforced in the Laplace (or Fourier)\ntransform by initiating a start time t0 such that\n\nL\u03c8(t) \u2261 \u03c8\u0302(\u03c9) =\n\n\u222b \u221e\nt0\n\n\u03c8(t)ei\u03c9tdt. (7)\n\nHaving a start time leads to non-operator initial condi-\ntion terms in the differential equation. These may be\nlumped together with any active source term (such as an\ninfalling particle) to eventually form what we call here\nthe source term S [10]. The value of \u03c9 in the Laplace\ntransform is implicitly offset from the real axis to ensure\nall poles are on the side of the contour causing decay.\nThe inverse of this transformation reveals this offset in\nthe integration bounds:\n\n\u03c8 =\n1\n\n2\u03c0\n\n\u222b \u221e+ic\n\n\u2212\u221e+ic\n\n\u03c8\u0302e\u2212i\u03c9td\u03c9. (8)\n\nAngular variables may be separated out of the Teukol-\nsky equation, provided that the source term is properly\nhandled [10], leaving the radial operator and harmonic-\nindexed variable\n\nRRlm =\n\n[\n\u22062 d\n\ndr\n\n(\n1\n\n\u2206\n\nd\n\ndr\n\n)\n\u2212 V (r)\n\n]\nRlm, (9)\n\nwhere\n\nV (r) = V = \u2212K\n2\nT + 4i(r \u2212M)KT\n\n\u2206\n+ 8i\u03c9r + \u03bb, (10)\n\n\u03bb is the eigenvalue of the spin-weighted spheroidal har-\nmonic equation left over from the separation [19], and\n\nKT = (r2 + a2)\u03c9 \u2212ma. (11)\n\nThe Teukolsky radial variable Rlm is indexed by the an-\ngular modes, and in this paper we will focus on the dom-\ninant l = m = 2 mode [20, 21].\n\nIn a schematic notation, where angular components\nand normalization factors are excluded, the Teukolsky\nvariable for s = \u22122 may be written as\n\n\u03c84,\u03c9 \u223c Rlm\u03c9. (12)\n\nThis is directly related to strain h (in time) by\n\n\u03c84 =\n1\n\n2\n(h\u0308+ \u2212 ih\u0308\u00d7), (13)\n\nand for this we define\n\nh(t) =\n1\n\n2\n(h+ \u2212 ih\u00d7). (14)\n\nB. Homogeneous Solutions and the\nSasaki-Nakamura Formalism\n\nBecause we only require the asymptotic signal that\nmakes its way to observers towards infinity, several sim-\nplifications occur. To discern these, it is helpful to first\nlook at the asymptotic homogenous (source-free) solu-\ntions to the Teukolsky equation, and to use the Green\u2019s\nfunction technique to connect these to the full asymptotic\nsignal [13].\n\nBecause of its nonlocal potential, the homogenous so-\nlutions to the Teukolsky equation feature radial depen-\ndence in their asymptotics. Including the exotic bound-\nary term from reflection off the wall, they are equal to\n\nRlm\u03c9 \u2192\n{\nBtrans\u2206\n\n2e\u2212ikx +Brefe\nikx, x\u2192 \u2212\u221e\n\nBin\n1\nr e\n\u2212i\u03c9x +Boutr\n\n3ei\u03c9x, x\u2192\u221e. (15)\n\nThe radial dependence of these homogenous solutions\non both sides of the angular momentum barrier leads\nto numerical difficulties, and various transformations are\npresent in the literature to simplify these asymptotics for\nnumerical efficiency. In this paper, we choose to work in\nthe Sasaki-Nakamura formalism, described in detail in\n[22], where the asymptotics are simple travelling waves\ndefined by the horizon frame frequency k towards the\nhorizon and \u03c9 towards infinity:\n\nXlm\u03c9 \u2192\n{\nAtranse\n\n\u2212ikx +Arefe\nikx, x\u2192 \u2212\u221e\n\nAine\n\u2212i\u03c9x +Aoute\n\ni\u03c9x, x\u2192\u221e. (16)\n\nIn particular, we solve for these homogenous amplitudes\nusing the SN differential equation, the local version of the\n\n\n\n5\n\nTeukolsky equation, and use the Green\u2019s function tech-\nnique to connect these to the source and the final result\nseen by an observer towards infinity.\n\nThe transformation between the Teukolsky and SN for-\nmalisms is well known in the literature [22]. For our pur-\nposes, since we are just interested in asymptotic spectral\namplitudes (the quantities just described), we are able\nto simply connect these two equivalent formalisms using\nthe known homogenous amplitude conversion factors [13]\n\nBin = \u2212 1\n4\u03c92Ain, Bout = \u2212 4\u03c92\n\nc0\nAout,\n\nBtrans = 1\ndAtrans, Bref = 1\n\ngAref, (17)\n\nwith coefficients defined by\n\nc0 = \u03bb(\u03bb+ 2)\u2212 12a\u03c9(a\u03c9 \u2212m)\u2212 i12\u03c9M,\n\nd = \u22124(2Mr+)5/2\n[\n(k2 \u2212 8\u03b52) + i6k\u03b5\n\n]\n,\n\ng =\n\u2212b0\n\n4k(2Mr+)3/2(k + i2\u03b5)\n, (18)\n\nb0 = \u03bb2 + 2\u03bb\u2212 96k2M2 + 72kMr+\u03c9 \u2212 12r2+\u03c9\n2\n\n\u2212 i[16kM\n\n(\n\u03bb+ 3\u2212 3\n\nM\n\nr+\n\n)\n\u2212 12M\u03c9 \u2212 8\u03bbr+\u03c9],\n\n\u03b5 = (r+ \u2212M)/(4Mr+), (19)\n\nwhere r+ = M +\n\u221a\nM2 \u2212 a2 is the outer horizon radius.\n\nPutting all of this together, we can write a few simple\nrelations connecting our variables. A general Teukolsky\namplitude Z is connected to strain h by\n\nZ \u223c \u03c92h\u03c9e\n\u2212i\u03c9x. (20)\n\nThe relevant Teukolsky amplitude for observation, mean-\ning for outgoing waves towards infinity, is related to the\nrelevant Sasaki-Nakamura amplitude X by\n\nZ = \u22124\u03c92\n\nc0\nX. (21)\n\nPutting all this together, the strain h\u03c9 is then extracted\nfrom the Sasaki-Nakamura amplitude by\n\nh\u03c9 \u223c \u2212\n4\n\nc0\nXei\u03c9x. (22)\n\nThe transmission and reflection coefficients in the\ntransfer function may be defined by the homogenous solu-\ntion satisfying the boundary conditions for waves towards\ninfinity\n\n\u03c8right(x)\u2192\n{\nDtranse\n\n\u2212ikx +Drefe\nikx, x\u2192 x0\n\nei\u03c9x, x\u2192\u221e (23)\n\naccording to\n\nTBH =\n\n\u221a\n\u03c9\n\nk\n\n\u2223\u2223\u2223\u2223b0c0\n\u2223\u2223\u2223\u2223 1\n\nDref\n(24)\n\nRBH =\n\n\u2223\u2223\u2223\u2223b0C\n\u2223\u2223\u2223\u2223 Dtrans\n\nDref\n, (25)\n\nwhere\n\n|C|2 =\u03bb4 + 4\u03bb3 + \u03bb2\n(\n\u221240a2\u03c92 + 40am\u03c9 + 4\n\n)\n+ 48a\u03bb\u03c9(a\u03c9 +m)\n\n+ 144\u03c92\n(\na4\u03c92 \u2212 2a3m\u03c9 + a2m2 +M2\n\n)\n. (26)\n\nSome of the key quantities defined here are shown in\nFig.28 in the appendix, where we plot the functions that\nappear when transforming between formalisms and con-\nverting between energies and amplitudes. Further details\nare provided in the appendix of [13]. We also plot in\nFig.29 in the appendix the reflection and transmission\ncoefficients.\n\nIn summary, echoes are described by gravitational\nwave perturbations on background geometries contain-\ning black holes with exotic boundary conditions. Such\nperturbations are described by the Teukolsky equation.\nHowever, the Teukolsky equation has a nonlocal potential\nthat leads to numerical challenges. Therefore we trans-\nform variables to obtain the Sasaki-Nakamura equation\nwhich is equivalent but with a localized potential. In\nthis paper, background calculations are done in the SN\nformalism, and these are connected back to the Teukol-\nsky equation through asymptotic homogenous spectral\namplitude conversion factors, and through these to the\nobservable strain by a final simple conversion.\n\nIII. THE MODEL\n\nIn Fourier space, echoes are characterized by a sum\nof sharp resonances. These correspond to complex poles\nin frequency, called quasinormal modes (QNM\u2019s), with\nthe real part giving the oscillation rate of the wave and\nthe imaginary part giving the exponential decay rate [6].\nThe shapes of QNM\u2019s in frequency space are Lorentzian,\nand therefore we model echoes as a sum over Lorentzians.\nThe model is parametrized by the location lr, amplitude\nar, width wr, and phase \u03c6r of the resonances such that\nthe full model is the sum\n\n\u03c8\u03c9 =\n\nn\u2211\nr=1\n\nar\n\u03c9 \u2212 lr + iwr\n\nei\u03c6r , (27)\n\nwhere n is the number of resonances. The parameters in\nthis model depend on the mass M , wall location x0, and\nspin a.\n\nFrequencies for echoes scale linearly with M , and it is\npossible to plot results as a function of the dimensionless\nquantity \u03c9M . We will often do this to maintain results\ngeneralizable to different gravitational wave events. To\nconvert back to SI units from these dimensionless fre-\nquencies, we multiply by c = 1/(4.9268 \u2217 10\u22126[s]M) with\nM in units of solar masses. Gravitational wave data is\nusually plotted as a function of frequency in Hertz rather\nthan \u03c9, so an extra division by 2\u03c0 may be required for\ncomparison.\n\n\n\n6\n\nQuantum deviations away from GR are expected to\noccur around the Planck scale, and for this x0 \u2248 \u2212450\n[23]. This estimate is approximated with the time delay\ntd where [24]\n\n2x0 \u2248 td \u2248\n4GM\n\nc3\n\n(\n1 +\n\n1\u221a\n1\u2212 a2\n\n)\n\u00d7 ln\n\n(\nM\n\nMP\n\n)\n. (28)\n\nA typical value for observed binary mergers is a \u2248 0.7,\nwith the relevant range extending from about a = 0.6 to\na = 0.8. For definiteness, the approximately Planckian\nvalue for the wall location and the mid-range spin will\noften be used in this paper, with the fuller ranges being\nexplored during model construction.\n\nIn the following subsections, we discuss the calcula-\ntion of the model parameters and we evaluate the model\nacross a wide range of background geometry values to\ntest its accuracy and relevance for echo searches.\n\nA. Location lr\n\nGiven their sharpness, the location of the resonances lr\nis the most sensitive parameter in this model, and small\ninaccuracies can lead to a significant loss of signal. We\nfind that the resonances are not quite evenly spaced, but\nwe can express the departure from constancy as a Tay-\nlor expansion about the superradiance frequency where\nBoltzmann echoes have their sharpest and highest reso-\nnances.\n\nThe separation of peaks \u2206lr = lr+1 \u2212 lr is calcu-\nlated by determining the location of the maximum of\neach resonance lr. The sharper the resonances, the more\nconsistently this may be determined as sharpness causes\nthe peak locations to be increasingly independent of the\nsource/initial conditions generating the echoes, as we will\ndiscuss. In Fig.1, we plot the separation between reso-\nnances lr+1\u2212 lr as a function of dimensionless frequency\nfor echoes from several different ECO\u2019s. The \u201cEnergy\u201d\ncurve gives the separation function for a wall boundary\ncondition that perfectly reflects incoming energy. This\nis not a physical boundary condition when linear per-\nturbation theory is assumed, since it leads to instability\nthrough superradiance, yet it is often studied for its sim-\nplicity, if one ignores excitation of the microstates of the\nblack hole. The \u201cDirichlet\u201d boundary condition perfectly\nreflects amplitudes rather than energy. This leads to ad-\nditional conversion factors compared to the \u201cEnergy\u201d re-\nflection. These curves depart from constancy at up to\nseveral percent. For the \u201cWormhole\u201d, waves travel across\nthe central point and reflect off the angular momentum\nbarrier on the other side. The boundary condition for\nthe wormhole is then equal to RBH. Fig.29 gives the re-\nflection and transmission rates for perturbations across\nthe angular momentum barrier.\n\nIn this paper, we focus on the Boltzmann boundary\ncondition, it arguably being the most physical, and here\ntwo points should be noted. First, the Boltzmann spec-\ntrum is localized to positive frequencies around the su-\n\nBoltzmann: \u03b1=1\n\nBoltzmann: \u03b1=2\n\nEnergy\n\nDirichlet\n\nWormhole\n\n0.25 0.30 0.35 0.40 0.45 0.50\n0.94\n\n0.96\n\n0.98\n\n1.00\n\n1.02\n\n1.04\n\n1.06\n\n\u03c9M\n\n-\n2x\n0\n\u0394\nl r\n/2\n\u03c0\n\nFIG. 1. The five legended curves give the separation \u2206lr =\nlr+1 \u2212 lr between resonances for each of the marked ECO\u2019s.\nThe superradiance frequency \u03c90 = m\u2126h (or, equivalently, k =\n\u03c9 \u2212 \u03c90 = 0) is marked by a vertical dashed black line. The\nresonances in the background (the black curve) are a sample\nspectrum, for perfect energy reflection, shifted vertically and\nresized for visualization. Here we set a = 0.7 and x0 = \u2212150.\nThe \u03b1 = 2 Boltzmann, Energy, and Dirichlet curves are barely\ndistinguishable over much of this frequency range.\n\nperradiance frequency, while the other boundary con-\nditions in Fig.1 feature resonances extending to about\n\u03c9M = \u22120.5 [11]. This is due to the boundary condi-\ntion which sharply peaks at the superradiance frequency\nwith exponential suppression elsewhere. We focus on the\nstandard \u03b1 = 1 Boltzmann model but also plot the \u03b1 = 2\nvariation which allows for more signal to be observed be-\ncause of less suppression at the boundary. Second, with\nthe exception of the wormhole, the Boltzmann boundary\ncondition, especially for \u03b1 = 2, is comparable to that of\nthe other boundary conditions over frequencies near \u03c90.\nIn this way, up to quantifiable deviations, the separations\nof resonances derived in this paper are relevant over pos-\nitive frequencies near the superradiance frequency for a\nvariety of ECO\u2019s, and the model presented here may be\nused in data searches for alternative ECO models with a\nslight expansion of the priors.\n\nIn the final analysis, the deviation of the separation\nfunction away from constancy is important since sharp\nresonance peaks can be missed by not including this in-\nformation. In Fig.2 we plot the scenario where the lowest\nfrequency peak is aligned and a constant separation be-\ntween peaks is assumed. This leads to a misalignment\nof the primary resonances causing the overlap integral\nof the plotted full solution with the constant-separation\nsurrogate model to be 38%. This is to be compared with\nthe value of 97% for the corrected model used in this\npaper. Though this number drops further as the prop-\nerly aligned peak goes to lower frequencies away from\nthe peak region, and especially if all of the peaks are\nmisaligned, we provide these percentages as conservative\nestimates relevant for data searches where the frequency\nband may be relatively narrow compared to the full spec-\n\n\n\n7\n\nData\n\nModel\n\n0.36 0.38 0.40 0.42 0.44 0.46\n0\n\n100\n\n200\n\n300\n\n400\n\n\u03c9M\n\n|h\uf02d\n(\u03c9\n)|\n\nFIG. 2. Orange: The full numerical solution to the final\nwaveform with a = 0.7 and x0 = \u2212450 using the GR surro-\ngate source. These parameters and the source are consistent\nwith the data search and will be discussed further through-\nout this paper. Blue: The model for the same parameters\nexcept assuming a constant separation between resonances,\nwith the first resonance in this plot properly aligned. Both\ncurves approximately cover the range of frequencies used in\nthe data search. This demonstrates the nearly worst-case sce-\nnario where the incorrect separation function leads to only\n38% overlap compared to 97% for the corrected model. On\nthe other hand, with constant separation and the highest peak\naligned (not shown here), the overlap goes up to 93%. These\nresults are for the standard Boltzmann model. For echoes\nwith sharper resonances, such as for when \u03b1 = 2, the need for\na corrected separation function becomes even more apparent.\nFor \u03b1 = 2, the full model presented here gives 99% overlap\nwith the full solution. For the constant time delay assumption\nwhen the first resonance is aligned, the overlap drops to 24%.\nFor the best-case scenario under this assumption, when the\nhighest peak is aligned, the overlap is 86%. These numbers\nassume a time delay measured by the size of the cavity. For a\ndata search with a flexible separation, these numbers could be\nmade higher by aligning the top two peaks, with the trade-off\nbeing loss in accuracy of the time delay measurement.\n\ntrum. The best case scenario, while still assuming a\nconstant separation, would be attained by aligning the\nprimary peaks and letting the less important auxiliary\npeaks to be misaligned. For standard \u03b1 = 1 Boltzmann\nechoes where the two peaks adjacent to the superradiance\nfrequency dominate, little signal is lost with the overlap\nintegral being as high as 93%. The reader considering\nthese numbers must determine where in the 38% - 93%\nrange their overlap might land, and whether it may be\nbetter to include nonlinearities such as in the separation\nfunction presented in this paper. Whatever the case, the\nbest solution is to account for the nonconstancy, even if\nthis is only an improvement in signal inclusion by several\npercent. It should be noted, however, that the upper end\nof this range is a limiting case that is unlikely to be found\nin many other searches. If, for example, there are more\nthan a few resonances that dominate, this value will de-\ncrease dramatically. Of particular note are models that\nfeature resonances at positive and negative frequencies,\n\n0.25 0.30 0.35 0.40 0.45 0.50 0.55\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n2.0\n\n\u03c9M\n\n|1\n-\nR\nB\nH\n*\nR\n*\nE\nxp\n[-\n2I\nkx\n0\n]|\n\nFIG. 3. The absolute value of the denominator of the trans-\nfer function |1 \u2212 RBH(\u03c9)R(\u03c9)e\u22122ikx0 | for Boltzmann echoes.\nAlong the real axis, the denominator never goes to zero, lead-\ning to larger imaginary parts for poles further from the su-\nperradiance frequency. Peak locations lr on the real axis are\nrelated to minima of this function.\n\nwhere misalignment over the large range of frequencies\nmay be fatal. Additionally, for models with wall absorp-\ntion significantly less than that of the Boltzmann model,\nthe auxiliary peaks can take on more importance caus-\ning the overlap to drop. For example, for the \u03b1 = 2\nBoltzmann model, the same overlap range drops to 24%\n- 86%, compared to the overlap of the corrected model\npresented here which is 99%.\n\nThe absolute value of the denominator of the spectrum\nd(\u03c9) = |1\u2212RBH(\u03c9)R(\u03c9)e\u22122ikx0 |, coming from the trans-\nfer function K, shown in Fig.3, generates the resonance\nstructure for echoes, and through its minima provides\nmost of the information that determines the values of lr\nalong the real axis. However, modulation from the nu-\nmerator, which includes the source function, still needs\nto be accounted for to obtain necessary accuracy (see\nSubsection III E for discussion on source functions).\n\nMost of the cause of the nonconstancy of the separation\nfunction is revealed in Fig.4, where we plot the separation\nfunction for a simple sum of poles with Boltzmann-like\nimaginary part, providing a toy model representation of\nthe echo spectrum. In this plot, the true locations of the\npoles are exactly known, but the phase of the Lorentzians\ncoming from the denominator shifts the lr towards the re-\ngion where the imaginary part in the denominator is min-\nimized. This information is accounted for in the model\nby calculating the separation of resonances from the full\nnumerical solution. This can be explained through Fig.5,\nwhere it is shown that the phase and magnitude of RBHR\nis not slowly varying near the superradiance frequency,\nand this distorts the apparent periodicity of the exponen-\ntial phase factor in P . The result is that e\u22122ikx0 does not\nminimize the denominator at constant integer multiples\nof the resonance frequency, but now this factor must ac-\ncount for phase and magnitude changes in the reflection\nfunctions.\n\n\n\n8\n\n\u0394lr\n\n10 12 14 16 18 20\n\n10\n\n15\n\n20\n\n25\n\n\u03c9\n\nf(\n\u03c9\n)\n\nFIG. 4. The imaginary part in the denominator is the pri-\nmary cause of the nonconstancy of the separation function,\nand causes peak locations of to shift away from regions of\nhigher amplitude. Plotted here is a spectrum of simple poles\nf(\u03c9) = \u03a330\n\nn=1|\u03c9 \u2212 n + 0.05i(1 + 0.95|n \u2212 15|)|\u22121 represent-\ning a toy Boltzmann model, plotted with the corresponding\nseparation function measuring the differences between peak\nlocations. The separation function is offset above its actual\nvalue for visualization.\n\nArg[RBHR]\n\n|RBHR|\n\n0.2 0.3 0.4 0.5 0.6 0.7 0.8\n\n-3\n\n-2\n\n-1\n\n0\n\n1\n\n2\n\n3\n\n\u03c9M\n\nFIG. 5. Red: The phase of RBHR for a = 0.7 for Boltz-\nmann reflectivity. Green: The magnitude of the same. The\nhorizontal dashed line is at unity, the peak of RBHR. The sep-\naration function deviates from integer multiples of the inverse\ntime delay 1/td \u2248 1/|2x0|, and this deviation is dependent on\nthe difference between the magnitude of RBHR and unity and\nthe dynamics of the phase. Towards negative frequencies, the\nphase increases, causing the phase for the minimum to need\nto be relatively negative, implying lower frequencies and thus\na stretching away from the superradiance frequency. The re-\nverse is true towards positive frequencies.\n\nMeasuring the peaks lr directly from the full spectrum,\nwe numerically obtained the separation functions for each\nof nine sets of background parameters from the set of\ncombinations (a, x0) where x0 \u2208 {\u2212150,\u2212450,\u2212900} and\na \u2208 {0.6, 0.7, 0.8}. We found two emergent patterns\nfrom which we construct a numerically efficient surrogate\n\na=0.6, x0=-150\n\na=0.7, x0=-450\n\na=0.8, x0=-900\n\n0.2 0.3 0.4 0.5 0.6\n0.000\n\n0.005\n\n0.010\n\n0.015\n\n0.020\n\n\u03c9M\n\nS\nep\nar\nat\nio\nn\n\nFIG. 6. The modelled separation function flowing between\nthe two extremes of tested parameter values. This function\nis defined by a Taylor expansion about the horizon frame fre-\nquency scaled by the inverse time delay k/td, and flattens\nand shifts to higher frequencies as a and x0 increase. The\ngrey curves here are the model at background values between\nthose of the green, blue, red curves which are directly calcu-\nlated data sets.\n\nmodel. In the first, the separation functions remain ap-\nproximately centered about the horizon frame frequency\nk and are somewhat symmetric. This suggested a Taylor\nexpansion representation in k, with a quartic polynomial\nstructure yielding the approximate flattened parabolic\nform. At first a quadratic parabolic form was tested,\nbut this was insufficient to model the relative flatness\nand asymmetry of these curves compared to parabolas.\nIn the second, by adjusting the cavity size x0, it became\napparent that not only did the separation function scale\nlinearly with x0, as expected, but the curvature also de-\ncreased according to some combination of powers. We\nfind that the Taylor expansion variable may account for\nthis by including inverse time delay factors scaling with\nthe cavity size. Accounting for these two patterns, we are\nable to write a separation function valid for all relevant\nbackground parameters as\n\n\u2206lr =\n1\n\ntd\n\n(\nc0 + c1\n\nk\n\ntd\n+ c2\n\nk2\n\nt2d\n+ c3\n\nk3\n\nt3d\n+ c4\n\nk4\n\nt4d\n\n)\n. (29)\n\nParticular fits to these coefficients are given in Appendix\nA. In Fig.6, we show how this surrogate function flows\nfrom a state constructed at the minimal values of a = 0.6\nand x0 = \u2212150 to the other extremal values of a = 0.8\nand x0 = \u2212900. Although these parameter ranges were\nuseful during testing and model building, in reality the\nrelevant ranges are much narrower. The accuracy of this\nmethod is discussed in Subsection III D.\n\nB. Amplitude ar and Width wr\n\nEcho resonances are Lorentzians modulated by a\nfrequency-dependent amplitude, and their heights along\n\n\n\n9\n\nthe real axis are equal to the amplitude divided by the\nimaginary part of the denominator. The widths of the\nLorentzians are determined by this same imaginary part.\nThe amplitudes and widths ar and wr, as defined in the\nmodel above, may be measured directly with this infor-\nmation, for example by measuring the full heights of the\nresonances as well as their half-widths at the half-max\npoints, but two issues will arise: First, the measured\nvalue of the height of a resonance is a mixture of the\namplitude and the width, thus any error in the width\nestimation carries through into the amplitude measure-\nment. Second, echo resonances, including those for Boltz-\nmann echoes, are generally not sharp enough to ignore\nthe overlap between them which forms a continuum.\n\nTo avoid the problems caused by overlap, the enve-\nlope of overlap, defined by the portion of the curve below\nthe line connecting minima (a.k.a. the continuum), can\nbe subtracted to isolate resonances. This improves the\nheight measurement by removing most of the superposi-\ntion, though it also removes some of the actual resonance\namplitude, but this is at the expense of accuracy in esti-\nmating the widths as this method effectively deletes the\nbases of the Lorentzians. Since this method targets the\nupper portions of each resonance, the subtracted spec-\ntrum is a sum of the caps of Lorentzians and the width is\nunderestimated leading to relatively narrow resonances.\nDespite these caveats, this method produces results con-\nsistent with the more accurate technique that will be pre-\nsented shortly. However, while numerically useful, this\nmethod adds unnecessary complexity to the model by\ngenerating the need for additional parameters describing\nthe envelope, which is not itself the physical quantity of\ninterest.\n\nTo calculate the amplitudes, a superior method is to\nconsider the pole structure analytically, which is possible\nunder the previously described geometric optics approx-\nimation. Recalling that the transfer function may be\nwritten as\n\nK \u2248 TBH(1 + P + P 2 + ...), (30)\n\nvalid when \u22121 < P < 1, we demonstrated that the echo\nspectrum with the GR component subtracted is equal to\n\n\u03c8\u03c9,echoe\ni\u03c9xTBHP\n\n1\u2212 P\nS. (31)\n\nUsing this, we may simply calculate the ar as the discrete\nsampling of |TBHPS|/td at the resonance frequencies,\nwhere the td factor comes from defining the full heights\nof the resonances as ar/wr, and expanding around each\npole along the real axis [13].\n\nComputing the functions TBH and P is expensive, de-\nspite their generally smooth form, and repeating this\ncomputation for each run of a data search would be inef-\nficient. Rather, we create a surrogate model that closely\napproximates the ar and is applicable across a range of\ncavity sizes and background spins. This is defined by\na linear fit to R and a quartic polynomial in k for mi-\nnor corrections, and gives excellent results because of the\n\nData\n\nFull Model\n\nZeroth\n\n0.2 0.3 0.4 0.5\n0\n\n20\n\n40\n\n60\n\n80\n\n\u03c9M\n\na\nr\n*\nt d\n\nFIG. 7. Green: The data for the amplitude multiplied by the\ntime delay, for a = 0.7 and x0 = \u2212450. This data is generated\nfrom the full numerical solution to the wave equation using a\nGR surrogate model source. Blue: The linear model fit using\nthe full model of R plus a quartic polynomial in k. Red: The\nzeroth order fit using just R.\n\ndomination of the Boltzmann factor. The best fit values\nfor the coefficients are given in the appendix. Using the\nsame notation as for the separation function but with\ndifferent values for the coefficients:\n\nar =\ncx0\n\ntd\n\n(\ncRR(|k|) + c0 + c1k + c2k\n\n2 + c3k\n3 + c4k\n\n4\n)\n.\n\n(32)\nFig.7 gives a comparison of the data, the fit at zeroth\norder where just R is used, and the full fit. \u201cData\u201d here\nrefers to the full numerically generated solution to the\nwave equation without the surrogate approximation. As\nwith the separation function, by tabulating data for the\nar over the range of parameters x0 \u2208 {\u2212150, ...,\u2212900}\nand a \u2208 {0.6, ..., 0.8}, we generate a surrogate form valid\nfor all physically relevant parameters.\n\nThe calculation of widths is similar. The half-width\nat half-max \u03c9w of a Lorentzian along the real axis is\n\u03c9w =\n\n\u221a\n3|wr|, where wr is the imaginary part of the\n\nQNM frequency, hence the name of \u201cwidths\u201d for the wr.\nNumerically, the wr may then be measured by determin-\ning the location of the half-max, and the height may be\ndetermined as the difference between the maximum and\nan adjacent minimum.\n\nTwo issues must be carefully handled with this ap-\nproach. First, as with the amplitudes, the actual height\nof the resonances is obscured to the degree that reso-\nnances are overlapping. Second, the envelope of overlap\ncauses an imbalance between adjacent sides of each res-\nonance and therefore an ambiguity in the definition of\nthe min-to-max peak height, though this can be partially\nmitigated by averaging the heights calculated on either\nside if the envelope curvature is small.\n\nBut such issues can be circumvented altogether since\nan approximate analytical form for the widths emerges\nwhen the boundary condition is chosen, and we find an-\nother surrogate function valid over the full range of rele-\n\n\n\n10\n\nData\n\nFull Model\n\nZeroth\n\n0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55\n0.0000\n\n0.0005\n\n0.0010\n\n0.0015\n\n0.0020\n\n0.0025\n\n0.0030\n\n0.0035\n\n\u03c9M\n\nw\nr\n\nFIG. 8. Green: The data for the width parameter. Blue:\nThe full linear model fit using |k| plus a polynomial in k up\nto third order. Red: The zeroth order approximation using\njust c0 + c1|k|.\n\nvant background parameters. For poles close to the real\naxis, and RBHR slowly varying along the imaginary axis,\nthe imaginary part of an echo resonance is approximately\nequal to\n\n\u03c9r \u2248\nln|P |\ntd\n\n. (33)\n\nThe primary functional form that approximates this is\n|k| plus an offset from the real axis. We use this and\npolynomial corrections in k up to third order to account\nfor nonlinearities caused by the asymmetry of RBH com-\npared to R across the axis where k = 0. We set\n\nwr =\n1\n\ntd\n(c0 + c1|k|+ c2k\n\n2 + c3k\n3), (34)\n\nwith best-fit values given in the appendix, and where\nthese c\u2019s are again distinct from those in the separation\nand amplitude functions. Fig.8 compares the fits to the\ndata for the zeroth order and full fit models.\n\nC. Phase \u03c6r\n\nHere we discuss the calculation of the phase factor for\neach resonance, and the method used for relating this to\nQNM\u2019s in the time domain.\n\nThe ringdown phase of a binary inspiral occurs after\nthe highly nonlinear merger, and is when the final object\nis considered to be in a perturbed final state, shedding\nits deformity through QNM\u2019s. These QNM\u2019s must be\ndefined with a starting time, as they feature exponential\ngrowth in one direction (for Boltzmann echoes this is into\nthe past) and must be truncated to prevent runaway ef-\nfects. For ringdown QNM\u2019s there exists a natural starting\ntime which is the start of the ringdown. For echoes, only\nthe initial pulse preserves the QNM structure of the GR\nsignal, since the QNM spectrum is different for echoes,\nand it may be possible that each mode of the echo QNM\u2019s\n\nWith \u03d5r\n\nWithout \u03d5r\n\n0.9 1.0 1.1 1.2 1.3 1.4\n\n-0.2\n\n-0.1\n\n0.0\n\n0.1\n\n0.2\n\nt [s]\n\nh(\nt)\n\nFIG. 9. Blue: The real part of the second echo after ringdown\nfrom the model without phase information included. Orange:\nThe same but with phase included. The observed shift of\nthe waveform is approximately one sixth of the wavelength\nfor this particular echo and background with a = 0.7 and\nx0 = \u2212450. More pronounced displacements are accessible\nwith other parameters.\n\nis created at a different time dependent on the geometry\nof the cavity and the initial perturbation.\n\nThis is plausible as the phase \u03c6r of each resonance\ncauses each mode to shift in the time domain, displacing\nthe echoes. Decomposing the phase for all resonances\nas the frequency-dependent function \u03c6(\u03c9) \u2261 \u03c9g(\u03c9), this\ntime shift is equal to \u2212g(\u03c9). From this decomposition,\nand by converting to SI units for comparison with obser-\nvational data, we plot a sample of the time shifting in\nFig.9.\n\nFor observational considerations, it is also important to\nnote that the measured phase is affected by the detector\norientation. The full waveform h = h+ + ih\u00d7 is not fully\ndetectable by a single L-shaped detector which can only\nmeasure one orthogonal projection of this. A detector\nmay observe instead hproj = c+h+ + ic\u00d7h\u00d7 where 0 \u2264\n|c\u00b1| \u2264 1 depend on the detector orientation relative to\nthe source.\n\nAccounting for all of this, we present our model in\nthe time domain in Fig.10. Here both the GR and echo\ncomponents are reproduced by our full model, with the\nGR waveform set to fairly closely match that observed\nin GW190521, which is a sample event of special interest\nfor which we perform a data analysis in this paper.\n\nD. Accuracy\n\nWe have now developed numerically efficient surrogate\nfunctions for each of the Boltzmann parameters. These\nmethods are applicable for other models as well with dif-\nferent values for the c coefficients. To test the accuracy of\nour surrogate model, we measure the difference between\nthe surrogate model and the full numerical solution with-\nout approximation in two ways. First, the location of the\n\n\n\n11\n\nGR\n\nEchoes\n\n-1 0 1 2 3 4 5\n\n-1000\n\n-500\n\n0\n\n500\n\n1000\n\nt - t 0 [s]\n\nR\ne[\nS\ntr\nai\nn]\n\nFIG. 10. The full waveform in time reproduced by our\nmodel. Blue: The GR inspiral-merger-ringdown set to fairly\nclosely match that observed in GW190521. Red: The echoes\ngenerated by taking this GR signal as the source. The GR\ncomponent was initially generated as a numerical relativity\nsurrogate model through the PyCBC waveform library. The\nparameters used to generate this are consistent with the LIGO\nmedian values and uncertainty intervals.\n\nresonances being the most sensitive parameter, we com-\npare the modelled separation function to the data over a\nwide range of background parameters. Second, we test\nthe overall accuracy of the model including all param-\neters by comparing the final modelled spectrum to the\ndata for the expected physical background values.\n\nTo quantify the accuracy of the separation function\nfor different spins and cavity sizes, we calculate the full\nspectra over extreme ranges of a and x0. For a the range\nincludes the values observed by LIGO, and for x0 we use\na very extreme range that includes Planckian deviations.\nFor x0 in particular, the actual priors are much narrower\nthan what we present here, a choice we made to be as\ngeneral as possible for different models that depart from\nPlanckian deviation. We then use the ranges of these pa-\nrameters to generate benchmark functions f1, f2, and f3\nand compare these to the surrogate model evaluated at\nthe same values, where the initial surrogate coefficients\nfor the spin comparison were derived using the extremal\nspin value of a = 0.6 and for the cavity size comparison\nusing the extremal value of x0 = \u2212150. The actual sur-\nrogate model used in the data search is developed from\nthe more physical a = 0.7 and x0 = \u2212450, but we test\nthe extremal values here to be conservative and consider\nedge cases. Fig.11 plots the percentage difference be-\ntween each evaluation of the surrogate function and the\n\u201cdata\u201d for the spin comparison. For example, to obtain\nthe blue curve f1 \u2212 f3, the surrogate model is gener-\nated from the data at a = 0.6 then rescaled to a = 0.8\nand compared to the data at that point. Performing the\nsame actions across cavity sizes yields Fig.12. From these\nevaluations, the separation function proves accurate up\nto differences of between approximately 0.2-1.5%. Practi-\ncally, for a data search this error margin is much smaller\nsince the expectation for the cavity size is set for each\n\nf1-f2\n\nf1-f3\n\nf2-f3\n\n0.36 0.38 0.40 0.42 0.44 0.46\n\n-0.2\n\n0.0\n\n0.2\n\n0.4\n\n\u03c9M\n\n%\ndi\nff\ner\nen\nce\n\nFIG. 11. Evaluating the effectiveness of the surrogate model\nover changes of spin. Here the surrogate model is generated\ndirectly from the data at a = 0.6 and x0 = \u2212450 to give f1,\nthen for a = 0.7 and a = 0.8 to give f2 and f3, respectively.\nThe colours here represent the percentage difference between\nthe surrogate models from the directly generated fits for each\nspin value and the rescaled evaluations at the respective val-\nues. The parameter and frequency ranges represented here\nare conservative, extending through the LIGO 90% credibil-\nity ranges.\n\nf1-f2\n\nf1-f3\n\nf2-f3\n\n0.36 0.38 0.40 0.42 0.44 0.46\n\n0.0\n\n0.5\n\n1.0\n\n1.5\n\n\u03c9M\n\n%\ndi\nff\ner\nen\nce\n\nFIG. 12. Evaluating the model over changes in cavity size x0.\nAll data points here have a = 0.7, and x0 goes from -150 to\n-450 to -900 for f1, f2, and f3, respectively. The range here\nis very conservative to test against edge cases for models that\nseverely depart from Planckian deviation. Our preference for\nthe data search is to focus on physically motivated Planckian\ndeviations, where the accuracy of the surrogate model is good\nto within about 0.2% or better.\n\nvalue of M and a to the approximately Planckian value\nand the spin is most likely closer to the best fit value\nrather than the extremes that we test.\n\nCombining all parameters, along with a final division\nof the width (and corresponding amplitude) by two for\nbetter agreement with the data, we plot the final form for\nour \u03b1 = 1 Boltzmann surrogate model using a numerical\nrelativity motivated source in Fig.13, along with the data,\nat the LIGO-measured median background values.\n\n\n\n12\n\nData\n\nModel\n\n0.36 0.38 0.40 0.42 0.44 0.46\n\n0\n\n100\n\n200\n\n300\n\n400\n\n\u03c9M\n\n|h\uf02d\n(\u03c9\n)|\n\nFIG. 13. Blue: The absolute value of the full surrogate model\nspectrum for Boltzmann echoes with a = 0.7 and x0 = \u2212450.\nOrange: The \u201cdata\u201d for the same background parameters,\ncorresponding to the full numerical solution without the sur-\nrogate approximations.\n\nE. Sourcing\n\nIn the absence of fully nonlinear numerical GR sim-\nulations for the binary merger of ECO\u2019s, much study\nhas been devoted to echoes sourced by simple analyti-\ncal forms, such as Gaussians and delta functions. Sig-\nnificant progress was made in [10] where the connec-\ntion between physical initial conditions in the Teukol-\nsky framework and the source integral in the Sasaki-\nNakamura formalism was established with applications\nfor echoes, along with the connection to angular modes\nvia the spin-weighted spheroidal harmonic distribution.\nIn [11], further progress was made in demonstrating that\na random distribution of Gaussians superimposed to cre-\nate a somewhat amorphous initial perturbation could still\nlead to distinct resonances, albeit with expected distor-\ntion. However, these works did not yet clarify what the\nphysical source distribution should be, but rather what\nit would be under certain reasonable conditions. This\ntask of physically motivating a source was partially ac-\ncomplished for a static background in [7] which used a\ntoy model simulation of a point particle falling into a\nstatic background along an \u201cISCO\u201d orbit, and collected\nthe source information numerically. This provides a help-\nful comparison to other work as this more physical source\nwas largely fit by a Gaussian, but with higher order struc-\nture and width and location defined by the toy model\ninspiral. Developing this to a more relevant scenario, [8]\nupgraded the toy model to include spin. The results were\nqualitatively similar, and affirmed progress made in ear-\nlier work.\n\nIn this paper, we gratefully make use of the surrogate\nmodel GR waveforms freely available through PyCBC\n[12]. Since our surrogate model is developed through\ninterpolation between nine sets of background parame-\nters, for each combination of (a, x0) values with x0 \u2208\n{\u2212150,\u2212450,\u2212900} and a \u2208 {0.6, 0.7, 0.8}, we required\n\nm\u03a9h Re[\u03c9n=0 ]\n\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8\n0.01\n\n0.10\n\n1\n\n10\n\n100\n\n1000\n\n104\n\n\u03c9M\n\n|h\n|\n\nFIG. 14. The PyCBC surrogate model from the SEOB-\nNRv4 opt approximant with mass1 = 40.0, mass2 = 40.0,\nspin1z = 0.09, and spin2 = 0, sampled at 4096Hz with\ndistance = 1280Mpc. With these parameters, and by the\nSEOBNRv4 approximant, the final remnant is calculated to\nhave a = 0.7 and M = 76. The mass and distance scales of the\nsurrogate models are irrelevant for model building and data\nanalysis since we construct the model with the dimensionless\nquantity \u03c9M and the normalization of the model cancels out\nin the data search.\n\nthe use of one surrogate waveform for each spin (GR sur-\nrogate models are independent of x0). Using the SEOB-\nNRv4 approximant, we took binary merger parameters\nof mass1 = 42.1, mass2 = 32.7, and spins = 0 to obtain\na = 0.6; mass1 = 40.0, mass2 = 40.0, and spin1z = 0.09\nto obtain a = 0.7; and mass1 = 40.0, mass2 = 40.0,\nspin1z = 0.7, and spin2z = 0.075 to obtain a = 0.8. For\nthe model-building and analysis, we converted to dimen-\nsionless frequencies \u03c9M so that our results are indepen-\ndent of the mass scale and the total masses for each of the\nsurrogate models is arbitrary. Because the normalization\nof the model cancels in the data search, the distance,\nwhich we chose to be 1280Mpc, is also arbitrary. The\nmost important features of these waveforms in frequency\nspace, see Fig.14, are the elbow near the fundamental\nQNM frequency at \u03c9f \u2248 1.5251\u2212 1.1568(1\u2212 a)0.1292 [6]\nand the adjacent plateau at lower frequencies, since the\nBoltzmann reflection exponentially suppresses the spec-\ntrum away from the superradiance frequency. To get the\nfrequency domain waveform we apply a Tukey window\nwith \u03b1 = 1/8 (not to be comfused with the Boltzmann\ntemperature variable of the same name) in the time do-\nmain and Fourier transform.\n\nThe first equation of this paper references what we call\nthe source function S. To ensure that our results repro-\nduce the standard GR waveform when the background\nobject is a standard black hole with no exotic boundary\ncondition, S must be divided by the initial pulse term\nfrom the transfer function. Specifically, we must define\n\nS = \u2212c0\n4\n\nh(\u03c9)\n\nTBH(\u03c9)\ne\u2212i\u03c9x0 , (35)\n\nwhere h is the GR waveform. We plot this S in Fig.15.\n\n\n\n13\n\nm\u03a9h Re[\u03c9n=0 ]\n\n0.2 0.3 0.4 0.5 0.6\n0\n\n5000\n\n10000\n\n15000\n\n20000\n\n25000\n\n30000\n\n35000\n\n\u03c9M\n\n|S\n|\n\nFIG. 15. The absolute value of the source function S which\nreproduces the standard GR waveform when R = 0, obtained\nthrough a PyCBC surrogate model. Because of the necessary\ndivision by the initial pulse factor from the transfer function\nK, |S| grows very large at low frequencies, and is singular\nat the superradiance frequency. See Fig.29 for the transmis-\nsion coefficient from the transfer function which serves as the\ndivisor.\n\nIt is important to note that for Boltzmann echoes, this\nform of the source function is accurate because there is\nexponential suppression around the horizon frequency.\nHowever, for models with boundary conditions that have\nless suppression at lower frequencies, an inconsistency\narises. The inspiral and merger components of the GR\nwaveform are too large to be included in the linear per-\nturbation theory discussed in this paper, thus necessitat-\ning either a modified source function or some bandpass\nthat removes the inspiral and merger frequencies. To use\nthe same motivation for the source function as presented\nhere, the echo analyst may therefore need to consider an\nadditional truncation.\n\nIV. GW190521\n\nThe highest network SNR gravitational wave event\nyet detected by LIGO and Virgo is the binary neutron\nstar merger GW170817, with an observable signal last-\ning approximately 100s for an SNR of about 33.0. The\nnext loudest are the far more massive binary black hole\nmerger events GW150914 and GW190521 074359 with\nnetwork SNR\u2019s of about 24.4 each. While these events\nmay be promising for the detection of echoes, as has been\nsuggested by some searches [2], we select another event\nwith less network SNR (14.4) but significant ringdown,\nGW190521, not to be mistaken with the previously men-\ntioned GW190521 074359 occuring about five hours later\n[15].\n\nGW190521 is unique in several ways. It is by far the\nmost massive event yet recorded, leading to a median\nmeasurement of the final mass of 142M\ufffd. The observ-\nable signal is also relatively very short lived, lasting only\nabout 0.1s and seen in the frequency range 30-80Hz with\n\npeak amplitude at 60Hz. Notably, this peak frequency is\nthe same as the U.S. mains power signature, hence the\nimportance of noise subtraction and independent detec-\ntor correlation. The primary reason why we are inter-\nested in this event is that it may be especially significant\nfor echoes since it generates a relatively large SNR in a\nshort duration of time, suggesting strong ringdown, and\nit is the ringdown portion of the waveform that sources\nthe echoes.\n\nIn this section we discuss our processing methods for\nthe LIGO data, the application of our model in the search\nmethod, and our characterization of the signal that we\nsee along with a statistical analysis of the results. In\nsummary, we find a signal with moderate statistical sig-\nnificance, and we interpret this as a measurement of the\nenergy found in the echoes by relating the observation to\nsimulated injections on background data sets.\n\nA. Processing the Data\n\nLIGO data is affected by instrumental and environ-\nmental noise, and techniques have been developed for\nquantifying this and cleaning the data. A key quantity\nhere is the power spectral density (PSD), defined as fol-\nlows. To calculate the PSD by Welch\u2019s method, first\ndivide a relatively large data set surrounding the region\nof interest into a number of segments of duration T , then\nsmoothly window each segment. This windowing is done\nto prevent spectral artifacts that would otherwise result\nfrom the sharp truncation (square windowing) of each\ndata segment. Then Fourier transform each segment,\ntake the square magnitude at each frequency, and av-\nerage the results to obtain the PSD. Here the important\nfactors are the time T , the windowing method, and the\ntotal duration of the data from which all segments are\ntaken. T sets the frequency resolution and determines\nthe number of segments that will be averaged, thereby\nsetting the noise reduction at each frequency. We use\nTukey windows that are tapered cosines at the edges with\nflat tops. These are equivalent to Hann windows when\nthe plateau region is set to have 0 width. We choose the\nplateau region to cover half of each segment, where each\nsegment is 4s long, consistent with LIGO recommenda-\ntions. We also select a 1/8 overlap between segments.\nWe use 1024s of data centered around the main event.\n\nThis PSD is then used in the process of whitening the\ndata by interpolating between the points of the PSD and\ndividing the spectrum of the desired data by this quan-\ntity. These interpolated PSD\u2019s for the Hanford and Liv-\ningston detectors are shown across the relevant frequency\nband in Fig.16. In addition to dividing out noise by the\nPSD, a bandpass is also imposed to cut out very low\nfrequencies (below about \u223c 20Hz) that are known to be\ndominated by noise and approaching the uncalibrated re-\ngion. Higher frequencies are also cut to avoid Nyquist\nsampling ambiguity and to filter out noise beyond the\nregion of interest. We choose a somewhat tight bandpass\n\n\n\n14\n\nLivingston\n\nHanford\n\n30 40 50 60 70 80 90 100\n1.\u00d7 10-47\n\n5.\u00d7 10-47\n\n1.\u00d7 10-46\n\n5.\u00d7 10-46\n\n1.\u00d7 10-45\n\nf [Hz]\n\nP\nS\nD\n\nFIG. 16. The power spectral densities (PSD\u2019s) computed by\nWelch\u2019s method across the frequency band relevant for echoes\nfrom GW190521. The peak at 60Hz in both detectors is at the\nfrequency of the U.S. mains power signature. The amplitude\nspectral density (ASD) is the square root of the PSD.\n\nof 30-100Hz as this satisfies noise cancellation require-\nments while preserving the echo signal with some buffer\nto account for errors in final remnant parameter esti-\nmates by LIGO, namely the mass M = 142+28\n\n\u221216 and spin\n\na = 0.72+0.09\n\u22120.12, where the errors correspond to the 90%\n\ncredible intervals that include statistical errors [15]. To\naccomplish this, we use the recommended Butterworth\nfilter which has a steeper cutoff at lower frequencies and\nsofter taper at higher frequencies, with a flat plateau in\nbetween.\n\nAfter whitening and bandpassing, the inverse Fourier\ntransform is taken to put the data back into the time\ndomain. At this stage a Tukey window is placed over the\ndesired data segment and the data is ready for analysis.\nWe use the same shape of Tukey window as previously\ndescribed, but to search for echoes we choose T = 15s to\nincrease the resolution and enhance the sharp resonances.\nFor the best fit parameters, this corresponds to about 14\nechoes after redshifting the signal to the detector frame.\nWhen we need to refer to a specific value of redshift,\nsuch as when approximating the number of echoes within\nT = 15s just now, we assume the median fit redshift of\nZ = 0.82.\n\nAt last, since the Boltzmann model is developed in\nFourier space, we Fourier transform the data and directly\ncompare it to the echo spectrum. Doing this consistently\nrequires that the model itself undergoes parallel processes\nof whitening and bandpassing. Since our model is scal-\nable and tested through ranges of spin from 0.6 to 0.8,\nand mass simply changes the frequency scale, we write\nour model as a function of spin and mass and calculate\nthe overlap between the data and the model for each. To\nget our model as a function of just the background pa-\nrameters of a and M , we do a dimensional reduction by\nassuming x0 = \u2212450, corresponding to nearly Planckian\ndeviations. For exactly Planckian deviations, x0 depends\non the spin and logarithmically on the mass of the back-\nground (see Equation 28), and we rely on the degeneracy\n\n42 44 46 48 50 52 54\n\nf [Hz]\n\nD\nat\na-\nL\n\nD\nat\na-\nH\n\nM\nod\nel\n-\nL\n\nM\nod\nel\n-\nH\n\nFIG. 17. The standard Boltzmann model with \u03b1 = 1 at the\nfinal remnant parameters M and a that gives the maximum\nSNR, plotted alongside the data, for each of the two LIGO\ndetectors (H = Hanford and L = Livingston). Here T = 15s,\nand the frequency range is symmetric about the superradiance\nfrequency. For visualization, the absolute value is taken for\neach set of data. Each curve in this figure is whitened and\nbandpassed consistent with LIGO recommendations.\n\nthat arises between the fixed cavity size model at differ-\nent spin and mass values and the exactly Planckian cav-\nity size model to accurately capture the echo waveform.\nThis degeneracy occurs since a determines the location\n(or shift) of the resonances and M determines the scal-\ning of frequencies. Example plots of the model overlaid\nwith the data for each detector are shown in Fig.17 and\nFig.18.\n\nB. Analysis\n\nWith the data cleaned and the parametrized surrogate\nmodel ready for application, we begin to look for echoes\nby calculating the combined signal-to-noise ratio (SNR)\nfor the Boltzmann model in the two LIGO detectors as\n\nSNR =\n1\u221a\n2Nf\n\n|\u03a3fdH,fm\u2217H,f |+ |\u03a3fdL,fm\u2217L,f |\u221a\n\u03a3f (mH,fm\u2217H,f +mL,fm\u2217L,f )\n\n, (36)\n\nwhere Nf is the length of the data sets dH,L and mH,L.\nHere, we have maximized SNR over an arbitrary phase\ndifference between the Hanford and Livingston detectors.\nWe limit the frequency range to a symmetric interval\nabout the superradiance frequency with a half width of\n7Hz, since beyond this the auxiliary resonances become\nless significant. The superradiance frequency is a func-\n\n\n\n15\n\n42 44 46 48 50 52 54\n\nf [Hz]\n\nD\nat\na-\nL\n\nD\nat\na-\nH\n\nM\nod\nel\n-\nL\n\nM\nod\nel\n-\nH\n\nFIG. 18. The Boltzmann model with \u03b1 = 2 at the final\nremnant parameters M and a that gives the maximum SNR,\nplotted alongside the data, for each of the two LIGO detectors\n(H = Hanford and L = Livingston). Here T = 15s, and\nthe frequency range is symmetric about the superradiance\nfrequency. For visualization, the absolute value is taken for\neach set of data. Each curve in this figure is whitened and\nbandpassed consistent with LIGO recommendations.\n\ntion of spin, mass, and redshift, so the location of this in-\nterval depends on the assumed parameters for each calcu-\nlation. This calculation is performed over mass and spin\nvalues derived from Monte Carlo chains that account for\nthe probability of each set of parameters being realized\nin the data.\n\nUsing this SNR equation as a search tool, our method\nis as follows.\n\nFirst, we search the data immediately after the event,\nwhere echoes would exist, and tabulate a set of SNRs for\neach set of (M,a) (see Fig.19 and Fig.20). In doing so,\nwe find a high SNR signal at a mass and spin well within\nthe 90% credibility ranges for the background parameters\nquoted by LIGO.\n\nSecond, we compare this signal to 100 sets of noise\nbackgrounds where it is known that no echoes exist, and\nfind that the observed maximum SNR can be seen in\n2/100 backgrounds, leading to a statistical significance\nof detection of about 2.3\u03c3 (Fig.21). We repeat the same\nbackground comparison for the \u03b1 = 2 Boltzmann model,\nwith 263 background searches and show the results in\nFig.22.\n\nThird, we characterize signal detection by injecting\nnoise into 263 backgrounds with a different amplitude\nfor each background. Since energy is the integral of\n\u03c92|f(\u03c9)|2, we relate the amplitude of these injections to\nthe energy of the injected echoes. Because the SNR2\n\nFIG. 19. SNR as a function of spin for a data search with over\n105 samples. Each value of spin is paired with a redshifted\nmass value. The maximum value here is approximately 12.\nThis search was done using the standard Boltzmann model\nwith a 15s time segment starting at a GPS time of 0s com-\npared to the LIGO event time. Because of the time-domain\nwindowing, the GR event is effectively deleted from the data\nand does not interfere with these results. The grey line in the\nbackground marks the best fit spin.\n\nFIG. 20. The SNR for the same data search as in Fig.19, but\nordered as a function of the redshifted mass. Several peaks\nare observed at somewhat even intervals. The grey line in the\nbackground marks the best fit mass.\n\ntends to increase linearly with the square of the injection\namplitude, we are then able to plot the energy of echoes\nas a function of SNR2 (Fig.23). The variation of the noise\nnaturally present in the 263 unique background data sets\nprovides error margins in the linear fit. Through this pro-\ncess, we find the most likely SNR for a given data set,\nand with the assumption that the signal data set features\ntypical noise, we measure the energy of the echoes as the\nvalue of the linear regression at the measured SNR (see\nFig.24).\n\nFinally, we make a couple moves away from our main\nanalysis to test the robustness of the signal against vari-\nations in the model and search method. We find that a\n\n\n\n16\n\n1\n\n25\n\n46\n\n21\n\n5\n\n1 1\n\nN = 100\n\n6 7 8 9 10 11 12 13\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nS/N\n\nFIG. 21. A histogram of the maximum SNR found within\neach background data set for the standard \u03b1 = 1 Boltzmann\nmodel, showing a strong bias towards SNRs between 8 and\n9, with a quick falloff towards higher values. This suggests a\nmost probable measurement of SNR for a random background\nof between 8 and 9. The measured signal SNR is just under\n12, so this plot suggests a p-value of about 1 in 50.\n\n1\n\n34\n\n13\n1\n\n64\n\n24\n\n5 1\n\nN = 263\n\n6 7 8 9 10 11 12 13\n0\n\n20\n\n40\n\n60\n\n80\n\n100\n\n120\n\n140\n\nS/N\n\nFIG. 22. A histogram of the maximum SNR found within\neach background data set for the \u03b1 = 2 Boltzmann model.\nThe measured signal SNR is again just under 12, leading to an\nestimated p-value of about 1 in 263. However, three anoma-\nlous points with SNR > 12, that we interpret as due to noise,\nwere removed from the dataset.\n\nsignal is preserved through changing the data length from\nT = 15s to T = 120s and the Boltzmann parameter from\n\u03b1 = 1 to \u03b1 = 2 (see Fig.25, Fig.26, and Fig.27). These\nare not fine-tuned parameters, but rather motivated by\nthe long-time searches found in the literature [13, 14].\n\nV. CONCLUSIONS\n\nWe have presented a physically motivated surrogate\nmodel for Boltzmann echoes and deployed this in a data\nsearch. The Boltzmann model is suggested by poten-\n\n100 150 200\n0.0\n\n0.5\n\n1.0\n\n1.5\n\nSNR2\n\nE\nne\nrg\ny\n\nFIG. 23. To calibrate the variation due to noise present in the\nlinear model for energy as a function of maximum SNR, here\nwe perform 263 injections in 263 sets of background data with\na different energy injection for every background for \u03b1 = 1\nBoltzmann echoes. The injections are ordered, starting at\nthe first background with 0 energy and increasing in energy\nwith each background up to an injection amplitude equal to\n1.28\u03c3, where here \u03c3 is calculated from the amplitudes of the\nLivingston data. The black line marks the linear model fit,\nwith the vertical grey dashed line marking the value of the\nsquared SNR seen in the echo data search and the horizontal\nline marking the corresponding measurement of the energy.\nThe shaded regions mark the 1, 2, and 3\u03c3 deviations away\nfrom the linear model. In this way, the echo data search and\nmeasured maximum SNR value can be seen as a measurement\nof echo energy at a value of \u223c 0.9+0.8\n\n\u22120.8, where the errors mark\nthe 99.7% credibility region. Note: For the calculation of\nthe linear model, three deviant points at high energy and\nhigh SNR were removed to improve the fit. Scaled by the GR\nevent energy, this gives EEchoes/EGR = 8.9\u00b14.5%, where the\nuncertainty range represents the 90% credible region. When\nrepeating the same analysis for \u03b1 = 2 Boltzmann echoes, we\nfind the same value for the energy ratio, but with \u00b18.1%\nuncertainty.\n\ntial quantum effects taking over within a Planck dis-\ntance from the horizon radius, and we include this as\nour exotic echo-producing boundary condition. We rep-\nresented the Boltzmann model as a sum over quasinormal\nmodes parametrized by the location, amplitude, width,\nand phase of the resonances. We carefully examined\neach of these parameters and found numerically efficient\nand accurate representations for them through which we\ndeveloped a computationally cheap surrogate model for\nBoltzmann echoes. For the separation function in par-\nticular, which is the function that determines the spac-\ning of the characteristic echo resonances, we quantified a\nquartic order departure from the often-assumed constant\n1/td spacing with magnitude variation up to the order of\nseveral percent. To source our echoes, we use a numer-\nical relativity surrogate model for the inspiral-merger-\nringdown of a binary black hole system. This allows\nus to reproduce the observed waveform for GW190521,\nan event of particular interest for echo research due to\nits loud ringdown, as well as to determine the echoes\n\n\n\n17\n\nData\n\nInjection\n\nData + Injection\n\n48 50 52 54 56 58 60\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n2500\n\n3000\n\n3500\n\nf[Hz]\n\nh\uf02d (\nf)\n\nFIG. 24. From the calculated function for echo energy as\na function of SNR, we can determine an approximate am-\nplitude for the echoes required to obtain the measured SNR\nmaximum of just under 12 in the data search. Shown here is\nthe absolute value of the echo spectrum superimposed with\nthe absolute value of the data before and after injection, for\nthe Livingston detector. This plot assumes the most probable\nnoise distribution where the maximum SNR prior to injection\nis 8.5.\n\nFIG. 25. Testing the robustness of the signal found in the\nstandard Boltzmann echo data search, we also perform the\nsame search but using the long time segment of 120s, showing\nthat a distinct signal is maintained.\n\nthat would be generated from this waveform. Finally,\nwith the surrogate model in hand, we prepare the data\nsurrounding GW190521 for analysis and perform a data\nsearch where we calculate the signal-to-noise ratio (SNR)\nover a range of Monto Carlo sets of mass and spin val-\nues distributed according to the most probable range of\nbackground values as measured by the LIGO and Virgo\nobservatories. We find an SNR peak with moderate sig-\nnificance, and interpret this as a measurement of echo\nenergy by relating the observed signal to simulated sig-\nnals coming from injections into backgrounds. With this\nnew tool at hand, we anticipate the future work of apply-\ning this physically motivated surrogate model, along with\nvariations accounting for uncertainties in the physics, to\n\nModel\n\nLivingston\n\nHanford\n\n42 44 46 48 50 52 54\n0\n\n2000\n\n4000\n\n6000\n\n8000\n\n10000\n\nf [Hz]\n\nh\uf02d (f\n)\n\nFIG. 26. The Boltzmann echoes primarily discussed in this\npaper assume standard reflectivity with \u03b1 = 1 [4], however\nthis parameter has some flexibility, and here we test the value\nof \u03b1 = 2, which reduces the exponential suppression of the\nreflectivity by dividing the exponent by 2, and is the limiting\nvalue that preserves stability. We also maintain the long-\nduration time segment of 120s. Compared to the standard\nshorter-time Boltzmann search, this result features a wider\nrange of sharper resonances.\n\nFIG. 27. Lastly, we repeat the original data search but with\nthe 120s segment and the Botlzmann model constructed with\n\u03b1 = 2. Once again a signal is seen, and the noise is further\nsuppressed away from the peak.\n\nadditional gravitational events to further quantify the\nsignificance of echoes, and what they may imply for the\nquantum nature of black holes.\n\nACKNOWLEDGMENTS\n\nWe thank Jahed Abedi for providing the Monte Carlo\nparameter chains used in the data search, Luis Longo for\nthe inspiralling particle source function used in the origi-\nnal analysis, and Naritaka Oshita for helpful suggestions\nregarding the width parameter. We also thank all the\nmembers of our weekly group meetings for their support-\nive discussion and continual patience through our many\n\n\n\n18\n\nconversations. We also thank Bob Holdom for invaluable\ndiscussion and advice. NA is supported by the Univer-\nsity of Waterloo, Natural Sciences and Engineering Re-\nsearch Council of Canada (NSERC) and the Perimeter\nInstitute for Theoretical Physics. Research at Perime-\nter Institute is supported in part by the Government of\nCanada through the Department of Innovation, Science\nand Economic Development Canada and by the Province\nof Ontario through the Ministry of Colleges and Uni-\nversities. This research has made use of data, software\nand/or web tools obtained from the GW Open Science\nCenter (https://www.gw-openscience.org), a service of\nLIGO Laboratory, the LIGO Scientific Collaboration and\nthe Virgo Collaboration. LIGO is funded by the U.S. Na-\ntional Science Foundation. Virgo is funded by the French\nCentre National de Recherche Scientifique (CNRS), the\nItalian Instituto Nazionale della Fisica Nucleare (INFN)\nand the Dutch Nikhef, with contributions by Polish and\nHungarian institutes.\n\nAppendix A: Model Parameters and Calibration\n\n1. Surrogate Coefficients\n\nHere we include some explicit valuations of the surro-\ngate model parameters, with units suppressed for sim-\nplicity. The surrogate model can be constructed for any\nset of background parameters studied in this paper, and\nhere we choose the representative values of a = 0.7 (im-\nplying k = \u03c9\u22120.408) and x0 = \u2212450 (implying td = 900).\nOther values may be calculated by the same methods.\n\n\u2206lr =\n1\n\ntd\n\n(\n6.33\u2212 117\n\nk\n\ntd\n\u2212 3.36 \u2217 106\n\nk2\n\nt2d\n\n\u22122.62 \u2217 1010\nk3\n\nt3d\n\u2212 7.24 \u2217 1013\n\nk4\n\nt4d\n\n)\n.\n\n(A1)\n\nar =\n450\n\ntd\n(2.68 \u2217 10\u22122R(|k|)\u2212 5.59 \u2217 10\u22125 \u2212 2.30 \u2217 10\u22122k\n\n\u2212 4.03 \u2217 10\u22122k2 + 0.510k3 + 1.46k4).\n\n(A2)\n\nwr =\n1\n\ntd\n(1.52 \u2217 10\u22122 + 6.64|k|+ 10.2k2 + 30.4k3). (A3)\n\n2. Conversions and RBH, TBH\n\nSeveral conversion factors required to transform be-\ntween the homogenous asymptotic spectral amplitudes\nfor the Teukolsky and the Sasaki-Nakamura formalisms\nare well known as formulas, and in Fig.28 we plot them\nfor convenience.\n\nThe transmission and reflection coefficients TBH and\nRBH, respectively, are frequently occurring in echo stud-\nies. This is especially true since they are independent of\n\n|C-1 |\n\n|c0\n-1 |\n\n|b0\n-1 |\n\n0.2 0.4 0.6 0.8 1.0 1.2\n0.0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n\u03c9M\n\nFIG. 28. Conversion factors present in the transforma-\ntions between the strain, Teukolsky, and Sasaki-Nakamura\nbases. Neglecting normalization factors, the outgoing Teukol-\nsky amplitude at infinity, Z, is related to the strain h by\nZ \u223c \u03c92he\u2212i\u03c9xobs , where xobs is the observation point. To\nget the observed strain from the outgoing Sasaki-Nakamura\namplitude at infinity, X, the conversion is h \u223c \u2212 4\n\nc0\nXei\u03c9xobs .\n\nOther amplitude and energy conversion factors and their uses\nare defined in [13].\n\n|RBH |\n\n|TBH |\n\n0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\n0.0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1.0\n\n\u03c9M\n\nFIG. 29. In red and blue, the absolute value of the transmis-\nsion and reflection coefficients TBH(\u03c9) and RBH(\u03c9), respec-\ntively. The black dashed lines on the left and the right are\nthe superradiance and fundamental QNM frequencies, respec-\ntively. The transmission function goes to zero and the reflec-\ntion function goes to unity at the superradiance frequency.\n\nthe boundary condition and are always present in some\nway in the transfer function. We plot them here in Fig.29.\nA couple key points should be mentioned here. First, the\nsum in quadrature of the absolute values of these is ap-\nproximately unity everywhere. Second, the transmission\ncoefficient goes to zero at the superradiance frequency -\nhence the spike in the source function at this frequency\nthat reproduces the GR event (see Fig.15) - and remains\nvery low below this frequency. With these features in\nmind, it is possible to gain some intuition behind the ge-\n\n\n\n19\n\nometric optics approximation for Boltzmann echoes be- tween the Boltzmann boundary condition and the angu-\nlar momentum barrier as a high pass filter.\n\n[1] V. Cardoso, S. Hopper, C. F. B. Macedo, C. Palenzuela,\nand P. Pani; Gravitational-wave signatures of exotic com-\npact objects and of quantum corrections at the horizon\nscale. Phys. Rev. D 94, 084031. 21 October 2016.\n\n[2] J. Abedi, N. Afshordi, N. Oshita, and Q. Wang; Quantum\nBlack Holes in the Sky. Universe, Volume 6, Number 3:43.\n10 March 2020.\n\n[3] P. O. Mazur and Emil Mottola; Gravitational Conden-\nsate Stars: An Alternative to Black Holes. arXiv:gr-\nqc/0109035v5 (gr-qc). 27 February 2002.\n\n[4] Q. Wang, N. Oshita, and N. Afshordi; Echoes from quan-\ntum black holes. Phys. Rev. D 101, 024031. 10 January\n2020.\n\n[5] R. Brito, V. Cardoso, and P. Pani; Superradiance.\narXiv:1501.06570v8 (gr-qc). 8 January 2021.\n\n[6] E. Berti, V. Cardoso, and A. O. Starinets; Quasinormal\nmodes of black holes and black branes. arXiv:0905.2975v2.\n29 July 2009.\n\n[7] Z. Mark, A. Zimmerman, S. M. Du, and Y. Chen; A\nrecipe for echoes from exotic compact objects. Phys. Rev.\nD 96, 084002. 3 October 2017.\n\n[8] L. F. L. Micchi and C. Chirenti; Spicing up the recipe for\nechoes from exotic compact objects: Orbital differences\nand corrections in rotating backgrounds. Phys. Rev. D\n101, 084010. 3 April 2020.\n\n[9] S. Xin, B. Chen, R. K. L. Lo, L. Sun, W. Han, X.\nZhong, M. Srivastava, S. Ma, Q. Wang, and Y. Chen;\nGravitational-wave echoes from spinning exotic compact\nobjects: numerical waveforms from the Teukolsky equa-\ntion. arXiv:2105.12313 (gr-qc). 26 May 2021.\n\n[10] R. S. Conklin; Gravitational wave perturbations on a\nKerr background and applications for echoes. Phys. Rev.\nD 101, 044045. 21 February 2020.\n\n[11] R. S. Conklin and B. Holdom; Gravitational wave echo\nspectra. Phys. Rev. D 100, 124030. 11 December 2019.\n\n[12] PyCBC. https://github.com/gwastro/pycbc\n[13] R. S. Conklin, B. Holdom, and J. Ren; Gravitational wave\n\nechoes through new windows. Phys. Rev. D 98, 044021.\n14 August 2018.\n\n[14] B. Holdom; Not quite black holes at LIGO. Phys. Rev. D\n101, 064063. 26 March 2020.\n\n[15] R. Abbott et al ; GW190521: A Binary Black Hole\nMerger with a Total Mass of 150 M\ufffd. Phys. Rev. Letters\n125, 101102. 23 October 2020.\n\n[16] S. A. Teukolsky; Perturbations of a Rotating Black Hole.\n1. Fundamental Equations for Gravitational, Electromag-\nnetic, and Neutrino-Field Perturbations. Astrophysical\nJournal, Volume 185, Number 2. 15 October 1973.\n\n[17] M. Sasaki and T. Nakamura; Gravitational Radiation\nfrom a Kerr Black Hole. I. Formulation and a Method\nfor Numerical Analysis. Progress of Theoretical Physics,\nVolume 67, Issue 6. 01 June 1982.\n\n[18] E. Berti and V. Cardoso; Quasinormal ringing of\nKerr black holes: The excitation factors. arXiv:gr-\nqc/0605118v2 (gr-qc). 10 November 2006.\n\n[19] Black Hole Perturbation Toolkit. http://bhptoolkit.org/\n[20] N. Oshita, D. Tsuna, and N. Afshordi; Quantum black\n\nhole seismology. I. Echoes, ergospheres, and spectra.\nPhys. Rev. D 102, 024045. 15 July 2020.\n\n[21] N. Oshita, D. Tsuna, and N. Afshordi; Quantum black\nhole seismology. II. Applications to astrophysical black\nholes. Phys. Rev. D 102, 024046. 15 July 2020.\n\n[22] M. Sasaki and H. Tagoshi; Analytic black hole per-\nturbation approach to gravitational radiation. arXiv:gr-\nqc/0306120 (gr-qc). 27 June 2003.\n\n[23] L. F. L. Micchi, N. Afshordi, and C. Chirenti; How loud\nare echoes from exotic compact objects?. Phys. Rev. D\n103, 044028. 15 February 2021.\n\n[24] J. Abedi and N. Afshordi; Echoes from the abyss: a highly\nspinning black hole remnant for the binary neutron star\nmerger GW170817. Journal of Cosmology and Astropar-\nticle Physics, Volume 103. 13 November 2019.\n\n\n\tBoltzmann Meets Lorentz: A Surrogate Model for Black Hole Echoes\n\tAbstract\n\tI Introduction\n\tII Setup\n\tA Teukolsky and Strain\n\tB Homogeneous Solutions and the Sasaki-Nakamura Formalism\n\n\tIII The Model\n\tA Location lr\n\tB Amplitude ar and Width wr\n\tC Phase r\n\tD Accuracy\n\tE Sourcing\n\n\tIV GW190521\n\tA Processing the Data\n\tB Analysis\n\n\tV Conclusions\n\t Acknowledgments\n\tA Model Parameters and Calibration\n\t1 Surrogate Coefficients\n\t2 Conversions and RBH, TBH\n\n\t References\n\n\n"}
